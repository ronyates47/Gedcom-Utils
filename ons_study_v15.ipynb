{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronyates47/Gedcom-Utils/blob/main/ons_study_v15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [CELL 1] Setup + Global Variables (V8 Baseline + Bio Proof Nav)\n",
        "import os, sys, re, csv, json, html, socket, pytz\n",
        "import pandas as pd\n",
        "from ftplib import FTP_TLS\n",
        "from datetime import datetime\n",
        "\n",
        "try:\n",
        "    import tqdm\n",
        "except ImportError:\n",
        "    os.system('pip install tqdm')\n",
        "    import tqdm\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"      [CELL 1] SETUP LOADED (V8 Baseline - Clean Nav)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "TNG_BASE_URL = \"https://yates.one-name.net/tng/verticalchart.php?personID=\"\n",
        "TNG_SUFFIX = \"&tree=tree1&parentset=0&display=vertical&generations=15\"\n",
        "\n",
        "# Orange background removed from Brick Wall Buster link\n",
        "NAV_HTML = r\"\"\"<style>nav.oldnav ul{display:flex;flex-wrap:wrap;justify-content:center;background-color:#006064!important;border-bottom:2px solid #00acc1!important;margin:0;padding:0;list-style:none} nav.oldnav li{display:inline-block} nav.oldnav a{display:block;padding:10px 15px;text-decoration:none;color:#e0f7fa!important;font-size:14px} nav.oldnav a:hover{background-color:#00838f!important} @media print { nav.oldnav, #nav-slot, .no-print, .action-btn, .control-panel, .tabs { display: none !important; } }</style><nav class=\"oldnav\"><ul><li><a href=\"/ons-study/research_admin.html\" style=\"color:#ffcc80 !important; font-weight:bold;\">Admin Hub</a></li><li><a href=\"/ons-study/contents.shtml\" style=\"color:#ffcc80 !important; font-weight:bold;\">Guide</a></li><li><a href=\"/ons-study/yates_ancestor_register.shtml\">DNA Register</a></li><li><a href=\"/ons-study/just-trees.shtml\">Trees</a></li><li><a href=\"/ons-study/dna_network.shtml\">DNA Network</a></li><li><a href=\"/ons-study/lineage_proof.html\">Lineage Proof</a></li><li><a href=\"/ons-study/biological_proof.html\" style=\"color:#fff !important; font-weight:bold;\">Biological Proof</a></li><li><a href=\"/ons-study/dna_dossier.html\">Forensic Dossier</a></li><li><a href=\"/ons-study/brick_wall_buster.shtml\">Brick Wall Buster</a></li><li><a href=\"/ons-study/data_glossary.shtml\">Data Glossary</a></li><li><a href=\"https://yates.one-name.net/gengen/images/cousin-calculator.jpg\" target=\"_blank\" style=\"color:#b2dfdb;\">Cousin Calc</a></li><li><a href=\"https://yates.one-name.net/gengen/images/Shared_cM_Project_v4.jpg\" target=\"_blank\" style=\"color:#b2dfdb;\">cM Chart</a></li><li><a href=\"/ons-study/share_dna.shtml\" style=\"background-color:#0277bd; font-weight:bold;\">Share DNA</a></li><li><a href=\"/ons-study/subscribe.shtml\" style=\"background-color:#004d40;\">Subscribe</a></li></ul></nav>\"\"\"\n",
        "\n",
        "SITE_INFO = r\"\"\"<div class=\"no-print\" style=\"background:#e0f2f1;border:1px solid #b2dfdb;padding:20px;margin:20px auto;width:90%;border-radius:8px;font-family:sans-serif;\"><h3 style=\"color:#006064;margin-top:0;border-bottom:2px solid #004d40;padding-bottom:10px;\">Establishing Kinship Through Collateral DNA Saturation</h3><p style=\"color:#333;line-height:1.6;font-size:1.05em;margin-bottom:0;\"><strong>Methodology:</strong> This register moves beyond the reliance on single \"golden matches\" to prove kinship. Instead, it employs <em>Collateral DNA Saturation</em>‚Äîa method that blends genealogical reasoning with data-driven logic.</p></div>\"\"\"\n",
        "\n",
        "JS_CORE = r\"\"\"<script type=\"text/javascript\">(function(){ function textOf(c){var val = c.getAttribute('data-sort') || c.textContent || c.innerText;return (val || '').replace(/\\s+/g,' ').trim().toLowerCase();} function sortTable(t,i,d){if(!(t&&t.tBodies&&t.tBodies[0]))return;var tb=t.tBodies[0],r=Array.prototype.slice.call(tb.rows||[]),asc=(d==='asc');r.sort(function(a,b){var A=textOf(a.cells[i]),B=textOf(b.cells[i]),nA=parseFloat(A.replace(/[^0-9.\\-]/g,'')),nB=parseFloat(B.replace(/[^0-9.\\-]/g,''));if(!isNaN(nA)&&!isNaN(nB))return asc?(nA-nB):(nB-nA);return(A<B)?(asc?-1:1):(A>B)?(asc?1:-1):0;});var f=document.createDocumentFragment();for(var k=0;k<r.length;k++)f.appendChild(r[k]);tb.appendChild(f);} function makeSortable(t){if(!(t&&t.tHead&&t.tHead.rows.length))return;var th=t.tHead.rows[0].cells;for(var i=0;i<th.length;i++){(function(idx){var h=th[idx],d='asc';h.style.cursor='pointer';h.onclick=function(){d=(d==='asc')?'desc':'asc';for(var j=0;j<th.length;j++)th[j].innerHTML=th[j].innerHTML.replace(/\\s+\\(asc\\)|\\s+\\(desc\\)/,'');h.innerHTML+=(d==='asc'?' (asc)':' (desc)');sortTable(t,idx,d);};})(i);}} window.filterTable = function() { var input = document.getElementById(\"tableSearch\"); var filter = input.value.toUpperCase(); var table = document.getElementById(\"reg-table\") || document.querySelector(\"table.dataframe\"); var tr = table.getElementsByTagName(\"tr\"); for (var i = 1; i < tr.length; i++) { var tdArr = tr[i].getElementsByTagName(\"td\"); var found = false; for (var j = 0; j < tdArr.length; j++) { if (tdArr[j]) { var txtValue = tdArr[j].textContent || tdArr[j].innerText; if (txtValue.toUpperCase().indexOf(filter) > -1) { found = true; break; } } } tr[i].style.display = found ? \"\" : \"none\"; } } function init(){ var t=document.getElementsByTagName('table'); for(var i=0;i<t.length;i++) if(/\\bsortable\\b/.test(t[i].className)) makeSortable(t[i]); } if(document.readyState==='loading')document.addEventListener('DOMContentLoaded',init,false);else init(); })();</script>\"\"\"\n",
        "\n",
        "# --- EXACT V8 MAKE_PAGE SIGNATURE RESTORED ---\n",
        "def make_page(title, content, count, view_type=\"\", extra=\"\", stats_bar=\"\"):\n",
        "    nav_blk = \"\"\n",
        "    if view_type in ['ancestor', 'participant', 'tree_az', 'tree_za', 'proof', 'hot_paths', 'network', 'dossier', 'subscribe', 'share', 'buster', 'singleton']:\n",
        "        nav_blk = SITE_INFO\n",
        "    if view_type == 'subscribe' or view_type == 'theory' or view_type == 'share' or view_type == 'glossary':\n",
        "        nav_blk = \"\"\n",
        "\n",
        "    toggle = \"\"\n",
        "    print_btn = \"\"\n",
        "    search_bar = \"\"\n",
        "\n",
        "    if view_type in ['ancestor', 'participant', 'singleton']:\n",
        "        search_bar = \"\"\"<div class=\"no-print\" style=\"margin:20px auto;max-width:600px;text-align:center;\"><input type=\"text\" id=\"tableSearch\" onkeyup=\"filterTable()\" placeholder=\"üîç Type a name to filter list...\" style=\"width:100%;padding:12px;font-size:16px;border:2px solid #006064;border-radius:4px;\"></div>\"\"\"\n",
        "\n",
        "    if view_type in ['ancestor', 'participant', 'singleton']:\n",
        "        view_name = \"Register\"\n",
        "        if view_type == 'singleton': view_name = \"Singleton List\"\n",
        "        print_btn = f\"\"\"<div class=\"no-print\" style=\"text-align:center;margin-bottom:15px;\"><button onclick=\"window.print()\" style=\"background:#0277bd;color:white;border:none;padding:10px 20px;border-radius:4px;font-weight:bold;cursor:pointer;font-size:14px;\">üñ®Ô∏è Print {view_name}</button></div>\"\"\"\n",
        "\n",
        "    if view_type == 'ancestor':\n",
        "        toggle = f\"\"\"<div class=\"no-print\" style=\"text-align:center;padding:10px;margin-bottom:10px;font-family:sans-serif;font-size:14px;background:#e0f7fa;border:1px solid #b2ebf2;\"><strong>Sort Register:</strong> &nbsp;<span style=\"font-weight:bold;color:#006064;\">By Ancestral Line</span> &nbsp;|&nbsp; <a href=\"ons_yates_dna_register_participants.shtml\" style=\"color:#00acc1;text-decoration:none;\">By Participant Name</a></div>\"\"\"\n",
        "    elif view_type == 'participant':\n",
        "        toggle = f\"\"\"<div class=\"no-print\" style=\"text-align:center;padding:10px;margin-bottom:10px;font-family:sans-serif;font-size:14px;background:#e0f7fa;border:1px solid #b2ebf2;\"><strong>Sort Register:</strong> &nbsp;<a href=\"ons_yates_dna_register.shtml\" style=\"color:#00acc1;text-decoration:none;\">By Ancestral Line</a> &nbsp;|&nbsp; <span style=\"font-weight:bold;color:#006064;\">By Participant Name</span></div>\"\"\"\n",
        "    elif 'tree' in view_type:\n",
        "        za = f'<span style=\"font-weight:bold;color:#000;\">Z-A</span>' if 'za' in view_type else f'<a href=\"just-trees.shtml\" style=\"color:#006064;text-decoration:underline;\">Z-A</a>'\n",
        "        az = f'<span style=\"font-weight:bold;color:#000;\">A-Z</span>' if 'az' in view_type else f'<a href=\"just-trees-az.shtml\" style=\"color:#006064;text-decoration:underline;\">A-Z</a>'\n",
        "        toggle = f\"\"\"<div class=\"no-print\" style=\"text-align:center;font-family:sans-serif;font-size:16px;margin:15px 0 10px 0;\">Individual Yates Family trees: &nbsp; {za} &nbsp;|&nbsp; {az}</div>\"\"\"\n",
        "\n",
        "    return f\"\"\"<!DOCTYPE html><html lang=\"en\"><head><meta charset=\"UTF-8\"><title>{title}</title><link rel=\"stylesheet\" href=\"partials_unified.css\"><link rel=\"stylesheet\" href=\"dna_tree_styles.css\">{extra}</head><body id=\"top\"><div class=\"wrap\"><h1 class=\"centerline\">{title}</h1><div id=\"nav-slot\">{stats_bar}{NAV_HTML}</div>{nav_blk}{search_bar}{print_btn}{toggle}{content}</div>{JS_CORE}</body></html>\"\"\"\n",
        "\n",
        "print(\"‚úÖ Cell 1 Loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV42lLHRnfJe",
        "outputId": "a4760f0c-eceb-4b81-df09-7af7b1d09094"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "      [CELL 1] SETUP LOADED (V8 Baseline - Clean Nav)\n",
            "============================================================\n",
            "‚úÖ Cell 1 Loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [CELL 3] The Data Engine (V123 - Deep Ancestry Radar)\n",
        "def run_engine():\n",
        "    print(\"=\"*60)\n",
        "    print(\"      [CELL 3] ENGINE STARTING (V123 - DEEP RADAR)...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    import os, sys, re, csv\n",
        "    from ftplib import FTP_TLS\n",
        "    from google.colab import userdata\n",
        "    from datetime import datetime\n",
        "\n",
        "    CSV_DB = \"engine_database.csv\"\n",
        "    if os.path.exists(CSV_DB): os.remove(CSV_DB)\n",
        "\n",
        "    try:\n",
        "        HOST = os.environ.get(\"FTP_HOST\") or userdata.get(\"FTP_HOST\")\n",
        "        USER = os.environ.get(\"FTP_USER\") or userdata.get(\"FTP_USER\")\n",
        "        PASS = os.environ.get(\"FTP_PASS\") or userdata.get(\"FTP_PASS\")\n",
        "    except: pass\n",
        "    REMOTE_SUBDIR = \"ons-study\"\n",
        "    KEY_FILE = \"match_to_unmasked.csv\"\n",
        "    PROCESSED_GED = \"_processed_unmasked.ged\"\n",
        "\n",
        "    def clean_and_standardize(raw_name):\n",
        "        if not raw_name: return \"findme\"\n",
        "        s = raw_name.replace(\"/\", \"\").strip()\n",
        "        triggers = [\"unknown\", \"missing\", \"searching\", \"still searching\", \"living\", \"private\", \"nee\", \"nee ?\", \"wife\", \"mrs\"]\n",
        "        if s.lower() in triggers or s == \"\": return \"findme\"\n",
        "        if \"?\" in s: return \"findme\"\n",
        "        if \"unknown\" in s.lower(): return \"findme\"\n",
        "        return s\n",
        "\n",
        "    def get_surname(full_name):\n",
        "        if not full_name or \"findme\" in full_name.lower(): return \"\"\n",
        "        clean = re.sub(r'\\b(jr\\.?|sr\\.?|iii|iv|esq\\.?|m\\.d\\.?|ph\\.d\\.?)\\b', '', full_name, flags=re.IGNORECASE)\n",
        "        parts = clean.replace(',', '').split()\n",
        "        return parts[-1] if parts else \"\"\n",
        "\n",
        "    def make_directory_label(name, dates):\n",
        "        if \"findme\" in name.lower(): return name\n",
        "        sur = get_surname(name)\n",
        "        if not sur: return name\n",
        "        firsts = re.sub(f\"{re.escape(sur)}$\", \"\", name).strip()\n",
        "        return f\"{sur}, {firsts} {dates}\"\n",
        "\n",
        "    print(\"\\n[STEP 1] Resolving Files (Local Priority)...\")\n",
        "    if os.path.exists(KEY_FILE):\n",
        "        print(f\"    ‚úÖ Found {KEY_FILE} locally. Skipping FTP download.\")\n",
        "    else:\n",
        "        print(f\"    üåê {KEY_FILE} not found locally. Attempting FTP fetch...\")\n",
        "        try:\n",
        "            ftps = FTP_TLS()\n",
        "            ftps.connect(HOST, 21); ftps.auth(); ftps.login(USER, PASS); ftps.prot_p()\n",
        "            try:\n",
        "                with open(KEY_FILE, \"wb\") as f: ftps.retrbinary(f\"RETR /{REMOTE_SUBDIR}/{KEY_FILE}\", f.write)\n",
        "                print(f\"    ‚úÖ Successfully downloaded {KEY_FILE}.\")\n",
        "            except Exception as e:\n",
        "                print(f\"    ‚ö†Ô∏è FTP download failed: {e}\")\n",
        "            ftps.quit()\n",
        "        except Exception as e:\n",
        "            print(f\"    ‚ö†Ô∏è FTP connection failed: {e}\")\n",
        "\n",
        "    all_files = os.listdir('.')\n",
        "    ged_files = [f for f in all_files if f.lower().endswith('.ged') and \"_processed\" not in f.lower()]\n",
        "    if not ged_files: return print(\"‚ùå No GEDCOM found. Please upload one.\")\n",
        "    ged_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)\n",
        "    DEFAULT_GEDCOM = ged_files[0]\n",
        "    print(f\"    üëâ Source GEDCOM: {DEFAULT_GEDCOM}\")\n",
        "\n",
        "    def resolve_code(payload):\n",
        "        m = re.search(r'(\\d+)\\s*&?\\s*([^ \\t\\n\\r\\f\\v]+)', payload)\n",
        "        return m.group(2).lower() if m else None\n",
        "\n",
        "    print(\"\\n[STEP 2] Loading Tester Authority CSV...\")\n",
        "    csv_auth = {}\n",
        "    if os.path.exists(KEY_FILE):\n",
        "        with open(KEY_FILE, 'r', errors='replace') as f:\n",
        "            reader = csv.reader(f)\n",
        "            for i, row in enumerate(reader):\n",
        "                if len(row) >= 2:\n",
        "                    if i == 0 and (\"tester\" in row[0].lower() or \"masked\" in row[0].lower() or \"code\" in row[0].lower()):\n",
        "                        continue\n",
        "                    code = row[0].strip().lower()\n",
        "                    name = row[1].strip()\n",
        "                    tid = row[2].strip() if len(row) > 2 else \"\"\n",
        "                    if tid: tid = \"I\" + re.sub(r'[^0-9]', '', tid)\n",
        "                    csv_auth[code] = {\"name\": name, \"id\": tid}\n",
        "\n",
        "    print(\"\\n[STEP 3] Parsing GEDCOM for Study| Tags & Lineages...\")\n",
        "    import shutil\n",
        "    shutil.copyfile(DEFAULT_GEDCOM, PROCESSED_GED)\n",
        "\n",
        "    individuals = {}; families = {}; study_testers = {}\n",
        "\n",
        "    def is_yates(name_str):\n",
        "        n = (name_str or \"\").lower()\n",
        "        return \"yates\" in n or \"yeates\" in n or \"yate\" in n\n",
        "\n",
        "    current_id = None; current_fam = None; current_tag = None\n",
        "    with open(PROCESSED_GED, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip(); parts = line.split(\" \", 2)\n",
        "            if len(parts) < 2: continue\n",
        "            lvl, tag, val = parts[0], parts[1], parts[2] if len(parts)>2 else \"\"\n",
        "\n",
        "            if lvl == \"0\" and \"INDI\" in val:\n",
        "                current_id = tag.replace(\"@\", \"\")\n",
        "                individuals[current_id] = {\"name\": \"findme\", \"famc\": None, \"fams\": [], \"match_code\": \"\", \"cm\": 0, \"birt\": \"\", \"deat\": \"\"}\n",
        "                current_fam = None; current_tag = \"INDI\"\n",
        "            elif current_id and lvl != \"0\":\n",
        "                if tag == \"NAME\" and lvl == \"1\":\n",
        "                    individuals[current_id][\"name\"] = clean_and_standardize(val)\n",
        "                elif tag == \"FAMC\" and lvl == \"1\":\n",
        "                    individuals[current_id][\"famc\"] = val.replace(\"@\", \"\")\n",
        "                elif tag == \"FAMS\" and lvl == \"1\":\n",
        "                    individuals[current_id][\"fams\"].append(val.replace(\"@\", \"\"))\n",
        "\n",
        "                elif tag == \"NICK\" and lvl == \"2\" and \"Study|\" in val:\n",
        "                    tester_code = val.split(\"Study|\")[-1].strip().lower()\n",
        "                    study_testers[tester_code] = {\"id\": current_id, \"name\": individuals[current_id][\"name\"]}\n",
        "\n",
        "                elif tag == \"NPFX\" and lvl == \"2\":\n",
        "                    code = resolve_code(val)\n",
        "                    if code: individuals[current_id][\"match_code\"] = code.lower()\n",
        "                    m = re.search(r'^(\\d+)|(\\d+)\\s*cM', val, re.IGNORECASE)\n",
        "                    if m: individuals[current_id][\"cm\"] = int(m.group(1) or m.group(2))\n",
        "\n",
        "                elif tag == \"BIRT\": current_tag = \"BIRT\"\n",
        "                elif tag == \"DEAT\": current_tag = \"DEAT\"\n",
        "                elif tag == \"DATE\" and current_tag:\n",
        "                    m = re.search(r'\\d{4}', val)\n",
        "                    if m: individuals[current_id][current_tag.lower()] = m.group(0)\n",
        "                    current_tag = None\n",
        "\n",
        "            if lvl == \"0\" and \"FAM\" in val:\n",
        "                current_fam = tag.replace(\"@\", \"\")\n",
        "                families[current_fam] = {\"husb\": None, \"wife\": None}\n",
        "                current_id = None\n",
        "            elif current_fam and lvl != \"0\":\n",
        "                if tag == \"HUSB\": families[current_fam][\"husb\"] = val.replace(\"@\", \"\")\n",
        "                elif tag == \"WIFE\": families[current_fam][\"wife\"] = val.replace(\"@\", \"\")\n",
        "\n",
        "    def get_parents(pid):\n",
        "        if not pid or pid not in individuals: return None, None\n",
        "        famc = individuals[pid][\"famc\"]\n",
        "        if not famc or famc not in families: return None, None\n",
        "        return families[famc][\"husb\"], families[famc][\"wife\"]\n",
        "\n",
        "    def get_mother_surname(pid):\n",
        "        if not pid: return \"\"\n",
        "        _, mom_id = get_parents(pid)\n",
        "        if mom_id and mom_id in individuals: return get_surname(individuals[mom_id][\"name\"])\n",
        "        return \"\"\n",
        "\n",
        "    def to_spanish_name(pid, current_name):\n",
        "        if \"findme\" in current_name.lower(): return current_name\n",
        "        mom_surname = get_mother_surname(pid)\n",
        "        if not mom_surname or \"findme\" in mom_surname.lower(): return current_name\n",
        "        if mom_surname.lower() not in current_name.lower(): return f\"{current_name}-{mom_surname}\"\n",
        "        return current_name\n",
        "\n",
        "    # üåü NEW: THE DEEP ANCESTRY RADAR\n",
        "    # This recursively checks if a specific person has ANY Yates in their documented ancestry\n",
        "    yates_memo = {}\n",
        "    def has_yates_ancestry(pid):\n",
        "        if not pid or pid not in individuals: return False\n",
        "        if pid in yates_memo: return yates_memo[pid]\n",
        "\n",
        "        # Base case: Is this person a Yates?\n",
        "        if is_yates(individuals[pid].get(\"name\", \"\")):\n",
        "            yates_memo[pid] = True\n",
        "            return True\n",
        "\n",
        "        # Recursive case: Check their parents\n",
        "        dad_id, mom_id = get_parents(pid)\n",
        "        res = has_yates_ancestry(dad_id) or has_yates_ancestry(mom_id)\n",
        "        yates_memo[pid] = res\n",
        "        return res\n",
        "\n",
        "    def climb_full_line(start_id):\n",
        "        curr = start_id; lineage_data = []\n",
        "        while curr:\n",
        "            p = individuals.get(curr)\n",
        "            if not p: break\n",
        "            spanish_name = to_spanish_name(curr, p[\"name\"])\n",
        "            spouse_name = \"findme\"; spouse_id = None\n",
        "            if p[\"fams\"]:\n",
        "                fid = p[\"fams\"][0]\n",
        "                if fid in families:\n",
        "                    f = families[fid]\n",
        "                    sid = f[\"wife\"] if f[\"husb\"] == curr else f[\"husb\"]\n",
        "                    if sid and sid in individuals:\n",
        "                        spouse_name = individuals[sid][\"name\"]; spouse_id = sid\n",
        "            spouse_spanish = to_spanish_name(spouse_id, spouse_name) if spouse_id else spouse_name\n",
        "            lineage_data.append({\"name\": spanish_name, \"raw_name\": p[\"name\"], \"id\": curr, \"spouse\": spouse_spanish, \"spouse_raw\": spouse_name, \"spouse_id\": spouse_id})\n",
        "\n",
        "            dad_id, mom_id = get_parents(curr)\n",
        "            if not dad_id and not mom_id: break\n",
        "\n",
        "            # üåü USE THE RADAR TO STEER THE CLIMB\n",
        "            dad_has_yates = has_yates_ancestry(dad_id)\n",
        "            mom_has_yates = has_yates_ancestry(mom_id)\n",
        "\n",
        "            if dad_has_yates and not mom_has_yates: curr = dad_id\n",
        "            elif mom_has_yates and not dad_has_yates: curr = mom_id\n",
        "            else: curr = dad_id if dad_id else mom_id\n",
        "\n",
        "        return lineage_data\n",
        "\n",
        "    def format_dates(uid):\n",
        "        if not uid or uid not in individuals: return \"findme\"\n",
        "        b = individuals[uid][\"birt\"] or \"findme\"\n",
        "        d = individuals[uid][\"deat\"] or \"findme\"\n",
        "        b = re.sub(r'\\?', 'findme', b); d = re.sub(r'\\?', 'findme', d)\n",
        "        if b == \"findme\" and d == \"findme\": return \"findme\"\n",
        "        return f\"({b} - {d})\"\n",
        "\n",
        "    testers = {}\n",
        "    for code, data in csv_auth.items():\n",
        "        testers[code] = {\"name\": data[\"name\"], \"id\": data[\"id\"]}\n",
        "\n",
        "    for code, data in study_testers.items():\n",
        "        if code not in testers:\n",
        "            testers[code] = {\"name\": data[\"name\"], \"id\": data[\"id\"]}\n",
        "        elif not testers[code][\"id\"]:\n",
        "            testers[code][\"id\"] = data[\"id\"]\n",
        "\n",
        "    for kcode, tdata in testers.items():\n",
        "        t_lin = \"\"; t_pids = \"\"\n",
        "        if tdata[\"id\"] and tdata[\"id\"] in individuals:\n",
        "            lin_data = climb_full_line(tdata[\"id\"])\n",
        "            if lin_data:\n",
        "                full = list(reversed(lin_data))\n",
        "                t_lin = \" -> \".join([x[\"name\"] for x in full])\n",
        "                t_pids = \",\".join([x[\"id\"] for x in full])\n",
        "        tdata[\"lineage_str\"] = t_lin\n",
        "        tdata[\"path_ids\"] = t_pids\n",
        "\n",
        "    print(\"\\n[STEP 4] Constructing Database...\")\n",
        "    rows = []\n",
        "    for uid, p in individuals.items():\n",
        "        if p[\"match_code\"]: # It's a found match!\n",
        "            kit_code = p[\"match_code\"]\n",
        "\n",
        "            if kit_code in testers:\n",
        "                t_name = testers[kit_code][\"name\"]\n",
        "                t_id = testers[kit_code][\"id\"]\n",
        "                t_lin = testers[kit_code][\"lineage_str\"]\n",
        "                t_pids = testers[kit_code][\"path_ids\"]\n",
        "                tester_display = f\"{t_name} [{t_id}]\" if t_id else f\"{t_name} [{kit_code}]\"\n",
        "            else:\n",
        "                t_name = kit_code\n",
        "                t_id = \"\"\n",
        "                t_lin = \"\"\n",
        "                t_pids = \"\"\n",
        "                tester_display = f\"{kit_code} [{kit_code}]\"\n",
        "\n",
        "            lineage_data = climb_full_line(uid)\n",
        "            if not lineage_data: continue\n",
        "\n",
        "            full_line = list(reversed(lineage_data))\n",
        "            gen1 = full_line[0]\n",
        "\n",
        "            top_name = gen1[\"raw_name\"]\n",
        "            top_dates = format_dates(gen1[\"id\"])\n",
        "            spouse_name = gen1[\"spouse_raw\"]\n",
        "            spouse_id = gen1[\"spouse_id\"]\n",
        "            spouse_dates = format_dates(spouse_id)\n",
        "\n",
        "            if spouse_name != \"findme\":\n",
        "                husb_sur = get_surname(top_name); wife_sur = get_surname(spouse_name)\n",
        "                if husb_sur.lower() == wife_sur.lower(): spouse_name += f\" (n√©e {wife_sur})\"\n",
        "\n",
        "            pair_dated = f\"{top_name} {top_dates}\"\n",
        "            if spouse_name != \"findme\": dir_label = make_directory_label(top_name, top_dates) + f\" & {spouse_name}\"\n",
        "            else: dir_label = make_directory_label(top_name, top_dates)\n",
        "\n",
        "            if spouse_name != \"findme\": pair_dated += f\" & {spouse_name} {spouse_dates}\"\n",
        "            pair_simple = f\"{top_name} & {spouse_name}\" if spouse_name != \"findme\" else top_name\n",
        "\n",
        "            clean_top = re.sub(r'[^a-zA-Z0-9]', '', top_name)\n",
        "            clean_sp = re.sub(r'[^a-zA-Z0-9]', '', spouse_name.split('(')[0]) if spouse_name != \"findme\" else \"ZZZ\"\n",
        "            sort_key = f\"{clean_top}_{clean_sp}\"\n",
        "\n",
        "            path_names = []\n",
        "            for i, x in enumerate(full_line):\n",
        "                if i == 0: path_names.append(pair_dated)\n",
        "                else: path_names.append(x[\"name\"])\n",
        "\n",
        "            lineage_str = \" -> \".join(path_names)\n",
        "            path_ids = \",\".join([x[\"id\"] for x in full_line])\n",
        "\n",
        "            _, fa1_mom_id = get_parents(gen1[\"id\"])\n",
        "            fa1_mother = to_spanish_name(fa1_mom_id, individuals[fa1_mom_id][\"name\"]) if fa1_mom_id else \"findme\"\n",
        "\n",
        "            fa2_mother = \"findme\"\n",
        "            if spouse_id:\n",
        "                _, fa2_mom_id = get_parents(spouse_id)\n",
        "                if fa2_mom_id: fa2_mother = to_spanish_name(fa2_mom_id, individuals[fa2_mom_id][\"name\"])\n",
        "\n",
        "            rows.append({\n",
        "                \"Tester_Code\": kit_code,\n",
        "                \"Tester_Name\": t_name,\n",
        "                \"Tester_ID\": t_id,\n",
        "                \"Tester_Display\": tester_display,\n",
        "                \"Tester_Lineage\": t_lin,\n",
        "                \"Tester_Path_IDs\": t_pids,\n",
        "                \"Match_Name\": p[\"name\"],\n",
        "                \"Match_ID\": uid,\n",
        "                \"cM\": p[\"cm\"],\n",
        "                \"Match_Lineage\": lineage_str,\n",
        "                \"Match_Path_IDs\": path_ids,\n",
        "                \"Authority_Directory_Label\": dir_label,\n",
        "                \"Authority_FirstAncestor\": pair_simple,\n",
        "                \"Authority_FirstAncestor_alpha\": sort_key,\n",
        "                \"Authority_FirstAncestor_dated\": pair_dated,\n",
        "                \"fa_1 extracted\": top_name, \"fa_1_Dates\": top_dates, \"fa_1_Mother\": fa1_mother,\n",
        "                \"fa_2 extracted\": spouse_name, \"fa_2 Dates\": spouse_dates, \"fa_2_Mother\": fa2_mother,\n",
        "                \"Gen_Count\": len(full_line)\n",
        "            })\n",
        "\n",
        "    rows.sort(key=lambda r: r[\"Authority_Directory_Label\"])\n",
        "\n",
        "    fieldnames = [\n",
        "        \"Tester_Code\", \"Tester_Name\", \"Tester_ID\", \"Tester_Display\",\n",
        "        \"Tester_Lineage\", \"Tester_Path_IDs\",\n",
        "        \"Match_Name\", \"Match_ID\", \"cM\", \"Match_Lineage\", \"Match_Path_IDs\",\n",
        "        \"Authority_Directory_Label\", \"Authority_FirstAncestor\", \"Authority_FirstAncestor_alpha\", \"Authority_FirstAncestor_dated\",\n",
        "        \"fa_1 extracted\", \"fa_1_Dates\", \"fa_1_Mother\",\n",
        "        \"fa_2 extracted\", \"fa_2 Dates\", \"fa_2_Mother\",\n",
        "        \"Gen_Count\"\n",
        "    ]\n",
        "\n",
        "    with open(CSV_DB, \"w\", encoding=\"iso-8859-15\", newline=\"\", errors=\"replace\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n",
        "        writer.writeheader(); writer.writerows(rows)\n",
        "\n",
        "    print(f\"\\n[SUCCESS] Engine V123 Complete. Saved {len(rows)} verified matches to {CSV_DB}.\")\n",
        "\n",
        "print(\"‚úÖ Cell 3 (Engine V123 - Deep Ancestry Radar) Loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqsLTwKqBEIl",
        "outputId": "4916763f-0691-4df2-ad43-9dbea5a75041"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Cell 3 (Engine V123 - Deep Ancestry Radar) Loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [CELL 4] The Template Library (V31: Checkbox UI & Inferred Ancestors)\n",
        "print(\"=\"*60)\n",
        "print(\"      [CELL 4] TEMPLATE LIBRARY LOADING...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "NAV_HTML = r\"\"\"<style>nav.oldnav ul{display:flex;flex-wrap:wrap;justify-content:center;background-color:#006064!important;border-bottom:2px solid #00acc1!important;margin:0;padding:0;list-style:none} nav.oldnav li{display:inline-block} nav.oldnav a{display:block;padding:10px 15px;text-decoration:none;color:#e0f7fa!important;font-size:14px} nav.oldnav a:hover{background-color:#00838f!important} @media print { nav.oldnav, #nav-slot, .no-print { display: none !important; } }</style><nav class=\"oldnav\"><ul><li><a href=\"/ons-study/research_admin.html\" style=\"color:#ffcc80 !important; font-weight:bold;\">Admin Hub</a></li><li><a href=\"/ons-study/contents.shtml\" style=\"color:#ffcc80 !important; font-weight:bold;\">Guide</a></li><li><a href=\"/ons-study/yates_ancestor_register.shtml\">DNA Register</a></li><li><a href=\"/ons-study/just-trees.shtml\">Trees</a></li><li><a href=\"/ons-study/dna_network.shtml\">DNA Network</a></li><li><a href=\"/ons-study/lineage_proof.html\">Lineage Proof</a></li><li><a href=\"/ons-study/biological_proof.html\">Biological Proof</a></li><li><a href=\"/ons-study/proof_consolidator.html\" style=\"background-color:#4a148c; color:#fff !important; font-weight:bold; border-left:1px solid #7c43bd; border-right:1px solid #7c43bd;\">Proof Consolidator</a></li><li><a href=\"/ons-study/dna_dossier.html\">Forensic Dossier</a></li><li><a href=\"/ons-study/brick_wall_buster.shtml\">Brick Wall Buster</a></li><li><a href=\"/ons-study/data_glossary.shtml\">Data Glossary</a></li><li><a href=\"https://yates.one-name.net/gengen/images/cousin-calculator.jpg\" target=\"_blank\" style=\"color:#b2dfdb;\">Cousin Calc</a></li><li><a href=\"/ons-study/share_dna.shtml\" style=\"background-color:#0277bd; font-weight:bold;\">Share DNA</a></li><li><a href=\"/ons-study/subscribe.shtml\" style=\"background-color:#004d40; font-weight:bold;\">Subscribe</a></li></ul></nav>\"\"\"\n",
        "SITE_INFO = r\"\"\"<div class=\"no-print\" style=\"background:#e0f2f1;border:1px solid #b2dfdb;padding:20px;margin:20px auto;width:90%;border-radius:8px;font-family:sans-serif;\"><h3 style=\"color:#006064;margin-top:0;border-bottom:2px solid #004d40;padding-bottom:10px;\">Establishing Kinship Through Collateral DNA Saturation</h3><p style=\"color:#333;line-height:1.6;margin-bottom:0;\">This register employs <em>Collateral DNA Saturation</em>‚Äîa method blending genealogical reasoning with data-driven logic to prove connections using multiple independent DNA cousins.</p></div>\"\"\"\n",
        "CSS_BASE = r\"\"\"body{font-family:'Segoe UI',sans-serif;background:#f0f2f5;padding:20px;display:flex;flex-direction:column;min-height:100vh;margin:0;} .wrap{flex:1;} .proof-card{background:white;max-width:1100px;margin:20px auto;border-radius:8px;box-shadow:0 4px 15px rgba(0,0,0,0.1);padding:40px} .badge{padding:5px 10px;border-radius:4px;font-weight:bold;font-size:0.85em;text-transform:uppercase;border:1px solid #ccc;} .badge-platinum{background:#eceff1;color:#263238} .badge-gold{background:#fff8e1;color:#f57f17} .badge-silver{background:#f5f5f5;color:#616161} .badge-bronze{background:#efebe9;color:#5d4037} .badge-descendant{background:#e3f2fd;color:#0d47a1} .badge-terminal{background:#fff;color:#000;border-color:#000;font-style:italic;} table{width:100%;border-collapse:collapse;margin-top:15px;margin-bottom:40px;font-family:'Georgia',serif;font-size:15px;} th{background:#eceff1;color:#263238;padding:12px;text-align:left;border-bottom:2px solid #000;} td{padding:12px;border-bottom:1px solid #ddd;vertical-align:top;} @media print{ .no-print{display:none !important;} .only-print{display:block !important;} .proof-card{box-shadow:none;border:none;padding:0;margin:0;} body{background:white;padding:0;display:block;} th{background:#f0f0f0 !important;color:#000 !important;} .badge{border:1px solid #000;color:#000;background:transparent !important;} .legal-footer{background:transparent !important; border-top:2px solid #000 !important; color:#000 !important; page-break-inside:avoid !important; padding:10px 0 !important; margin-top:30px !important;} } .only-print{display:none;}\"\"\"\n",
        "JS_CORE = r\"\"\"<script type=\"text/javascript\">(function(){ function textOf(c){var val = c.getAttribute('data-sort') || c.textContent || c.innerText;return (val || '').replace(/ +/g,' ').trim().toLowerCase();} function sortTable(t,i,d){if(!(t&&t.tBodies&&t.tBodies[0]))return;var tb=t.tBodies[0],r=Array.prototype.slice.call(tb.rows||[]),asc=(d==='asc');r.sort(function(a,b){var A=textOf(a.cells[i]),B=textOf(b.cells[i]),nA=parseFloat(A.replace(/[^0-9.-]/g,'')),nB=parseFloat(B.replace(/[^0-9.-]/g,''));if(!isNaN(nA)&&!isNaN(nB))return asc?(nA-nB):(nB-nA);return(A<B)?(asc?-1:1):(A>B)?(asc?1:-1):0;});var f=document.createDocumentFragment();for(var k=0;k<r.length;k++)f.appendChild(r[k]);tb.appendChild(f);} function makeSortable(t){if(!(t&&t.tHead&&t.tHead.rows.length))return;var th=t.tHead.rows[0].cells;for(var i=0;i<th.length;i++){(function(idx){var h=th[idx],d='asc';h.style.cursor='pointer';h.onclick=function(){d=(d==='asc')?'desc':'asc';for(var j=0;j<th.length;j++)th[j].innerHTML=th[j].innerHTML.replace(' (asc)','').replace(' (desc)','');h.innerHTML+=(d==='asc'?' (asc)':' (desc)');sortTable(t,idx,d);};})(i);}} window.filterTable = function() { var input = document.getElementById(\"tableSearch\"); var filter = input.value.toUpperCase(); var table = document.getElementById(\"reg-table\") || document.querySelector(\"table.dataframe\"); var tr = table.getElementsByTagName(\"tr\"); for (var i = 1; i < tr.length; i++) { var tdArr = tr[i].getElementsByTagName(\"td\"); var found = false; for (var j = 0; j < tdArr.length; j++) { if (tdArr[j]) { var txtValue = tdArr[j].textContent || tdArr[j].innerText; if (txtValue.toUpperCase().indexOf(filter) > -1) { found = true; break; } } } tr[i].style.display = found ? \"\" : \"none\"; } } function init(){ var t=document.getElementsByTagName('table'); for(var i=0;i<t.length;i++) if(t[i].className.indexOf('sortable') !== -1) makeSortable(t[i]); } if(document.readyState==='loading')document.addEventListener('DOMContentLoaded',init,false);else init(); })();</script>\"\"\"\n",
        "BTT_BTN = r\"\"\"<style>.btt{position:fixed;bottom:20px;right:20px;background:#00838f;color:white;padding:10px 15px;text-decoration:none;border-radius:4px;font-weight:bold;box-shadow:0 2px 5px rgba(0,0,0,0.3);z-index:1000;opacity:0.9;} .btt:hover{opacity:1;background:#006064;} @media print { .btt { display: none !important; } }</style><a href=\"#top\" class=\"btt no-print\">‚¨ÜÔ∏è Top</a>\"\"\"\n",
        "\n",
        "LEGAL_FOOTER_TMPL = r\"\"\"<div class=\"legal-footer no-print\" style=\"margin-top:50px;padding:20px;background:#f4f4f4;border-top:1px solid #ddd;text-align:center;color:#666;font-family:sans-serif;font-size:0.85em;clear:both;\"><p style=\"margin-bottom:5px;font-size:1.1em;color:#333;\"><strong>&copy; __YEAR__ Ronald Eugene Yates. All Rights Reserved.</strong></p><p style=\"margin-bottom:5px;\">Generated by <em>The Forensic Genealogy Publisher&trade;</em></p><p style=\"font-style:italic;color:#888;margin-bottom:0;max-width:800px;margin-left:auto;margin-right:auto;\">The terms \"Forensic Handshake\", \"Brick Wall Buster\", and \"Collateral Saturation\" are trademarks of the Yates One-Name Study.</p></div><div class=\"only-print\" style=\"margin-top:40px;padding-top:10px;border-top:2px solid #000;text-align:center;color:#000;font-family:'Georgia',serif;font-size:12px;clear:both;page-break-inside:avoid;\"><strong>&copy; __YEAR__ Ronald Eugene Yates. All Rights Reserved.</strong><br><em>Generated by The Forensic Genealogy Publisher&trade; | yates.one-name.net</em></div>\"\"\"\n",
        "\n",
        "CONSOLIDATOR_CSS = r\"\"\"<style>\n",
        ".consol-panel { background: #f3e5f5; border: 1px solid #ab47bc; padding: 25px; border-radius: 8px; margin-bottom: 25px; font-family: 'Segoe UI', sans-serif; text-align: center; }\n",
        ".consol-panel select { padding: 8px; font-size: 14px; width: 100%; border: 1px solid #7b1fa2; border-radius: 4px; }\n",
        ".consol-btn { background: #4a148c; color: white; border: none; padding: 12px 25px; font-size: 16px; font-weight: bold; border-radius: 4px; cursor: pointer; box-shadow: 0 4px 6px rgba(0,0,0,0.1); margin-top: 10px; }\n",
        ".consol-btn:hover { background: #38006b; }\n",
        ".academic-brief { background: white; max-width: 1000px; margin: 0 auto 30px auto; padding: 60px 80px; box-shadow: 0 4px 20px rgba(0,0,0,0.1); font-family: 'Georgia', serif; color: #000; line-height: 1.6; }\n",
        ".title-page { page-break-after: always; display: flex; flex-direction: column; justify-content: center; min-height: 70vh; padding: 20px; }\n",
        ".brief-header { text-align: center; border-bottom: 3px solid #000; padding-bottom: 20px; margin-bottom: 30px; }\n",
        ".brief-header h1 { font-size: 28px; text-transform: uppercase; margin: 0; letter-spacing: 1px; color: #000; }\n",
        ".brief-header p { font-size: 16px; font-style: italic; color: #444; margin: 5px 0 0 0; }\n",
        ".brief-meta { background: #fafafa; border: 1px solid #ddd; padding: 20px; margin-bottom: 30px; font-size: 15px; }\n",
        ".brief-meta strong { color: #000; }\n",
        ".brief-section-title { font-size: 18px; text-transform: uppercase; border-bottom: 1px solid #ccc; padding-bottom: 5px; margin-top: 40px; margin-bottom: 20px; font-weight: bold; }\n",
        ".collateral-list { margin-left: 20px; font-size: 15px; }\n",
        ".collateral-list li { margin-bottom: 8px; }\n",
        ".brief-table { width: 100%; border-collapse: collapse; margin-top: 15px; font-size: 14px; }\n",
        ".brief-table th { background: #f0f0f0; color: #000; border-bottom: 2px solid #000; border-top: 1px solid #000; padding: 10px; text-align: left; }\n",
        ".brief-table td { padding: 10px; border-bottom: 1px solid #ddd; vertical-align: middle; }\n",
        ".brief-table tr { page-break-inside: avoid; }\n",
        ".verdict-stamp { border: 3px double #4a148c; padding: 20px; text-align: center; margin-top: 40px; font-size: 18px; font-weight: bold; color: #4a148c; background: #fafafa; text-transform: uppercase; letter-spacing: 1px; }\n",
        "@media print { .no-print { display: none !important; } body { background: white; padding: 0; } .academic-brief { box-shadow: none; padding: 0; max-width: 100%; border: none; margin-bottom: 0; } .verdict-stamp { border: 3px double #000; color: #000; } }\n",
        ".vg-checkbox-container { height:150px; overflow-y:auto; border:1px solid #7b1fa2; background:white; border-radius:4px; padding:10px; font-size:13px; text-align:left; }\n",
        ".vg-checkbox-container label { display:block; margin-bottom:5px; cursor:pointer; }\n",
        ".vg-checkbox-container label:hover { background-color:#f3e5f5; }\n",
        "</style>\"\"\"\n",
        "\n",
        "APPENDIX_A_HTML = r\"\"\"\n",
        "<div class=\"academic-brief\" style=\"max-width: 1000px; margin-top: 40px; page-break-before: always; text-align: left; padding: 60px 80px;\">\n",
        "  <h2 style=\"color: #4a148c; border-bottom: 2px solid #ccc; padding-bottom: 5px; margin-top:0; font-size:22px; text-transform:uppercase;\">Appendix A: CSS Field Definitions &amp; Data Sources</h2>\n",
        "  <p><b>Purpose:</b> This appendix defines each field used in the Collateral Saturation Score (CSS) matrix, documents the intended data source(s) within the Yates DNA Study reporting system, and states calculation rules and quality checks so results are reproducible by an independent reviewer.</p>\n",
        "  <h3 style=\"color: #4a148c; margin-top: 30px;\">A1. Core Entities</h3>\n",
        "  <ul>\n",
        "    <li><b>Participant (ID):</b> A unique tester kit identifier.</li>\n",
        "    <li><b>Cluster:</b> The set of proper matches and related evidence assigned to a participant‚Äôs claimed lineage path.</li>\n",
        "    <li><b>Virtual Group:</b> A user-defined composite of multiple independent kits treated as a single \"Super-Kit\" to test combined evidence density.</li>\n",
        "    <li><b>Handshake:</b> A cross-match instance where a kit in the participant‚Äôs cluster intersects a kit assigned to a known lineage.</li>\n",
        "  </ul>\n",
        "  <h3 style=\"color: #4a148c; margin-top: 30px;\">A2. CSS Matrix Fields</h3>\n",
        "  <table class=\"brief-table\" style=\"font-size: 13px;\">\n",
        "    <thead><tr><th>Field</th><th>Abbrev</th><th>Definition</th><th>Computation</th><th>Desired Range</th></tr></thead>\n",
        "    <tbody>\n",
        "      <tr><td><b>Proper Matches</b></td><td>PM</td><td>Count of matches that meet study criteria assigned to the participant‚Äôs cluster.</td><td>PM = confirmed matches.</td><td>‚â•15 required; 50‚Äì150 strong.</td></tr>\n",
        "      <tr><td><b>Target Handshakes</b></td><td>HC-T</td><td>Handshake instances supporting the rank #1 candidate lineage.</td><td>HC-T = participant's match instances intersecting target node.</td><td>30‚Äì100 strong; 100+ saturated.</td></tr>\n",
        "      <tr><td><b>Second Handshakes</b></td><td>HC-2</td><td>Handshake instances for the rank #2 candidate lineage.</td><td>HC-2 = participant's match instances for runner-up lineage.</td><td>Lower is better; typical &lt;30.</td></tr>\n",
        "      <tr><td><b>Dominance Ratio</b></td><td>DR</td><td>Relative support for target lineage over the runner-up lineage.</td><td>DR = HC-T / max(HC-2, 1).</td><td>3‚Äì10 strong; 10+ fully saturated.</td></tr>\n",
        "      <tr><td><b>Independent Branches</b></td><td>BR</td><td>Count of independent descendant branches represented in the cluster.</td><td>BR = distinct descendant branches meeting criteria.</td><td>2‚Äì3 minimum; 4‚Äì10 strong.</td></tr>\n",
        "      <tr><td><b>Unique Testers</b></td><td>TB</td><td>Number of unique tester kits contributing evidence to the participant's cluster.</td><td>TB = count of unique NPFX kits on target node (Node-Level).</td><td>15‚Äì40 strong; 40+ saturated.</td></tr>\n",
        "      <tr><td><b>Node Saturation</b></td><td>NS</td><td>Maximum independent kit corroboration observed for the deepest proven ancestor node.</td><td>NS = max(independent kits) across the spine (Node-Level).</td><td>15‚Äì50 validated; 50‚Äì150 strong.</td></tr>\n",
        "      <tr><td><b>Stability</b></td><td>ST</td><td>Sensitivity outcome (PASS/PARTIAL/FAIL) indicating robustness.</td><td>Multiplier applied: PASS=1.00, PARTIAL=0.85, FAIL=0.60.</td><td>Desired PASS.</td></tr>\n",
        "      <tr><td><b>CSS v2a (score)</b></td><td>CSSv2a</td><td>Composite normalized score for cross-participant comparison.</td><td>100 √ó weighted_mean(component norms) √ó ST.</td><td>85‚Äì100 platinum.</td></tr>\n",
        "    </tbody>\n",
        "  </table>\n",
        "  <h3 style=\"color: #4a148c; margin-top: 30px;\">A3. Mathematical Weighting &amp; Normalization</h3>\n",
        "  <ul style=\"font-size: 14px; margin-bottom: 0;\">\n",
        "    <li><b>Empirical Caps:</b> Logarithmic caps (e.g., PM=150, HC=100, TB=40) are not arbitrary; they were established empirically based on observed saturation limits within the Yates DNA Study dataset. Values exceeding these caps provide diminishing marginal evidence and are constrained to a maximum normalized score of 1.0.</li>\n",
        "    <li><b>Weighted Mean:</b> To reflect genealogical reality, components are not weighted equally. Structural replication (BR, weight 2.0) and lineage dominance (DR, weight 1.5) carry more mathematical gravity. Raw match volume (PM) carries a weight of 1.0 to ensure participants with low personal evidence are properly separated from highly verified anchors. Handshakes, testers, and node saturation carry a standard weight of 1.0.</li>\n",
        "    <li><b>Categorical Branch Logic:</b> Independent Branches (BR) is treated as a stepwise categorical variable (BR=2‚Üí0.25, BR=3‚Üí0.50... BR‚â•6‚Üí1.0) mapped onto a continuous scale, reflecting the rapid diminishing returns of branch replication beyond 6 independent lines.</li>\n",
        "  </ul>\n",
        "  <h3 style=\"color: #4a148c; margin-top: 30px;\">A4. Matrix Inclusion Rules &amp; Flags</h3>\n",
        "  <ul style=\"font-size: 14px; margin-bottom: 0;\">\n",
        "    <li><b>Strict PM Minimum:</b> Participants with PM &lt; 15 automatically trigger a FAIL stability penalty (0.60 multiplier) as they lack the minimum personal evidence mass for proof-grade analysis. They are included in the matrix strictly to demonstrate the noise-to-signal gradient.</li>\n",
        "    <li><b>Node-Level Duplication:</b> In saturated clusters, descendants of the same ancestor will naturally display identical TB and NS values because these measure the shared ancestral node, not the individual kit.</li>\n",
        "  </ul>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "CONSOLIDATOR_JS = r\"\"\"<script>__JS_GLOBALS__\n",
        "const getCM = (val) => { let m = String(val).match(/(\\d+)/); return m ? parseInt(m[1]) : 0; };\n",
        "function cleanNum(str){let res=\"\";for(let i=0;i<str.length;i++)if(str[i]>='0'&&str[i]<='9')res+=str[i];return res;}\n",
        "\n",
        "const partSel = document.getElementById('testerSelect');\n",
        "const groupDiv = document.getElementById('groupCheckboxes');\n",
        "const ancSel = document.getElementById('ancestorSelect');\n",
        "\n",
        "const validTesters = DB.filter(r => r.t_names && r.t_names.trim() !== \"\");\n",
        "const uniqueTesters = [...new Set(validTesters.map(r => r.participant))];\n",
        "\n",
        "uniqueTesters.sort((a, b) => {\n",
        "    const keyA = DATA.participants[a] ? DATA.participants[a].sort_key : a.toLowerCase();\n",
        "    const keyB = DATA.participants[b] ? DATA.participants[b].sort_key : b.toLowerCase();\n",
        "    if (keyA === keyB) return a.localeCompare(b);\n",
        "    return keyA.localeCompare(keyB);\n",
        "});\n",
        "\n",
        "// Populate Single Dropdown & Checkboxes\n",
        "uniqueTesters.forEach(t => {\n",
        "    const o1 = document.createElement('option'); o1.value = t; o1.innerText = t; partSel.appendChild(o1);\n",
        "\n",
        "    const lbl = document.createElement('label');\n",
        "    lbl.innerHTML = `<input type=\"checkbox\" value=\"${t}\" class=\"vg-checkbox\"> ${t}`;\n",
        "    groupDiv.appendChild(lbl);\n",
        "});\n",
        "\n",
        "const allAncestors = Object.keys(DATA.ancestors).sort((a,b) => DATA.ancestors[a].name.localeCompare(DATA.ancestors[b].name));\n",
        "allAncestors.forEach(k => { const o = document.createElement('option'); o.value = DATA.ancestors[k].name; o.innerText = DATA.ancestors[k].name; ancSel.appendChild(o); });\n",
        "\n",
        "const cleanName = (str) => {\n",
        "    if(!str) return \"\";\n",
        "    return str.replace(/findme/gi, '?').replace(/\\(\\? - \\?\\)/g, '').replace(/\\( - \\)/g, '').replace(/\\(\\? - /g, '(d. ').replace(/ - \\?\\)/g, '(b. ').replace(/& \\?/g, '').trim();\n",
        "};\n",
        "\n",
        "let secCounter = 1;\n",
        "const getSec = () => {\n",
        "    let num = secCounter++;\n",
        "    const rules = {M:1000,CM:900,D:500,CD:400,C:100,XC:90,L:50,XL:40,X:10,IX:9,V:5,IV:4,I:1};\n",
        "    let res = '';\n",
        "    for(let i in rules){ while(num >= rules[i]){ res += i; num -= rules[i]; } }\n",
        "    return res + \".\";\n",
        "};\n",
        "\n",
        "const getStudyStats = () => {\n",
        "    const d = new Date();\n",
        "    const datePart = d.toLocaleDateString('en-US', { month: 'long', day: 'numeric', year: 'numeric' });\n",
        "    const timePart = d.toLocaleTimeString('en-US', { hour: 'numeric', minute: '2-digit', timeZoneName: 'short' });\n",
        "    return `Study Data Current As Of: ${datePart} ${timePart} | Total Autosomal matches: ${DB.length.toLocaleString()}`;\n",
        "};\n",
        "\n",
        "const getTitlePage = () => {\n",
        "    const year = new Date().getFullYear();\n",
        "    return `\n",
        "    <div class=\"academic-brief title-page\">\n",
        "      <div style=\"font-family: Arial, sans-serif; text-align:center; line-height:1.6;\">\n",
        "        <h1 style=\"font-size:36px; border-bottom:none; margin-bottom:5px;\">Collateral Saturation</h1>\n",
        "        <h2 style=\"font-size:20px; font-weight:normal; color:#444; margin-top:0;\">A Quantitative Method for Autosomal Lineage Reconstruction</h2>\n",
        "        <br><br><br><p style=\"font-size:18px;\"><b>Ronald Eugene Yates, MPH</b><br>University of California, Los Angeles<br>1975</p>\n",
        "        <br><br><br><p style=\"font-size:16px;\">Yates DNA Study<br>Autosomal Lineage Reconstruction Project</p>\n",
        "        <br><br><br><br><br><p style=\"font-size:16px;\">${year}</p>\n",
        "        <p style=\"font-size:14px; color:#004d40; margin-top:20px; font-weight:bold;\">${getStudyStats()}</p>\n",
        "        <br><br><br><p style=\"font-size:14px; color:#555;\">&copy; ${year} Ronald Eugene Yates<br>All Rights Reserved.</p>\n",
        "      </div>\n",
        "    </div>`;\n",
        "};\n",
        "\n",
        "const getMethodologyPage = () => {\n",
        "    return `\n",
        "    <div class=\"academic-brief\" style=\"max-width: 1000px; margin-top: 40px; page-break-before: always; text-align: left; padding: 60px 80px;\">\n",
        "        <h2 style=\"color: #4a148c; border-bottom: 2px solid #ccc; padding-bottom: 5px; margin-top:0; font-size:22px; text-transform:uppercase;\">Methodological Principles of Collateral Saturation</h2>\n",
        "        <p style=\"font-size:15px; line-height:1.6; color:#333; margin-top:20px;\">\n",
        "            <b>Collateral Saturation</b> is a lineage-validation method in which autosomal DNA evidence is evaluated at the level of descendant networks rather than isolated matches. A lineage hypothesis is considered reliable when it is supported by sufficient descendant density, replicated across independent branches, and remains stable under perturbation tests. The following principles define the minimum standard for applying Collateral Saturation in the Yates DNA Study.\n",
        "        </p>\n",
        "        <h3 style=\"color: #4a148c; margin-top: 25px; font-size:16px;\">1) Minimum Descendant Count</h3>\n",
        "        <p style=\"font-size:15px; line-height:1.6; color:#333;\">The study requires adequate descendant representation to produce interpretable inheritance patterns. A lineage claim must be supported by a descendant network large enough to reduce reliance on any single match. In practice, this means that clusters should have multiple descendant lines and a sufficient number of corroborating kits to allow replication testing and competition testing (dominance over alternate hypotheses).</p>\n",
        "\n",
        "        <h3 style=\"color: #4a148c; margin-top: 20px; font-size:16px;\">2) Minimum Proper Matches (PM &ge; 15)</h3>\n",
        "        <p style=\"font-size:15px; line-height:1.6; color:#333;\">A lineage cluster must contain at least <b>15 proper matches</b> before Collateral Saturation analysis is applied. A ‚Äúproper match‚Äù is a match that meets platform matching thresholds, includes sufficient match metadata, and has been attributable to the lineage cluster through study classification rules. This threshold establishes a minimum evidence mass so that measured patterns (handshakes, dominance, and stability) are based on multiple observations rather than chance alignment.</p>\n",
        "\n",
        "        <h3 style=\"color: #4a148c; margin-top: 20px; font-size:16px;\">3) Minimum Branches (BR &ge; 2)</h3>\n",
        "        <p style=\"font-size:15px; line-height:1.6; color:#333;\">A cluster must be sourced from at least <b>two independent descendant branches</b>. Independence is defined genealogically when pedigree documentation exists (distinct child-lines descending from the target ancestor), and may be inferred genetically when documentary data are incomplete (e.g., absence of close-relationship shared DNA patterns that indicate a single nuclear-family source). This requirement prevents over-weighting of one family group and ensures that the lineage signal replicates across distinct inheritance pathways.</p>\n",
        "\n",
        "        <h3 style=\"color: #4a148c; margin-top: 20px; font-size:16px;\">4) No Singleton Lines</h3>\n",
        "        <p style=\"font-size:15px; line-height:1.6; color:#333;\">No lineage conclusion may be based on a single tester or a single descendant line. A cluster must be sourced from at least <b>two participants</b>, and the branch requirement (BR &ge; 2) must be met. Singleton clusters may be cataloged as hypotheses, but they are not eligible for proof-grade inference under Collateral Saturation because they cannot be tested for replication or stability.</p>\n",
        "\n",
        "        <h3 style=\"color: #4a148c; margin-top: 20px; font-size:16px;\">5) Handshake Replication</h3>\n",
        "        <p style=\"font-size:15px; line-height:1.6; color:#333;\">A lineage hypothesis must show <b>replicated cross-line corroboration</b> through ‚Äúhandshakes,‚Äù defined as cross-matches between kits assigned to the participant‚Äôs cluster and kits assigned to established reference lineages. The key principle is replication: the handshake signal must appear across multiple independent branches rather than being driven by one highly connected kit. In saturated lineages, handshake evidence is expected to show dominance over competing candidate lineages and to persist under stricter thresholds.</p>\n",
        "\n",
        "        <h3 style=\"color: #4a148c; margin-top: 20px; font-size:16px;\">6) Stability Testing</h3>\n",
        "        <p style=\"font-size:15px; line-height:1.6; color:#333;\">Collateral Saturation requires that lineage conclusions be <b>robust</b> when subjected to sensitivity tests. Typical perturbations include: removing the largest bridge participant(s), removing close relatives above a defined cM threshold, raising the minimum match threshold, and recomputing lineage rankings. A lineage conclusion is considered proof-grade when it remains stable under these perturbations (recorded as <b>PASS</b>, <b>PARTIAL</b>, or <b>FAIL</b>), demonstrating that the inference is not dependent on a single individual, a single segment class, or a single permissive threshold.</p>\n",
        "\n",
        "        <h3 style=\"color: #4a148c; margin-top: 20px; font-size:16px;\">7) Node-Level Saturation Properties</h3>\n",
        "        <p style=\"font-size:15px; line-height:1.6; color:#333;\">In highly saturated lineages, metrics such as Unique Testers (TB) and Node Saturation (NS) become node-level properties shared by all descendants of that ancestor. Variation between participants representing the same lineage is therefore primarily expressed through their personal Proper Matches (PM), Target Handshakes (HC-T), and Dominance Ratio (DR).</p>\n",
        "\n",
        "        <h3 style=\"color: #4a148c; margin-top: 20px; font-size:16px;\">Summary Principle</h3>\n",
        "        <p style=\"font-size:15px; line-height:1.6; color:#333;\">In Collateral Saturation, <b>proof emerges from replication</b>: adequate descendant density, multiple independent branches, repeated handshake corroboration, and stability under perturbation. These conditions collectively reduce the probability that an observed lineage signal is an artifact of chance, population structure, or data errors, and they establish a consistent, scalable standard for lineage reconstruction in autosomal surname studies.</p>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"academic-brief\" style=\"max-width: 1000px; margin-top: 40px; page-break-before: always; text-align: left; padding: 60px 80px;\">\n",
        "        <h2 style=\"color: #4a148c; border-bottom: 2px solid #ccc; padding-bottom: 5px; margin-top:0; font-size:22px; text-transform:uppercase;\">Virtual Group Protocol for Brick-Wall Ancestors</h2>\n",
        "        <h3 style=\"color: #4a148c; margin-top: 25px; font-size:16px;\">Definition</h3>\n",
        "        <p style=\"font-size:15px; line-height:1.6; color:#333;\">A <strong>Virtual Group</strong> is a composite lineage cluster formed by combining multiple independently tested participants who share the same unresolved ancestral hypothesis. Virtual Groups are intended primarily for unresolved ancestral problems where multiple independent descendants exist but individual evidence clusters remain underpowered. Virtual Groups are used when individual participants lack sufficient evidence mass to meet Collateral Saturation criteria independently, but collectively demonstrate a stable and replicated lineage signal.<br><br>Under this protocol, Collateral Saturation is evaluated at the group level, while individual participant results are retained for transparency.</p>\n",
        "\n",
        "        <h3 style=\"color: #4a148c; margin-top: 25px; font-size:16px;\">Eligibility Requirements</h3>\n",
        "        <p style=\"font-size:15px; line-height:1.6; color:#333; margin-bottom:10px;\"><strong>1. Shared Brick-Wall Ancestor</strong><br>All participants in a Virtual Group must descend from the same unresolved ancestor or ancestral couple representing the target lineage hypothesis. The brick-wall ancestor must be explicitly defined and documented. Each participant must independently claim descent from this ancestor through genealogical evidence or credible family tradition.</p>\n",
        "        <p style=\"font-size:15px; line-height:1.6; color:#333; margin-bottom:10px;\"><strong>2. Independent Participants</strong><br>Virtual Groups must include at least two or more participants, preferably representing multiple descendant branches (BR &ge; 2). Participants must represent independent lines of descent and may not consist solely of close relatives. Independence may be determined through documented pedigrees, genetic relationship distances, or the absence of close-family match patterns.</p>\n",
        "        <p style=\"font-size:15px; line-height:1.6; color:#333; margin-bottom:10px;\"><strong>3. Independent Lineage Signals</strong><br>Each participant must independently produce measurable evidence linking them to the target lineage. Evidence may include proper matches, handshake connections, shared lineage clusters, and supporting testers. Participants do not need to meet Collateral Saturation thresholds individually. However, each participant must contribute at least minimal independent evidence supporting the shared lineage hypothesis.</p>\n",
        "\n",
        "        <h3 style=\"color: #4a148c; margin-top: 25px; font-size:16px;\">Evaluation Procedure</h3>\n",
        "        <ul style=\"font-size:15px; line-height:1.6; color:#333; padding-left:20px;\">\n",
        "            <li style=\"margin-bottom:8px;\"><strong>Step 1 ‚Äî Individual Assessment:</strong> Each participant is first evaluated independently using standard Collateral Saturation criteria. Individual results are recorded. Participants that fail individual thresholds remain eligible for Virtual Group inclusion.</li>\n",
        "            <li style=\"margin-bottom:8px;\"><strong>Step 2 ‚Äî Composite Cluster Construction:</strong> The Virtual Group is constructed by combining proper matches, handshake connections, bridge connections, and supporting testers. Duplicate matches and testers are removed to avoid double-counting. Metrics are recalculated for the composite cluster.</li>\n",
        "            <li style=\"margin-bottom:8px;\"><strong>Step 3 ‚Äî Target Node Confirmation:</strong> The Virtual Group must demonstrate a consistent dominant lineage signal pointing to the shared brick-wall ancestor. The target node must be the highest-ranked lineage hypothesis for the composite cluster. Dominance ratio must indicate a clear preference for the target lineage over competing hypotheses.</li>\n",
        "            <li style=\"margin-bottom:8px;\"><strong>Step 4 ‚Äî Stability Testing:</strong> The Virtual Group must pass sensitivity testing. Recommended perturbations include the removal of the strongest participant, bridge kits, or close relatives, and raising match thresholds. The lineage signal must remain stable under perturbation.</li>\n",
        "        </ul>\n",
        "\n",
        "        <h3 style=\"color: #4a148c; margin-top: 25px; font-size:16px;\">Interpretation &amp; Reporting Standard</h3>\n",
        "        <p style=\"font-size:15px; line-height:1.6; color:#333;\">Virtual Groups demonstrate that Collateral Saturation is a network-level property rather than an individual property. Multiple independent descendant kits may jointly produce a proof-grade lineage signal even when individual kits remain below threshold.<br><br>Virtual Group reports must include the list of participants included, individual participant metrics, composite cluster metrics, stability test results, and target ancestor definition. Both individual FAIL results and composite PASS results must be reported to ensure transparency.</p>\n",
        "\n",
        "        <h3 style=\"color: #4a148c; margin-top: 25px; font-size:16px;\">Key Principle</h3>\n",
        "        <p style=\"font-size:15px; line-height:1.6; color:#333;\">Collateral Saturation may be achieved collectively when independent descendant signals converge on the same unresolved ancestor. <strong>Proof emerges from replicated network evidence rather than from any single participant.</strong></p>\n",
        "    </div>\n",
        "    `;\n",
        "};\n",
        "\n",
        "const getAuthorshipPage = () => {\n",
        "    return `\n",
        "    <div class=\"academic-brief\" style=\"max-width: 1000px; margin-top: 40px; page-break-before: always; text-align: left; padding: 60px 80px;\">\n",
        "        <h2 style=\"color: #4a148c; border-bottom: 2px solid #ccc; padding-bottom: 5px; margin-top:0; font-size:22px; text-transform:uppercase;\">Appendix B: Authorship &amp; Metric Development</h2>\n",
        "        <p style=\"font-size:15px; line-height:1.6; color:#333; margin-top:20px;\">The Collateral Saturation methodology originated from the long-term design and execution of the Yates DNA Study by Ron Yates. Over a period of several years, the study evolved from traditional autosomal DNA matching into a structured lineage-based analytical framework emphasizing dense collateral descendant sampling and cross-lineage corroboration.</p>\n",
        "        <p style=\"font-size:15px; line-height:1.6; color:#333;\">The conceptual framework underlying Collateral Saturation‚Äîincluding the emphasis on independent descendant branches, handshake replication, node saturation, and lineage dominance‚Äîwas developed through empirical observation of inheritance patterns across the Yates surname dataset. The study demonstrated that lineage signals become increasingly stable as collateral representation increases, leading to the formulation of Collateral Saturation as a generalizable method for lineage reconstruction.</p>\n",
        "        <p style=\"font-size:15px; line-height:1.6; color:#333;\">The formal metric definitions, normalization procedures, and scoring formulas were developed through collaborative methodological work between Ron Yates and ChatGPT (OpenAI). Ron Yates provided the empirical dataset, methodological insights, terminology, and structural requirements derived from the Yates DNA Study, while ChatGPT assisted in translating these concepts into explicit mathematical definitions, normalization procedures, and reproducible scoring formulas (including the CSS and CSS v2a/v2a variants).</p>\n",
        "        <p style=\"font-size:15px; line-height:1.6; color:#333;\">This collaboration produced a documented field dictionary and a quantitative scoring framework intended to support consistent cross-participant comparison, sensitivity testing, and publication-grade reporting. The methodology reflects the integration of empirical genealogical research with formal quantitative modeling and is grounded in observed match-network behavior within the study.</p>\n",
        "    </div>`;\n",
        "};\n",
        "\n",
        "function getCSS(testerArray, customName = null) {\n",
        "    const isGroup = testerArray.length > 1;\n",
        "    const pName = isGroup ? (customName || `VIRTUAL GROUP (${testerArray.length} Kits)`) : testerArray[0];\n",
        "\n",
        "    const myMatches = DB.filter(m => testerArray.includes(m.participant) && m.ancestor !== 'No Matches' && m.ancestor);\n",
        "    let PM = myMatches.length;\n",
        "    if(PM === 0) return null;\n",
        "\n",
        "    let dirs = {};\n",
        "    myMatches.forEach(m => { dirs[m.ancestor] = (dirs[m.ancestor] || 0) + 1; });\n",
        "    let sortedDirs = Object.entries(dirs).sort((a,b) => b[1] - a[1]);\n",
        "    let HC_T = sortedDirs.length > 0 ? sortedDirs[0][1] : PM;\n",
        "    let HC_2 = sortedDirs.length > 1 ? sortedDirs[1][1] : 0;\n",
        "\n",
        "    let TB = 0; let NS = 0; let BR = 0;\n",
        "\n",
        "    let idCounts = {};\n",
        "    myMatches.forEach(m => {\n",
        "        if(m.search_ids) {\n",
        "            let ids = m.search_ids.split(',').map(x=>cleanNum(x));\n",
        "            ids.forEach(id => { if(id) idCounts[id] = (idCounts[id] || 0) + 1; });\n",
        "        }\n",
        "    });\n",
        "\n",
        "    let highestHeat = 0; let targetID = null;\n",
        "    for (let [id, count] of Object.entries(idCounts)) {\n",
        "        const nodeMatches = DB.filter(m => m.search_ids && m.search_ids.split(',').map(x=>cleanNum(x)).includes(id));\n",
        "        const nodeUniqueKits = new Set(nodeMatches.map(m => m.participant)).size;\n",
        "        if (nodeUniqueKits > highestHeat) { highestHeat = nodeUniqueKits; targetID = id; }\n",
        "    }\n",
        "    NS = highestHeat;\n",
        "\n",
        "    if (targetID) {\n",
        "        const collaterals = DB.filter(m => m.search_ids && m.search_ids.split(',').map(x=>cleanNum(x)).includes(targetID));\n",
        "        TB = new Set(collaterals.map(m => m.participant)).size;\n",
        "        let branches = new Set();\n",
        "        collaterals.forEach(r => {\n",
        "            const ids = r.search_ids.split(',').map(x => cleanNum(x));\n",
        "            const names = r.search_names.split('|');\n",
        "            let idx = ids.indexOf(targetID);\n",
        "            if(idx !== -1 && idx + 1 < names.length) {\n",
        "                branches.add(names[idx+1].replace(/findme/gi, '?').split(' (')[0].trim());\n",
        "            } else { branches.add(\"Direct Descendant\"); }\n",
        "        });\n",
        "        BR = branches.size;\n",
        "    }\n",
        "\n",
        "    let DR = HC_T / (HC_2 > 0 ? HC_2 : 1);\n",
        "    const norm = (val, cap) => Math.min(1, Math.log(1+val) / Math.log(1+cap));\n",
        "    let PM_n = norm(PM, 150); let HC_n = norm(HC_T, 100); let DR_n = norm(DR, 10); let TB_n = norm(TB, 40); let NS_n = norm(NS, 150);\n",
        "\n",
        "    let BR_n = 0;\n",
        "    if(BR >= 6) BR_n = 1.0; else if(BR === 5) BR_n = 0.85; else if(BR === 4) BR_n = 0.70; else if(BR === 3) BR_n = 0.50; else if(BR === 2) BR_n = 0.25;\n",
        "\n",
        "    let ST_str = \"FAIL\"; let ST_val = 0.60;\n",
        "    if (PM >= 15) {\n",
        "        if(BR >= 3 && DR >= 1.5) { ST_str = \"PASS\"; ST_val = 1.0; }\n",
        "        else if(BR >= 2) { ST_str = \"PARTIAL\"; ST_val = 0.85; }\n",
        "    }\n",
        "\n",
        "    let weightedSum = (PM_n * 1.0) + (HC_n * 1.0) + (DR_n * 1.5) + (TB_n * 1.0) + (BR_n * 2.0) + (NS_n * 1.0);\n",
        "    let cssBase = 100 * (weightedSum / 7.5);\n",
        "    let cssFinal = cssBase * ST_val;\n",
        "\n",
        "    return { pName, PM, HC_T, HC_2, DR, TB, BR, NS, ST_str, cssFinal, isGroup };\n",
        "}\n",
        "\n",
        "function getDiagnosticHTML(testerArray, ancName) {\n",
        "    let css = getCSS(testerArray);\n",
        "    if(!css) return ``;\n",
        "\n",
        "    let stColor = css.ST_str === \"PASS\" ? \"green\" : (css.ST_str === \"PARTIAL\" ? \"#f57f17\" : \"red\");\n",
        "    let brStr = css.BR >= 6 ? \"&ge;6\" : css.BR;\n",
        "\n",
        "    let narrative = \"\";\n",
        "    if(css.PM < 15) {\n",
        "        narrative = `The evaluated subject triggers a <strong style=\"color:red;\">FAIL</strong> stability warning.<br><br><strong>Limiting Factor:</strong> Insufficient match volume (PM = ${css.PM}), failing the minimum study threshold of 15 proper matches required to act as an independent lineage anchor.<br><br><strong>Recommendation:</strong> This subject cannot currently serve as a proof-grade anchor. More matches must be mapped to this cluster before an independent Collateral Saturation evaluation can be performed.`;\n",
        "    } else if(css.ST_str === \"PASS\") {\n",
        "        narrative = `The cluster demonstrates strong structural integrity (Stability: <strong style=\"color:green;\">PASS</strong>) with ${css.BR} independent branches and a dominance ratio of ${css.DR.toFixed(1)}. This lineage signature is highly saturated and reliable. No immediate corrective action is required.`;\n",
        "    } else if (css.ST_str === \"PARTIAL\") {\n",
        "        narrative = `The cluster demonstrates moderate integrity but flags a <strong style=\"color:#f57f17;\">PARTIAL</strong> stability warning.<br><br><strong>Limiting Factor:</strong> The genetic evidence relies on only ${css.BR} independent branches, creating a potential single-family bias.<br><br><strong>Recommendation:</strong> To upgrade this line to Platinum/PASS status, targeted DNA testing should be recruited from descendants of alternate children of the target ancestor to broaden the Forensic Handshake.`;\n",
        "    } else {\n",
        "        narrative = `The cluster triggers a <strong style=\"color:red;\">FAIL</strong> stability warning.<br><br><strong>Limiting Factor:</strong> The evidence lacks independent branch replication (Branch Count: ${css.BR}) and/or fails to establish dominance over competing lineage theories (Dominance Ratio: ${css.DR.toFixed(1)}).<br><br><strong>Recommendation:</strong> This connection is currently considered structurally insufficient. Targeted recruitment of distant cousins from entirely different branches is strictly required to resolve the biological proof.`;\n",
        "    }\n",
        "\n",
        "    return `\n",
        "    <div class=\"brief-section-title\">${getSec()} Diagnostic Review & Lineage Viability</div>\n",
        "    <p>This section evaluates the structural viability of the DNA cluster using the Collateral Saturation Score (CSS v2a) methodology.</p>\n",
        "    <table class=\"brief-table\" style=\"text-align:center; margin-bottom:20px;\">\n",
        "        <thead><tr><th style=\"text-align:left;\">Evaluated Subject</th><th>PM</th><th>HC-T</th><th>HC-2</th><th>DR</th><th>TB</th><th>BR</th><th>NS</th><th>ST</th><th style=\"background:#f3e5f5; color:#4a148c;\">CSS v2a</th></tr></thead>\n",
        "        <tbody>\n",
        "            <tr>\n",
        "                <td style=\"text-align:left;\"><strong>${css.pName}</strong></td>\n",
        "                <td>${css.PM}</td><td>${css.HC_T}</td><td>${css.HC_2}</td><td>${css.DR.toFixed(1)}</td><td>${css.TB}</td><td>${brStr}</td><td>${css.NS}</td>\n",
        "                <td style=\"font-weight:bold; color:${stColor};\">${css.ST_str}</td>\n",
        "                <td style=\"font-weight:bold; color:#4a148c; background:#fafafa; font-size:1.1em;\">${css.cssFinal.toFixed(2)}</td>\n",
        "            </tr>\n",
        "        </tbody>\n",
        "    </table>\n",
        "    <div style=\"background:#fbfbfb; border-left:4px solid ${stColor}; padding:15px; text-align:left; font-size:14px; line-height:1.6;\">\n",
        "        <strong>Diagnostic Analysis:</strong><br>${narrative}\n",
        "    </div>\n",
        "    `;\n",
        "}\n",
        "\n",
        "function getMatrixHTML(vgCSS = null) {\n",
        "    let matrixRows = [];\n",
        "    uniqueTesters.forEach(t => { let c = getCSS([t]); if(c) matrixRows.push(c); });\n",
        "    if (vgCSS && vgCSS.isGroup) matrixRows.push(vgCSS);\n",
        "\n",
        "    matrixRows.sort((a,b) => b.cssFinal - a.cssFinal);\n",
        "    let tableHTML = `<table class=\"brief-table sortable\" style=\"text-align:center; font-family:sans-serif;\">\n",
        "        <thead><tr><th style=\"text-align:left; cursor:pointer; width:22%;\">Participant Kit</th><th title=\"Proper Matches\" style=\"cursor:pointer;\">PM</th><th title=\"Target Handshakes\" style=\"cursor:pointer;\">HC-T</th><th title=\"Secondary Handshakes\" style=\"cursor:pointer;\">HC-2</th><th title=\"Dominance Ratio\" style=\"cursor:pointer;\">DR</th><th title=\"Unique Testers\" style=\"cursor:pointer;\">TB</th><th title=\"Independent Branches\" style=\"cursor:pointer;\">BR</th><th title=\"Node Saturation\" style=\"cursor:pointer;\">NS</th><th title=\"Stability\" style=\"cursor:pointer;\">ST</th><th style=\"background:#f3e5f5; color:#4a148c; cursor:pointer;\">CSS v2a</th></tr></thead><tbody>`;\n",
        "\n",
        "    matrixRows.forEach(r => {\n",
        "        let stColor = r.ST_str === \"PASS\" ? \"green\" : (r.ST_str === \"PARTIAL\" ? \"#f57f17\" : \"red\");\n",
        "        let brStr = r.BR >= 6 ? \"&ge;6\" : r.BR;\n",
        "        let rowStyle = r.isGroup ? 'background:#fff8e1; border:2px solid #fbc02d;' : '';\n",
        "        let nameFmt = r.isGroup ? `<span style=\"color:#f57f17; font-weight:bold;\">‚òÖ ${r.pName}</span>` : `<strong>${r.pName}</strong>`;\n",
        "\n",
        "        tableHTML += `<tr style=\"${rowStyle}\"><td style=\"text-align:left;\" data-sort=\"${r.pName}\">${nameFmt}</td><td>${r.PM}</td><td>${r.HC_T}</td><td>${r.HC_2}</td><td>${r.DR.toFixed(1)}</td><td>${r.TB}</td><td data-sort=\"${r.BR}\">${brStr}</td><td>${r.NS}</td><td data-sort=\"${r.ST_str}\"><span style=\"color:${stColor};font-weight:bold;\">${r.ST_str}</span></td><td style=\"background:#fafafa; font-weight:bold; color:#4a148c; font-size:1.1em;\" data-sort=\"${r.cssFinal}\">${r.cssFinal.toFixed(2)}</td></tr>`;\n",
        "    });\n",
        "    tableHTML += `</tbody></table>`;\n",
        "\n",
        "    return `<div class=\"academic-brief\" style=\"max-width: 1100px; padding: 60px 80px; page-break-before: always;\">\n",
        "        <div class=\"brief-section-title\" style=\"margin-top:20px;\">${getSec()} Master CSS v2a Evaluation Matrix</div>\n",
        "        <p style=\"font-size:14px; color:#004d40; margin-bottom:10px; font-weight:bold; border-bottom:1px solid #ddd; padding-bottom:10px;\">${getStudyStats()}</p>\n",
        "        <p style=\"font-size:13px; color:#555; margin-bottom:15px;\"><strong>Note:</strong> Scores are provisional CSS v2a computed with empirically-weighted logarithmic normalization. This matrix evaluates and ranks active study participants based on their structural viability as keystone lineage representatives. <b style=\"color:#b71c1c;\">Participants with PM &lt; 15 are included for comparison but do not meet minimum Collateral Saturation criteria.</b> Within a single saturated ancestral node, CSS primarily differentiates participants by PM, HC-T, and DR; between different nodes, TB/NS/BR drive separation.</p>\n",
        "        ${tableHTML}\n",
        "    </div>`;\n",
        "}\n",
        "\n",
        "function runConsolidator(mode) {\n",
        "    const singleTester = partSel.value;\n",
        "    const checkedBoxes = document.querySelectorAll('.vg-checkbox:checked');\n",
        "    const groupTesters = Array.from(checkedBoxes).map(cb => cb.value);\n",
        "    const ancName = ancSel.value;\n",
        "\n",
        "    let activeTesters = [];\n",
        "    if (groupTesters.length > 0) activeTesters = groupTesters;\n",
        "    else if (singleTester) activeTesters = [singleTester];\n",
        "\n",
        "    if(activeTesters.length === 0 && !ancName && mode !== 'matrix') return alert(\"Please select a Tester, a Virtual Group, or an Ancestor.\");\n",
        "    secCounter = 1;\n",
        "\n",
        "    let pdfTitle = \"Proof_Consolidator\";\n",
        "    if (activeTesters.length > 1) {\n",
        "        pdfTitle = `Virtual_Group_${activeTesters.length}_Kits`;\n",
        "    } else if (activeTesters.length === 1) {\n",
        "        let m = activeTesters[0].match(/(.+) \\[I?(\\d+)\\]/i);\n",
        "        if(m) {\n",
        "            let tName = m[1].trim().replace(/\\./g, '').replace(/\\s+/g, '-');\n",
        "            pdfTitle = m[2] + \"_\" + tName;\n",
        "        } else {\n",
        "            pdfTitle = activeTesters[0].replace(/[^a-zA-Z0-9]/g, '-');\n",
        "        }\n",
        "    } else if (ancName) {\n",
        "        pdfTitle = cleanName(ancName).replace(/[^a-zA-Z0-9]/g, '-');\n",
        "    }\n",
        "    if (mode === 'assembled') pdfTitle = pdfTitle + \"_Assembled\";\n",
        "    document.title = pdfTitle;\n",
        "\n",
        "    let vgCSS = null;\n",
        "    if (activeTesters.length > 1) {\n",
        "        vgCSS = getCSS(activeTesters);\n",
        "    }\n",
        "\n",
        "    if(mode === 'matrix') {\n",
        "        document.title = \"Master_CSS_Matrix\";\n",
        "        document.getElementById('report-container').innerHTML = getTitlePage() + getMethodologyPage() + getMatrixHTML(vgCSS) + `__APPENDIX_A_HTML__` + getAuthorshipPage();\n",
        "        setTimeout(() => { if(window.init) window.init(); }, 100);\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    const isAssembled = (mode === 'assembled');\n",
        "    const dateStr = new Date().toLocaleDateString('en-US', { year: 'numeric', month: 'long', day: 'numeric' });\n",
        "    let spineHTML = \"\", branchesHTML = \"\", manifestHTML = \"\", verdict = \"INSUFFICIENT DATA\", kitCount = 0, totalCM = 0, targetGen = 0, targetAncestor = cleanName(ancName);\n",
        "    let inferredAncestorText = \"\";\n",
        "\n",
        "    if (activeTesters.length > 1) {\n",
        "        const collaterals = DB.filter(m => activeTesters.includes(m.participant) && m.ancestor !== 'No Matches' && m.ancestor);\n",
        "        kitCount = new Set(collaterals.map(r => r.participant)).size;\n",
        "        totalCM = collaterals.reduce((sum, r) => sum + getCM(r.cm), 0);\n",
        "\n",
        "        let idCounts = {};\n",
        "        collaterals.forEach(m => {\n",
        "            if(m.search_ids) {\n",
        "                let ids = m.search_ids.split(',').map(x=>cleanNum(x));\n",
        "                ids.forEach(id => { if(id) idCounts[id] = (idCounts[id] || 0) + 1; });\n",
        "            }\n",
        "        });\n",
        "\n",
        "        let highestHeat = 0; let targetID = null;\n",
        "        for (let [id, count] of Object.entries(idCounts)) {\n",
        "            const nodeMatches = DB.filter(m => m.search_ids && m.search_ids.split(',').map(x=>cleanNum(x)).includes(id));\n",
        "            const nodeUniqueKits = new Set(nodeMatches.map(m => m.participant)).size;\n",
        "            if (nodeUniqueKits > highestHeat) { highestHeat = nodeUniqueKits; targetID = id; }\n",
        "        }\n",
        "\n",
        "        if (targetID) {\n",
        "            const globalCollaterals = DB.filter(m => m.search_ids && m.search_ids.split(',').map(x=>cleanNum(x)).includes(targetID));\n",
        "            let branches = new Set();\n",
        "            let discoveredName = \"\";\n",
        "            globalCollaterals.forEach(r => {\n",
        "                const ids = r.search_ids.split(',').map(x => cleanNum(x));\n",
        "                const names = r.search_names.split('|');\n",
        "                let idx = ids.indexOf(targetID);\n",
        "                if(idx !== -1) {\n",
        "                    discoveredName = cleanName(names[idx]);\n",
        "                    if (idx + 1 < names.length) {\n",
        "                        branches.add(names[idx+1].replace(/findme/gi, '?').split(' (')[0].trim());\n",
        "                    } else { branches.add(\"Direct Descendant\"); }\n",
        "                }\n",
        "            });\n",
        "            branchesHTML = `<ul class=\"collateral-list\">`;\n",
        "            Object.keys(branches).sort().forEach(b => { branchesHTML += `<li>Descendants via <strong>${b}</strong>: (${branches[b].size} corroborating kits)</li>`; });\n",
        "            branchesHTML += `</ul>`;\n",
        "\n",
        "            manifestHTML = `<table class=\"brief-table\"><thead><tr><th>Supporting DNA Kit</th><th>Shared cM</th><th>Branch Intersecting Path</th></tr></thead><tbody>`;\n",
        "            globalCollaterals.sort((a,b) => getCM(b.cm) - getCM(a.cm)).slice(0, 50).forEach(r => {\n",
        "                const rIDs = r.search_ids.split(',').map(x => cleanNum(x));\n",
        "                const rNames = r.search_names.split('|');\n",
        "                let idx = rIDs.indexOf(targetID);\n",
        "                let downPath = (idx !== -1) ? rNames.slice(idx).slice(0, 4).map(cleanName).join(' &rarr; ') + (rNames.length - idx > 4 ? \"...\" : \"\") : cleanName(r.lineage);\n",
        "                manifestHTML += `<tr><td><strong>${r.participant}</strong></td><td>${r.cm}</td><td style=\"font-size:0.9em;color:#555;\">${downPath}</td></tr>`;\n",
        "            });\n",
        "            if(globalCollaterals.length > 50) manifestHTML += `<tr><td colspan=\"3\" style=\"text-align:center;font-style:italic;\">... plus ${globalCollaterals.length - 50} additional supporting kits.</td></tr>`;\n",
        "            manifestHTML += `</tbody></table>`;\n",
        "\n",
        "            if(!targetAncestor) {\n",
        "                targetAncestor = discoveredName || `Ancestor I${targetID}`;\n",
        "                inferredAncestorText = \" (Discovered via cluster convergence)\";\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if(highestHeat >= 30) verdict = \"PLATINUM STANDARD - FULLY VERIFIED\";\n",
        "        else if(highestHeat >= 15) verdict = \"GOLD STANDARD - STRONGLY VALIDATED\";\n",
        "        else if(highestHeat >= 5) verdict = \"SILVER STANDARD - VERIFIED\";\n",
        "        else if(highestHeat >= 2) verdict = \"BRONZE STANDARD - EMERGING\";\n",
        "    }\n",
        "    else if(activeTesters.length === 1 && ancName) {\n",
        "        const testerName = activeTesters[0];\n",
        "        const myRow = DB.find(r => r.participant === testerName);\n",
        "        if(!myRow || !myRow.t_names) return alert(\"Tester paper trail not found.\");\n",
        "        const ancRow = DB.find(r => r.ancestor === ancName);\n",
        "        if(!ancRow) return alert(\"Ancestor node not found in database.\");\n",
        "        const targetID = cleanNum(ancRow.id);\n",
        "        const tNames = myRow.t_names.split('|');\n",
        "        const tIDs = myRow.t_ids.split('|').map(x => cleanNum(x.split('+')[0]));\n",
        "        const targetIdx = tIDs.indexOf(targetID);\n",
        "        if(targetIdx === -1) return alert(\"This tester's documented lineage does not intersect with the selected ancestor.\");\n",
        "        targetGen = tNames.length - targetIdx;\n",
        "        targetAncestor = cleanName(tNames[targetIdx]);\n",
        "\n",
        "        spineHTML = `<table class=\"brief-table\"><thead><tr><th style=\"width:50px;\">Gen</th><th>Documented Ancestral Lineage</th></tr></thead><tbody>`;\n",
        "        for(let i = targetIdx; i < tNames.length; i++) { spineHTML += `<tr><td><strong>${tNames.length - i}</strong></td><td>${cleanName(tNames[i])}</td></tr>`; }\n",
        "        spineHTML += `</tbody></table>`;\n",
        "\n",
        "        const collaterals = DB.filter(r => r.search_ids && r.search_ids.split(',').map(x => cleanNum(x)).includes(targetID));\n",
        "        kitCount = new Set(collaterals.map(r => r.participant)).size;\n",
        "        totalCM = collaterals.reduce((sum, r) => sum + getCM(r.cm), 0);\n",
        "\n",
        "        let branches = {};\n",
        "        collaterals.forEach(r => {\n",
        "            const ids = r.search_ids.split(',').map(x => cleanNum(x));\n",
        "            const names = r.search_names.split('|');\n",
        "            let idx = ids.indexOf(targetID);\n",
        "            let branchName = (idx !== -1 && idx + 1 < names.length) ? cleanName(names[idx+1]) : \"Direct Descendant\";\n",
        "            if(!branches[branchName]) branches[branchName] = new Set();\n",
        "            branches[branchName].add(r.participant);\n",
        "        });\n",
        "        branchesHTML = `<ul class=\"collateral-list\">`;\n",
        "        Object.keys(branches).sort().forEach(b => { branchesHTML += `<li>Descendants via <strong>${b}</strong>: (${branches[b].size} corroborating kits)</li>`; });\n",
        "        branchesHTML += `</ul>`;\n",
        "\n",
        "        manifestHTML = `<table class=\"brief-table\"><thead><tr><th>Supporting DNA Kit</th><th>Shared cM</th><th>Branch Intersection Path</th></tr></thead><tbody>`;\n",
        "        collaterals.sort((a,b) => getCM(b.cm) - getCM(a.cm)).slice(0, 50).forEach(r => {\n",
        "            const rIDs = r.search_ids.split(',').map(x => cleanNum(x));\n",
        "            const rNames = r.search_names.split('|');\n",
        "            let idx = rIDs.indexOf(targetID);\n",
        "            let downPath = (idx !== -1) ? rNames.slice(idx).slice(0, 4).map(cleanName).join(' &rarr; ') + (rNames.length - idx > 4 ? \"...\" : \"\") : cleanName(r.lineage);\n",
        "            manifestHTML += `<tr><td><strong>${r.participant}</strong></td><td>${r.cm}</td><td style=\"font-size:0.9em;color:#555;\">${downPath}</td></tr>`;\n",
        "        });\n",
        "        if(collaterals.length > 50) manifestHTML += `<tr><td colspan=\"3\" style=\"text-align:center;font-style:italic;\">... plus ${collaterals.length - 50} additional supporting kits.</td></tr>`;\n",
        "        manifestHTML += `</tbody></table>`;\n",
        "    }\n",
        "    else if (activeTesters.length === 1 && !ancName) {\n",
        "        const testerName = activeTesters[0];\n",
        "        const myRow = DB.find(r => r.participant === testerName);\n",
        "        if(!myRow || !myRow.t_names) return alert(\"Tester paper trail not found.\");\n",
        "        const tNames = myRow.t_names.split('|');\n",
        "        const tIDs = myRow.t_ids.split('|').map(x => cleanNum(x.split('+')[0]));\n",
        "        const totalGens = tNames.length;\n",
        "        targetAncestor = cleanName(tNames[0]);\n",
        "        targetGen = totalGens;\n",
        "\n",
        "        spineHTML = `<table class=\"brief-table\"><thead><tr><th style=\"width:50px;\">Gen</th><th>Ancestral Node</th><th style=\"text-align:center;\">Independent Kits</th><th>Status</th></tr></thead><tbody>`;\n",
        "        let highestHeat = 0; let targetID = null;\n",
        "        for(let i=0; i<totalGens; i++) {\n",
        "            const primaryID = tIDs[i];\n",
        "            const nodeMatches = DB.filter(m => m.search_ids && m.search_ids.split(',').map(x=>cleanNum(x)).includes(primaryID));\n",
        "            const nodeHeat = new Set(nodeMatches.map(m => m.participant)).size;\n",
        "            if(nodeHeat > highestHeat) { highestHeat = nodeHeat; targetID = primaryID; }\n",
        "            let statusText = nodeHeat >= 30 ? \"Confirmed Standard (30+)\" : (nodeHeat >= 15 ? \"Confirmed Validation (15+)\" : (nodeHeat >= 5 ? \"Verified Node (5+)\" : (nodeHeat >= 2 ? \"Emerging Node (2+)\" : \"Private Line\")));\n",
        "            if(i === totalGens - 1) statusText = \"Subject Tester\";\n",
        "            spineHTML += `<tr><td><strong>${totalGens - i}</strong></td><td>${cleanName(tNames[i])}</td><td style=\"text-align:center;\">${nodeHeat}</td><td>${statusText}</td></tr>`;\n",
        "        }\n",
        "        spineHTML += `</tbody></table>`;\n",
        "        kitCount = highestHeat;\n",
        "        verdict = highestHeat >= 30 ? \"PLATINUM STANDARD\" : (highestHeat >= 15 ? \"GOLD STANDARD\" : (highestHeat >= 5 ? \"SILVER STANDARD\" : \"INSUFFICIENT DATA\"));\n",
        "\n",
        "        if (targetID && highestHeat > 0) {\n",
        "            const collaterals = DB.filter(m => m.search_ids && m.search_ids.split(',').map(x=>cleanNum(x)).includes(targetID));\n",
        "            totalCM = collaterals.reduce((sum, r) => sum + getCM(r.cm), 0);\n",
        "            let branches = {};\n",
        "            collaterals.forEach(r => {\n",
        "                const ids = r.search_ids.split(',').map(x => cleanNum(x));\n",
        "                const names = r.search_names.split('|');\n",
        "                let idx = ids.indexOf(targetID);\n",
        "                let branchName = (idx !== -1 && idx + 1 < names.length) ? cleanName(names[idx+1]) : \"Direct Descendant\";\n",
        "                if(!branches[branchName]) branches[branchName] = new Set();\n",
        "                branches[branchName].add(r.participant);\n",
        "            });\n",
        "            branchesHTML = `<ul class=\"collateral-list\">`;\n",
        "            Object.keys(branches).sort().forEach(b => { branchesHTML += `<li>Descendants via <strong>${b}</strong>: (${branches[b].size} corroborating kits)</li>`; });\n",
        "            branchesHTML += `</ul>`;\n",
        "\n",
        "            manifestHTML = `<table class=\"brief-table\"><thead><tr><th>Supporting DNA Kit</th><th>Shared cM</th><th>Branch Intersecting Path</th></tr></thead><tbody>`;\n",
        "            collaterals.sort((a,b) => getCM(b.cm) - getCM(a.cm)).slice(0, 50).forEach(r => {\n",
        "                const rIDs = r.search_ids.split(',').map(x => cleanNum(x));\n",
        "                const rNames = r.search_names.split('|');\n",
        "                let idx = rIDs.indexOf(targetID);\n",
        "                let downPath = (idx !== -1) ? rNames.slice(idx).slice(0, 4).map(cleanName).join(' &rarr; ') + (rNames.length - idx > 4 ? \"...\" : \"\") : cleanName(r.lineage);\n",
        "                manifestHTML += `<tr><td><strong>${r.participant}</strong></td><td>${r.cm}</td><td style=\"font-size:0.9em;color:#555;\">${downPath}</td></tr>`;\n",
        "            });\n",
        "            if(collaterals.length > 50) manifestHTML += `<tr><td colspan=\"3\" style=\"text-align:center;font-style:italic;\">... plus ${collaterals.length - 50} additional supporting kits.</td></tr>`;\n",
        "            manifestHTML += `</tbody></table>`;\n",
        "        }\n",
        "    }\n",
        "    else if (activeTesters.length === 0 && ancName) {\n",
        "        const ancRow = DB.find(r => r.ancestor === ancName);\n",
        "        if(!ancRow) return alert(\"Ancestor node not found in database.\");\n",
        "        const targetID = cleanNum(ancRow.id);\n",
        "        const collaterals = DB.filter(r => r.search_ids && r.search_ids.split(',').map(x => cleanNum(x)).includes(targetID));\n",
        "        kitCount = new Set(collaterals.map(r => r.participant)).size;\n",
        "        totalCM = collaterals.reduce((sum, r) => sum + getCM(r.cm), 0);\n",
        "\n",
        "        let branches = {};\n",
        "        collaterals.forEach(r => {\n",
        "            const ids = r.search_ids.split(',').map(x => cleanNum(x));\n",
        "            const names = r.search_names.split('|');\n",
        "            let idx = ids.indexOf(targetID);\n",
        "            let branchName = (idx !== -1 && idx + 1 < names.length) ? cleanName(names[idx+1]) : \"Direct Descendant\";\n",
        "            if(!branches[branchName]) branches[branchName] = new Set();\n",
        "            branches[branchName].add(r.participant);\n",
        "        });\n",
        "\n",
        "        branchesHTML = `<ul class=\"collateral-list\">`;\n",
        "        Object.keys(branches).sort().forEach(b => { branchesHTML += `<li>Descendants via <strong>${b}</strong>: (${branches[b].size} corroborating kits)</li>`; });\n",
        "        branchesHTML += `</ul>`;\n",
        "\n",
        "        manifestHTML = `<table class=\"brief-table\"><thead><tr><th>Supporting DNA Kit</th><th>Shared cM</th><th>Branch Intersecting Path</th></tr></thead><tbody>`;\n",
        "        collaterals.sort((a,b) => getCM(b.cm) - getCM(a.cm)).slice(0, 50).forEach(r => {\n",
        "            const rIDs = r.search_ids.split(',').map(x => cleanNum(x));\n",
        "            const rNames = r.search_names.split('|');\n",
        "            let idx = rIDs.indexOf(targetID);\n",
        "            let downPath = (idx !== -1) ? rNames.slice(idx).slice(0, 4).map(cleanName).join(' &rarr; ') + (rNames.length - idx > 4 ? \"...\" : \"\") : cleanName(r.lineage);\n",
        "            manifestHTML += `<tr><td><strong>${r.participant}</strong></td><td>${r.cm}</td><td style=\"font-size:0.9em;color:#555;\">${downPath}</td></tr>`;\n",
        "        });\n",
        "        if(collaterals.length > 50) manifestHTML += `<tr><td colspan=\"3\" style=\"text-align:center;font-style:italic;\">... plus ${collaterals.length - 50} additional supporting kits.</td></tr>`;\n",
        "        manifestHTML += `</tbody></table>`;\n",
        "\n",
        "        if(kitCount >= 30) verdict = \"PLATINUM STANDARD - FULLY VERIFIED\";\n",
        "        else if(kitCount >= 15) verdict = \"GOLD STANDARD - STRONGLY VALIDATED\";\n",
        "        else if(kitCount >= 5) verdict = \"SILVER STANDARD - VERIFIED\";\n",
        "        else if(kitCount >= 2) verdict = \"BRONZE STANDARD - EMERGING\";\n",
        "    }\n",
        "\n",
        "    let reportHTML = isAssembled ? getTitlePage() + getMethodologyPage() : '';\n",
        "    let pbStyle = isAssembled ? 'page-break-before: always;' : '';\n",
        "\n",
        "    let subjectHeader = \"\";\n",
        "    if (activeTesters.length > 1) {\n",
        "        let kitList = activeTesters.map(t => `<li style=\"margin-bottom:3px;\">${t}</li>`).join(\"\");\n",
        "        subjectHeader = `<strong>Subject Tester:</strong> VIRTUAL GROUP (${activeTesters.length} Kits)<br><ul style=\"margin:5px 0 10px 0; padding-left:20px; font-size:13px; color:#333; font-weight:bold;\">${kitList}</ul>`;\n",
        "    } else if (activeTesters.length === 1) {\n",
        "        subjectHeader = `<strong>Subject Tester:</strong> ${activeTesters[0]}<br>`;\n",
        "    }\n",
        "\n",
        "    let execPara = activeTesters.length > 1 ?\n",
        "        `This brief evaluates the composite genetic evidence of a Virtual Group comprising ${activeTesters.length} individual testers. By pooling their isolated matches into a single structural cluster, we test if their combined evidence satisfies the Collateral Saturation threshold for proof-grade lineage assignment. The documentary paper trail is corroborated by <strong>${kitCount} independent participant kits</strong> sharing an aggregate of <strong>${totalCM.toLocaleString()} cM</strong> of Autosomal DNA.` :\n",
        "        `This brief evaluates the genetic evidence corroborating the descent from the Target Ancestral Node. Through the application of Collateral DNA Saturation methodology, the documentary paper trail is corroborated by <strong>${kitCount} independent participant kits</strong> sharing an aggregate of <strong>${totalCM.toLocaleString()} cM</strong> of Autosomal DNA.`;\n",
        "\n",
        "    reportHTML += `\n",
        "    <div class=\"academic-brief\" style=\"${pbStyle}\">\n",
        "        ${!isAssembled ? `<div class=\"brief-header\"><h1>Formal Genetic Lineage Brief</h1><p>Biological Verification via Collateral Saturation</p></div>` : ''}\n",
        "        <div class=\"brief-meta\">\n",
        "            ${subjectHeader}\n",
        "            <strong>${(!ancName && activeTesters.length > 1) ? 'Inferred Target Node (Consensus):' : 'Target Ancestral Node:'}</strong> ${targetAncestor} ${inferredAncestorText} ${targetGen ? `(Gen ${targetGen})` : ''}<br>\n",
        "            <strong>Date Compiled:</strong> ${dateStr}<br>\n",
        "            <strong>Study Authority:</strong> Yates One-Name Study (ONS)<br>\n",
        "            <strong>Database Status:</strong> ${getStudyStats()}\n",
        "        </div>\n",
        "\n",
        "        <div class=\"brief-section-title\">${getSec()} Executive Abstract</div>\n",
        "        <p>${execPara}</p>\n",
        "\n",
        "        ${isAssembled ? getDiagnosticHTML(activeTesters, ancName) : ''}\n",
        "\n",
        "        ${spineHTML !== \"\" ? `\n",
        "        <div class=\"brief-section-title\">${getSec()} Documented Lineage Spine</div>\n",
        "        <p>The following genealogical paper trail connects the Subject Tester directly to the Target Ancestral Node:</p>\n",
        "        ${spineHTML}` : ''}\n",
        "\n",
        "        ${branchesHTML !== \"\" ? `\n",
        "        <div class=\"brief-section-title\" style=\"page-break-before: always;\">${getSec()} Genetic Convergence (The Forensic Handshake)</div>\n",
        "        <p>To rule out isolated coincidence or false-positive segment sharing, genetic genealogy relies on triangulation and cluster saturation. The biological integrity of this node is verified by independent lines of descent converging from the following documented children:</p>\n",
        "        ${branchesHTML}` : ''}\n",
        "\n",
        "        ${manifestHTML !== \"\" ? `\n",
        "        <div class=\"brief-section-title\">${getSec()} Empirical Data Manifest (Top 50 Kits)</div>\n",
        "        ${manifestHTML}` : ''}\n",
        "\n",
        "        <div class=\"verdict-stamp\">FORENSIC STATUS: ${verdict}</div>\n",
        "    </div>`;\n",
        "\n",
        "    if(isAssembled) {\n",
        "        reportHTML += getMatrixHTML(vgCSS);\n",
        "        reportHTML += `__APPENDIX_A_HTML__`;\n",
        "        reportHTML += getAuthorshipPage();\n",
        "    }\n",
        "\n",
        "    document.getElementById('report-container').innerHTML = reportHTML;\n",
        "    setTimeout(() => { if(window.init) window.init(); }, 100);\n",
        "}\n",
        "\n",
        "// Ensure mutual exclusivity in UI\n",
        "document.getElementById('testerSelect').addEventListener('change', function() {\n",
        "    if(this.value) {\n",
        "        document.querySelectorAll('.vg-checkbox').forEach(cb => cb.checked = false);\n",
        "    }\n",
        "});\n",
        "document.getElementById('groupCheckboxes').addEventListener('change', function(e) {\n",
        "    if(e.target.classList.contains('vg-checkbox')) {\n",
        "        if(e.target.checked) document.getElementById('testerSelect').value = \"\";\n",
        "    }\n",
        "});\n",
        "</script>\"\"\".replace('__APPENDIX_A_HTML__', APPENDIX_A_HTML)\n",
        "\n",
        "CONSOLIDATOR_HTML = f\"\"\"\n",
        "<div class=\"no-print consol-panel\">\n",
        "    <h2 style=\"color:#4a148c; margin-top:0;\">The Omni-Proof Consolidator</h2>\n",
        "    <p style=\"color:#555; margin-bottom:20px;\">Generate a formal academic white-paper. Select a Tester, an Ancestor, or compute the Master Matrix.</p>\n",
        "\n",
        "    <div style=\"display:flex; justify-content:center; gap:15px; flex-wrap:wrap; margin-bottom:15px;\">\n",
        "        <div style=\"flex:1; min-width:250px; text-align:left;\">\n",
        "            <label style=\"font-size:12px; font-weight:bold; color:#4a148c;\">1A. Select Single Tester</label>\n",
        "            <select id=\"testerSelect\" style=\"width:100%; padding:8px; border:1px solid #7b1fa2; border-radius:4px;\"><option value=\"\">-- Choose One --</option></select>\n",
        "        </div>\n",
        "        <div style=\"flex:1; min-width:250px; text-align:left;\">\n",
        "            <label style=\"font-size:12px; font-weight:bold; color:#e65100;\">1B. OR Create Virtual Group</label>\n",
        "            <div id=\"groupCheckboxes\" class=\"vg-checkbox-container\"></div>\n",
        "            <div style=\"font-size:11px; color:#666; margin-top:3px;\">*Check multiple kits to pool evidence</div>\n",
        "        </div>\n",
        "        <div style=\"flex:1; min-width:250px; text-align:left;\">\n",
        "            <label style=\"font-size:12px; font-weight:bold; color:#4a148c;\">2. Select Target Ancestor (Optional)</label>\n",
        "            <select id=\"ancestorSelect\" style=\"width:100%; padding:8px; border:1px solid #7b1fa2; border-radius:4px;\"><option value=\"\">-- Choose Target --</option></select>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <button class=\"consol-btn\" onclick=\"runConsolidator('brief')\">Generate Formal Brief</button>\n",
        "    <button class=\"consol-btn\" style=\"background:#2e7d32; margin-left:10px;\" onclick=\"runConsolidator('matrix')\">üìä Generate CSS Matrix</button>\n",
        "    <button class=\"consol-btn\" style=\"background:#e65100; margin-left:10px;\" onclick=\"runConsolidator('assembled')\">üìö Assembled Report</button>\n",
        "    <button class=\"consol-btn no-print\" style=\"background:#0277bd; margin-left:10px;\" onclick=\"window.print()\">üñ®Ô∏è Print to PDF</button>\n",
        "</div>\n",
        "<div id=\"report-container\"></div>\n",
        "\"\"\"\n",
        "\n",
        "# Bind Legal Footer to regular tools\n",
        "BIO_TMPL = BIO_TMPL.replace('</div></div></div><script>', '</div>__LEGAL_FOOTER__</div></div><script>')\n",
        "PROOF_TMPL = PROOF_TMPL.replace('</table></div></div></div></div><script>', '</table></div></div>__LEGAL_FOOTER__</div></div><script>')\n",
        "DOSS_TMPL = DOSS_TMPL.replace('<div id=\"report-stack\"></div></div><script>', '<div id=\"report-stack\"></div>__LEGAL_FOOTER__</div><script>')\n",
        "BUST_TMPL = BUST_TMPL.replace('<div id=\"cluster-table-div\"></div></div></div></div><script>', '<div id=\"cluster-table-div\"></div></div>__LEGAL_FOOTER__</div></div><script>')\n",
        "\n",
        "print(\"‚úÖ Cell 4 (Template Library) Loaded Successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoXW3hacE5bG",
        "outputId": "34d15284-854e-44d3-b90f-30de4af35ca4"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "      [CELL 4] TEMPLATE LIBRARY LOADING...\n",
            "============================================================\n",
            "‚úÖ Cell 4 (Template Library) Loaded Successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qcAe9eQMoUf",
        "outputId": "100ede6f-3c27-4967-a20b-0f1bc49b1259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Cell 4 Loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNfvxw6bkFjE",
        "outputId": "c0e7f22f-abea-4b00-9eb1-3eda9745a50e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "      MASTER ORCHESTRATOR (V81)\n",
            "      (Running Engine -> Publisher -> Upload)\n",
            "============================================================\n",
            "\n",
            ">>> üöÄ PHASE 1: EXECUTING DATA ENGINE...\n",
            "============================================================\n",
            "      [CELL 3] ENGINE STARTING (V113 - CLEAN)...\n",
            "============================================================\n",
            "\n",
            "[STEP 1] Setup...\n",
            "    üëâ Source: yates_study_2025.ged\n",
            "\n",
            "[STEP 4] Tracing Lineages...\n",
            "\n",
            "[SUCCESS] Engine V113 Complete. Saved 1712 verified matches to engine_database.csv.\n",
            "‚úÖ PHASE 1 COMPLETE.\n",
            "\n",
            ">>> üåê PHASE 2: EXECUTING PUBLISHER & UPLOAD...\n",
            "============================================================\n",
            "      [CELL 4] PUBLISHER STARTING (Upgraded V8)...\n",
            "============================================================\n",
            "    ‚úÖ Core Registers and Static Pages Built Locally.\n",
            "\n",
            "[PHASE 3] Uploading via FTP to Live Server...\n",
            "    üì§ Uploaded: contents.shtml\n",
            "    üì§ Uploaded: subscribe.shtml\n",
            "    üì§ Uploaded: ons_yates_dna_register.shtml\n",
            "    üì§ Uploaded: research_admin.html\n",
            "    üì§ Uploaded: brick_wall_buster.shtml\n",
            "    üì§ Uploaded: ons_yates_dna_register_participants.shtml\n",
            "    üì§ Uploaded: dna_dossier.html\n",
            "    üì§ Uploaded: engine_database.csv\n",
            "    üì§ Uploaded: share_dna.shtml\n",
            "    üì§ Uploaded: lineage_proof.html\n",
            "    üì§ Uploaded: admin_singletons_participants.shtml\n",
            "    üì§ Uploaded: dna_theory_of_the_case.htm\n",
            "    üì§ Uploaded: just-trees-az.shtml\n",
            "    üì§ Uploaded: yates_ancestor_register.shtml\n",
            "    üì§ Uploaded: just-trees.shtml\n",
            "    üì§ Uploaded: data_glossary.shtml\n",
            "    üì§ Uploaded: biological_proof.html\n",
            "    üì§ Uploaded: admin_singletons.shtml\n",
            "    üì§ Uploaded: dna_network.shtml\n",
            "\n",
            "üéâ MASTER PIPELINE COMPLETE. Check your live site.\n",
            "‚úÖ PHASE 2 COMPLETE.\n",
            "\n",
            "============================================================\n",
            "      üèÜ V81 UPDATE SUCCESSFUL\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr5VToo07xOg",
        "outputId": "471cae48-5258-495f-cd1a-7b716d3567f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Cell 5 Loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bED6aQmM-hnY",
        "outputId": "1b3d05f4-a576-47a0-8e38-f6f4da26d769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Cell 5 Loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [CELL 5] Core Publisher & FTP Uploader (V26: Admin Hub Hotlinks Restored)\n",
        "def run_publisher():\n",
        "    print(\"=\"*60)\n",
        "    print(\"      [CELL 5] PUBLISHER STARTING (Upgraded V26 - Hotlinks Restored)...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    import os, re, pytz, json, csv\n",
        "    import pandas as pd\n",
        "    from datetime import datetime\n",
        "    from google.colab import userdata\n",
        "    from ftplib import FTP_TLS\n",
        "\n",
        "    if 'LEGAL_FOOTER_TMPL' not in globals():\n",
        "        return print(\"‚ùå ERROR: Templates not found. You must run Cell 4 first!\")\n",
        "\n",
        "    try:\n",
        "        HOST = os.environ.get(\"FTP_HOST\") or userdata.get(\"FTP_HOST\")\n",
        "        USER = os.environ.get(\"FTP_USER\") or userdata.get(\"FTP_USER\")\n",
        "        PASS = os.environ.get(\"FTP_PASS\") or userdata.get(\"FTP_PASS\")\n",
        "    except Exception as e:\n",
        "        return print(f\"‚ùå Credential Error: {e}\")\n",
        "\n",
        "    REMOTE_SUBDIR = \"ons-study\"\n",
        "    CSV_DB = \"engine_database.csv\"\n",
        "    KEY_FILE = \"match_to_unmasked.csv\"\n",
        "\n",
        "    if not os.path.exists(CSV_DB): return print(\"‚ùå ERROR: engine_database.csv not found.\")\n",
        "\n",
        "    # üåü LOCAL FIRST LOGIC\n",
        "    print(f\"\\n[STEP 1] Resolving {KEY_FILE}...\")\n",
        "    if os.path.exists(KEY_FILE):\n",
        "        print(f\"    ‚úÖ Found {KEY_FILE} locally. Skipping FTP download.\")\n",
        "    else:\n",
        "        try:\n",
        "            ftps = FTP_TLS()\n",
        "            ftps.connect(HOST, 21); ftps.auth(); ftps.login(USER, PASS); ftps.prot_p()\n",
        "            try:\n",
        "                with open(KEY_FILE, \"wb\") as f: ftps.retrbinary(f\"RETR /{REMOTE_SUBDIR}/{KEY_FILE}\", f.write)\n",
        "                print(f\"    ‚úÖ Successfully downloaded {KEY_FILE}.\")\n",
        "            except Exception as e:\n",
        "                print(f\"    ‚ö†Ô∏è FTP download failed: {e}\")\n",
        "            ftps.quit()\n",
        "        except Exception as e:\n",
        "            pass\n",
        "\n",
        "    df = pd.read_csv(CSV_DB, encoding=\"iso-8859-15\")\n",
        "    df.fillna('', inplace=True)\n",
        "    df.replace('nan', '', inplace=True)\n",
        "\n",
        "    # üåü PRIVACY-FOCUSED TRUNCATION ALGORITHM (P.K. Musick) üåü\n",
        "    def shorten_name(full_name):\n",
        "        if pd.isna(full_name) or str(full_name).lower() == 'nan' or not str(full_name).strip(): return \"Unknown\"\n",
        "        s = re.sub(r'\\[.*?\\]', '', str(full_name)).strip() # Remove any existing brackets\n",
        "        parts = s.split()\n",
        "        if len(parts) <= 1: return s\n",
        "\n",
        "        # Handle Suffixes cleanly\n",
        "        suffix = \"\"\n",
        "        if parts[-1].lower() in ['jr', 'jr.', 'sr', 'sr.', 'iii', 'iv', 'v', 'md', 'm.d.', 'esq', 'esq.']:\n",
        "            suffix = \" \" + parts.pop()\n",
        "\n",
        "        if len(parts) == 1: return parts[0] + suffix\n",
        "\n",
        "        # Convert all first/middle names to concatenated initials (e.g. \"P.K.\")\n",
        "        initials = \"\".join([p[0].upper() + \".\" for p in parts[:-1]])\n",
        "        last_name = parts[-1]\n",
        "\n",
        "        return f\"{initials} {last_name}{suffix}\"\n",
        "\n",
        "    # üåü EXTRACT GEDCOM IDS TO RESTORE ADMIN HOTLINKS\n",
        "    db_ids = {}\n",
        "    for _, r in df.iterrows():\n",
        "        c = str(r.get('Tester_Code', '')).strip().lower()\n",
        "        i = str(r.get('Tester_ID', '')).replace('I', '').strip()\n",
        "        if c and i and i != 'nan':\n",
        "            db_ids[c] = i\n",
        "\n",
        "    tester_auth = []\n",
        "    if os.path.exists(KEY_FILE):\n",
        "        with open(KEY_FILE, 'r', errors='replace') as f:\n",
        "            reader = csv.reader(f)\n",
        "            for i, row in enumerate(reader):\n",
        "                if len(row) >= 2:\n",
        "                    if i == 0 and (\"tester\" in row[0].lower() or \"masked\" in row[0].lower() or \"code\" in row[0].lower()):\n",
        "                        continue\n",
        "                    code = row[0].strip().lower()\n",
        "                    name = row[1].strip()\n",
        "                    tid = row[2].strip() if len(row) > 2 else \"\"\n",
        "                    tid = re.sub(r'[^0-9]', '', tid)\n",
        "                    if code in db_ids:\n",
        "                        tid = db_ids[code]  # Prioritize the exact TNG ID from the GEDCOM\n",
        "                    tester_auth.append({'Kit_Code': code, 'Tester_Name': shorten_name(name), 'Tester_ID': tid})\n",
        "\n",
        "    df_testers = pd.DataFrame(tester_auth)\n",
        "    if df_testers.empty:\n",
        "        fallback = []\n",
        "        for kcode, grp in df.groupby('Tester_Code'):\n",
        "            tid = str(grp.iloc[0]['Tester_ID']).replace('I','').strip()\n",
        "            fallback.append({'Kit_Code': kcode, 'Tester_Name': shorten_name(grp.iloc[0]['Tester_Name']), 'Tester_ID': tid})\n",
        "        df_testers = pd.DataFrame(fallback)\n",
        "\n",
        "    # Apply truncation directly to the main dataframe\n",
        "    df['Kit_Name'] = df.apply(\n",
        "        lambda r: f\"{shorten_name(r['Tester_Name'])} [I{re.sub(r'[^0-9]','',str(r['Tester_ID']))}]\"\n",
        "        if pd.notna(r['Tester_ID']) and re.sub(r'[^0-9]','',str(r['Tester_ID']))\n",
        "        else f\"{shorten_name(r['Tester_Name'])} [{r['Tester_Code']}]\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    df.rename(columns={\n",
        "        \"Authority_Directory_Label\": \"Dir_Label\",\n",
        "        \"Authority_FirstAncestor_alpha\": \"Alpha_Key\",\n",
        "        \"Tester_Code\": \"Kit_Code\",\n",
        "        \"Match_Lineage\": \"Lineage\",\n",
        "        \"Match_Path_IDs\": \"s_ids\"\n",
        "    }, inplace=True)\n",
        "\n",
        "    def normalize_id(val): return f\"I{str(val).replace('@', '').strip()}\" if str(val).replace('@', '').strip().isdigit() else str(val).replace('@', '').strip()\n",
        "\n",
        "    df['search_ids'] = df['s_ids']\n",
        "    df['search_names'] = df['Lineage'].astype(str).str.replace(' -> ', '|')\n",
        "    df['t_names'] = df['Tester_Lineage'].astype(str).str.replace(' -> ', '|')\n",
        "    df['t_ids'] = df['Tester_Path_IDs'].astype(str).str.replace(',', '|')\n",
        "    df['Linked_Tree_Line'] = df.apply(lambda r: str(r.get('Lineage', '')).replace(str(r.get('Match_Name', '')), f'<a href=\"https://yates.one-name.net/tng/verticalchart.php?personID={normalize_id(r.get(\"Match_ID\", \"\"))}&tree=tree1&parentset=0&display=vertical&generations=15\" target=\"_blank\" style=\"color:#006064;text-decoration:none;font-weight:bold;\">{r.get(\"Match_Name\", \"\")}</a>') if str(r.get('Match_Name', '')) in str(r.get('Lineage', '')) else str(r.get('Lineage', '')), axis=1)\n",
        "\n",
        "    est = pytz.timezone('US/Eastern')\n",
        "    current_year = datetime.now(est).year\n",
        "    timestamp = datetime.now(est).strftime(\"%B %d, %Y %-I:%M %p EST\")\n",
        "    stats_bar_full = f'<div style=\"background:#f4f4f4;border-top:1px solid #ddd;border-bottom:1px solid #ddd;font-family:sans-serif;font-size:12px;color:#555;padding:8px 15px;text-align:center;margin-bottom:0;\"><strong>Study Data Current As Of:</strong> {timestamp} | <strong>Total Autosomal matches:</strong> {len(df):,}</div>'\n",
        "    LEGAL_FOOTER = LEGAL_FOOTER_TMPL.replace('__YEAR__', str(current_year))\n",
        "\n",
        "    def get_sort_key(name):\n",
        "        if pd.isna(name) or not name: return \"zzz\"\n",
        "        s = str(name)\n",
        "        s = re.sub(r'\\[.*?\\]', '', s) # Strip ID before sorting\n",
        "        cleaned = re.sub(r'\\b(jr\\.?|sr\\.?|iii|iv|v|md|m\\.d\\.|esq\\.?)\\b', '', s, flags=re.IGNORECASE)\n",
        "        parts = re.split(r'\\bnee\\b|\\bn√©e\\b', cleaned.lower())[0].replace(',', '').replace('.', '').strip().split()\n",
        "        return parts[-1] if parts else \"zzz\"\n",
        "\n",
        "    match_counts = df.groupby('Kit_Code').size().reset_index(name='Match_Count')\n",
        "    part_stats = pd.merge(df_testers, match_counts, on='Kit_Code', how='left')\n",
        "    part_stats['Match_Count'] = part_stats['Match_Count'].fillna(0).astype(int)\n",
        "    part_stats['Sort_Key'] = part_stats['Tester_Name'].apply(get_sort_key)\n",
        "\n",
        "    total_m = part_stats['Match_Count'].sum()\n",
        "    total_participants = len(part_stats)\n",
        "\n",
        "    def make_admin_row(r):\n",
        "        tid = str(r['Tester_ID']).strip()\n",
        "        tname = str(r[\"Tester_Name\"])\n",
        "        kcode = str(r[\"Kit_Code\"])\n",
        "        mc = r['Match_Count']\n",
        "        if tid and tid != 'nan' and tid != '':\n",
        "            t_link = f'<a href=\"https://yates.one-name.net/tng/getperson.php?personID=I{tid}&tree=tree1\" target=\"_blank\" style=\"color:#00838f;text-decoration:underline;font-weight:bold;\">{tname}</a>'\n",
        "            tid_display = f\" <span style='color:#777;font-size:0.85em;'>[I{tid}]</span>\"\n",
        "        else:\n",
        "            t_link = f'<b style=\"color:#333;\">{tname}</b>'\n",
        "            tid_display = \"\"\n",
        "        mc_str = f\"<span style='color:#d32f2f;font-weight:bold;'>0</span>\" if mc == 0 else str(mc)\n",
        "        return f\"<tr><td data-sort='{r['Sort_Key']}'>{t_link}{tid_display}<br><span style='color:#666;font-size:0.85em;'>Kit: {kcode}</span></td><td style='text-align:center;font-size:1.1em;vertical-align:middle;'>{mc_str}</td></tr>\"\n",
        "\n",
        "    part_stats_az = part_stats.sort_values(['Sort_Key', 'Tester_Name'], ascending=[True, True])\n",
        "    admin_rows_az = [make_admin_row(r) for _, r in part_stats_az.iterrows()]\n",
        "    part_stats_asc = part_stats.sort_values(['Match_Count', 'Sort_Key'], ascending=[True, True])\n",
        "    admin_rows_asc = [make_admin_row(r) for _, r in part_stats_asc.iterrows()]\n",
        "\n",
        "    anc_data = {}; part_data = {}\n",
        "    for lbl, grp in df.groupby('Dir_Label'):\n",
        "        if len(grp)<2: continue\n",
        "        unique_t = len(grp['Kit_Name'].unique())\n",
        "        integ = min(100, (len(grp)*2) + (unique_t*10))\n",
        "        anc_data[grp.iloc[0]['Alpha_Key']] = {\n",
        "            \"name\": lbl, \"matches\": len(grp), \"cm\": int(grp['cM'].sum()),\n",
        "            \"badge\": \"Platinum\" if len(grp)>=30 else \"Gold\" if len(grp)>=15 else \"Silver\" if len(grp)>=5 else \"Bronze\",\n",
        "            \"list_data\": grp['Kit_Name'].value_counts().head(3).to_dict(),\n",
        "            \"verdict\": \"Verified.\", \"integrity\": integ, \"testers\": unique_t\n",
        "        }\n",
        "\n",
        "    for kname, grp in df.groupby('Kit_Name'):\n",
        "        dir_lbl = grp.iloc[0]['Dir_Label']\n",
        "        same_dir = df[df['Dir_Label'] == dir_lbl] if pd.notna(dir_lbl) else pd.DataFrame()\n",
        "        integ = min(100, len(same_dir) * 5)\n",
        "        part_data[kname] = {\n",
        "            \"name\": kname, \"sort_key\": get_sort_key(kname), \"matches\": len(grp), \"cm\": int(grp['cM'].sum()),\n",
        "            \"badge\": \"Keystone Tester\" if len(grp)>=15 else \"Study Participant\",\n",
        "            \"list_data\": grp['Dir_Label'].value_counts().head(3).to_dict(),\n",
        "            \"verdict\": f\"Verified matches across {len(grp['Dir_Label'].unique())} ancestral lines.\",\n",
        "            \"integrity\": integ, \"testers\": 1\n",
        "        }\n",
        "\n",
        "    for _, r in part_stats[part_stats['Match_Count'] == 0].iterrows():\n",
        "        tid = str(r['Tester_ID']).strip()\n",
        "        kname = f\"{r['Tester_Name']} [I{tid}]\" if tid else f\"{r['Tester_Name']} [{r['Kit_Code']}]\"\n",
        "        if kname not in part_data:\n",
        "            part_data[kname] = {\n",
        "                \"name\": kname, \"sort_key\": r['Sort_Key'], \"matches\": 0, \"cm\": 0,\n",
        "                \"badge\": \"Pending Matches\", \"list_data\": {\"No Matching DNA in Database\": 0},\n",
        "                \"verdict\": \"This kit has no matching DNA records in the study database yet.\",\n",
        "                \"integrity\": 0, \"testers\": 1\n",
        "            }\n",
        "\n",
        "    smart_json = json.dumps({\"ancestors\": anc_data, \"participants\": part_data})\n",
        "    db_json = df[['Dir_Label', 'Kit_Name', 'cM', 'Match_ID', 'Lineage', 'search_ids', 'search_names', 't_names', 't_ids', 'Tester_ID']].rename(columns={'Dir_Label':'ancestor', 'Kit_Name':'participant', 'cM':'cm', 'Match_ID':'id', 'Lineage':'lineage', 'Tester_ID':'tester_id'}).to_json(orient='records')\n",
        "    JS_GLOBALS = f\"const DATA={smart_json}; const DB={db_json};\"\n",
        "\n",
        "    def make_page(title, content, nav_b, bar, extra_css=\"\"):\n",
        "        s_info = SITE_INFO if nav_b else \"\"\n",
        "        return f\"<!DOCTYPE html>\\n<html lang=\\\"en\\\">\\n<head>\\n<meta charset=\\\"UTF-8\\\">\\n<title>{title}</title>\\n<link rel=\\\"stylesheet\\\" href=\\\"partials_unified.css\\\">\\n<link rel=\\\"stylesheet\\\" href=\\\"dna_tree_styles.css\\\">\\n{extra_css}\\n</head>\\n<body id=\\\"top\\\">\\n<div class=\\\"wrap\\\">\\n<h1 class=\\\"centerline no-print\\\">{title}</h1>\\n<div id=\\\"nav-slot\\\">{bar}{NAV_HTML}</div>\\n{s_info}{content}\\n</div>\\n{LEGAL_FOOTER}{JS_CORE}{BTT_BTN}\\n</body>\\n</html>\"\n",
        "\n",
        "    print(\"\\n[STEP 2] Building HTML Files...\")\n",
        "    pages_to_upload = {}\n",
        "\n",
        "    pages_to_upload[\"proof_consolidator.html\"] = make_page(\"Proof Consolidator\", CONSOLIDATOR_HTML, False, stats_bar_full, extra_css=CONSOLIDATOR_CSS).replace('</body>', CONSOLIDATOR_JS.replace('__JS_GLOBALS__', JS_GLOBALS) + '</body>')\n",
        "    pages_to_upload[\"biological_proof.html\"] = BIO_TMPL.replace('__CSS_BASE__', CSS_BASE).replace('__STATS_BAR__', stats_bar_full).replace('__NAV_HTML__', NAV_HTML).replace('__JS_GLOBALS__', JS_GLOBALS).replace('__PRINT_STATS__', stats_bar_full).replace('__LEGAL_FOOTER__', LEGAL_FOOTER)\n",
        "    pages_to_upload[\"lineage_proof.html\"] = PROOF_TMPL.replace('__STATS_BAR__', stats_bar_full).replace('__NAV_HTML__', NAV_HTML).replace('__JS_GLOBALS__', JS_GLOBALS).replace('__PRINT_STATS__', stats_bar_full).replace('__LEGAL_FOOTER__', LEGAL_FOOTER)\n",
        "    pages_to_upload[\"dna_dossier.html\"] = DOSS_TMPL.replace('__STATS_BAR__', stats_bar_full).replace('__NAV_HTML__', NAV_HTML).replace('__JS_GLOBALS__', JS_GLOBALS).replace('__LEGAL_FOOTER__', LEGAL_FOOTER)\n",
        "    pages_to_upload[\"brick_wall_buster.shtml\"] = BUST_TMPL.replace('__STATS_BAR__', stats_bar_full).replace('__NAV_HTML__', NAV_HTML).replace('__JS_GLOBALS__', JS_GLOBALS).replace('__LEGAL_FOOTER__', LEGAL_FOOTER)\n",
        "\n",
        "    admin_content = f\"\"\"<div class=\"dashboard-grid\"><a href=\"ons_yates_dna_register.shtml\" class=\"dash-card\"><span class=\"dash-icon\">üìã</span><span class=\"dash-title\">DNA Register</span></a><a href=\"dna_network.shtml\" class=\"dash-card\"><span class=\"dash-icon\">üï∏Ô∏è</span><span class=\"dash-title\">DNA Network</span></a><a href=\"proof_consolidator.html\" class=\"dash-card\" style=\"border-color:#4a148c; background:#f3e5f5;\"><span class=\"dash-icon\">üéì</span><span class=\"dash-title\" style=\"color:#4a148c;\">Proof Consolidator</span></a><a href=\"biological_proof.html\" class=\"dash-card\"><span class=\"dash-icon\">üìú</span><span class=\"dash-title\">Bio Proof</span></a><a href=\"lineage_proof.html\" class=\"dash-card\"><span class=\"dash-icon\">üß¨</span><span class=\"dash-title\">Proof Engine</span></a><a href=\"dna_dossier.html\" class=\"dash-card\"><span class=\"dash-icon\">üìÅ</span><span class=\"dash-title\">Forensic Dossier</span></a></div>\n",
        "    <div class=\"audit-table-wrapper\">\n",
        "        <h2 style=\"color:#004d40;border-bottom:2px solid #004d40;padding-bottom:10px;margin-top:0;\">Participant Activity Report - {total_participants} Official Testers</h2>\n",
        "        <div style=\"text-align:center;margin:20px 0;\"><a href=\"admin_singletons.shtml\" style=\"padding:10px 20px;text-decoration:none;border-radius:4px;font-weight:bold;display:inline-block;background:#fbc02d;color:#333;margin-right:10px;\">üîç View Singleton Lines</a><a href=\"engine_database.csv\" style=\"padding:10px 20px;text-decoration:none;border-radius:4px;font-weight:bold;display:inline-block;background:#455a64;color:white;\">‚¨áÔ∏è Download CSV</a></div>\n",
        "        <div style=\"display:flex; gap:30px; flex-wrap:wrap;\">\n",
        "            <div style=\"flex: 1; min-width: 400px;\">\n",
        "                <h3 style=\"color:#006064;background:#e0f7fa;padding:10px;border-radius:4px;text-align:center;margin-bottom:0;border:1px solid #b2ebf2;\">View 1: Sorted by Matches (Lowest &rarr; Highest)</h3>\n",
        "                <div style=\"max-height:600px;overflow-y:auto;border:1px solid #ddd;border-top:none;background:#fafafa;\"><table style=\"width:100%;border-collapse:collapse;\"><thead><tr><th style=\"background:#004d40;color:white;padding:12px;text-align:left;position:sticky;top:0;\">Participant Kit (TNG Linked)</th><th style=\"background:#004d40;color:white;padding:12px;text-align:center;position:sticky;top:0;\">Matches</th></tr></thead><tbody>{''.join(admin_rows_asc)}</tbody></table></div>\n",
        "            </div>\n",
        "            <div style=\"flex: 1; min-width: 400px;\">\n",
        "                <h3 style=\"color:#006064;background:#e0f7fa;padding:10px;border-radius:4px;text-align:center;margin-bottom:0;border:1px solid #b2ebf2;\">View 2: Sorted Alphabetically (A &rarr; Z)</h3>\n",
        "                <div style=\"max-height:600px;overflow-y:auto;border:1px solid #ddd;border-top:none;background:#fafafa;\"><table style=\"width:100%;border-collapse:collapse;\"><thead><tr><th style=\"background:#004d40;color:white;padding:12px;text-align:left;position:sticky;top:0;\">Participant Kit (TNG Linked)</th><th style=\"background:#004d40;color:white;padding:12px;text-align:center;position:sticky;top:0;\">Matches</th></tr></thead><tbody>{''.join(admin_rows_az)}</tbody></table></div>\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\"\"\"\n",
        "    pages_to_upload[\"research_admin.html\"] = make_page(\"Yates Research Admin Hub\", admin_content, False, stats_bar_full, extra_css=\"<style>.dashboard-grid{display:grid;grid-template-columns:repeat(auto-fit,minmax(200px,1fr));gap:20px;margin:30px auto;max-width:1200px}.dash-card{background:white;padding:20px;border-radius:8px;text-align:center;box-shadow:0 4px 6px rgba(0,0,0,0.1);transition:transform 0.2s;text-decoration:none;color:#333;border:1px solid #ddd}.dash-card:hover{transform:translateY(-5px);border-color:#006064;background:#e0f7fa}.dash-icon{font-size:40px;margin-bottom:10px;display:block}.dash-title{font-weight:bold;font-size:1.1em;color:#006064}.audit-table-wrapper{background:white;padding:25px;border-radius:8px;box-shadow:0 4px 6px rgba(0,0,0,0.1);max-width:1400px;margin:0 auto} td{padding:10px;border-bottom:1px solid #eee}</style>\")\n",
        "\n",
        "    pages_to_upload[\"contents.shtml\"] = make_page(\"Yates Study User Guide\", CONTENTS_CONTENT, False, stats_bar_full, extra_css=CONTENTS_CSS)\n",
        "    pages_to_upload[\"share_dna.shtml\"] = make_page(\"Share Your Ancestry DNA Matches\", SHARE_CONTENT, False, stats_bar_full)\n",
        "    pages_to_upload[\"subscribe.shtml\"] = make_page(\"Join the Yates Research Community\", SUBSCRIBE_CONTENT, False, stats_bar_full)\n",
        "    pages_to_upload[\"dna_theory_of_the_case.htm\"] = make_page(\"The Yates DNA Strategy\", THEORY_CONTENT, False, stats_bar_full)\n",
        "    pages_to_upload[\"data_glossary.shtml\"] = make_page(\"Data Glossary\", GLOSSARY_CONTENT, False, stats_bar_full, extra_css=GLOSS_CSS)\n",
        "\n",
        "    df_p = df[df['cM'] > 0].copy()\n",
        "    df_p['sort_key'] = df_p['Kit_Name'].apply(get_sort_key)\n",
        "    df_p.sort_values(by=['sort_key', 'Match_Name'], ascending=[True, True], inplace=True)\n",
        "    df_p['Long_Narrative'] = df_p.apply(lambda r: f\"<b>{r['Kit_Name']}</b> is a {r['cM']} cM match to <a href='https://yates.one-name.net/tng/verticalchart.php?personID={normalize_id(r['Match_ID'])}&tree=tree1&parentset=0&display=vertical&generations=15' target='_blank'><b>{r['Match_Name']}</b></a> via {r.get('Dir_Label', '').split('(')[0]} back {len(str(r.get('Lineage', '')).split('->'))} generations.\", axis=1)\n",
        "    df_p.rename(columns={'Long_Narrative': 'Participants who tested-Who they matched-Oldest known Yates ancestor'}, inplace=True)\n",
        "    pages_to_upload[\"ons_yates_dna_register_participants.shtml\"] = make_page(\"ONS Yates Study DNA Register\", sb_str_part + f'<div class=\"table-scroll-wrapper\">{df_p.to_html(columns=[\"Participants who tested-Who they matched-Oldest known Yates ancestor\"], index=False, border=1, classes=\"dataframe sortable\", escape=False, table_id=\"reg-table\")}</div>', True, stats_bar_full, extra_css=REGISTER_CSS)\n",
        "\n",
        "    mc = df['Dir_Label'].value_counts()\n",
        "    df_a = df[(df['Dir_Label'].isin(mc[mc >= 2].index)) & (df['Dir_Label'] != 'No Matches')].copy().sort_values(by=['Dir_Label', 'Lineage'], ascending=[True, True])\n",
        "    df_a['Long_Narrative'] = df_a.apply(lambda r: f\"{r['Kit_Name']} is a {r['cM']} cM match to <a href='https://yates.one-name.net/tng/verticalchart.php?personID={normalize_id(r['Match_ID'])}&tree=tree1&parentset=0&display=vertical&generations=15' target='_blank'><b>{r['Match_Name']}</b></a> via {r.get('Dir_Label', '').split('(')[0]} back {len(str(r.get('Lineage', '')).split('->'))} generations.\", axis=1)\n",
        "    df_a.rename(columns={'Long_Narrative': 'Participants who tested-Who they matched-Oldest known Yates ancestor'}, inplace=True)\n",
        "    sbar_a = f\"\"\"<div style=\"background:#f4f4f4;border-top:1px solid #ddd;border-bottom:1px solid #ddd;font-family:sans-serif;font-size:12px;color:#555;padding:8px 15px;text-align:center;margin-bottom:0;\"><strong>Last updated:</strong> {timestamp} &nbsp;|&nbsp; <strong>Validated Matches (2+):</strong> {len(df_a):,} <span style=\"color:#d32f2f;\">(Singleton matches hidden)</span></div>\"\"\"\n",
        "    pages_to_upload[\"ons_yates_dna_register.shtml\"] = make_page(\"ONS Yates Study DNA Register\", sb_str_anc + f'<div class=\"table-scroll-wrapper\">{df_a.to_html(columns=[\"Participants who tested-Who they matched-Oldest known Yates ancestor\"], index=False, border=1, classes=\"dataframe sortable\", escape=False, table_id=\"reg-table\")}</div>', True, sbar_a, extra_css=REGISTER_CSS)\n",
        "    pages_to_upload[\"yates_ancestor_register.shtml\"] = pages_to_upload[\"ons_yates_dna_register.shtml\"]\n",
        "\n",
        "    df_s = df[(df['Dir_Label'].isin(mc[mc == 1].index)) & (df['Dir_Label'] != 'No Matches')].copy()\n",
        "    stats_bar_single = f\"\"\"<div style=\"background:#f4f4f4;border-top:1px solid #ddd;border-bottom:1px solid #ddd;font-family:sans-serif;font-size:12px;color:#555;padding:8px 15px;text-align:center;margin-bottom:0;\"><strong>HOUSEKEEPING VIEW:</strong> Showing {len(df_s):,} singleton matches.</div>\"\"\"\n",
        "    df_s_anc = df_s.sort_values(by=['Dir_Label'], ascending=False).copy()\n",
        "    df_s_anc['Long_Narrative'] = df_s_anc.apply(lambda r: f\"{r['Kit_Name']} is a {r['cM']} cM match to <a href='https://yates.one-name.net/tng/verticalchart.php?personID={normalize_id(r['Match_ID'])}&tree=tree1&parentset=0&display=vertical&generations=15' target='_blank'><b>{r['Match_Name']}</b></a> via {r.get('Dir_Label', '').split('(')[0]} back {len(str(r.get('Lineage', '')).split('->'))} generations.\", axis=1)\n",
        "    df_s_anc.rename(columns={'Long_Narrative': 'Participants who tested-Who they matched-Oldest known Yates ancestor'}, inplace=True)\n",
        "    pages_to_upload[\"admin_singletons.shtml\"] = make_page(\"Singleton Match Register\", sb_str_single_anc + f'<div class=\"table-scroll-wrapper\">{df_s_anc.to_html(columns=[\"Participants who tested-Who they matched-Oldest known Yates ancestor\"], index=False, border=1, classes=\"dataframe sortable\", escape=False, table_id=\"reg-table\")}</div>', True, stats_bar_single, extra_css=REGISTER_CSS)\n",
        "\n",
        "    df_s_part = df_s.copy()\n",
        "    df_s_part['sort_key'] = df_s_part['Kit_Name'].apply(get_sort_key)\n",
        "    df_s_part.sort_values(by=['sort_key', 'Match_Name'], ascending=[True, True], inplace=True)\n",
        "    df_s_part['Long_Narrative'] = df_s_part.apply(lambda r: f\"<b>{r['Kit_Name']}</b> is a {r['cM']} cM match to <a href='https://yates.one-name.net/tng/verticalchart.php?personID={normalize_id(r['Match_ID'])}&tree=tree1&parentset=0&display=vertical&generations=15' target='_blank'><b>{r['Match_Name']}</b></a> via {r.get('Dir_Label', '').split('(')[0]} back {len(str(r.get('Lineage', '')).split('->'))} generations.\", axis=1)\n",
        "    df_s_part.rename(columns={'Long_Narrative': 'Participants who tested-Who they matched-Oldest known Yates ancestor'}, inplace=True)\n",
        "    pages_to_upload[\"admin_singletons_participants.shtml\"] = make_page(\"Singleton Match Register\", sb_str_single_part + f'<div class=\"table-scroll-wrapper\">{df_s_part.to_html(columns=[\"Participants who tested-Who they matched-Oldest known Yates ancestor\"], index=False, border=1, classes=\"dataframe sortable\", escape=False, table_id=\"reg-table\")}</div>', True, stats_bar_single, extra_css=REGISTER_CSS)\n",
        "\n",
        "    df_tree = df_a[['Linked_Tree_Line', 'Dir_Label']].copy()\n",
        "    df_tree.rename(columns={'Linked_Tree_Line': 'TEMP'}, inplace=True)\n",
        "    df_tree.sort_values(by=['Dir_Label'], ascending=[False], inplace=True)\n",
        "    pages_to_upload[\"just-trees.shtml\"] = make_page(\"Ancestor Register (Trees View)\", tree_za_toggle + f'<div class=\"table-scroll-wrapper\">{df_tree[[\"TEMP\"]].to_html(index=False, border=1, classes=\"dataframe sortable\", escape=False, table_id=\"reg-table\").replace(\"<th>TEMP</th>\", \"<th>&nbsp;</th>\")}</div>', True, sbar_a, extra_css=TREE_CSS)\n",
        "    df_tree.sort_values(by=['Dir_Label'], ascending=[True], inplace=True)\n",
        "    pages_to_upload[\"just-trees-az.shtml\"] = make_page(\"Ancestor Register (Trees View)\", tree_az_toggle + f'<div class=\"table-scroll-wrapper\">{df_tree[[\"TEMP\"]].to_html(index=False, border=1, classes=\"dataframe sortable\", escape=False, table_id=\"reg-table\").replace(\"<th>TEMP</th>\", \"<th>&nbsp;</th>\")}</div>', True, sbar_a, extra_css=TREE_CSS)\n",
        "\n",
        "    net_buf = []\n",
        "    for anc, g in sorted(df.groupby('Dir_Label'), key=lambda x: len(x[1]), reverse=True):\n",
        "        if len(g) < 2 or anc == 'No Matches': continue\n",
        "        net_buf.append(f\"\"\"<details style=\"background:white;margin-bottom:15px;border:1px solid #ddd;border-radius:5px;overflow:hidden;\"><summary style=\"background:#e0f2f1;padding:15px;cursor:pointer;font-weight:bold;color:#006064;list-style:none;\"><span style=\"font-size:1.1em;\">{anc}</span> <span style=\"float:right;color:#004d40;font-size:0.9em;\">Matches: {len(g)} | Total cM: {g['cM'].sum()}</span></summary><div style=\"padding:15px;\"><div style=\"background:#fffde7;border-left:6px solid #fbc02d;padding:10px;margin-bottom:15px;font-family:sans-serif;color:#333;font-size:0.95em;\"><strong>Collateral Saturation Analysis:</strong> Validated by <b>{len(g['Kit_Name'].unique())} independent tester kits</b>.</div><table class=\"dataframe\" border=\"1\"><thead><tr style=\"text-align:left;\"><th>Tester Kit</th><th>cM</th><th>Lineage</th></tr></thead><tbody>\"\"\")\n",
        "        for _, r in g.sort_values('cM', ascending=False).iterrows(): net_buf.append(f\"<tr><td>{r['Kit_Name']}</td><td>{r['cM']}</td><td>{r['Lineage']}</td></tr>\")\n",
        "        net_buf.append(\"</tbody></table></div></details>\")\n",
        "\n",
        "    NET_TMPL = f\"\"\"<!DOCTYPE html><html lang=\"en\"><head><meta charset=\"UTF-8\"><title>Participating DNA Network</title><link rel=\"stylesheet\" href=\"partials_unified.css\"><link rel=\"stylesheet\" href=\"dna_tree_styles.css\"><style>summary::-webkit-details-marker{{display:none}}summary{{outline:none}}</style></head><body id=\"top\"><div class=\"wrap\"><h1 class=\"centerline\">Participating DNA Network</h1><div id=\"nav-slot\">{stats_bar_full}{NAV_HTML}</div>{SITE_INFO}<div style=\"margin:20px auto;max-width:1400px;width:95%;\">{\"\".join(net_buf)}</div></div>{LEGAL_FOOTER}{JS_CORE}{BTT_BTN}</body></html>\"\"\"\n",
        "    pages_to_upload[\"dna_network.shtml\"] = NET_TMPL\n",
        "\n",
        "    print(\"\\n[STEP 3] Uploading via FTP to Live Server...\")\n",
        "    try:\n",
        "        ftps = FTP_TLS()\n",
        "        ftps.connect(HOST, 21)\n",
        "        ftps.auth()\n",
        "        ftps.login(USER, PASS)\n",
        "        ftps.prot_p()\n",
        "\n",
        "        found_dir = False\n",
        "        for d in [f\"/{REMOTE_SUBDIR}\", f\"/{REMOTE_SUBDIR}/\", \"htdocs/ons-study\", REMOTE_SUBDIR]:\n",
        "            try:\n",
        "                ftps.cwd(d)\n",
        "                found_dir = True\n",
        "                break\n",
        "            except: pass\n",
        "\n",
        "        if not found_dir:\n",
        "            print(\"‚ùå FTP Directory Not Found.\")\n",
        "        else:\n",
        "            upload_count = 0\n",
        "            if os.path.exists(CSV_DB):\n",
        "                with open(CSV_DB, \"rb\") as fh:\n",
        "                    ftps.storbinary(f\"STOR {CSV_DB}\", fh)\n",
        "                print(f\"    üì§ Uploaded: {CSV_DB}\")\n",
        "\n",
        "            for fn, content in pages_to_upload.items():\n",
        "                with open(fn, \"w\", encoding=\"utf-8\") as f: f.write(content)\n",
        "                with open(fn, \"rb\") as fh:\n",
        "                    ftps.storbinary(f\"STOR {fn}\", fh)\n",
        "                print(f\"    üì§ Uploaded: {fn}\")\n",
        "                upload_count += 1\n",
        "\n",
        "            print(f\"\\nüéâ MASTER PIPELINE COMPLETE. Successfully uploaded {upload_count} pages + {CSV_DB} to the live site.\")\n",
        "        ftps.quit()\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Upload Failed: {e}\")\n",
        "\n",
        "print(\"‚úÖ Cell 5 (Pure Logic Engine) Loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Xfpv2P1BiFo",
        "outputId": "dc2b5306-bd0b-48ab-a535-40ea6a12db34"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Cell 5 (Pure Logic Engine) Loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [CELL 6] MASTER ORCHESTRATOR (Run This Button)\n",
        "import os, sys\n",
        "print(\"=\"*60)\n",
        "print(\"      MASTER ORCHESTRATOR\")\n",
        "print(\"      (Running Engine -> Publisher -> Upload)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if 'run_engine' not in globals() or 'run_publisher' not in globals():\n",
        "    print(\"‚ùå ERROR: Modules not loaded! Please run the Engine and Publisher setup cells first.\")\n",
        "else:\n",
        "    print(\"\\n>>> üöÄ PHASE 1: EXECUTING DATA ENGINE...\")\n",
        "    try:\n",
        "        run_engine()\n",
        "        print(\"‚úÖ PHASE 1 COMPLETE.\")\n",
        "\n",
        "        print(\"\\n>>> üåê PHASE 2: EXECUTING PUBLISHER & UPLOAD...\")\n",
        "        run_publisher()\n",
        "        print(\"‚úÖ PHASE 2 COMPLETE.\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"      üèÜ MASTER PIPELINE SUCCESSFUL\")\n",
        "        print(\"=\"*60)\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå CRITICAL FAILURE: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDC3rDZu8iX2",
        "outputId": "60b7e5e6-34d8-4fdc-b395-56a85984914a"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "      MASTER ORCHESTRATOR\n",
            "      (Running Engine -> Publisher -> Upload)\n",
            "============================================================\n",
            "\n",
            ">>> üöÄ PHASE 1: EXECUTING DATA ENGINE...\n",
            "============================================================\n",
            "      [CELL 3] ENGINE STARTING (V123 - DEEP RADAR)...\n",
            "============================================================\n",
            "\n",
            "[STEP 1] Resolving Files (Local Priority)...\n",
            "    ‚úÖ Found match_to_unmasked.csv locally. Skipping FTP download.\n",
            "    üëâ Source GEDCOM: yates_study_2025.ged\n",
            "\n",
            "[STEP 2] Loading Tester Authority CSV...\n",
            "\n",
            "[STEP 3] Parsing GEDCOM for Study| Tags & Lineages...\n",
            "\n",
            "[STEP 4] Constructing Database...\n",
            "\n",
            "[SUCCESS] Engine V123 Complete. Saved 1713 verified matches to engine_database.csv.\n",
            "‚úÖ PHASE 1 COMPLETE.\n",
            "\n",
            ">>> üåê PHASE 2: EXECUTING PUBLISHER & UPLOAD...\n",
            "============================================================\n",
            "      [CELL 5] PUBLISHER STARTING (Upgraded V26 - Hotlinks Restored)...\n",
            "============================================================\n",
            "\n",
            "[STEP 1] Resolving match_to_unmasked.csv...\n",
            "    ‚úÖ Found match_to_unmasked.csv locally. Skipping FTP download.\n",
            "\n",
            "[STEP 2] Building HTML Files...\n",
            "\n",
            "[STEP 3] Uploading via FTP to Live Server...\n",
            "    üì§ Uploaded: engine_database.csv\n",
            "    üì§ Uploaded: proof_consolidator.html\n",
            "    üì§ Uploaded: biological_proof.html\n",
            "    üì§ Uploaded: lineage_proof.html\n",
            "    üì§ Uploaded: dna_dossier.html\n",
            "    üì§ Uploaded: brick_wall_buster.shtml\n",
            "    üì§ Uploaded: research_admin.html\n",
            "    üì§ Uploaded: contents.shtml\n",
            "    üì§ Uploaded: share_dna.shtml\n",
            "    üì§ Uploaded: subscribe.shtml\n",
            "    üì§ Uploaded: dna_theory_of_the_case.htm\n",
            "    üì§ Uploaded: data_glossary.shtml\n",
            "    üì§ Uploaded: ons_yates_dna_register_participants.shtml\n",
            "    üì§ Uploaded: ons_yates_dna_register.shtml\n",
            "    üì§ Uploaded: yates_ancestor_register.shtml\n",
            "    üì§ Uploaded: admin_singletons.shtml\n",
            "    üì§ Uploaded: admin_singletons_participants.shtml\n",
            "    üì§ Uploaded: just-trees.shtml\n",
            "    üì§ Uploaded: just-trees-az.shtml\n",
            "    üì§ Uploaded: dna_network.shtml\n",
            "\n",
            "üéâ MASTER PIPELINE COMPLETE. Successfully uploaded 19 pages + engine_database.csv to the live site.\n",
            "‚úÖ PHASE 2 COMPLETE.\n",
            "\n",
            "============================================================\n",
            "      üèÜ MASTER PIPELINE SUCCESSFUL\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [CELL The Time Machine (Archiver + Dropbox Sync)]\n",
        "import zipfile\n",
        "import os\n",
        "import pytz\n",
        "import time\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "from google.colab import userdata\n",
        "\n",
        "# --- 1. INSTALL DROPBOX (IF MISSING) ---\n",
        "try:\n",
        "    import dropbox\n",
        "    from dropbox.exceptions import AuthError\n",
        "except ImportError:\n",
        "    os.system('pip install dropbox')\n",
        "    import dropbox\n",
        "    from dropbox.exceptions import AuthError\n",
        "\n",
        "def run_archiver():\n",
        "    print(\"=\"*60)\n",
        "    print(\"      [CELL 6] MANUAL ARCHIVER + DROPBOX SYNC\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # --- 2. CREATE ZIP (SAFE MODE) ---\n",
        "    # We explicitly exclude .zip to prevent \"Zip Bombs\"\n",
        "    extensions = ('.csv', '.shtml', '.html', '.json', '.js', '.css')\n",
        "    files_to_pack = [f for f in os.listdir('.') if f.lower().endswith(extensions) and \"sample_data\" not in f]\n",
        "\n",
        "    if not files_to_pack:\n",
        "        print(\"‚ùå No generated files found! Run the Publisher (Cell 4) first.\")\n",
        "        return\n",
        "\n",
        "    est = pytz.timezone('US/Eastern')\n",
        "    timestamp = datetime.now(est).strftime(\"%Y-%m-%d_%H%M\")\n",
        "    zip_name = f\"Yates_Study_Backup_{timestamp}.zip\"\n",
        "\n",
        "    print(f\"üì¶ Compressing {len(files_to_pack)} files into {zip_name}...\")\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
        "            for file in files_to_pack:\n",
        "                zf.write(file)\n",
        "        print(f\"    ‚úÖ Archive Created: {zip_name} ({os.path.getsize(zip_name)/1024:.1f} KB)\")\n",
        "    except Exception as e:\n",
        "        print(f\"    ‚ùå Compression Failed: {e}\")\n",
        "        return\n",
        "\n",
        "    # --- 3. FTP UPLOAD (BACKUPS FOLDER) ---\n",
        "    print(\"\\n[STEP 2] Uploading to Web Server (FTP)...\")\n",
        "    try:\n",
        "        from ftplib import FTP_TLS\n",
        "        HOST = os.environ.get(\"FTP_HOST\") or userdata.get(\"FTP_HOST\")\n",
        "        USER = os.environ.get(\"FTP_USER\") or userdata.get(\"FTP_USER\")\n",
        "        PASS = os.environ.get(\"FTP_PASS\") or userdata.get(\"FTP_PASS\")\n",
        "\n",
        "        ftps = FTP_TLS()\n",
        "        ftps.connect(HOST, 21); ftps.auth(); ftps.login(USER, PASS); ftps.prot_p()\n",
        "\n",
        "        try:\n",
        "            ftps.cwd(\"/ons-study/backups\")\n",
        "        except:\n",
        "            try:\n",
        "                ftps.mkd(\"/ons-study/backups\")\n",
        "                ftps.cwd(\"/ons-study/backups\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        with open(zip_name, \"rb\") as fh:\n",
        "            ftps.storbinary(f\"STOR {zip_name}\", fh)\n",
        "        print(f\"    ‚úÖ FTP Success: /ons-study/backups/{zip_name}\")\n",
        "        ftps.quit()\n",
        "    except Exception as e:\n",
        "        print(f\"    ‚ö†Ô∏è FTP Upload skipped: {e}\")\n",
        "\n",
        "    # --- 4. DROPBOX SYNC (NEW) ---\n",
        "    print(\"\\n[STEP 3] Syncing to Dropbox...\")\n",
        "    try:\n",
        "        # Initialize with Refresh Token (Long-term access)\n",
        "        dbx = dropbox.Dropbox(\n",
        "            app_key=userdata.get('DBX_APP_KEY'),\n",
        "            app_secret=userdata.get('DBX_APP_SECRET'),\n",
        "            oauth2_refresh_token=userdata.get('DBX_REFRESH_TOKEN')\n",
        "        )\n",
        "\n",
        "        # Upload the Zip\n",
        "        target_path = f\"/Backups/{zip_name}\"\n",
        "        with open(zip_name, \"rb\") as f:\n",
        "            dbx.files_upload(f.read(), target_path, mode=dropbox.files.WriteMode.overwrite)\n",
        "\n",
        "        print(f\"    ‚úÖ Dropbox Success: {target_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    ‚ùå Dropbox Upload Failed: {e}\")\n",
        "        print(\"       (Check DBX_APP_KEY, DBX_APP_SECRET, DBX_REFRESH_TOKEN in Colab Secrets)\")\n",
        "\n",
        "    # --- 5. LOCAL DOWNLOAD (SAFETY NET) ---\n",
        "    print(\"\\n[STEP 4] Triggering Local Download...\")\n",
        "    try:\n",
        "        files.download(zip_name)\n",
        "    except Exception as e:\n",
        "        print(f\"    ‚ö†Ô∏è Auto-download blocked: {e}\")\n",
        "\n",
        "    print(\"‚úÖ Archival Process Complete.\")\n",
        "\n",
        "# Run it\n",
        "run_archiver()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "8mBBkH977YS8",
        "outputId": "8e3d4c6a-246a-4fb5-d506-82b16bda7992"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "      [CELL 6] MANUAL ARCHIVER + DROPBOX SYNC\n",
            "============================================================\n",
            "üì¶ Compressing 20 files into Yates_Study_Backup_2026-02-22_1750.zip...\n",
            "    ‚úÖ Archive Created: Yates_Study_Backup_2026-02-22_1750.zip (2041.9 KB)\n",
            "\n",
            "[STEP 2] Uploading to Web Server (FTP)...\n",
            "    ‚úÖ FTP Success: /ons-study/backups/Yates_Study_Backup_2026-02-22_1750.zip\n",
            "\n",
            "[STEP 3] Syncing to Dropbox...\n",
            "    ‚úÖ Dropbox Success: /Backups/Yates_Study_Backup_2026-02-22_1750.zip\n",
            "\n",
            "[STEP 4] Triggering Local Download...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3f0e5f56-d3fe-451c-8ad1-939f10ea1bbe\", \"Yates_Study_Backup_2026-02-22_1750.zip\", 2090922)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Archival Process Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [CELL Manual Zip & Download]\n",
        "import os\n",
        "import zipfile\n",
        "import pytz\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"      [CELL 7] MANUAL ZIP & DOWNLOADER\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create a timestamped zip file name\n",
        "est = pytz.timezone('US/Eastern')\n",
        "timestamp = datetime.now(est).strftime(\"%Y-%m-%d_%H%M\")\n",
        "zip_filename = f\"Yates_Study_Manual_Upload_{timestamp}.zip\"\n",
        "\n",
        "# Find all the files we normally FTP\n",
        "extensions = ('.html', '.shtml', '.htm', '.csv')\n",
        "files_to_pack = [f for f in os.listdir('.') if f.lower().endswith(extensions) and \"sample_data\" not in f]\n",
        "\n",
        "if not files_to_pack:\n",
        "    print(\"‚ùå No files found to zip! Make sure you ran the Builder cells first.\")\n",
        "else:\n",
        "    print(f\"üì¶ Found {len(files_to_pack)} files. Compressing into {zip_filename}...\\n\")\n",
        "\n",
        "    # Create the zip archive\n",
        "    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
        "        for file in files_to_pack:\n",
        "            zf.write(file)\n",
        "            print(f\"  + Added: {file}\")\n",
        "\n",
        "    print(f\"\\n‚úÖ Zip file created successfully! ({os.path.getsize(zip_filename)/1024:.1f} KB)\")\n",
        "\n",
        "    # Trigger the browser download\n",
        "    print(\"‚¨áÔ∏è Prompting browser to download...\")\n",
        "    try:\n",
        "        files.download(zip_filename)\n",
        "        print(\"üéâ Download initiated! You can now manually upload these via FileZilla/Cyberduck.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Auto-download blocked by browser: {e}\")\n",
        "        print(f\"üëâ You can manually download '{zip_filename}' by clicking the Folder icon üìÅ on the far left menu.\")"
      ],
      "metadata": {
        "id": "fkxPJ23tKvri",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "0347b472-711e-41c8-aefa-caa6647cf52b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "      [CELL 7] MANUAL ZIP & DOWNLOADER\n",
            "============================================================\n",
            "üì¶ Found 21 files. Compressing into Yates_Study_Manual_Upload_2026-02-22_0937.zip...\n",
            "\n",
            "  + Added: contents.shtml\n",
            "  + Added: subscribe.shtml\n",
            "  + Added: match_to_unmasked.csv\n",
            "  + Added: ons_yates_dna_register.shtml\n",
            "  + Added: research_admin.html\n",
            "  + Added: brick_wall_buster.shtml\n",
            "  + Added: ons_yates_dna_register_participants.shtml\n",
            "  + Added: dna_dossier.html\n",
            "  + Added: engine_database.csv\n",
            "  + Added: share_dna.shtml\n",
            "  + Added: lineage_proof.html\n",
            "  + Added: admin_singletons_participants.shtml\n",
            "  + Added: proof_consolidator.html\n",
            "  + Added: dna_theory_of_the_case.htm\n",
            "  + Added: just-trees-az.shtml\n",
            "  + Added: yates_ancestor_register.shtml\n",
            "  + Added: just-trees.shtml\n",
            "  + Added: data_glossary.shtml\n",
            "  + Added: biological_proof.html\n",
            "  + Added: admin_singletons.shtml\n",
            "  + Added: dna_network.shtml\n",
            "\n",
            "‚úÖ Zip file created successfully! (1639.3 KB)\n",
            "‚¨áÔ∏è Prompting browser to download...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_71c2da47-d4f6-481e-bbe8-bdfc204f3039\", \"Yates_Study_Manual_Upload_2026-02-22_0937.zip\", 1678643)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéâ Download initiated! You can now manually upload these via FileZilla/Cyberduck.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title GEDCOM Search: The Gremlin Hunter\n",
        "import os\n",
        "\n",
        "def find_errant_participant(search_term=\"yatesjohnrob\"):\n",
        "    print(\"=\"*75)\n",
        "    print(f\"      GEDCOM SEARCH: LOOKING FOR '{search_term}'\")\n",
        "    print(\"=\"*75)\n",
        "\n",
        "    # Find the original GEDCOM file\n",
        "    ged_files = [f for f in os.listdir('.') if f.lower().endswith('.ged') and \"_processed\" not in f.lower()]\n",
        "    if not ged_files:\n",
        "        return print(\"‚ùå No original GEDCOM found.\")\n",
        "\n",
        "    ged_file = sorted(ged_files, key=lambda x: os.path.getmtime(x), reverse=True)[0]\n",
        "    print(f\"üîç Scanning File: {ged_file}\\n\")\n",
        "\n",
        "    current_id = None\n",
        "    current_name = \"Unknown\"\n",
        "    matches_found = 0\n",
        "\n",
        "    print(f\"{'ID#'.ljust(12)} | {'NAME'.ljust(30)} | EXACT LINE FOUND\")\n",
        "    print(\"-\" * 75)\n",
        "\n",
        "    with open(ged_file, 'r', encoding='utf-8', errors='replace') as f:\n",
        "        for line_num, line in enumerate(f, 1):\n",
        "            line_clean = line.strip()\n",
        "            parts = line_clean.split(\" \", 2)\n",
        "            if len(parts) < 2: continue\n",
        "\n",
        "            lvl = parts[0]\n",
        "            tag = parts[1]\n",
        "            val = parts[2] if len(parts) > 2 else \"\"\n",
        "\n",
        "            # Track the current individual block\n",
        "            if lvl == \"0\" and \"INDI\" in val:\n",
        "                current_id = tag.replace(\"@\", \"\")\n",
        "                current_name = \"Unknown\"\n",
        "\n",
        "            # Track the Name so we know who we are looking at\n",
        "            elif lvl == \"1\" and tag == \"NAME\":\n",
        "                current_name = val.replace(\"/\", \"\").strip()\n",
        "\n",
        "            # Trigger if the search term is anywhere in this line\n",
        "            if search_term.lower() in line_clean.lower():\n",
        "                if current_id:\n",
        "                    print(f\"{current_id.ljust(12)} | {current_name[:28].ljust(30)} | {line_clean}\")\n",
        "                else:\n",
        "                    print(f\"{'N/A'.ljust(12)} | {'(Outside INDI block)'.ljust(30)} | {line_clean}\")\n",
        "                matches_found += 1\n",
        "\n",
        "    print(\"-\" * 75)\n",
        "    print(f\"‚úÖ Found {matches_found} total mentions of '{search_term}'.\")\n",
        "\n",
        "find_errant_participant(\"yatesjohnrob\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92YiTqQvs7VH",
        "outputId": "bbd603c3-9660-4603-c666-341ce7a9c4fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===========================================================================\n",
            "      GEDCOM SEARCH: LOOKING FOR 'yatesjohnrob'\n",
            "===========================================================================\n",
            "üîç Scanning File: yates_study_2025.ged\n",
            "\n",
            "ID#          | NAME                           | EXACT LINE FOUND\n",
            "---------------------------------------------------------------------------\n",
            "I51017       | Terri Ann Yates                | 2 NPFX 361&yatesjohnrob\n",
            "I51033       | Cynthia Lou Miller             | 2 NPFX 20&yatesjohnrob\n",
            "I51044       | Rhonda Rowe                    | 2 NPFX 19&yatesjohnrob\n",
            "---------------------------------------------------------------------------\n",
            "‚úÖ Found 3 total mentions of 'yatesjohnrob'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title DIAGNOSTIC: The Orphan Kit Hunter\n",
        "import os\n",
        "import csv\n",
        "import re\n",
        "\n",
        "def find_missing_kits():\n",
        "    print(\"=\"*60)\n",
        "    print(\"      DIAGNOSTIC: FINDING THE MISSING KITS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    KEY_FILE = \"match_to_unmasked.csv\"\n",
        "    csv_kits = {}\n",
        "\n",
        "    # 1. Load the 94 kits from the CSV\n",
        "    if os.path.exists(KEY_FILE):\n",
        "        with open(KEY_FILE, 'r', errors='replace') as f:\n",
        "            for row in csv.reader(f):\n",
        "                if len(row) >= 2:\n",
        "                    code = row[0].strip().lower()\n",
        "                    name = row[1].strip()\n",
        "                    csv_kits[code] = name\n",
        "    else:\n",
        "        return print(\"‚ùå Cannot find match_to_unmasked.csv\")\n",
        "\n",
        "    # 2. Find the GEDCOM\n",
        "    ged_files = [f for f in os.listdir('.') if f.lower().endswith('.ged') and \"_processed\" not in f.lower()]\n",
        "    if not ged_files:\n",
        "        return print(\"‚ùå No original GEDCOM found.\")\n",
        "    ged_file = sorted(ged_files, key=lambda x: os.path.getmtime(x), reverse=True)[0]\n",
        "\n",
        "    def resolve_code(payload):\n",
        "        m = re.search(r'(\\d+)\\s*&?\\s*([^ \\t\\n\\r\\f\\v]+)', payload)\n",
        "        return m.group(2).lower() if m else None\n",
        "\n",
        "    # 3. Scan GEDCOM for every unique NPFX code actually in use\n",
        "    gedcom_codes = set()\n",
        "    with open(ged_file, 'r', encoding='utf-8', errors='replace') as f:\n",
        "        for line in f:\n",
        "            if \"NPFX\" in line:\n",
        "                parts = line.strip().split(\" \", 2)\n",
        "                if len(parts) > 2:\n",
        "                    code = resolve_code(parts[2])\n",
        "                    if code:\n",
        "                        gedcom_codes.add(code)\n",
        "\n",
        "    # 4. Compare CSV against GEDCOM matches\n",
        "    missing = []\n",
        "    for csv_code, csv_name in csv_kits.items():\n",
        "        if csv_code not in gedcom_codes:\n",
        "            missing.append(f\"{csv_name} (Masked Code: {csv_code})\")\n",
        "\n",
        "    print(f\"üìä Total Kits in CSV: {len(csv_kits)}\")\n",
        "    print(f\"üß¨ Kits with active Matches in GEDCOM: {len(csv_kits) - len(missing)}\")\n",
        "    print(f\"‚ö†Ô∏è Orphaned Kits (0 matches found): {len(missing)}\\n\")\n",
        "\n",
        "    print(\"--- THE MISSING 5 ---\")\n",
        "    for m in missing:\n",
        "        print(f\" ‚ùå {m}\")\n",
        "\n",
        "find_missing_kits()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tErAKOrK9Bgt",
        "outputId": "d1de8a6d-91c5-4372-a0ae-6a4fc776fe36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "      DIAGNOSTIC: FINDING THE MISSING KITS\n",
            "============================================================\n",
            "üìä Total Kits in CSV: 95\n",
            "üß¨ Kits with active Matches in GEDCOM: 89\n",
            "‚ö†Ô∏è Orphaned Kits (0 matches found): 6\n",
            "\n",
            "--- THE MISSING 5 ---\n",
            " ‚ùå unmasked (Masked Code: code)\n",
            " ‚ùå Anaya Yates (Masked Code: aanya)\n",
            " ‚ùå Donald Coram (Masked Code: coram)\n",
            " ‚ùå Fiona Houston (Masked Code: houston)\n",
            " ‚ùå Jan King (Masked Code: king)\n",
            " ‚ùå How Yates (Masked Code: yates_nj-h)\n"
          ]
        }
      ]
    }
  ]
}