{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNSeApKi+l63aY97qeowjo+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronyates47/Gedcom-Utils/blob/main/Gold__1_%26_2_%26_3_20251111_1200.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PIP"
      ],
      "metadata": {
        "id": "XtvXRl-lcavJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT5s4n9S5ZpZ",
        "outputId": "889572d9-f6f8-47ce-b86a-93fdad7da884",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting python-gedcom\n",
            "  Downloading python_gedcom-1.0.0-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Downloading python_gedcom-1.0.0-py2.py3-none-any.whl (35 kB)\n",
            "Installing collected packages: python-gedcom\n",
            "Successfully installed python-gedcom-1.0.0\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Collecting xlsxwriter\n",
            "  Downloading xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\n",
            "Downloading xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.9\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.12/dist-packages (0.23.4)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (1.16.3)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (1.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (1.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.1->mlxtend) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.17.0)\n",
            "ERROR: unknown command \"caas_jupyter_tools\"\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install python-gedcom\n",
        "!pip install openpyxl\n",
        "!pip install xlsxwriter\n",
        "!pip install mlxtend\n",
        "!pip caas_jupyter_tools"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ron Rules-QUICK CODE CARD (v2025.10.27-Refined)\n",
        "# - Complete & runnable in Colab; ISO-8859-15 (ASCII-only in source).\n",
        "# - Punctuation in strings use HTML entities (&rsquo; &ldquo; &rdquo; &mdash; &rarr;).\n",
        "# - Deliver Python code (inline, executable, CUT-ready section)\n",
        "# - XHTML 1.0 Transitional; old-school friendly; Times New Roman body.\n",
        "# - Use CUT markers; five # spacer lines follow the STOP marker."
      ],
      "metadata": {
        "id": "g3hSp6RQHgPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Style Sheet"
      ],
      "metadata": {
        "id": "hqUDdX5zb3Eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] UPDATE /partials/dna_tree_styles.css — SITE-WIDE SANS ==================\n",
        "# RON RULES — QUICK CODE CARD (v2025.11.06-SharedCSS-SiteWideSans)\n",
        "# - Complete & runnable in Colab; ISO-8859-15 (ASCII-only in source).\n",
        "# - Purpose: Switch site-wide body typeface to a sans stack in /partials/dna_tree_styles.css\n",
        "# - Creates a timestamped .bak on the server before overwrite.\n",
        "\n",
        "import os, re, socket, time, traceback\n",
        "from ftplib import FTP_TLS\n",
        "\n",
        "# ---------- Secrets ----------\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ['FTP_HOST'] = userdata.get('FTP_HOST')\n",
        "    os.environ['FTP_USER'] = userdata.get('FTP_USER')\n",
        "    os.environ['FTP_PASS'] = userdata.get('FTP_PASS')\n",
        "    try:  os.environ['FTP_PORT'] = userdata.get('FTP_PORT')\n",
        "    except Exception: os.environ.setdefault('FTP_PORT', '21')\n",
        "    try:  os.environ['FTP_DIR']  = userdata.get('FTP_DIR')\n",
        "    except Exception: os.environ.setdefault('FTP_DIR', '')\n",
        "except Exception:\n",
        "    os.environ.setdefault('FTP_HOST', '')\n",
        "    os.environ.setdefault('FTP_USER', '')\n",
        "    os.environ.setdefault('FTP_PASS', '')\n",
        "    os.environ.setdefault('FTP_PORT', '21')\n",
        "    os.environ.setdefault('FTP_DIR', '')\n",
        "\n",
        "FTP_HOST = os.environ.get('FTP_HOST','')\n",
        "FTP_USER = os.environ.get('FTP_USER','')\n",
        "FTP_PASS = os.environ.get('FTP_PASS','')\n",
        "FTP_PORT = int(os.environ.get('FTP_PORT','21'))\n",
        "FTP_DIR  = (os.environ.get('FTP_DIR','') or '').strip('/')\n",
        "\n",
        "TARGET_DIR  = 'partials'\n",
        "TARGET_NAME = 'dna_tree_styles.css'\n",
        "LOCAL_ORIG  = 'dna_tree_styles.orig.css'\n",
        "LOCAL_NEW   = 'dna_tree_styles.css'\n",
        "\n",
        "if not all([FTP_HOST, FTP_USER, FTP_PASS]):\n",
        "    raise SystemExit(\"[EXIT] Missing FTP creds in Colab userdata: FTP_HOST/FTP_USER/FTP_PASS\")\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def _connect():\n",
        "    socket.setdefaulttimeout(30)\n",
        "    ftps = FTP_TLS(timeout=30)\n",
        "    ftps.connect(FTP_HOST, FTP_PORT)\n",
        "    ftps.login(FTP_USER, FTP_PASS)\n",
        "    try: ftps.prot_p()\n",
        "    except Exception: pass\n",
        "    try: ftps.set_pasv(True)\n",
        "    except Exception: pass\n",
        "    if FTP_DIR:\n",
        "        for p in [p for p in FTP_DIR.split('/') if p]:\n",
        "            try: ftps.cwd(p)\n",
        "            except Exception:\n",
        "                try: ftps.mkd(p)\n",
        "                except Exception: pass\n",
        "                ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "def _cwd(ftps, path):\n",
        "    for p in [q for q in path.split('/') if q]:\n",
        "        try:\n",
        "            ftps.cwd(p)\n",
        "        except Exception:\n",
        "            try: ftps.mkd(p)\n",
        "            except Exception: pass\n",
        "            ftps.cwd(p)\n",
        "\n",
        "def _download(ftps, remote_name, local_name):\n",
        "    with open(local_name, 'wb') as f:\n",
        "        ftps.retrbinary('RETR ' + remote_name, f.write)\n",
        "    print(\"[OK] Downloaded:\", remote_name, \"->\", os.path.abspath(local_name))\n",
        "\n",
        "def _upload(ftps, local_name, remote_name):\n",
        "    with open(local_name, 'rb') as f:\n",
        "        ftps.storbinary('STOR ' + remote_name, f)\n",
        "    print(\"[OK] Uploaded:\", os.path.abspath(local_name), \"->\", remote_name)\n",
        "\n",
        "def _server_backup(ftps, remote_name):\n",
        "    ts = time.strftime(\"%Y%m%d%H%M\")\n",
        "    bak = remote_name + \".\" + ts + \".bak\"\n",
        "    try:\n",
        "        with open(\"__tmp_bak.css\", \"wb\") as tmp:\n",
        "            ftps.retrbinary('RETR ' + remote_name, tmp.write)\n",
        "        with open(\"__tmp_bak.css\", \"rb\") as tmp:\n",
        "            ftps.storbinary('STOR ' + bak, tmp)\n",
        "        try: os.remove(\"__tmp_bak.css\")\n",
        "        except Exception: pass\n",
        "        print(\"[OK] Server backup created:\", bak)\n",
        "    except Exception as e:\n",
        "        print(\"[WARN] Could not create server backup:\", e)\n",
        "\n",
        "def _set_body_sans(css_text):\n",
        "    # Switch the body stack to sans-serif; add a body rule if missing\n",
        "    if re.search(r'body\\s*\\{[^}]*font-family\\s*:', css_text, flags=re.I|re.S):\n",
        "        return re.sub(\n",
        "            r'(body\\s*\\{[^}]*?)font-family\\s*:\\s*[^;]+;',\n",
        "            r\"\\1font-family: Arial, Helvetica, sans-serif;\",\n",
        "            css_text, flags=re.I|re.S\n",
        "        )\n",
        "    else:\n",
        "        return \"body { font-family: Arial, Helvetica, sans-serif; }\\n\\n\" + css_text\n",
        "\n",
        "# ---------- Main ----------\n",
        "try:\n",
        "    ftps = _connect()\n",
        "    _cwd(ftps, TARGET_DIR)\n",
        "\n",
        "    # 1) Pull current css\n",
        "    _download(ftps, TARGET_NAME, LOCAL_ORIG)\n",
        "\n",
        "    # 2) Transform body font-family to sans stack\n",
        "    with open(LOCAL_ORIG, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "        css = f.read()\n",
        "    new_css = _set_body_sans(css)\n",
        "\n",
        "    # 3) Save ISO-8859-15 safe\n",
        "    with open(LOCAL_NEW, 'w', encoding='iso-8859-15', errors='xmlcharrefreplace') as f:\n",
        "        f.write(new_css)\n",
        "    print(\"[OK] Prepared modified CSS locally:\", os.path.abspath(LOCAL_NEW))\n",
        "\n",
        "    # 4) Server backup + upload\n",
        "    _server_backup(ftps, TARGET_NAME)\n",
        "    _upload(ftps, LOCAL_NEW, TARGET_NAME)\n",
        "\n",
        "    try: ftps.quit()\n",
        "    except Exception: pass\n",
        "\n",
        "    print(\"\\nDONE. Site-wide body font set to Arial, Helvetica, sans-serif.\")\n",
        "    print(\"If a page still shows serif, it likely has later inline <style> forcing Times New Roman.\")\n",
        "    print(\"Add ?v=1 to the page URL or hard-refresh to bust cache.\")\n",
        "except SystemExit as e:\n",
        "    print(str(e))\n",
        "except Exception as e:\n",
        "    print(\"[ERROR] CSS update failed:\", e)\n",
        "    traceback.print_exc()\n",
        "# ====== CUT STOP  [1/1] UPDATE /partials/dna_tree_styles.css — SITE-WIDE SANS ==================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntMaP8X-cDLm",
        "outputId": "bb4cf408-e70b-4b8a-a41e-a44f6d0b639a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ERROR] CSS update failed: timed out\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-506644834.py\", line 106, in <cell line: 0>\n",
            "    ftps = _connect()\n",
            "           ^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-506644834.py\", line 45, in _connect\n",
            "    ftps.connect(FTP_HOST, FTP_PORT)\n",
            "  File \"/usr/lib/python3.12/ftplib.py\", line 158, in connect\n",
            "    self.sock = socket.create_connection((self.host, self.port), self.timeout,\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/socket.py\", line 865, in create_connection\n",
            "    raise exceptions[0]\n",
            "  File \"/usr/lib/python3.12/socket.py\", line 850, in create_connection\n",
            "    sock.connect(sa)\n",
            "TimeoutError: timed out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] CENTERLINE FIX — Update shared CSS + Upload =============================\n",
        "# RON RULES — QUICK CODE CARD (v2025.11.06-CSS-Centerline-Fix)\n",
        "# - Complete & runnable in Colab; ISO-8859-15 safe in source.\n",
        "# - Purpose: ensure \"Last updated …\" (meta) is centered site-wide via shared stylesheet.\n",
        "# - Actions: edit/insert CENTERLINE FIX block in dna_tree_styles.css and FTPS-upload to /partials/.\n",
        "\n",
        "import os, re, socket, posixpath, traceback\n",
        "from ftplib import FTP_TLS\n",
        "from datetime import datetime\n",
        "\n",
        "# ---------- 0) Secrets ----------\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ['FTP_HOST'] = userdata.get('FTP_HOST')\n",
        "    os.environ['FTP_USER'] = userdata.get('FTP_USER')\n",
        "    os.environ['FTP_PASS'] = userdata.get('FTP_PASS')\n",
        "    try: os.environ['FTP_DIR']  = userdata.get('FTP_DIR')\n",
        "    except Exception: os.environ.setdefault('FTP_DIR', '')\n",
        "    try: os.environ['FTP_PORT'] = userdata.get('FTP_PORT')\n",
        "    except Exception: os.environ.setdefault('FTP_PORT', '21')\n",
        "except Exception:\n",
        "    os.environ.setdefault('FTP_HOST', '')\n",
        "    os.environ.setdefault('FTP_USER', '')\n",
        "    os.environ.setdefault('FTP_PASS', '')\n",
        "    os.environ.setdefault('FTP_DIR',  '')\n",
        "    os.environ.setdefault('FTP_PORT', '21')\n",
        "\n",
        "FTP_DIR   = (os.environ.get(\"FTP_DIR\",\"\") or \"\").strip()\n",
        "LOCAL_CSS = \"dna_tree_styles.css\"\n",
        "REMOTE_CSS = posixpath.join(\"partials\", \"dna_tree_styles.css\")\n",
        "\n",
        "# ---------- 1) Ensure local css exists (create if missing) ----------\n",
        "if not os.path.exists(LOCAL_CSS):\n",
        "    with open(LOCAL_CSS, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"/* yates.one-name.net shared stylesheet */\\n\")\n",
        "    print(\"[INFO] Created new local stylesheet:\", os.path.abspath(LOCAL_CSS))\n",
        "else:\n",
        "    print(\"[OK] Using existing local stylesheet:\", os.path.abspath(LOCAL_CSS))\n",
        "\n",
        "# ---------- 2) Insert/replace CENTERLINE FIX block ----------\n",
        "with open(LOCAL_CSS, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
        "    css = f.read()\n",
        "\n",
        "start_tag = \"/* === CENTERLINE FIX (do not remove) START === */\"\n",
        "end_tag   = \"/* === CENTERLINE FIX (do not remove) END === */\"\n",
        "block_re  = re.compile(re.escape(start_tag) + r\".*?\" + re.escape(end_tag), flags=re.S)\n",
        "\n",
        "center_block = f\"\"\"{start_tag}\n",
        ":root {{\n",
        "  /* nothing here yet; reserved for future tokens */\n",
        "}}\n",
        "/* Utility: hard center text, wins against generic .meta rules */\n",
        ".centerline {{ text-align: center !important; }}\n",
        "\n",
        "/* Meta display: keep centered across pages, even if other CSS sets .meta {{text-align:left}} */\n",
        ".wrap .meta, .intro .meta, .updated, .updated.centerline {{\n",
        "  text-align: center !important;\n",
        "}}\n",
        "\n",
        "/* Table meta stamping alignment on partials and main pages */\n",
        "#last-updated, #auto-count, #showing-count {{ /* inline metrics */ }}\n",
        "{end_tag}\n",
        "\"\"\"\n",
        "\n",
        "if block_re.search(css):\n",
        "    css = block_re.sub(center_block, css)\n",
        "    action = \"[OK] Replaced existing CENTERLINE FIX block.\"\n",
        "else:\n",
        "    # Append with a divider so it overrides earlier rules\n",
        "    css += \"\\n\\n/* ------------------------------------------------------------------ */\\n\" + center_block + \"\\n\"\n",
        "    action = \"[OK] Appended CENTERLINE FIX block.\"\n",
        "\n",
        "with open(LOCAL_CSS, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(css)\n",
        "\n",
        "print(action)\n",
        "\n",
        "# ---------- 3) Upload via FTPS ----------\n",
        "def ftp_connect() -> FTP_TLS:\n",
        "    ftps = FTP_TLS(timeout=30)\n",
        "    socket.setdefaulttimeout(30)\n",
        "    ftps.connect(os.environ.get('FTP_HOST',''), int(os.environ.get('FTP_PORT','21')))\n",
        "    ftps.login(os.environ.get('FTP_USER',''), os.environ.get('FTP_PASS',''))\n",
        "    try: ftps.prot_p()\n",
        "    except Exception: pass\n",
        "    try: ftps.set_pasv(True)\n",
        "    except Exception: pass\n",
        "    if FTP_DIR:\n",
        "        for p in [p for p in FTP_DIR.split(\"/\") if p]:\n",
        "            try: ftps.mkd(p)\n",
        "            except Exception: pass\n",
        "            ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "def ensure_remote_dirs(ftps: FTP_TLS, path: str):\n",
        "    parts = [p for p in path.split(\"/\")[:-1] if p]\n",
        "    for seg in parts:\n",
        "        try: ftps.cwd(seg)\n",
        "        except Exception:\n",
        "            try: ftps.mkd(seg)\n",
        "            except Exception: pass\n",
        "            ftps.cwd(seg)\n",
        "\n",
        "if all(os.environ.get(k) for k in (\"FTP_HOST\",\"FTP_USER\",\"FTP_PASS\")):\n",
        "    try:\n",
        "        ftps = ftp_connect()\n",
        "        ensure_remote_dirs(ftps, REMOTE_CSS)\n",
        "        with open(LOCAL_CSS, \"rb\") as fh:\n",
        "            ftps.storbinary(f\"STOR {REMOTE_CSS}\", fh)\n",
        "        try: sz = ftps.size(REMOTE_CSS)\n",
        "        except Exception: sz = None\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "        print(f\"[PUT] {LOCAL_CSS} -> /{REMOTE_CSS}  (size: {sz if sz is not None else 'unknown'})\")\n",
        "        print(\"Cache-bust tip: add ?v=\" + datetime.utcnow().strftime(\"%Y%m%d%H%M%S\") + \" once if needed.\")\n",
        "    except Exception as e:\n",
        "        print(\"[FAIL] FTPS upload:\", e)\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"[SKIP] Missing FTP creds; upload not attempted.\")\n",
        "\n",
        "print(\"\\nNext step:\")\n",
        "print(\"1) In Cell 3 template, ensure the meta block uses class 'centerline':\")\n",
        "print(\"   <div class=\\\"meta centerline\\\">Last updated: <span id=\\\"last-updated\\\"></span> ...</div>\")\n",
        "print(\"   (Cell 2 already uses 'updated centerline'.)\")\n",
        "print(\"2) Re-run Cell 3 to regenerate HTML, or refresh the page with ?v=1.\")\n",
        "# ====== CUT STOP  [1/1] CENTERLINE FIX — Update shared CSS + Upload =============================\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zPfncKCDLVk",
        "outputId": "372acbbe-1c6f-413f-8623-e59bd062a30f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Using existing local stylesheet: /content/dna_tree_styles.css\n",
            "[OK] Appended CENTERLINE FIX block.\n",
            "[FAIL] FTPS upload: 553 Can't open that file: No such file or directory\n",
            "\n",
            "Next step:\n",
            "1) In Cell 3 template, ensure the meta block uses class 'centerline':\n",
            "   <div class=\"meta centerline\">Last updated: <span id=\"last-updated\"></span> ...</div>\n",
            "   (Cell 2 already uses 'updated centerline'.)\n",
            "2) Re-run Cell 3 to regenerate HTML, or refresh the page with ?v=1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-992470288.py\", line 109, in <cell line: 0>\n",
            "    ftps.storbinary(f\"STOR {REMOTE_CSS}\", fh)\n",
            "  File \"/usr/lib/python3.12/ftplib.py\", line 495, in storbinary\n",
            "    with self.transfercmd(cmd, rest) as conn:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/ftplib.py\", line 393, in transfercmd\n",
            "    return self.ntransfercmd(cmd, rest)[0]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/ftplib.py\", line 771, in ntransfercmd\n",
            "    conn, size = super().ntransfercmd(cmd, rest)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/ftplib.py\", line 359, in ntransfercmd\n",
            "    resp = self.sendcmd(cmd)\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/ftplib.py\", line 281, in sendcmd\n",
            "    return self.getresp()\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/ftplib.py\", line 254, in getresp\n",
            "    raise error_perm(resp)\n",
            "ftplib.error_perm: 553 Can't open that file: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] CELL — iOS Font/Spacing CSS Fix + Cache-Busted Reupload =================\n",
        "# RON RULES — QUICK CODE CARD (v2025.11.07-iOS-CSS-Fix)\n",
        "# - Complete & runnable in Colab; ISO-8859-15 (ASCII-only in source).\n",
        "# - No snippets; no fabrication; explicit prints.\n",
        "# - Actions:\n",
        "#   (1) Download /partials/dna_tree_styles.css, append a minimal iOS fix block (safe, idempotent).\n",
        "#   (2) Upload patched css back to /partials/dna_tree_styles.css.\n",
        "#   (3) For selected HTML pages in /partials/, download, inject/refresh '?v=TIMESTAMP' on\n",
        "#       '/partials/dna_tree_styles.css' link, and upload back (cache-bust so iPhone fetches new CSS).\n",
        "# - This cell does NOT change any other content; only the CSS and the cache-buster query on the CSS link.\n",
        "\n",
        "import os, re, io, posixpath, socket, traceback, datetime\n",
        "from ftplib import FTP_TLS\n",
        "\n",
        "# ---------- 0) Secrets ----------\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ['FTP_HOST'] = userdata.get('FTP_HOST')\n",
        "    os.environ['FTP_USER'] = userdata.get('FTP_USER')\n",
        "    os.environ['FTP_PASS'] = userdata.get('FTP_PASS')\n",
        "    try: os.environ['FTP_DIR']  = userdata.get('FTP_DIR')\n",
        "    except Exception: os.environ.setdefault('FTP_DIR', '')\n",
        "    try: os.environ['FTP_PORT'] = userdata.get('FTP_PORT')\n",
        "    except Exception: os.environ.setdefault('FTP_PORT', '21')\n",
        "except Exception:\n",
        "    os.environ.setdefault('FTP_HOST', '')\n",
        "    os.environ.setdefault('FTP_USER', '')\n",
        "    os.environ.setdefault('FTP_PASS', '')\n",
        "    os.environ.setdefault('FTP_DIR',  '')\n",
        "    os.environ.setdefault('FTP_PORT', '21')\n",
        "\n",
        "FTP_DIR     = (os.environ.get(\"FTP_DIR\",\"\") or \"\").strip()\n",
        "FTP_TIMEOUT = int(os.environ.get(\"FTP_TIMEOUT\", \"30\"))\n",
        "FTP_PASSIVE = True\n",
        "\n",
        "def ftp_connect() -> FTP_TLS:\n",
        "    ftps = FTP_TLS(timeout=FTP_TIMEOUT)\n",
        "    socket.setdefaulttimeout(FTP_TIMEOUT)\n",
        "    ftps.connect(os.environ.get('FTP_HOST',''), int(os.environ.get('FTP_PORT', 21)))\n",
        "    ftps.login(os.environ.get('FTP_USER',''), os.environ.get('FTP_PASS',''))\n",
        "    try: ftps.prot_p()\n",
        "    except Exception: pass\n",
        "    try: ftps.set_pasv(FTP_PASSIVE)\n",
        "    except Exception: pass\n",
        "    if FTP_DIR:\n",
        "        parts = [p for p in FTP_DIR.split(\"/\") if p]\n",
        "        for p in parts:\n",
        "            try: ftps.mkd(p)\n",
        "            except Exception: pass\n",
        "            ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "def _remote_path(name: str) -> str:\n",
        "    return posixpath.join(FTP_DIR, name) if FTP_DIR else name\n",
        "\n",
        "def ensure_remote_dirs(ftps: FTP_TLS, remote_path: str):\n",
        "    if \"/\" not in remote_path: return\n",
        "    pwd0 = ftps.pwd()\n",
        "    for seg in [p for p in remote_path.split(\"/\")[:-1] if p and p != \".\"]:\n",
        "        try: ftps.cwd(seg)\n",
        "        except Exception:\n",
        "            try: ftps.mkd(seg)\n",
        "            except Exception: pass\n",
        "            ftps.cwd(seg)\n",
        "    ftps.cwd(pwd0)\n",
        "\n",
        "def ftp_download(ftps: FTP_TLS, remote_name: str) -> bytes:\n",
        "    buf = io.BytesIO()\n",
        "    ftps.retrbinary(f\"RETR {remote_name}\", buf.write)\n",
        "    return buf.getvalue()\n",
        "\n",
        "def ftp_download_if_exists(ftps: FTP_TLS, remote_name: str) -> bytes:\n",
        "    try:\n",
        "        return ftp_download(ftps, remote_name)\n",
        "    except Exception as e:\n",
        "        raise FileNotFoundError(f\"Missing remote file: {remote_name} ({e})\")\n",
        "\n",
        "def ftp_upload_overwrite(ftps: FTP_TLS, content_bytes: bytes, remote_name: str):\n",
        "    ensure_remote_dirs(ftps, remote_name)\n",
        "    bio = io.BytesIO(content_bytes)\n",
        "    ftps.storbinary(f\"STOR {remote_name}\", bio)\n",
        "\n",
        "def ftp_size(ftps: FTP_TLS, remote_name: str):\n",
        "    try:\n",
        "        sz = ftps.size(remote_name)\n",
        "        return int(sz) if sz is not None else None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# ---------- 1) Targets ----------\n",
        "CSS_REMOTE = \"partials/dna_tree_styles.css\"\n",
        "\n",
        "# HTML pages where we refresh the cache-buster on the CSS link.\n",
        "HTML_TARGETS = [\n",
        "    \"partials/yates_ancestor_register.htm\",\n",
        "    \"partials/ons_yates_dna_register.htm\",\n",
        "    \"partials/justdna.htm\",\n",
        "    \"partials/just-trees.htm\",\n",
        "    \"partials/yates_ancestor_register_plus.htm\",\n",
        "    \"partials/work_plus.htm\",\n",
        "    \"partials/match_count.htm\",\n",
        "    \"partials/lineage_count.htm\",\n",
        "    \"partials/cousin_list_print.htm\",\n",
        "]\n",
        "\n",
        "# ---------- 2) Patch builder (idempotent) ----------\n",
        "def patch_css_for_ios(css_text: str) -> str:\n",
        "    # Minimal iOS-friendly adjustments. We wrap in a clearly-marked block; re-running does not duplicate.\n",
        "    # - table.sortable th/td line-height and word-break normalization\n",
        "    # - -webkit-text-size-adjust safeguard\n",
        "    block_header = \"/* --- iOS font/spacing fix (2025-11-07) --- */\"\n",
        "    block_rules  = (\n",
        "        \"html, body { -webkit-text-size-adjust:100%; }\\n\"\n",
        "        \"table.sortable th, table.sortable td { line-height:1.5; word-break:normal; }\\n\"\n",
        "    )\n",
        "    if block_header in css_text:\n",
        "        # Already present; optionally refresh the block content in place to ensure exact rules.\n",
        "        rx = re.compile(r\"/\\*\\s*--- iOS font/spacing fix .*?--- \\*/\\s*[^/]*?(?=$|/\\*)\", re.S)\n",
        "        if rx.search(css_text):\n",
        "            css_text = rx.sub(block_header + \"\\n\" + block_rules, css_text, count=1)\n",
        "        else:\n",
        "            # Edge case: header string present but regex did not match; append once.\n",
        "            css_text = css_text.rstrip() + \"\\n\\n\" + block_header + \"\\n\" + block_rules\n",
        "    else:\n",
        "        css_text = css_text.rstrip() + \"\\n\\n\" + block_header + \"\\n\" + block_rules\n",
        "    return css_text\n",
        "\n",
        "def refresh_css_cache_buster(html_text: str, ts: str) -> str:\n",
        "    # Replace any existing query (?v=...) on /partials/dna_tree_styles.css with the new timestamp.\n",
        "    # Handles single/double-quoted attributes.\n",
        "    def _repl(m):\n",
        "        prefix = m.group(1)  # href=\" or href='\n",
        "        path   = m.group(2)  # /partials/dna_tree_styles.css\n",
        "        return f'{prefix}{path}?v={ts}\"'\n",
        "    # Normalize to double-quote for replacement safety.\n",
        "    html_text = html_text.replace(\"'\", '\"')\n",
        "    pat = re.compile(r'(href=\")(/partials/dna_tree_styles\\.css)(?:\\?[^\"]*)?\"', re.I)\n",
        "    if pat.search(html_text):\n",
        "        html_text = pat.sub(_repl, html_text)\n",
        "    else:\n",
        "        # If a link tag exists without direct match, try to inject one in <head> (rare fallback).\n",
        "        head_pat = re.compile(r\"<head[^>]*>\", re.I)\n",
        "        if head_pat.search(html_text):\n",
        "            link_tag = f'<link rel=\"stylesheet\" type=\"text/css\" href=\"/partials/dna_tree_styles.css?v={ts}\" />'\n",
        "            html_text = head_pat.sub(lambda m: m.group(0) + \"\\n\" + link_tag, html_text, count=1)\n",
        "    return html_text\n",
        "\n",
        "# ---------- 3) Execute patch + uploads ----------\n",
        "def run_fix():\n",
        "    if not all(os.environ.get(k) for k in ['FTP_HOST','FTP_USER','FTP_PASS']):\n",
        "        print(\"[SKIP] Missing FTP creds; uploads skipped.\")\n",
        "        return\n",
        "\n",
        "    ts = datetime.datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "    print(\"[INFO] Cache-buster timestamp:\", ts)\n",
        "\n",
        "    try:\n",
        "        ftps = ftp_connect()\n",
        "\n",
        "        # Patch CSS\n",
        "        print(\"[STEP] Download existing CSS:\", \"/\" + _remote_path(CSS_REMOTE))\n",
        "        css_bytes = ftp_download_if_exists(ftps, _remote_path(CSS_REMOTE))\n",
        "        try:\n",
        "            css_text = css_bytes.decode(\"utf-8\")\n",
        "        except Exception:\n",
        "            css_text = css_bytes.decode(\"iso-8859-15\", errors=\"ignore\")\n",
        "\n",
        "        patched = patch_css_for_ios(css_text)\n",
        "        # Keep CSS ASCII to maintain ISO-8859-15 safety; rules are ASCII-only.\n",
        "        patched_bytes = patched.encode(\"ascii\", errors=\"ignore\")\n",
        "        ftp_upload_overwrite(ftps, patched_bytes, _remote_path(CSS_REMOTE))\n",
        "        print(\"[OK] Uploaded patched CSS -> /\" + _remote_path(CSS_REMOTE))\n",
        "\n",
        "        # Touch each HTML to refresh the cache-buster on the CSS link.\n",
        "        for rel in HTML_TARGETS:\n",
        "            rp = _remote_path(rel)\n",
        "            try:\n",
        "                html_bytes = ftp_download(ftps, rp)\n",
        "            except Exception as e:\n",
        "                print(f\"[MISS] {rp} ({e}); skipping.\")\n",
        "                continue\n",
        "            # Decode as ISO-8859-15 first (your pages are authored that way), fallback to utf-8.\n",
        "            try:\n",
        "                html_text = html_bytes.decode(\"iso-8859-15\")\n",
        "            except Exception:\n",
        "                html_text = html_bytes.decode(\"utf-8\", errors=\"ignore\")\n",
        "\n",
        "            updated = refresh_css_cache_buster(html_text, ts)\n",
        "            # Write back in ISO-8859-15 with entity fallback.\n",
        "            out_bytes = updated.encode(\"iso-8859-15\", errors=\"xmlcharrefreplace\")\n",
        "            ftp_upload_overwrite(ftps, out_bytes, rp)\n",
        "            print(\"[PUT]  cache-busted:\", \"/\" + rp)\n",
        "\n",
        "        # Size check (best-effort)\n",
        "        print(\"\\n--- SIZE Verification (if supported) ---\")\n",
        "        for p in [ _remote_path(CSS_REMOTE) ] + [ _remote_path(h) for h in HTML_TARGETS ]:\n",
        "            try:\n",
        "                sz = ftp_size(ftps, p)\n",
        "                print(f\"/{p} : {sz if sz is not None else '(SIZE unsupported)'}\")\n",
        "            except Exception:\n",
        "                print(f\"/{p} : (check skipped)\")\n",
        "\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "\n",
        "        print(\"\\n--- Open a couple of pages (manual hard-refresh optional) ---\")\n",
        "        print(\"DNA Register:          https://yates.one-name.net/partials/yates_ancestor_register.htm\")\n",
        "        print(\"Register PLUS:         https://yates.one-name.net/partials/yates_ancestor_register_plus.htm\")\n",
        "        print(\"Trees:                 https://yates.one-name.net/partials/just-trees.htm\")\n",
        "        print(\"Shared stylesheet:     https://yates.one-name.net/partials/dna_tree_styles.css\")\n",
        "        print(\"\\nIf an iPhone still shows old spacing, try a hard-refresh (Safari: tap-reload or clear cache).\")\n",
        "    except Exception as e:\n",
        "        print(\"[FAIL] Session:\", e)\n",
        "        traceback.print_exc()\n",
        "\n",
        "run_fix()\n",
        "# ====== CUT STOP  [1/1] CELL ====================================================================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Inck5IHqXqQu",
        "outputId": "be610741-668e-46de-bc45-e384de77478c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3198153314.py:154: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  ts = datetime.datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Cache-buster timestamp: 20251107221012\n",
            "[STEP] Download existing CSS: /partials/dna_tree_styles.css\n",
            "[OK] Uploaded patched CSS -> /partials/dna_tree_styles.css\n",
            "[PUT]  cache-busted: /partials/yates_ancestor_register.htm\n",
            "[PUT]  cache-busted: /partials/ons_yates_dna_register.htm\n",
            "[PUT]  cache-busted: /partials/justdna.htm\n",
            "[PUT]  cache-busted: /partials/just-trees.htm\n",
            "[PUT]  cache-busted: /partials/yates_ancestor_register_plus.htm\n",
            "[PUT]  cache-busted: /partials/work_plus.htm\n",
            "[PUT]  cache-busted: /partials/match_count.htm\n",
            "[PUT]  cache-busted: /partials/lineage_count.htm\n",
            "[PUT]  cache-busted: /partials/cousin_list_print.htm\n",
            "\n",
            "--- SIZE Verification (if supported) ---\n",
            "/partials/dna_tree_styles.css : 3814\n",
            "/partials/yates_ancestor_register.htm : 1267364\n",
            "/partials/ons_yates_dna_register.htm : 1267364\n",
            "/partials/justdna.htm : 1267364\n",
            "/partials/just-trees.htm : 794896\n",
            "/partials/yates_ancestor_register_plus.htm : 1343103\n",
            "/partials/work_plus.htm : 1267364\n",
            "/partials/match_count.htm : 18955\n",
            "/partials/lineage_count.htm : 47782\n",
            "/partials/cousin_list_print.htm : 499776\n",
            "\n",
            "--- Open a couple of pages (manual hard-refresh optional) ---\n",
            "DNA Register:          https://yates.one-name.net/partials/yates_ancestor_register.htm\n",
            "Register PLUS:         https://yates.one-name.net/partials/yates_ancestor_register_plus.htm\n",
            "Trees:                 https://yates.one-name.net/partials/just-trees.htm\n",
            "Shared stylesheet:     https://yates.one-name.net/partials/dna_tree_styles.css\n",
            "\n",
            "If an iPhone still shows old spacing, try a hard-refresh (Safari: tap-reload or clear cache).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 1"
      ],
      "metadata": {
        "id": "JvOlmbj91AGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] CELL 1 — GEDCOM -> CSV + HTML + Upload (Explicit FTPS, ISO-8859-15) ===\n",
        "# RON GOLDEN RULES — CLIFF NOTES (v2025.11.09)\n",
        "# • Complete & runnable Colab Cell — one contiguous block (no fragments, no cross-refs).\n",
        "# • Source ASCII-only; outputs written with encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\".\n",
        "# • XHTML 1.0 Transitional; typography via /partials/dna_tree_styles.css (HTML export only).\n",
        "# • Deterministic audit:\n",
        "#   [CONFIRM] Golden Rules active | Cell=Cell1_FTPS_Explicit | Version=2025.11.09 | Encoding=ISO-8859-15\n",
        "# • Enforce ISO-8859-15 printable chars on writes; DECLARED_LINES printed at start.\n",
        "# ==============================================================================================\n",
        "\n",
        "import os, re, glob, logging, functools, socket, traceback, hashlib\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from ftplib import FTP_TLS, all_errors\n",
        "from string import Template\n",
        "\n",
        "CELL_NAME = \"Cell1_FTPS_Explicit\"\n",
        "VERSION   = \"2025.11.09\"\n",
        "\n",
        "print(\"[CONFIRM] Golden Rules active | Cell=%s | Version=%s | Encoding=ISO-8859-15\" % (CELL_NAME, VERSION))\n",
        "\n",
        "# ---------- Logging ----------\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "logger = logging.getLogger(CELL_NAME)\n",
        "\n",
        "# ---------- Secrets (env or userdata) ----------\n",
        "def _get_env(k, default=\"\"):\n",
        "    try:\n",
        "        from google.colab import userdata  # type: ignore\n",
        "        v = userdata.get(k)\n",
        "        return v if v is not None else os.environ.get(k, default)\n",
        "    except Exception:\n",
        "        return os.environ.get(k, default)\n",
        "\n",
        "FTP_HOST = (_get_env(\"FTP_HOST\",\"\") or \"\").strip()\n",
        "FTP_USER = (_get_env(\"FTP_USER\",\"\") or \"\").strip()\n",
        "FTP_PASS = _get_env(\"FTP_PASS\",\"\") or \"\"\n",
        "FTP_PORT = int(_get_env(\"FTP_PORT\",\"21\") or \"21\")\n",
        "FTP_DIR  = (_get_env(\"FTP_DIR\",\"\") or \"\").strip().strip(\"/\")\n",
        "PASSIVE_MODE = True\n",
        "\n",
        "def _mask(s, keep=3):\n",
        "    s = \"\" if s is None else str(s)\n",
        "    if not s: return \"(empty)\"\n",
        "    return (s[:keep] + \"***\" + s[-keep:]) if len(s) > keep*2 else s[0:1] + \"***\"\n",
        "\n",
        "print(\"[ENV] HOST=%s  USER=%s  PASS=%s  PORT=%d  DIR=%s\" %\n",
        "      (_mask(FTP_HOST), _mask(FTP_USER,2), \"***\", FTP_PORT, (\"/\"+FTP_DIR) if FTP_DIR else \"(root)\"))\n",
        "\n",
        "# ---------- FTPS (Explicit AUTH TLS) ----------\n",
        "def _ftps_connect():\n",
        "    if not (FTP_HOST and FTP_USER and FTP_PASS):\n",
        "        raise RuntimeError(\"Missing FTP_HOST/FTP_USER/FTP_PASS.\")\n",
        "    socket.setdefaulttimeout(30)\n",
        "    ftps = FTP_TLS(timeout=30)\n",
        "    ftps.connect(FTP_HOST, FTP_PORT)\n",
        "    ftps.auth()                 # Explicit FTPS: AUTH TLS before login\n",
        "    ftps.login(FTP_USER, FTP_PASS)\n",
        "    try: ftps.prot_p()          # Encrypt data channel\n",
        "    except Exception: pass\n",
        "    try: ftps.set_pasv(PASSIVE_MODE)\n",
        "    except Exception: pass\n",
        "    if FTP_DIR:\n",
        "        for p in [p for p in FTP_DIR.split(\"/\") if p]:\n",
        "            ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "def _ftps_ensure_dir(ftps, path):\n",
        "    if not path: return\n",
        "    for p in [p for p in path.split(\"/\") if p]:\n",
        "        try:\n",
        "            ftps.cwd(p)\n",
        "        except all_errors:\n",
        "            try: ftps.mkd(p)\n",
        "            except all_errors: pass\n",
        "            ftps.cwd(p)\n",
        "\n",
        "def _ftps_upload(ftps, local_path, remote_name):\n",
        "    with open(local_path, \"rb\") as fh:\n",
        "        ftps.storbinary(\"STOR \" + remote_name, fh)\n",
        "    print(\"[OK] Uploaded: %s -> %s/%s\" % (local_path, ftps.pwd().rstrip(\"/\"), remote_name))\n",
        "\n",
        "# ---------- Outputs / Paths ----------\n",
        "REMOTE_DIR       = \"partials\"\n",
        "CSV_OUT_LOCAL    = \"final_combined_df_with_value_labels.csv\"\n",
        "HTML_OUT_LOCAL   = \"cell1_work_table.htm\"\n",
        "ABS_CSV_URL      = \"/%s/%s\" % (REMOTE_DIR, os.path.basename(CSV_OUT_LOCAL))\n",
        "ABS_HOME_URL     = \"/index.htm\"\n",
        "\n",
        "# ---------- Minimal GEDCOM parse helpers ----------\n",
        "anchor_gen1 = None\n",
        "visited_pairs = set()\n",
        "generation_table = []\n",
        "\n",
        "class GedcomDataset:\n",
        "    def __init__(self, gen_person):\n",
        "        self.gen_person = gen_person\n",
        "        self.extractable_detail = {}\n",
        "        self.anchor_gen1 = None\n",
        "    def add_extractable_detail(self, key, value):\n",
        "        self.extractable_detail[key] = value\n",
        "    def get_gen_person(self):\n",
        "        name = self.extractable_detail.get('NAME', '') or ''\n",
        "        parts = name.split('/', 1)\n",
        "        first_name = parts[0].split(' ')[0] if parts else \"\"\n",
        "        last_name  = parts[1].rstrip('/') if len(parts) > 1 else \"\"\n",
        "        self.anchor_gen1 = last_name.replace(\" \", \"\") + first_name.replace(\" \", \"\")\n",
        "        global anchor_gen1; anchor_gen1 = self.anchor_gen1\n",
        "        return self.gen_person.strip('@')\n",
        "    def get_extractable_NPFX(self): return self.extractable_detail.get('NPFX','') or ''\n",
        "    def get_extractable_cm(self):\n",
        "        v = self.extractable_detail.get('NPFX','') or ''\n",
        "        if '&' in v: cm = v.split('&')[0].strip()\n",
        "        elif '**' in v: cm = v.split('**')[0].strip()\n",
        "        else: cm = v.strip()\n",
        "        try: int(cm); return cm\n",
        "        except Exception: return ''\n",
        "    def get_extractable_sort(self):\n",
        "        v = self.extractable_detail.get('NPFX','') or ''\n",
        "        if '&' in v:\n",
        "            s = v.split('&')[1]\n",
        "            return (s.split('**')[0] if '**' in s else s).strip()\n",
        "        return ''\n",
        "    def get_extractable_YDNA(self):\n",
        "        v = self.extractable_detail.get('NPFX','') or ''\n",
        "        return v.split('**')[1].strip() if '**' in v else ''\n",
        "    def get_extractable_FAMC(self): return (self.extractable_detail.get('FAMC','') or '').strip('@')\n",
        "\n",
        "class Gedcom:\n",
        "    def __init__(self, file_name):\n",
        "        self.file_name = file_name\n",
        "        self.gedcom_datasets = []\n",
        "        self.filter_pool = []\n",
        "    def parse_gedcom(self):\n",
        "        with open(self.file_name, 'r', encoding='utf-8-sig') as f:\n",
        "            lines = f.readlines()\n",
        "        current = None\n",
        "        npfx_count = ydna_count = total = 0\n",
        "        for line in lines:\n",
        "            parts = line.strip().split(' ', 2)\n",
        "            level = int(parts[0]); tag = parts[1]; value = parts[2] if len(parts) > 2 else None\n",
        "            if level == 0 and tag.startswith('@') and tag.endswith('@') and value == 'INDI':\n",
        "                total += 1; current = GedcomDataset(tag); self.gedcom_datasets.append(current)\n",
        "            elif current is not None:\n",
        "                if level == 1 and tag in ['NAME','FAMC']:\n",
        "                    current.add_extractable_detail(tag, value)\n",
        "                elif level == 2 and tag == 'NPFX':\n",
        "                    npfx_count += 1; current.add_extractable_detail(tag, value)\n",
        "                    if value and '**' in value: ydna_count += 1\n",
        "        autosomal = npfx_count - ydna_count\n",
        "        print(\"GEDCOM contained %d total records\" % total)\n",
        "        print(\"Records tagged and filtered by NPFX: %d\" % npfx_count)\n",
        "        print(\"Records with YDNA information: %d\" % ydna_count)\n",
        "        print(\"Autosomal matches: %d\" % autosomal)\n",
        "        for ds in self.gedcom_datasets:\n",
        "            if ds.get_extractable_NPFX():\n",
        "                self.filter_pool.append(ds)\n",
        "        try:\n",
        "            df_filter = pd.read_excel('filtered_ids.xlsx')\n",
        "            manual_ids = set(str(x) for x in df_filter['ID'])\n",
        "            self.filter_pool = [d for d in self.filter_pool if d.get_gen_person() in manual_ids]\n",
        "            print(\"After manual filter, total records: %d\" % len(self.filter_pool))\n",
        "        except FileNotFoundError:\n",
        "            logger.warning(\"filtered_ids.xlsx not found. Skipping second-level manual filter.\")\n",
        "        return autosomal\n",
        "\n",
        "def _chunks(lst, n):\n",
        "    for i in range(0, len(lst), n): yield lst[i:i+n]\n",
        "\n",
        "def _quick_extract_name(full_text):\n",
        "    name_marker = \"\\n1 NAME \"\n",
        "    idx = full_text.find(name_marker)\n",
        "    if idx == -1:\n",
        "        if full_text.startswith(\"1 NAME \"): idx = 0\n",
        "        else: return \"UnknownName\"\n",
        "    start = idx + len(name_marker)\n",
        "    end = full_text.find('\\n', start); end = len(full_text) if end == -1 else end\n",
        "    name_line = full_text[start:end].strip()\n",
        "    if '/' not in name_line: return name_line[:10].replace(\" \",\"\")\n",
        "    first_name, last_name = name_line.split('/', 1)\n",
        "    last_name = last_name.replace(\"/\", \"\").strip()\n",
        "    return last_name[:10].replace(\" \",\"\") + first_name[:10].replace(\" \",\"\")\n",
        "\n",
        "def _find_parents(individual_id, generation, parents_map):\n",
        "    global visited_pairs, generation_table\n",
        "    if individual_id not in parents_map: return\n",
        "    father_id, mother_id = parents_map[individual_id]\n",
        "    if not father_id and not mother_id: return\n",
        "    pair = (father_id, mother_id)\n",
        "    if pair not in visited_pairs:\n",
        "        visited_pairs.add(pair)\n",
        "        generation_table.append((generation, pair))\n",
        "    if father_id: _find_parents(father_id, generation+1, parents_map)\n",
        "    if mother_id: _find_parents(mother_id, generation+1, parents_map)\n",
        "\n",
        "def _find_distant(individual_id, parents_map, path=None):\n",
        "    if path is None: path = []\n",
        "    path.append(individual_id)\n",
        "    if individual_id not in parents_map: return [path]\n",
        "    father_id, mother_id = parents_map[individual_id]\n",
        "    if not father_id and not mother_id: return [path]\n",
        "    paths = []\n",
        "    if father_id: paths.extend(_find_distant(father_id, parents_map, path[:]))\n",
        "    if mother_id: paths.extend(_find_distant(mother_id, parents_map, path[:]))\n",
        "    return paths if paths else [path]\n",
        "\n",
        "def _filter_lineage(winning_ids, gen_table, names_map):\n",
        "    matching = []\n",
        "    for generation, pair in gen_table:\n",
        "        id1, id2 = pair\n",
        "        if id1 in winning_ids or id2 in winning_ids:\n",
        "            matching.append((generation, pair))\n",
        "    matching.sort(key=lambda x: x[0])\n",
        "    lines = []\n",
        "    for _, pair in matching:\n",
        "        name_pair = [names_map.get(pid, \"UnknownName\") for pid in pair]\n",
        "        lines.append(\"%s&%s\" % (name_pair[0], name_pair[1]))\n",
        "    lines.reverse()\n",
        "    return \"~~~\".join(lines)\n",
        "\n",
        "def _process_record(individual_id, ged, parents_map, names_map):\n",
        "    global generation_table, visited_pairs, anchor_gen1\n",
        "    generation_table = []; visited_pairs = set()\n",
        "    _find_parents(individual_id, 1, parents_map)\n",
        "    paths = _find_distant(individual_id, parents_map)\n",
        "    best_score, best_path = None, None\n",
        "    for path in paths:\n",
        "        name_path = [names_map.get(pid, \"UnknownName\") for pid in path]\n",
        "        score = sum((idx+1) for idx, nm in enumerate(name_path) if 'Yates' in nm)\n",
        "        if best_score is None or score > best_score:\n",
        "            best_score, best_path = score, path\n",
        "    best_path = best_path or []\n",
        "    best_ids  = [pid for pid in best_path if pid != individual_id]\n",
        "    line_str  = _filter_lineage(set(best_ids), generation_table, names_map)\n",
        "    cm_value=''; sort_value=''; ydna_value=''\n",
        "    for ds in ged.filter_pool:\n",
        "        if ds.get_gen_person() == individual_id:\n",
        "            cm_value  = ds.get_extractable_cm()\n",
        "            sort_value= ds.get_extractable_sort()\n",
        "            ydna_value= ds.get_extractable_YDNA()\n",
        "            break\n",
        "    short_name = names_map.get(individual_id, \"UnknownName\")\n",
        "    return [individual_id, sort_value, short_name, cm_value, line_str, ydna_value]\n",
        "\n",
        "# ---------- Main build ----------\n",
        "def main():\n",
        "    # Audit: DECLARED_LINES\n",
        "    import inspect\n",
        "    try:\n",
        "        declared = len(inspect.getsource(main).splitlines())\n",
        "    except Exception:\n",
        "        declared = -1\n",
        "    print(\"[AUDIT] DECLARED_LINES=%s\" % str(declared))\n",
        "\n",
        "    files = glob.glob(\"*.ged\")\n",
        "    if not files:\n",
        "        print(\"No GEDCOM files found.\"); return False\n",
        "    print(\"Automatically selecting the first GEDCOM file.\")\n",
        "    gedcom_path = files[0]\n",
        "\n",
        "    ged = Gedcom(gedcom_path)\n",
        "    autosomal_count = ged.parse_gedcom()\n",
        "\n",
        "    with open(\"autosomal_count.txt\", \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(str(autosomal_count))\n",
        "\n",
        "    with open(gedcom_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        raw = f.read()\n",
        "\n",
        "    blocks = raw.split(\"\\n0 \")\n",
        "    all_records = {}\n",
        "    for blk in blocks:\n",
        "        blk = blk.strip()\n",
        "        if not blk: continue\n",
        "        flend = blk.find('\\n'); flend = len(blk) if flend == -1 else flend\n",
        "        first_line = blk[:flend]\n",
        "        if '@' in first_line:\n",
        "            s = first_line.find('@') + 1\n",
        "            e = first_line.find('@', s)\n",
        "            rec_id = first_line[s:e].strip()\n",
        "            all_records[rec_id] = blk\n",
        "\n",
        "    parents_map, names_map, families = {}, {}, {}\n",
        "    for rec_id, txt in all_records.items():\n",
        "        if 'FAM' in txt[:50]:\n",
        "            father_idx = txt.find('1 HUSB @')\n",
        "            husb_id = txt[father_idx+len('1 HUSB @'):txt.find('@', father_idx+len('1 HUSB @'))] if father_idx != -1 else None\n",
        "            wife_idx = txt.find('1 WIFE @')\n",
        "            wife_id = txt[wife_idx+len('1 WIFE @'):txt.find('@', wife_idx+len('1 WIFE @'))] if wife_idx != -1 else None\n",
        "            kids = [ln.split('@')[1] for ln in txt.split('\\n') if ln.strip().startswith('1 CHIL @')]\n",
        "            families[rec_id] = (husb_id, wife_id, kids)\n",
        "    for fam_id, (f_id, m_id, k_list) in families.items():\n",
        "        for kid in k_list:\n",
        "            parents_map[kid] = (f_id, m_id)\n",
        "    for rec_id, txt in all_records.items():\n",
        "        names_map[rec_id] = _quick_extract_name(\"\\n\" + txt)\n",
        "\n",
        "    individual_ids = [d.get_gen_person() for d in ged.filter_pool]\n",
        "    print(\"Processing %d individuals with chunk-based parallel...\" % len(individual_ids))\n",
        "\n",
        "    combined_rows = []\n",
        "    chunk_size = 50\n",
        "    max_workers = os.cpu_count() or 4\n",
        "    from functools import partial\n",
        "    with ProcessPoolExecutor(max_workers=max_workers) as ex, tqdm(total=len(individual_ids), desc=\"Building Yates Lines (Stage 1)\") as pbar:\n",
        "        for chunk in _chunks(individual_ids, chunk_size):\n",
        "            func = partial(_process_record, ged=ged, parents_map=parents_map, names_map=names_map)\n",
        "            results = list(ex.map(func, chunk))\n",
        "            combined_rows.extend(results); pbar.update(len(chunk))\n",
        "\n",
        "    columns = [\"ID#\", \"Match to\", \"Name\", \"cM\", \"Yates DNA Ancestral Line\", \"haplogroup\"]\n",
        "    df = pd.DataFrame(combined_rows, columns=columns)\n",
        "    df.index += 1\n",
        "\n",
        "    def _trim_prefix(row):\n",
        "        prefix = \"YatesJohn&SearchingStill~~~YatesWilliam&SearchingStill~~~YatesWilliam&SearchingStill~~~YatesEdmund&CornellMargaret~~~YatesRichard&AshendonJoan~~~YatesJohn&HydeAlice~~~YatesThomas&FauconerElizabeth~~~\"\n",
        "        s = str(row[\"Yates DNA Ancestral Line\"])\n",
        "        if s.startswith(prefix): row[\"Yates DNA Ancestral Line\"] = s[len(prefix):]\n",
        "        return row\n",
        "    df = df.apply(_trim_prefix, axis=1)\n",
        "    df.sort_values(by=[\"Yates DNA Ancestral Line\"], inplace=True)\n",
        "\n",
        "    # CSV (ISO-8859-15 as required)\n",
        "    with open(CSV_OUT_LOCAL, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(df.to_csv(index=False))\n",
        "    logger.info(\"Exported CSV -> %s\", CSV_OUT_LOCAL)\n",
        "\n",
        "    # HTML (XHTML 1.0 Transitional; Times via external CSS is implied; inline minimal styles ok)\n",
        "    final_cols = [\"ID#\", \"cM\", \"haplogroup\", \"Match to\", \"Yates DNA Ancestral Line\"]\n",
        "    table_html = df.to_html(index=False, columns=final_cols, escape=False, border=1)\n",
        "    page_tpl = Template(\"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "<title>Cell 1 Working Table</title>\n",
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"/partials/dna_tree_styles.css\" />\n",
        "<style type=\"text/css\">\n",
        "  html { scroll-behavior: smooth; }\n",
        "  body { background:#ffffff; color:#222; margin:0; padding:20px; }\n",
        "  h1 { margin:0 0 8px 0; font-size:24px; line-height:1.2; text-align:center; }\n",
        "  .meta { text-align:center; font-size:12px; color:#555; margin:2px 0 12px 0; }\n",
        "  .downloads { text-align:center; margin:4px 0 12px 0; font-size:13px; }\n",
        "  a { color:#154b8b; text-decoration:none; } a:hover { text-decoration:underline; }\n",
        "  table { width:100%; border-collapse:collapse; }\n",
        "  th, td { border:1px solid #333; padding:6px 8px; vertical-align:top; }\n",
        "  th { background:#e3eaf8; text-align:left; }\n",
        "  td:nth-child(5) { text-align:left; white-space:normal; }\n",
        "</style>\n",
        "<script type=\"text/javascript\">\n",
        "//<![CDATA[\n",
        "(function(){ function z(n){return (n<10?'0':'')+n;}\n",
        "document.addEventListener('DOMContentLoaded', function(){\n",
        "  var el = document.getElementById('last-updated');\n",
        "  if(el){ var d=new Date(document.lastModified||new Date());\n",
        "    el.innerHTML = d.getFullYear()+'-'+z(d.getMonth()+1)+'-'+z(d.getDate())+' '+z(d.getHours())+':'+z(d.getMinutes()); }\n",
        "}, false); })();\n",
        "//]]>\n",
        "</script>\n",
        "</head>\n",
        "<body>\n",
        "  <h1>Cell 1 Working Table</h1>\n",
        "  <div class=\"meta\">\n",
        "    <a href=\"$HOME\" target=\"_blank\" rel=\"noopener\">Home</a>\n",
        "    &nbsp;|&nbsp; Last updated: <span id=\"last-updated\"></span>\n",
        "    &nbsp;|&nbsp; Download: <a href=\"$CSV\">$CSV</a>\n",
        "  </div>\n",
        "  <div class=\"downloads\"><a href=\"$CSV\">/partials/$CSV_NAME</a></div>\n",
        "  $TABLE\n",
        "</body>\n",
        "</html>\"\"\")\n",
        "    page = page_tpl.safe_substitute(HOME=ABS_HOME_URL, CSV=ABS_CSV_URL, CSV_NAME=os.path.basename(ABS_CSV_URL), TABLE=table_html)\n",
        "    with open(HTML_OUT_LOCAL, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(page)\n",
        "    logger.info(\"Exported HTML -> %s\", HTML_OUT_LOCAL)\n",
        "\n",
        "    return True\n",
        "\n",
        "ok = main()\n",
        "\n",
        "# ---------- Upload to /partials (Explicit FTPS AUTH TLS) ----------\n",
        "if ok and FTP_HOST and FTP_USER and FTP_PASS:\n",
        "    print(\"[INFO] Uploading artifacts to /partials/ ...\")\n",
        "    try:\n",
        "        ftps = _ftps_connect()\n",
        "        _ftps_ensure_dir(ftps, \"partials\")\n",
        "        try: _ftps_upload(ftps, CSV_OUT_LOCAL, os.path.basename(CSV_OUT_LOCAL))\n",
        "        except Exception as e: print(\"[ERROR] CSV upload failed:\", e)\n",
        "        try: _ftps_upload(ftps, HTML_OUT_LOCAL, os.path.basename(HTML_OUT_LOCAL))\n",
        "        except Exception as e: print(\"[ERROR] HTML upload failed:\", e)\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "        print(\"[OK] Uploads complete to /partials/\")\n",
        "    except Exception as e:\n",
        "        print(\"[ERROR] FTP session failed:\", e)\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"[INFO] Skipping FTP upload (missing creds or build failed).\")\n",
        "\n",
        "print(\"\\n--- Cell 1 Complete: CSV + HTML built and handled with ISO-8859-15; explicit FTPS used. ---\")\n",
        "# ====== CUT STOP  [1/1] CELL 1 — GEDCOM -> CSV + HTML + Upload (Explicit FTPS, ISO-8859-15) ===\n"
      ],
      "metadata": {
        "id": "qWEuviY1aQQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02655f38-6a9e-4b6e-c7f7-d105fb9385a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CONFIRM] Golden Rules active | Cell=Cell1_FTPS_Explicit | Version=2025.11.09 | Encoding=ISO-8859-15\n",
            "[ENV] HOST=ftp***net  USER=ad***et  PASS=***  PORT=21  DIR=(root)\n",
            "[AUDIT] DECLARED_LINES=133\n",
            "Automatically selecting the first GEDCOM file.\n",
            "GEDCOM contained 62312 total records\n",
            "Records tagged and filtered by NPFX: 1572\n",
            "Records with YDNA information: 0\n",
            "Autosomal matches: 1572\n",
            "After manual filter, total records: 7\n",
            "Processing 7 individuals with chunk-based parallel...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Yates Lines (Stage 1): 100%|██████████| 7/7 [00:06<00:00,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Uploading artifacts to /partials/ ...\n",
            "[OK] Uploaded: final_combined_df_with_value_labels.csv -> /partials/final_combined_df_with_value_labels.csv\n",
            "[OK] Uploaded: cell1_work_table.htm -> /partials/cell1_work_table.htm\n",
            "[OK] Uploads complete to /partials/\n",
            "\n",
            "--- Cell 1 Complete: CSV + HTML built and handled with ISO-8859-15; explicit FTPS used. ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 2"
      ],
      "metadata": {
        "id": "s1Oa3qUz0_Yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] CELL 2 - Build + Publish DNA Register (Responsive widths; external CSS handles typography) ======\n",
        "# RON RULES - QUICK CODE CARD (v2025.11.08-Cell2-Responsive-FIXED-NAMES-ASCII)\n",
        "# - Complete & runnable in Colab; ISO-8859-15 (ASCII-only in source).\n",
        "# - XHTML 1.0 Transitional; explicit prints; no fabrication.\n",
        "# - Typography is controlled ONLY by /partials/dna_tree_styles.css (no inline font-family anywhere).\n",
        "# - Publishes SAME HTML to:\n",
        "#       /partials/yates_ancestor_register.htm     (canonical)\n",
        "#       /partials/ons_yates_dna_register.htm     (legacy clone)\n",
        "#       /partials/justdna.htm                    (JUSTDNA alias)\n",
        "\n",
        "import os, re, posixpath, socket, traceback, urllib.parse as _u\n",
        "from ftplib import FTP_TLS\n",
        "import pandas as pd\n",
        "import html as _html\n",
        "from string import Template\n",
        "\n",
        "# ---------- 0) Secrets ----------\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ['FTP_HOST'] = userdata.get('FTP_HOST')\n",
        "    os.environ['FTP_USER'] = userdata.get('FTP_USER')\n",
        "    os.environ['FTP_PASS'] = userdata.get('FTP_PASS')\n",
        "    try:\n",
        "        os.environ['FTP_DIR'] = userdata.get('FTP_DIR')\n",
        "    except Exception:\n",
        "        os.environ.setdefault('FTP_DIR', '')\n",
        "    try:\n",
        "        os.environ['FTP_PORT'] = userdata.get('FTP_PORT')\n",
        "    except Exception:\n",
        "        os.environ.setdefault('FTP_PORT', '21')\n",
        "except Exception:\n",
        "    os.environ.setdefault('FTP_HOST', '')\n",
        "    os.environ.setdefault('FTP_USER', '')\n",
        "    os.environ.setdefault('FTP_PASS', '')\n",
        "    os.environ.setdefault('FTP_DIR', '')\n",
        "    os.environ.setdefault('FTP_PORT', '21')\n",
        "\n",
        "# ---------- 1) Config ----------\n",
        "CSV_IN = \"final_combined_df_with_value_labels.csv\"\n",
        "\n",
        "LOCAL_HTML = \"yates_ancestor_register.htm\"\n",
        "REMOTE_HTML_CANON = posixpath.join(\"partials\", \"yates_ancestor_register.htm\")\n",
        "REMOTE_HTML_LEG = posixpath.join(\"partials\", \"ons_yates_dna_register.htm\")\n",
        "REMOTE_HTML_SIMPLE = posixpath.join(\"partials\", \"justdna.htm\")\n",
        "\n",
        "DNA_REGISTER_ABS = \"https://yates.one-name.net/partials/justdna.htm\"\n",
        "TREES_ABS = \"https://yates.one-name.net/partials/just-trees.htm\"\n",
        "\n",
        "EXPORT_BASENAME = \"yates_ancestor_register\"\n",
        "LOCAL_CSV = f\"{EXPORT_BASENAME}.csv\"\n",
        "LOCAL_XLSX = f\"{EXPORT_BASENAME}.xlsx\"\n",
        "REMOTE_CSV = posixpath.join(\"partials\", os.path.basename(LOCAL_CSV))\n",
        "REMOTE_XLSX = posixpath.join(\"partials\", os.path.basename(LOCAL_XLSX))\n",
        "\n",
        "WORK_PLUS_LOCAL = os.path.join(\"partials\", \"work_plus.htm\")\n",
        "WORK_PLUS_REMOTE = posixpath.join(\"partials\", \"work_plus.htm\")\n",
        "\n",
        "LOCAL_COUNT_FILE = \"/content/autosomal_count.txt\"\n",
        "REMOTE_COUNT_NAME = \"autosomal_count.txt\"\n",
        "\n",
        "FTP_DIR = (os.environ.get(\"FTP_DIR\", \"\") or \"\").strip()\n",
        "TNG_BASE = \"https://yates.one-name.net/tng\"\n",
        "TNG_TREE = \"tree1\"\n",
        "HOME_URL = \"https://yates.one-name.net/partials/yates_ancestor_register.htm\"\n",
        "REMOTE_NAME_ABS = HOME_URL\n",
        "COUNT_PUBLIC_URL = (f\"/{FTP_DIR}/{REMOTE_COUNT_NAME}\" if FTP_DIR else f\"/{REMOTE_COUNT_NAME}\")\n",
        "\n",
        "# === Requested widths (responsive) ===\n",
        "TABLE_WIDTH_PX = 2550\n",
        "COL_A_PX = 775\n",
        "FIND_COL_PX = 75\n",
        "ARROW_ENTITY = \"&rarr;\"\n",
        "REMOVE_PERIOD_AT_END = True\n",
        "\n",
        "SERVER_PARTIALS_DIR = \"partials\"\n",
        "SERVER_MAPPING_BASENAME = \"match_to_unmasked.csv\"\n",
        "SERVER_MAPPING_REMOTE = posixpath.join(SERVER_PARTIALS_DIR, SERVER_MAPPING_BASENAME)\n",
        "SERVER_MAPPING_LOCAL_CACHE = \"match_to_unmasked.server.csv\"\n",
        "\n",
        "# External stylesheet (controls typography site-wide)\n",
        "STYLESHEET_HREF = \"/partials/dna_tree_styles.css\"\n",
        "CSS_VERSION = \"v2025-11-06\"\n",
        "HEAD_LINK = f'<link rel=\"stylesheet\" type=\"text/css\" href=\"{STYLESHEET_HREF}?{CSS_VERSION}\" />'\n",
        "\n",
        "# ---------- 2) FTP helpers ----------\n",
        "FTP_TIMEOUT = int(os.environ.get(\"FTP_TIMEOUT\", \"30\"))\n",
        "FTP_PASSIVE = True\n",
        "\n",
        "def ftp_connect() -> FTP_TLS:\n",
        "    ftps = FTP_TLS(timeout=FTP_TIMEOUT)\n",
        "    socket.setdefaulttimeout(FTP_TIMEOUT)\n",
        "    ftps.connect(os.environ.get('FTP_HOST', ''), int(os.environ.get('FTP_PORT', 21)))\n",
        "    ftps.login(os.environ.get('FTP_USER', ''), os.environ.get('FTP_PASS', ''))\n",
        "    try:\n",
        "        ftps.prot_p()\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        ftps.set_pasv(FTP_PASSIVE)\n",
        "    except Exception:\n",
        "        pass\n",
        "    if FTP_DIR:\n",
        "        parts = [p for p in FTP_DIR.split(\"/\") if p]\n",
        "        for p in parts:\n",
        "            try:\n",
        "                ftps.mkd(p)\n",
        "            except Exception:\n",
        "                pass\n",
        "            ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "def _remote_path(name: str) -> str:\n",
        "    return posixpath.join(FTP_DIR, name) if FTP_DIR else name\n",
        "\n",
        "def ensure_remote_dirs(ftps: FTP_TLS, remote_path: str):\n",
        "    if \"/\" not in remote_path:\n",
        "        return\n",
        "    pwd0 = ftps.pwd()\n",
        "    for seg in [p for p in remote_path.split(\"/\")[:-1] if p and p != \".\"]:\n",
        "        try:\n",
        "            ftps.cwd(seg)\n",
        "        except Exception:\n",
        "            try:\n",
        "                ftps.mkd(seg)\n",
        "            except Exception:\n",
        "                pass\n",
        "            ftps.cwd(seg)\n",
        "    ftps.cwd(pwd0)\n",
        "\n",
        "def ftp_download_if_exists(ftps: FTP_TLS, remote_name: str, local_name: str) -> bool:\n",
        "    try:\n",
        "        with open(local_name, \"wb\") as f:\n",
        "            ftps.retrbinary(f\"RETR {remote_name}\", f.write)\n",
        "        print(f\"[PULL] {remote_name} -> {os.path.abspath(local_name)}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            if os.path.exists(local_name):\n",
        "                os.remove(local_name)\n",
        "        except Exception:\n",
        "            pass\n",
        "        print(f\"[MISS] {remote_name} ({e})\")\n",
        "        return False\n",
        "\n",
        "def ftp_upload_overwrite(ftps: FTP_TLS, local_path: str, remote_name: str):\n",
        "    ensure_remote_dirs(ftps, remote_name)\n",
        "    with open(local_path, \"rb\") as fh:\n",
        "        ftps.storbinary(f\"STOR {remote_name}\", fh)\n",
        "    print(f\"[PUT] {local_path} -> {remote_name}\")\n",
        "\n",
        "def ftp_size(ftps: FTP_TLS, remote_name: str):\n",
        "    try:\n",
        "        sz = ftps.size(remote_name)\n",
        "        return int(sz) if sz is not None else None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# ---------- 3) Resolver ----------\n",
        "def _read_mapping_csv(path: str) -> pd.DataFrame:\n",
        "    encs = (\"iso-8859-15\", \"utf-8-sig\", \"utf-8\", \"cp1252\", \"latin1\")\n",
        "    last = None\n",
        "    df = None\n",
        "    for enc in encs:\n",
        "        try:\n",
        "            df = pd.read_csv(path, encoding=enc, dtype=str, keep_default_na=False)\n",
        "            break\n",
        "        except Exception as e:\n",
        "            last = e\n",
        "    if df is None:\n",
        "        raise RuntimeError(f\"Unable to read mapping CSV {path}: {last}\")\n",
        "    if df.shape[1] < 2:\n",
        "        raise RuntimeError(\"Mapping CSV must have at least two columns: code, unmasked\")\n",
        "    df = df.iloc[:, :2].copy()\n",
        "    df.columns = [\"code\", \"unmasked\"]\n",
        "    df[\"code\"] = df[\"code\"].astype(str).str.strip().str.lower()\n",
        "    df[\"unmasked\"] = df[\"unmasked\"].astype(str).str.strip()\n",
        "    df = df[df[\"code\"] != \"\"].drop_duplicates(subset=[\"code\"], keep=\"first\")\n",
        "    if df.empty:\n",
        "        raise RuntimeError(\"Mapping CSV empty after normalization.\")\n",
        "    return df\n",
        "\n",
        "def load_resolver_from_server() -> dict:\n",
        "    with ftp_connect() as ftps:\n",
        "        try:\n",
        "            ftps.cwd(SERVER_PARTIALS_DIR)\n",
        "        except Exception:\n",
        "            pass\n",
        "        ok = ftp_download_if_exists(ftps, SERVER_MAPPING_BASENAME, SERVER_MAPPING_LOCAL_CACHE)\n",
        "        try:\n",
        "            ftps.quit()\n",
        "        except Exception:\n",
        "            pass\n",
        "    if not ok:\n",
        "        raise RuntimeError(\n",
        "            \"Resolver not found on server: /\" + _remote_path(SERVER_MAPPING_REMOTE)\n",
        "            + \". Upload match_to_unmasked.csv into /partials/ and re-run.\"\n",
        "        )\n",
        "    df_map = _read_mapping_csv(SERVER_MAPPING_LOCAL_CACHE)\n",
        "    print(f\"[OK] Resolver loaded: {len(df_map)} codes\")\n",
        "    return dict(zip(df_map[\"code\"], df_map[\"unmasked\"]))\n",
        "\n",
        "MATCH_TO_UNMASKED = {}\n",
        "def _setup_resolver():\n",
        "    global MATCH_TO_UNMASKED\n",
        "    if not MATCH_TO_UNMASKED:\n",
        "        MATCH_TO_UNMASKED = load_resolver_from_server()\n",
        "\n",
        "def resolve_match_to(code: str) -> str:\n",
        "    if not isinstance(code, str):\n",
        "        return \"\"\n",
        "    return MATCH_TO_UNMASKED.get(code.strip().lower(), code)\n",
        "\n",
        "# ---------- 4) Name & text utils ----------\n",
        "SEP_RE = re.compile(r\"\\s*(?:\\u2192|&rarr;|;|>|,|~{2,}|/{2,}|\\|{2,})\\s*\")\n",
        "def split_tokens(s):\n",
        "    if pd.isna(s):\n",
        "        return []\n",
        "    if not isinstance(s, str):\n",
        "        s = str(s)\n",
        "    return [p.strip() for p in SEP_RE.split(s) if str(p).strip()]\n",
        "\n",
        "def _clean_piece(text: str) -> str:\n",
        "    t = re.sub(r'~+', ' ', str(text))\n",
        "    t = re.sub(r'\\s+', ' ', t)\n",
        "    return t.strip()\n",
        "\n",
        "_PARTICLES = {\"de\", \"del\", \"della\", \"der\", \"van\", \"von\", \"da\", \"dos\", \"das\", \"di\", \"la\", \"le\", \"du\", \"of\"}\n",
        "\n",
        "def _smart_title(token: str) -> str:\n",
        "    if not token:\n",
        "        return token\n",
        "    token = re.sub(\n",
        "        r\"(^|\\b)([a-z])(['’])([a-z])\",\n",
        "        lambda m: m.group(1) + m.group(2).upper() + m.group(3) + m.group(4).upper(),\n",
        "        token.lower(),\n",
        "    )\n",
        "    token = \"-\".join([w.capitalize() for w in token.split(\"-\")])\n",
        "    token = re.sub(r\"\\bmc([a-z])\", lambda m: \"Mc\" + m.group(1).upper(), token)\n",
        "    token = re.sub(r\"\\bmac([a-z])\", lambda m: \"Mac\" + m.group(1).upper(), token)\n",
        "    return token\n",
        "\n",
        "def smart_titlecase(name: str) -> str:\n",
        "    name = _clean_piece(name)\n",
        "    if not name:\n",
        "        return name\n",
        "    if \",\" in name:\n",
        "        last, first = [p.strip() for p in name.split(\",\", 1)]\n",
        "        pieces = (first + \" \" + last).split()\n",
        "    else:\n",
        "        pieces = name.split()\n",
        "    out = []\n",
        "    for i, w in enumerate(pieces):\n",
        "        out.append(w.lower() if (i > 0 and w.lower() in _PARTICLES) else _smart_title(w))\n",
        "    return \" \".join(out)\n",
        "\n",
        "def surname_given_from_token(token):\n",
        "    token = token.strip()\n",
        "    idx = None\n",
        "    for i in range(1, len(token)):\n",
        "        if token[i - 1].islower() and token[i].isupper():\n",
        "            idx = i\n",
        "            break\n",
        "    if idx is None:\n",
        "        for i in range(1, len(token)):\n",
        "            if token[i].isupper():\n",
        "                idx = i\n",
        "                break\n",
        "    if idx is None:\n",
        "        return (token,)\n",
        "    surname = token[:idx]\n",
        "    given = token[idx:]\n",
        "    given_spaced = re.sub(r'(?<!^)([A-Z])', r' \\1', given)\n",
        "    return (f\"{given_spaced.strip()} {surname.strip()}\",)\n",
        "\n",
        "def normalize_person_name(s: str) -> str:\n",
        "    if pd.isna(s):\n",
        "        return \"\"\n",
        "    s = _clean_piece(str(s))\n",
        "    if \",\" in s:\n",
        "        last, first = [p.strip() for p in s.split(\",\", 1)]\n",
        "        s = f\"{first} {last}\"\n",
        "    if \" \" not in s and s.isalpha():\n",
        "        return smart_titlecase(surname_given_from_token(s)[0])\n",
        "    return smart_titlecase(s)\n",
        "\n",
        "_CAMEL_WORDS = re.compile(r\"[A-Z][a-z]*|[A-Z]+(?![a-z])|[a-z]+\")\n",
        "def norm_matchee_name(raw: str) -> str:\n",
        "    raw = str(raw or \"\").strip()\n",
        "    if not raw:\n",
        "        return \"\"\n",
        "    if \" \" in raw or \",\" in raw:\n",
        "        nm = smart_titlecase(raw)\n",
        "        parts = nm.split()\n",
        "        if len(parts) == 1:\n",
        "            return nm\n",
        "        given = parts[0]\n",
        "        surname = parts[-1]\n",
        "        return f\"{given} {surname}\".strip()\n",
        "    words = _CAMEL_WORDS.findall(raw)\n",
        "    while words and len(words[0]) == 1:\n",
        "        words.pop(0)\n",
        "    if not words:\n",
        "        nm = smart_titlecase(surname_given_from_token(raw)[0])\n",
        "        ps = nm.split()\n",
        "        if len(ps) == 1:\n",
        "            return nm\n",
        "        return f\"{ps[0]} {ps[-1]}\".strip()\n",
        "    surname = smart_titlecase(words[0])\n",
        "    given_candidates = [w for w in words[1:] if w.lower() != surname.lower()]\n",
        "    if not given_candidates:\n",
        "        return surname\n",
        "    given = smart_titlecase(given_candidates[0])\n",
        "    return f\"{given} {surname}\".strip()\n",
        "\n",
        "def truncate_first(name: str, n: int = 7) -> str:\n",
        "    name = name.strip()\n",
        "    if not name:\n",
        "        return name\n",
        "    parts = name.split()\n",
        "    return parts[0][:n] if len(parts) == 1 else f\"{parts[0][:n]} {parts[-1]}\"\n",
        "\n",
        "def derive_common_from_first_token(tokens):\n",
        "    if not tokens:\n",
        "        return (\"\", \"\")\n",
        "    first = _clean_piece(tokens[0])\n",
        "    parts = re.split(r\"\\s*(?:&| and )\\s*\", first, maxsplit=1, flags=re.I)\n",
        "    if len(parts) != 2:\n",
        "        return (\"\", \"\")\n",
        "    def _norm(s):\n",
        "        return smart_titlecase(s) if \" \" in s else smart_titlecase(surname_given_from_token(s)[0])\n",
        "    return (_norm(parts[0]), _norm(parts[1]))\n",
        "\n",
        "def degree_label_from_generations(g):\n",
        "    if g <= 1:\n",
        "        return (\"parents\" if g == 1 else \"self\")\n",
        "    if g == 2:\n",
        "        return \"grandparents\"\n",
        "    greats = g - 2\n",
        "    if greats == 1:\n",
        "        return \"great-grandparents\"\n",
        "    return f\"{greats}x-great-grandparents\"\n",
        "\n",
        "def build_header(subject_name, cm_val, matchee_name_html, gens, husband, wife):\n",
        "    try:\n",
        "        cm_str = f\"{int(round(float(cm_val)))}\"\n",
        "    except Exception:\n",
        "        cm_str = (str(cm_val).strip() or \"0\")\n",
        "    degree_label = degree_label_from_generations(gens)\n",
        "    parts = [\n",
        "        f\"{subject_name} is a {cm_str} cM cousin match to {matchee_name_html}, whose\",\n",
        "        f\"{degree_label} (back {gens} Gens)\",\n",
        "        \"are\",\n",
        "        f\"{husband} & {wife}.\"\n",
        "    ]\n",
        "    s = \" \".join(parts)\n",
        "    if REMOVE_PERIOD_AT_END:\n",
        "        s = re.sub(r'\\.\\s*$', '', s)\n",
        "    return s\n",
        "\n",
        "# ---------- 5) Read CSV; detect columns ----------\n",
        "def find_col(df, patterns, prefer_exact=None):\n",
        "    cols = list(df.columns)\n",
        "    lowmap = {c.lower(): c for c in cols}\n",
        "    if prefer_exact:\n",
        "        for name in prefer_exact:\n",
        "            if name in df.columns:\n",
        "                return name\n",
        "            if name and name.lower() in lowmap:\n",
        "                return lowmap[name.lower()]\n",
        "    for pat in patterns:\n",
        "        rx = re.compile(pat, re.I)\n",
        "        for c in cols:\n",
        "            if rx.search(c):\n",
        "                return c\n",
        "    return None\n",
        "\n",
        "_encs = (\"utf-8-sig\", \"utf-8\", \"cp1252\", \"iso-8859-15\", \"latin1\")\n",
        "_last_err = None\n",
        "df = None\n",
        "for _e in _encs:\n",
        "    try:\n",
        "        df = pd.read_csv(CSV_IN, encoding=_e, dtype=str, keep_default_na=False)\n",
        "        break\n",
        "    except Exception as _ex:\n",
        "        _last_err = _ex\n",
        "        df = None\n",
        "if df is None:\n",
        "    raise RuntimeError(f\"Unable to read CSV: {CSV_IN} ({_last_err})\")\n",
        "print(f\"[OK] Loaded CSV: {len(df)} rows, {len(df.columns)} cols\")\n",
        "\n",
        "id_col = find_col(df, [r'^(id#|personid)$'], [\"ID#\", \"ID\", \"PersonID\", \"personID\"])\n",
        "match_col = find_col(df, [r'^match\\s*to$'], [\"Match to\", \"Match\"])\n",
        "name_col = find_col(df, [r'^name$'], [\"Name\"])\n",
        "cm_col = find_col(df, [r'^(c\\s*:?m|cm)$', r'centi.?morgan'], [\"cM\", \"cm\"])\n",
        "path_col = find_col(df, [r'(yates\\s*dna\\s*ancestral\\s*line|ancestral\\s*line|lineage)'], [\"Yates DNA Ancestral Line\", \"Ancestral Line\", \"Lineage\"])\n",
        "\n",
        "if not id_col:\n",
        "    raise ValueError(\"CSV missing an ID#/PersonID column.\")\n",
        "if not match_col:\n",
        "    raise ValueError(\"CSV missing 'Match to' column.\")\n",
        "if not name_col:\n",
        "    raise ValueError(\"CSV missing 'Name' column.\")\n",
        "if not cm_col:\n",
        "    raise ValueError(\"CSV missing 'cM' column.\")\n",
        "if not path_col:\n",
        "    raise ValueError(\"CSV missing lineage/path column.\")\n",
        "\n",
        "# ---------- 6) Transform -> display_df ----------\n",
        "ID_PAT = re.compile(r\"\\bI\\d+\\b\", re.I)\n",
        "def extract_person_id(s: str) -> str:\n",
        "    m = ID_PAT.search(str(s or \"\"))\n",
        "    return m.group(0).upper() if m else \"\"\n",
        "\n",
        "# Resolver\n",
        "def _setup_resolver_and_return():\n",
        "    _setup_resolver()\n",
        "    return MATCH_TO_UNMASKED\n",
        "_ = _setup_resolver_and_return()\n",
        "\n",
        "headers, lineages, findcol = [], [], []\n",
        "subjects, first_ancestors = [], []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    subject_raw = row.get(match_col, \"\")\n",
        "    subject_name = normalize_person_name(resolve_match_to(subject_raw))\n",
        "    subject_name_b = f\"<strong>{subject_name}</strong>\" if subject_name else subject_name\n",
        "\n",
        "    pid = extract_person_id(row.get(id_col, \"\"))\n",
        "    matchee_name = norm_matchee_name(row.get(name_col, \"\")) or subject_name\n",
        "\n",
        "    if pid:\n",
        "        matchee_name_html = (\n",
        "            f'<a href=\"{TNG_BASE}/verticalchart.php?personID={pid}&tree={TNG_TREE}&parentset=0&display=vertical&generations=15\" '\n",
        "            f'target=\"_blank\" rel=\"noopener\">{matchee_name}</a>'\n",
        "        )\n",
        "    else:\n",
        "        matchee_name_html = matchee_name\n",
        "\n",
        "    cm_val = row.get(cm_col, \"0\")\n",
        "    tokens = split_tokens(row.get(path_col, \"\"))\n",
        "    gens_total = len(tokens)\n",
        "    tokens_disp = tokens[:7]\n",
        "\n",
        "    if \"common_husband\" in df.columns and \"common_wife\" in df.columns:\n",
        "        husband_raw = str(row.get(\"common_husband\", \"\")).strip()\n",
        "        wife_raw = str(row.get(\"common_wife\", \"\")).strip()\n",
        "        if not husband_raw and not wife_raw:\n",
        "            husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "    else:\n",
        "        husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "\n",
        "    header_html = build_header(\n",
        "        subject_name_b,\n",
        "        cm_val,\n",
        "        matchee_name_html,\n",
        "        gens_total,\n",
        "        husband_raw,\n",
        "        wife_raw\n",
        "    )\n",
        "\n",
        "    if tokens_disp:\n",
        "        tokens_disp[0] = f\"<strong>{tokens_disp[0]}</strong>\"\n",
        "    sep = f\" {ARROW_ENTITY} \"\n",
        "    lineage_text = sep.join(tokens_disp) if tokens_disp else \"\"\n",
        "\n",
        "    q = _u.quote(subject_name)\n",
        "    quick = (\n",
        "        f'<a class=\"find-btn\" href=\"{REMOTE_NAME_ABS}?q={q}\" target=\"_blank\" rel=\"noopener\" '\n",
        "        f'title=\"Open a filtered view for {subject_name}\">Find</a>'\n",
        "    )\n",
        "\n",
        "    headers.append(header_html)\n",
        "    lineages.append(lineage_text)\n",
        "    findcol.append(quick)\n",
        "    subjects.append(subject_name)\n",
        "    first_ancestors.append(tokens[0] if tokens else \"\")\n",
        "\n",
        "LINEAGE_HEADER_SAFE = \"Lineage (Starting with oldest ancestor, the line is:)\"\n",
        "df[\"Match Summary\"] = headers\n",
        "df[LINEAGE_HEADER_SAFE] = lineages\n",
        "df[\"Find\"] = findcol\n",
        "df[\"Subject\"] = subjects\n",
        "df[\"First Ancestor\"] = [_clean_piece(x) for x in first_ancestors]\n",
        "display_df = df[[\"Find\", \"Match Summary\", LINEAGE_HEADER_SAFE]]\n",
        "\n",
        "# ---------- 6.1) Clean exports ----------\n",
        "TAG_RE = re.compile(r\"<[^>]+>\")\n",
        "def _html_to_text(s: str) -> str:\n",
        "    t = TAG_RE.sub(\"\", str(s or \"\"))\n",
        "    t = _html.unescape(t)\n",
        "    t = t.replace(\"\\u2192\", \"->\")\n",
        "    return re.sub(r\"\\s+\", \" \", t).strip()\n",
        "\n",
        "def _extract_find_url(cell_html: str) -> str:\n",
        "    m = re.search(r'href=\"([^\"]+)\"', str(cell_html or \"\"))\n",
        "    return _html.unescape(m.group(1)) if m else \"\"\n",
        "\n",
        "export_df = pd.DataFrame({\n",
        "    \"Find URL\": [_extract_find_url(v) for v in display_df[\"Find\"].tolist()],\n",
        "    \"Match Summary\": [_html_to_text(v) for v in display_df[\"Match Summary\"].tolist()],\n",
        "    \"Lineage\": [_html_to_text(v) for v in display_df[LINEAGE_HEADER_SAFE].tolist()],\n",
        "})\n",
        "export_df.to_csv(LOCAL_CSV, index=False, encoding=\"iso-8859-15\")\n",
        "try:\n",
        "    export_df.to_excel(LOCAL_XLSX, index=False)\n",
        "except Exception:\n",
        "    with pd.ExcelWriter(LOCAL_XLSX) as _writer:\n",
        "        export_df.to_excel(_writer, index=False)\n",
        "print(\"[OK] Wrote exports:\", os.path.abspath(LOCAL_CSV), \"and\", os.path.abspath(LOCAL_XLSX))\n",
        "\n",
        "# ---------- 7) HTML (Register main page) ----------\n",
        "TABLE_CSS = f\"\"\"\n",
        "<style type=\"text/css\">\n",
        "  html {{ scroll-behavior: smooth; }}\n",
        "  body {{ font-size:100%; background:#ffffff; color:#222; margin:0; padding:0; line-height:1.5; }}\n",
        "  .wrap {{ max-width:100%; margin:0 auto; background:#ffffff; padding:16px; padding-bottom:48px; }}\n",
        "  a {{ color:#154b8b; text-decoration:none; }} a:hover {{ text-decoration:underline; }}\n",
        "  h1 {{ margin:0 0 6px 0; font-size:26px; line-height:1.2; text-align:center; }}\n",
        "  .centerline {{ text-align:center; }}\n",
        "  .downloads {{ text-align:center; margin:4px 0 10px 0; font-size:13px; }}\n",
        "  .updated {{ font-size:12px; color:#555; text-align:center; margin:2px 0 10px 0; }}\n",
        "  .sortbar {{ margin:6px 0 10px 0; font-size:13px; background:#ffffff; padding:6px 8px; border-radius:6px; display:flex; flex-wrap:wrap; gap:5px; align-items:center; border:1px solid #ddd; justify-content:center; }}\n",
        "  .btn {{ display:inline-block; border:1px solid #5b79b8; background:#5b79b8; color:#fff; padding:4px 9px; text-decoration:none; cursor:pointer; border-radius:5px; line-height:1.2; }}\n",
        "  .btn:hover {{ background:#4668aa; }}\n",
        "  input.btn.search {{ background:#fff; color:#111; border-color:#bbb; }}\n",
        "\n",
        "  .table-scroll {{ max-height:70vh; overflow-y:auto; overflow-x:auto; border:1px solid #ddd; }}\n",
        "  table.sortable {{ border-collapse:collapse; width:100%; table-layout:fixed; }}\n",
        "  table.sortable th, table.sortable td {{ border:1px solid #ddd; padding:6px 8px; vertical-align:top; word-wrap:break-word; overflow-wrap:break-word; }}\n",
        "  table.sortable th {{ background:#e3eaf8; text-align:left; position:sticky; top:0; z-index:2; box-shadow:0 1px 0 #ccc; cursor:pointer; }}\n",
        "  #first-row td {{ border-top:2px solid #999; }}\n",
        "\n",
        "  .find-cell {{ white-space:nowrap; }}\n",
        "  .selbox {{ margin-right:6px; vertical-align:middle; }}\n",
        "\n",
        "  .back-to-top {{ position:fixed; right:16px; bottom:16px; padding:6px 10px; border:1px solid #3e5a97; background:#5b79b8; color:#fff; cursor:pointer; border-radius:6px; font-size:12px; display:none; z-index:9999; }}\n",
        "  .back-to-top:hover {{ background:#4668aa; }}\n",
        "\n",
        "  @media screen and (min-width: 1200px) {{\n",
        "    #refactor-table col:nth-child(1) {{ width:{FIND_COL_PX}px; }}\n",
        "    #refactor-table col:nth-child(2) {{ width:{COL_A_PX}px; }}\n",
        "    .wrap {{ max-width:{TABLE_WIDTH_PX}px; }}\n",
        "  }}\n",
        "\n",
        "  @media screen and (max-width: 1199px) {{\n",
        "    #refactor-table {{ table-layout:auto; }}\n",
        "    #refactor-table col:nth-child(1) {{ width:12%; }}\n",
        "    #refactor-table col:nth-child(2) {{ width:44%; }}\n",
        "    #refactor-table col:nth-child(3) {{ width:44%; }}\n",
        "  }}\n",
        "\n",
        "  @media screen and (max-width: 700px) {{\n",
        "    table.sortable th, table.sortable td {{ padding:5px 6px; }}\n",
        "    #refactor-table col:nth-child(1) {{ width:16%; }}\n",
        "    #refactor-table col:nth-child(2) {{ width:42%; }}\n",
        "    #refactor-table col:nth-child(3) {{ width:42%; }}\n",
        "    .btn {{ padding:4px 7px; }}\n",
        "  }}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "DYNAMIC_BLOCK = (\n",
        "    '<div class=\"sortbar\">'\n",
        "    '<a class=\"btn\" href=\"https://yates.one-name.net/gengen/dna_cousin_surname_study.htm\" target=\"_blank\" rel=\"noopener\">Study Details</a>'\n",
        "    '<a class=\"btn\" href=\"https://yates.one-name.net/gengen/dna_theory_of_the_case.htm\" target=\"_blank\" rel=\"noopener\">Theory in Action</a>'\n",
        "    '<a class=\"btn\" href=\"/gengen/images/cousin-calculator.jpg\" target=\"_blank\" rel=\"noopener\">Cousin Connection</a>'\n",
        "    '<a class=\"btn\" href=\"/gengen/images/Shared_cM_Project_v4.jpg\" target=\"_blank\" rel=\"noopener\">Cousin by DNA</a>'\n",
        "    '<a class=\"btn\" href=\"/partials/match_count.htm\" target=\"_blank\" rel=\"noopener\">Match Count</a>'\n",
        "    '<a class=\"btn\" href=\"/partials/lineage_count.htm\" target=\"_blank\" rel=\"noopener\">Lineage Count</a>'\n",
        "    f'<a class=\"btn\" href=\"{DNA_REGISTER_ABS}\" target=\"_blank\" rel=\"noopener\">DNA Register</a>'\n",
        "    f'<a class=\"btn\" href=\"{TREES_ABS}\" target=\"_blank\" rel=\"noopener\">Trees</a>'\n",
        "    '<span class=\"btn\" id=\"show-selected\" title=\"Show all rows for the checked name(s)\">Show Selected</span>'\n",
        "    '<span class=\"btn\" id=\"show-all\" title=\"Show All\">Show All</span>'\n",
        "    '<span class=\"btn\" id=\"print-cousin-list\" style=\"cursor:pointer;\" title=\"Open a printable list of the *currently visible* rows\">Cousin List (Printable)</span>'\n",
        "    '<span class=\"btn\" id=\"clear-selected\">Reset</span>'\n",
        "    '<input type=\"text\" id=\"search-box\" class=\"btn search\" size=\"24\" value=\"\" placeholder=\"Search&amp;hellip;\" />'\n",
        "    '</div>'\n",
        ")\n",
        "\n",
        "JS_COUNT_URL = COUNT_PUBLIC_URL.replace(\"'\", \"%27\")\n",
        "UPDATED_BLOCK = (\n",
        "    '<div class=\"updated centerline\">'\n",
        "    'Last updated: <span id=\"last-updated\"></span>'\n",
        "    ' &nbsp;|&nbsp; Autosomal matches: <span id=\"auto-count\" class=\"js-count\"></span>'\n",
        "    ' &nbsp;|&nbsp; Showing: <span id=\"showing-count\"></span>'\n",
        "    '</div>'\n",
        ")\n",
        "\n",
        "DOWNLOADS_BLOCK = (\n",
        "    '<p class=\"downloads centerline\">Download: '\n",
        "    f'<a href=\"/partials/{_html.escape(os.path.basename(LOCAL_CSV))}\">CSV</a> | '\n",
        "    f'<a href=\"/partials/{_html.escape(os.path.basename(LOCAL_XLSX))}\">Excel</a></p>'\n",
        ")\n",
        "\n",
        "page_tpl = Template(\"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "<title>ONS Yates Study Autosomal DNA Register</title>\n",
        "$HEAD_LINK\n",
        "$TABLE_CSS\n",
        "</head>\n",
        "<body id=\"top\">\n",
        "<div class=\"wrap\">\n",
        "  <h1 class=\"centerline\">ONS Yates Study Autosomal DNA Register</h1>\n",
        "  $DOWNLOADS_BLOCK\n",
        "  $UPDATED_BLOCK\n",
        "  $DYNAMIC_BLOCK\n",
        "  <div class=\"table-scroll\">\n",
        "    $HTML_TABLE\n",
        "  </div>\n",
        "</div>\n",
        "<button id=\"back-to-top\" class=\"back-to-top\">&#9650; Top</button>\n",
        "<script type=\"text/javascript\">\n",
        "//<![CDATA[\n",
        "(function(){\n",
        "  function textOf(cell){ return (cell && (cell.textContent || cell.innerText) || '').replace(/\\\\s+/g,' ').trim().toLowerCase(); }\n",
        "  function sortTable(tbl, colIndex, dir){\n",
        "    var tb=tbl && tbl.tBodies ? tbl.tBodies[0] : null; if(!tb) return;\n",
        "    var rows=[].slice.call(tb.rows||[]); var asc=(dir==='asc');\n",
        "    rows.sort(function(a,b){var A=textOf(a.cells[colIndex]),B=textOf(b.cells[colIndex]); if(A<B) return asc?-1:1; if(A>B) return asc?1:-1; return 0;});\n",
        "    var frag=document.createDocumentFragment(); for(var i=0;i<rows.length;i++) frag.appendChild(rows[i]); tb.appendChild(frag);\n",
        "    updateShowing();\n",
        "  }\n",
        "  function bindHeaderSort(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tHead && tbl.tHead.rows.length)) return;\n",
        "    var ths=tbl.tHead.rows[0].cells; if(!ths) return;\n",
        "    for(var i=0;i<ths.length;i++)(function(idx){\n",
        "      var th = ths[idx]; var dir='asc';\n",
        "      th.addEventListener('click',function(){\n",
        "        dir=(dir==='asc')?'desc':'asc';\n",
        "        for (var j = 0; j < ths.length; j++){ ths[j].innerHTML = ths[j].innerHTML.replace(/\\\\s+\\\\(asc\\\\)|\\\\s+\\\\(desc\\\\)/,''); }\n",
        "        th.innerHTML += (dir==='asc' ? ' (asc)' : ' (desc)');\n",
        "        sortTable(tbl,idx,dir);\n",
        "      },false);\n",
        "    })(i);\n",
        "  }\n",
        "  function formatWithCommas(n){\n",
        "    try{ var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return ''; return x.toLocaleString('en-US'); }catch(e){ return String(n||''); }\n",
        "  }\n",
        "  function visibleRowCount(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return 0;\n",
        "    var rows=tbl.tBodies[0].rows, n=0; for(var i=0;i<rows.length;i++){ if(rows[i].style.display!=='none') n++; } return n;\n",
        "  }\n",
        "  function updateShowing(){ var el=document.getElementById('showing-count'); if(!el) return; el.textContent = formatWithCommas(visibleRowCount()); }\n",
        "  function getParam(name){ var m=location.search.match(new RegExp('[?&]'+name+'=([^&]+)')); return m?decodeURIComponent(m[1].replace(/\\\\+/g,' ')):''; }\n",
        "  function norm(s){ return String(s||'').replace(/\\\\s+/g,' ').toLowerCase(); }\n",
        "  function bindSearch(){\n",
        "    var box=document.getElementById('search-box'); var tbl=document.getElementById('refactor-table'); if(!(box && tbl && tbl.tBodies && tbl.tBodies[0])) return; var tb=tbl.tBodies[0];\n",
        "    function rowText(tr){ var t=''; for(var i=1;i<tr.cells.length;i++){ t+= ' ' + (tr.cells[i].textContent||tr.cells[i].innerText||''); } return norm(t); }\n",
        "    var cached=[]; (function seed(){ var rows=tb.rows; cached=[]; for(var i=0;i<rows.length;i++){ cached.push({el:rows[i], txt:rowText(rows[i])}); } })();\n",
        "    function apply(q){\n",
        "      q = String(q||''); var parts = q.split('|').map(function(s){return norm(s);}).filter(function(s){return !!s;});\n",
        "      for(var i=0;i<cached.length;i++){\n",
        "        var hit = !parts.length || parts.some(function(p){ return cached[i].txt.indexOf(p)>-1; });\n",
        "        cached[i].el.style.display = hit? '' : 'none';\n",
        "      }\n",
        "      updateShowing();\n",
        "    }\n",
        "    var to=null; function onInput(){ if(to) clearTimeout(to); to=setTimeout(function(){ apply(box.value); }, 60); }\n",
        "    box.addEventListener('input', onInput, false);\n",
        "    box.addEventListener('search', onInput, false);\n",
        "    var q0=getParam('q');\n",
        "    if(q0){ box.value=q0; apply(q0); try{ history.replaceState(null, '', location.pathname); }catch(e){} }\n",
        "    else { box.value=''; apply(''); setTimeout(function(){ if(!getParam('q')){ box.value=''; apply(''); } }, 0); }\n",
        "  }\n",
        "  function allRowCheckboxes(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return [];\n",
        "    var tb=tbl.tBodies[0], out=[];\n",
        "    for(var i=0;i<tb.rows.length;i++){\n",
        "      var cb=tb.rows[i].querySelector('.selbox');\n",
        "      if(cb) out.push(cb);\n",
        "    }\n",
        "    return out;\n",
        "  }\n",
        "  function bindGroupSync(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!tbl) return;\n",
        "    tbl.addEventListener('click', function(e){\n",
        "      var t=e.target||e.srcElement;\n",
        "      if(!(t && t.classList && t.classList.contains('selbox'))) return;\n",
        "      var nm = t.getAttribute('data-name') || '';\n",
        "      var checked = !!t.checked;\n",
        "      var cbs = allRowCheckboxes();\n",
        "      for(var i=0;i<cbs.length;i++){\n",
        "        if((cbs[i].getAttribute('data-name')||'') === nm){ cbs[i].checked = checked; }\n",
        "      }\n",
        "      updateShowing();\n",
        "    }, false);\n",
        "  }\n",
        "  function bindShowSelected(){\n",
        "    var btn=document.getElementById('show-selected'); if(!btn) return;\n",
        "    btn.addEventListener('click', function(){\n",
        "      var cbs = allRowCheckboxes();\n",
        "      var names = {};\n",
        "      for(var i=0;i<cbs.length;i++){ if(cbs[i].checked){ names[cbs[i].getAttribute('data-name')||''] = true; } }\n",
        "      var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "      var tb=tbl.tBodies[0];\n",
        "      for(var r=0;r<tb.rows.length;r++){\n",
        "        var cb = tb.rows[r].querySelector('.selbox');\n",
        "        var nm = cb ? (cb.getAttribute('data-name')||'') : '';\n",
        "        tb.rows[r].style.display = names[nm] ? '' : 'none';\n",
        "      }\n",
        "      updateShowing();\n",
        "    }, false);\n",
        "  }\n",
        "  function bindShowAll(){\n",
        "    var btn=document.getElementById('show-all'); if(!btn) return;\n",
        "    btn.addEventListener('click', function(){\n",
        "      var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "      var tb=tbl.tBodies[0];\n",
        "      for(var i=0;i<tb.rows.length;i++){ tb.rows[i].style.display=''; }\n",
        "      updateShowing();\n",
        "    }, false);\n",
        "  }\n",
        "  function bindClear(){\n",
        "    var btn=document.getElementById('clear-selected'); if(!btn) return;\n",
        "    btn.addEventListener('click', function(){\n",
        "      var cbs=allRowCheckboxes(); for(var i=0;i<cbs.length;i++) cbs[i].checked=false;\n",
        "      var tbl=document.getElementById('refactor-table'); if(tbl && tbl.tBodies && tbl.tBodies[0]){\n",
        "        var tb=tbl.tBodies[0]; for(var j=0;j<tb.rows.length;j++){ tb.rows[j].style.display=''; }\n",
        "      }\n",
        "      updateShowing();\n",
        "    }, false);\n",
        "  }\n",
        "  function addCheckboxes(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "    var tb=tbl.tBodies[0];\n",
        "    for(var i=0;i<tb.rows.length;i++){\n",
        "      var tr=tb.rows[i]; var cell=tr.cells[0]; var findBtn=cell ? cell.querySelector('.find-btn') : null;\n",
        "      var name = findBtn ? (findBtn.getAttribute('title')||'').replace('Open a filtered view for ','') : ('Row '+(i+1));\n",
        "      if(cell){\n",
        "        cell.classList.add('find-cell');\n",
        "        cell.innerHTML = '<input type=\"checkbox\" class=\"selbox\" title=\"Select this row\" data-name=\"'+name.replace(/\"/g,'&quot;')+'\" /> ' + cell.innerHTML.replace(/^\\\\s*/, '');\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  function initShowingStatic(){ try{ document.getElementById('showing-count').textContent = document.getElementById('refactor-table').tBodies[0].rows.length; }catch(e){}}\n",
        "  document.addEventListener('DOMContentLoaded', function(){\n",
        "    addCheckboxes();\n",
        "    (function(){\n",
        "      var el=document.getElementById('last-updated');\n",
        "      if(!el) return;\n",
        "      var d=new Date(document.lastModified||new Date());\n",
        "      var months=['January','February','March','April','May','June','July','August','September','October','November','December'];\n",
        "      var day=d.getDate();\n",
        "      var month=months[d.getMonth()];\n",
        "      var year=d.getFullYear();\n",
        "      var hour=d.getHours();\n",
        "      var min=d.getMinutes();\n",
        "      var ampm = hour >= 12 ? 'pm' : 'am';\n",
        "      hour = hour % 12; hour = hour ? hour : 12;\n",
        "      var minStr = min < 10 ? '0' + min : min;\n",
        "      el.innerHTML = day + ' ' + month + ', ' + year + ' at ' + hour + ':' + minStr + ' ' + ampm;\n",
        "    })();\n",
        "    bindHeaderSort();\n",
        "    bindSearch();\n",
        "    bindGroupSync();\n",
        "    bindShowSelected();\n",
        "    bindShowAll();\n",
        "    bindClear();\n",
        "    initShowingStatic();\n",
        "  });\n",
        "})();\n",
        "//]]>\n",
        "</script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\")\n",
        "\n",
        "html_table = display_df.to_html(index=False, escape=False, classes=\"dataframe sortable\")\n",
        "\n",
        "# Step 1: table/id/first row\n",
        "html_table = html_table.replace('<table border=\"1\" class=\"dataframe sortable\">', '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">', 1)\n",
        "html_table = html_table.replace('<tbody>\\n<tr>', '<tbody>\\n<tr id=\"first-row\">', 1)\n",
        "html_table = html_table.replace(\"<th>Find</th>\", '<th>Select:</th>', 1)\n",
        "\n",
        "# Step 2: headers\n",
        "html_table = html_table.replace('<th>Match Summary</th>', '<th>Match Summary&amp;ndash;click to sort</th>', 1)\n",
        "html_table = html_table.replace(f'<th>{_html.escape(LINEAGE_HEADER_SAFE)}</th>', '<th>Lineage (Starting with oldest ancestor&amp;ndash;click to sort)</th>', 1)\n",
        "\n",
        "# Step 3: colgroup\n",
        "colgroup_html = (\n",
        "    \"<colgroup>\\n\"\n",
        "    f\"  <col style=\\\"width:{FIND_COL_PX}px;\\\" />\\n\"\n",
        "    f\"  <col style=\\\"width:{COL_A_PX}px;\\\" />\\n\"\n",
        "    \"  <col />\\n\"\n",
        "    \"</colgroup>\\n\"\n",
        ")\n",
        "html_table = html_table.replace(\n",
        "    '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">',\n",
        "    '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">\\n' + colgroup_html,\n",
        "    1\n",
        ")\n",
        "\n",
        "# Build main page\n",
        "final_html = page_tpl.safe_substitute(\n",
        "    HEAD_LINK=HEAD_LINK,\n",
        "    TABLE_CSS=TABLE_CSS,\n",
        "    UPDATED_BLOCK=UPDATED_BLOCK,\n",
        "    DYNAMIC_BLOCK=DYNAMIC_BLOCK,\n",
        "    HTML_TABLE=html_table,\n",
        "    JS_COUNT_URL=JS_COUNT_URL,\n",
        "    DOWNLOADS_BLOCK=DOWNLOADS_BLOCK\n",
        ").replace(\"$HEAD_LINK_URL_JS$\", (STYLESHEET_HREF + \"?\" + CSS_VERSION))\n",
        "\n",
        "# ---------- 8) Partials (simple shells share the same date/time stamp logic) ----------\n",
        "def _norm_code_for_count(s):\n",
        "    t = str(s or \"\").strip()\n",
        "    if (t.startswith('\"') and t.endswith('\"')) or (t.startswith(\"'\") and t.endswith(\"'\")):\n",
        "        t = t[1:-1]\n",
        "    t = re.sub(r'\\s+', ' ', t).strip()\n",
        "    t = t.lower()\n",
        "    return t\n",
        "\n",
        "def _partial_css_wrapper_simple():\n",
        "    return (\n",
        "        \"<style type=\\\"text/css\\\">\\n\"\n",
        "        \"  html { scroll-behavior: smooth; }\\n\"\n",
        "        \"  body { background:#ffffff; color:#222; margin:0; padding:0; }\\n\"\n",
        "        \"  .wrap { max-width:100%; margin:0 auto; padding:16px; }\\n\"\n",
        "        \"  a { color:#154b8b; text-decoration:none; } a:hover { text-decoration:underline; }\\n\"\n",
        "        \"  h1 { margin:0 0 8px 0; font-size:24px; line-height:1.2; text-align:center; }\\n\"\n",
        "        \"  .meta { text-align:center; font-size:12px; color:#555; margin:2px 0 10px 0; }\\n\"\n",
        "        \"  .toolbar { display:flex; gap:10px; align-items:center; margin:6px 0 10px 0; flex-wrap:wrap; justify-content:center; }\\n\"\n",
        "        \"  .btn { display:inline-block; border:1px solid #5b79b8; background:#5b79b8; color:#fff; padding:4px 9px; text-decoration:none; cursor:pointer; border-radius:5px; line-height:1.2; }\\n\"\n",
        "        \"  table { border-collapse:collapse; width:100%; table-layout:fixed; }\\n\"\n",
        "        \"  th, td { border:1px solid #ddd; padding:6px 8px; word-wrap:break-word; overflow-wrap:break-word; }\\n\"\n",
        "        \"  th { background:#e3eaf8; text-align:left; position:sticky; top:0; z-index:2; }\\n\"\n",
        "        \"  tr.sel { background:#fff7d6; }\\n\"\n",
        "        \"  .count a { font-weight:bold; }\\n\"\n",
        "        \"  @media screen and (max-width: 700px) { th, td { padding:5px 6px; } }\\n\"\n",
        "        \"</style>\\n\"\n",
        "    )\n",
        "\n",
        "def _partial_head(title):\n",
        "    return (\n",
        "        \"<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Transitional//EN\\\"\\n\"\n",
        "        \" \\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\\\">\\n\"\n",
        "        \"<html xmlns=\\\"http://www.w3.org/1999/xhtml\\\" lang=\\\"en\\\">\\n<head>\\n\"\n",
        "        f\"{HEAD_LINK}\\n\"\n",
        "        \"<meta http-equiv=\\\"Content-Type\\\" content=\\\"text/html; charset=iso-8859-15\\\" />\\n\"\n",
        "        f\"<title>{_html.escape(title)}</title>\\n\"\n",
        "    )\n",
        "\n",
        "def _partial_toolbar():\n",
        "    safe_home = HOME_URL.replace('\"', '&quot;')\n",
        "    return (\n",
        "        \"<div class=\\\"toolbar\\\">\"\n",
        "        f\"<a class=\\\"btn\\\" href=\\\"{safe_home}\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">DNA Register</a>\"\n",
        "        \" <button id=\\\"mc-show-selected\\\" class=\\\"btn\\\" title=\\\"Open DNA Register filtered to selected\\\">Show Selected</button>\"\n",
        "        \" <button id=\\\"mc-show-all\\\" class=\\\"btn\\\" title=\\\"Show all rows (this table)\\\">Show All</button>\"\n",
        "        \" <button id=\\\"mc-reset\\\" class=\\\"btn\\\" title=\\\"Clear selection and show all\\\">Reset</button>\"\n",
        "        \" <button id=\\\"view\\\" class=\\\"btn\\\" title=\\\"Open DNA Register with selected (alias)\\\">View Now</button>\"\n",
        "        \"</div>\\n\"\n",
        "    )\n",
        "\n",
        "def _partial_js_common():\n",
        "    _safe_home = HOME_URL.replace(\"'\", \"%27\")\n",
        "    return (\n",
        "        \"<script type=\\\"text/javascript\\\">\\n//<![CDATA[\\n\"\n",
        "        \"(function(){\\n\"\n",
        "        \"  var REG = '\" + _safe_home + \"';\\n\"\n",
        "        \"  function fmt(n){ try{ var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return '0'; return x.toLocaleString('en-US'); }catch(e){ return String(n||'0'); } }\\n\"\n",
        "        \"  function selected(){ var out=[]; var tb=document.getElementById('ref-tb'); if(!tb) return out; var rows=tb.rows; for(var i=0;i<rows.length;i++){ if((' '+rows[i].className+' ').indexOf(' sel ')>-1) out.push(rows[i]); } return out; }\\n\"\n",
        "        \"  function update(){ var sel=selected(), sum=0; for(var i=0;i<sel.length;i++){ var v=parseInt((sel[i].getAttribute('data-count')||'0').replace(/[^0-9\\\\-]/g,''),10); if(!isNaN(v)) sum+=v; } var nEl=document.getElementById('sel-n'); var sEl=document.getElementById('sel-sum'); if(nEl) nEl.innerHTML=fmt(sel.length); if(sEl) sEl.innerHTML=fmt(sum); }\\n\"\n",
        "        \"  function qJoin(parts){ var out=[]; var seen={}; for(var i=0;i<parts.length;i++){ var p=String(parts[i]||''); if(p && !seen[p]){ seen[p]=1; out.push(encodeURIComponent(p)); } } return out.join('%7C'); }\\n\"\n",
        "        \"  function openRegisterForSelected(){ var sel=selected(); if(!sel.length) return; var qs=[]; for(var i=0;i<sel.length;i++){ qs.push(sel[i].getAttribute('data-q')||''); } var q = qJoin(qs); var url = REG + '?q=' + q; var w=null; try{ w=window.open(url,'RegisterFiltered'); if(!w) throw new Error('popup'); w.focus(); } catch(e){ window.location.href = url; } }\\n\"\n",
        "        \"  function toggleFrom(el){ var tr=el; while(tr && tr.nodeName && tr.nodeName.toLowerCase()!=='tr'){ tr=tr.parentNode; } if(!tr) return; var c=tr.className||''; tr.className = ((' '+c+' ').indexOf(' sel ')>-1) ? c.replace(/\\\\bsel\\\\b/,'').replace(/\\\\s{2,}/g,' ').trim() : (c?c+' ':'')+'sel'; update(); }\\n\"\n",
        "        \"  document.addEventListener('click', function(e){ var t=e.target||e.srcElement; if(!t) return; if(t.classList && t.classList.contains('count-pick')){ e.preventDefault(); toggleFrom(t); return; } if(t.id=='view' || t.id=='mc-show-selected'){ e.preventDefault(); openRegisterForSelected(); return; } if(t.id=='mc-reset'){ e.preventDefault(); var tb=document.getElementById('ref-tb'); if(tb){ var rows=tb.rows; for(var i=0;i<rows.length;i++){ rows[i].className = rows[i].className.replace(/\\\\bsel\\\\b/,'').replace(/\\\\s{2,}/g,' ').trim(); rows[i].style.display=''; } } update(); return; } if(t.id=='mc-show-all'){ e.preventDefault(); var tb2=document.getElementById('ref-tb'); if(!tb2) return; for(var k=0;k<tb2.rows.length;k++){ tb2.rows[k].style.display=''; } return; } }, false);\\n\"\n",
        "        \"  document.addEventListener('DOMContentLoaded', update, false);\\n\"\n",
        "        \"})();\\n\"\n",
        "        \"//]]>\\n</script>\\n\"\n",
        "    )\n",
        "\n",
        "def _shell_open(title):\n",
        "    return (\n",
        "        _partial_head(title) +\n",
        "        _partial_css_wrapper_simple() +\n",
        "        \"</head>\\n<body>\\n<div class=\\\"wrap\\\">\\n\" +\n",
        "        f\"<h1>{_html.escape(title)}</h1>\\n\" +\n",
        "        \"<div class=\\\"meta\\\">\"\n",
        "        \"Last updated: <span id=\\\"last-updated\\\"></span>\"\n",
        "        \" &nbsp;|&nbsp; Autosomal matches: <span id=\\\"auto-count\\\">&mdash;</span>\"\n",
        "        \" &nbsp;|&nbsp; Selected: <span id=\\\"sel-n\\\">0</span> &nbsp; Sum: <span id=\\\"sel-sum\\\">0</span>\"\n",
        "        \"</div>\\n\" +\n",
        "        _partial_toolbar() +\n",
        "        \"<div class=\\\"table-scroll\\\">\\n\"\n",
        "    )\n",
        "\n",
        "def _shell_close():\n",
        "    safe_count = COUNT_PUBLIC_URL.replace(\"'\", \"%27\")\n",
        "    return (\n",
        "        \"</div>\\n</div>\\n\"\n",
        "        \"<script type=\\\"text/javascript\\\">\\n//<![CDATA[\\n\"\n",
        "        \"(function(){ \"\n",
        "        \"function stamp(){\"\n",
        "        \" var el=document.getElementById('last-updated'); if(!el) return; \"\n",
        "        \" var d=new Date(document.lastModified||new Date()); \"\n",
        "        \" var months=['January','February','March','April','May','June','July','August','September','October','November','December']; \"\n",
        "        \" var day=d.getDate(); \"\n",
        "        \" var month=months[d.getMonth()]; \"\n",
        "        \" var year=d.getFullYear(); \"\n",
        "        \" var hour=d.getHours(); \"\n",
        "        \" var min=d.getMinutes(); \"\n",
        "        \" var ampm = hour >= 12 ? 'pm' : 'am'; \"\n",
        "        \" hour = hour % 12; hour = hour ? hour : 12; \"\n",
        "        \" var minStr = min < 10 ? '0' + min : min; \"\n",
        "        \" el.innerHTML = day + ' ' + month + ', ' + year + ' at ' + hour + ':' + minStr + ' ' + ampm; \"\n",
        "        \"}\"\n",
        "        \"function load(){var el=document.getElementById('auto-count'); if(!el) return; var URL='\" + safe_count + \"'; try{var xhr=new XMLHttpRequest(); xhr.open('GET', URL+(URL.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true); xhr.onreadystatechange=function(){if(xhr.readyState===4){if(xhr.status>=200&&xhr.status<300){var m=(xhr.responseText||'').match(/(\\\\d+)/); el.textContent=(m?m[1]:'');} else {el.textContent='(unavailable)';}}}; xhr.send(null);}catch(e){el.textContent='(unavailable)';}}\\n\"\n",
        "        \"document.addEventListener('DOMContentLoaded', function(){ stamp(); load(); }, false); })();\\n\"\n",
        "        \"//]]>\\n</script>\\n\"\n",
        "        + _partial_js_common() +\n",
        "        \"</body>\\n</html>\"\n",
        "    )\n",
        "\n",
        "def build_match_count_partial(main_df: pd.DataFrame) -> str:\n",
        "    codes_raw = main_df[match_col].astype(str).map(lambda x: x.strip())\n",
        "    keys_norm = codes_raw.map(_norm_code_for_count)\n",
        "    counts_series = keys_norm.value_counts(dropna=False)\n",
        "    counts = counts_series.reset_index()\n",
        "    if counts.shape[1] >= 2:\n",
        "        counts.columns = [\"norm_key\", \"Count\"]\n",
        "    else:\n",
        "        counts[\"norm_key\"] = counts.index.astype(str)\n",
        "        counts[\"Count\"] = counts_series.values\n",
        "        counts = counts[[\"norm_key\", \"Count\"]]\n",
        "    first_display = {}\n",
        "    for code_disp, k in zip(codes_raw.tolist(), keys_norm.tolist()):\n",
        "        if k not in first_display and str(k) != \"\":\n",
        "            first_display[k] = code_disp\n",
        "    counts[\"Code\"] = counts[\"norm_key\"].map(lambda k: first_display.get(k, k))\n",
        "    counts[\"Unmasked\"] = counts[\"norm_key\"].map(lambda k: MATCH_TO_UNMASKED.get(k, \"\"))\n",
        "    counts = counts.sort_values(by=[\"Code\", \"Count\"], ascending=[True, False], kind=\"mergesort\").reset_index(drop=True)\n",
        "\n",
        "    html = []\n",
        "    html.append(_shell_open(\"Match Count\"))\n",
        "    html.append('<table id=\"ref-table\" border=\"1\" class=\"sortable\" style=\"width:100%\"><thead><tr>')\n",
        "    html.append('<th style=\"width:35%\">Code</th><th style=\"width:45%\">Unmasked</th><th style=\"width:20%\">Count</th>')\n",
        "    html.append('</tr></thead><tbody id=\"ref-tb\">')\n",
        "    for _, r in counts.iterrows():\n",
        "        code = r.get(\"Code\", \"\")\n",
        "        unm  = r.get(\"Unmasked\", \"\")\n",
        "        cnt  = int(str(r.get(\"Count\", \"0\")).strip() or \"0\")\n",
        "        label = (unm or code).strip()\n",
        "        tr = (\n",
        "            f'<tr data-q=\"{_html.escape(label, quote=True)}\" data-count=\"{cnt}\">'\n",
        "            f'<td>{_html.escape(code)}</td>'\n",
        "            f'<td>{_html.escape(unm)}</td>'\n",
        "            f'<td class=\"count\"><a href=\"#\" class=\"count-pick\" title=\"Toggle select\">{cnt}</a></td>'\n",
        "            f'</tr>'\n",
        "        )\n",
        "        html.append(tr)\n",
        "    html.append('</tbody></table>')\n",
        "    html.append(_shell_close())\n",
        "    return \"\".join(html)\n",
        "\n",
        "def build_lineage_count_partial(main_df: pd.DataFrame) -> str:\n",
        "    first_series = main_df.get(\"First Ancestor\", pd.Series(dtype=str)).astype(str).map(lambda x: x.strip())\n",
        "    vc = first_series[first_series != \"\"].value_counts(dropna=False)\n",
        "    lin_df = vc.reset_index()\n",
        "    if lin_df.shape[1] >= 2:\n",
        "        lin_df.columns = [\"First Ancestor\", \"Count\"]\n",
        "    else:\n",
        "        lin_df[\"First Ancestor\"] = lin_df.index.astype(str)\n",
        "        lin_df[\"Count\"] = vc.values\n",
        "        lin_df = lin_df[[\"First Ancestor\", \"Count\"]]\n",
        "    lin_df = lin_df.sort_values([\"Count\", \"First Ancestor\"], ascending=[False, True], kind=\"mergesort\").reset_index(drop=True)\n",
        "\n",
        "    html = []\n",
        "    html.append(_shell_open(\"Lineage Count\"))\n",
        "    html.append('<table id=\"ref-table\" border=\"1\" class=\"sortable\" style=\"width:100%\"><thead><tr>')\n",
        "    html.append('<th style=\"width:80%\">First Ancestor</th><th style=\"width:20%\">Count</th>')\n",
        "    html.append('</tr></thead><tbody id=\"ref-tb\">')\n",
        "    for _, r in lin_df.iterrows():\n",
        "        first = str(r.get(\"First Ancestor\", \"\")).strip()\n",
        "        cnt   = int(str(r.get(\"Count\", \"0\")).strip() or \"0\")\n",
        "        tr = (\n",
        "            f'<tr data-q=\"{_html.escape(first, quote=True)}\" data-count=\"{cnt}\">'\n",
        "            f'<td>{_html.escape(first)}</td>'\n",
        "            f'<td class=\"count\"><a href=\"#\" class=\"count-pick\" title=\"Toggle select\">{cnt}</a></td>'\n",
        "            f'</tr>'\n",
        "        )\n",
        "        html.append(tr)\n",
        "    html.append('</tbody></table>')\n",
        "    html.append(_shell_close())\n",
        "    return \"\".join(html)\n",
        "\n",
        "def build_and_write_partials(main_df: pd.DataFrame):\n",
        "    _setup_resolver()\n",
        "    os.makedirs(\"partials\", exist_ok=True)\n",
        "\n",
        "    mc_html = build_match_count_partial(main_df)\n",
        "    mc_local = os.path.join(\"partials\", \"match_count.htm\")\n",
        "    with open(mc_local, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(mc_html)\n",
        "    print(\"[OK] Wrote partial:\", mc_local)\n",
        "\n",
        "    lc_html = build_lineage_count_partial(main_df)\n",
        "    lc_local = os.path.join(\"partials\", \"lineage_count.htm\")\n",
        "    with open(lc_local, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(lc_html)\n",
        "    print(\"[OK] Wrote partial:\", lc_local)\n",
        "\n",
        "    # Printable cousin list\n",
        "    cousin_df = main_df[[\"Match Summary\"]].copy()\n",
        "    cousin_df = cousin_df.sort_values(by=\"Match Summary\", ascending=True, kind=\"mergesort\").reset_index(drop=True)\n",
        "    cousin_rows = ['<table border=\"1\" id=\"refactor-table\"><thead><tr><th>Match Summary</th></tr></thead><tbody>']\n",
        "    for v in cousin_df[\"Match Summary\"].tolist():\n",
        "        cousin_rows.append(f\"<tr><td>{v}</td></tr>\")\n",
        "    cousin_rows.append(\"</tbody></table>\")\n",
        "    cousin_html = (\n",
        "        \"<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Transitional//EN\\\" \\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\\\">\"\n",
        "        \"<html xmlns=\\\"http://www.w3.org/1999/xhtml\\\" lang=\\\"en\\\"><head>\"\n",
        "        f\"{HEAD_LINK}\"\n",
        "        \"<meta http-equiv=\\\"Content-Type\\\" content=\\\"text/html; charset=iso-8859-15\\\" />\"\n",
        "        \"<title>Cousin List (Printable)</title>\"\n",
        "        \"<style type=\\\"text/css\\\"> body{font-size:12px;margin:20px;} h1{text-align:center;font-size:20px;} table{border-collapse:collapse;width:100%;} th,td{border:1px solid #999;padding:5px 7px;vertical-align:top;text-align:left;} th{background:#f0f0f0;} a{color:#000;text-decoration:none;} </style>\"\n",
        "        \"</head><body onload=\\\"window.print();\\\">\"\n",
        "        \"<h1>Cousin List (Printable)</h1>\" + \"\".join(cousin_rows) +\n",
        "        \"</body></html>\"\n",
        "    )\n",
        "    cl_local = os.path.join(\"partials\", \"cousin_list_print.htm\")\n",
        "    with open(cl_local, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(cousin_html)\n",
        "    print(\"[OK] Wrote partial:\", cl_local)\n",
        "\n",
        "    return mc_local, lc_local, cl_local\n",
        "\n",
        "# Build partials + main page\n",
        "PARTIAL_MATCH_LOCAL, PARTIAL_LINEAGE_LOCAL, PARTIAL_COUSIN_LOCAL = build_and_write_partials(df)\n",
        "\n",
        "def build_register_html_for_abs(remote_abs_path: str) -> str:\n",
        "    q_links = []\n",
        "    subs = df[\"Subject\"].astype(str).tolist()\n",
        "    for subject_name in subs:\n",
        "        q = _u.quote(subject_name)\n",
        "        q_links.append(\n",
        "            f'<a class=\"find-btn\" href=\"{remote_abs_path}?q={q}\" target=\"_blank\" rel=\"noopener\" '\n",
        "            f'title=\"Open a filtered view for {subject_name}\">Find</a>'\n",
        "        )\n",
        "    df_plus = df.copy()\n",
        "    df_plus[\"Find\"] = q_links\n",
        "    disp_plus = df_plus[[\"Find\", \"Match Summary\", LINEAGE_HEADER_SAFE]]\n",
        "    tbl = disp_plus.to_html(index=False, escape=False, classes=\"dataframe sortable\")\n",
        "    tbl = tbl.replace('<table border=\"1\" class=\"dataframe sortable\">', '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">', 1)\n",
        "    tbl = tbl.replace('<tbody>\\n<tr>', '<tbody>\\n<tr id=\"first-row\">', 1)\n",
        "    tbl = tbl.replace(\"<th>Find</th>\", '<th>Select:</th>', 1)\n",
        "    tbl = tbl.replace(\"<th>Match Summary</th>\", '<th>Match Summary&amp;ndash;click to sort</th>', 1)\n",
        "    tbl = tbl.replace(f\"<th>{_html.escape(LINEAGE_HEADER_SAFE)}</th>\", \"<th>Lineage (Starting with oldest ancestor&amp;ndash;click to sort)</th>\", 1)\n",
        "\n",
        "    colgroup_html_local = (\n",
        "        \"<colgroup>\\n\"\n",
        "        f\"  <col style=\\\"width:{FIND_COL_PX}px;\\\" />\\n\"\n",
        "        f\"  <col style=\\\"width:{COL_A_PX}px;\\\" />\\n\"\n",
        "        \"  <col />\\n\"\n",
        "        \"</colgroup>\\n\"\n",
        "    )\n",
        "    tbl = tbl.replace(\n",
        "        '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">',\n",
        "        '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">\\n' + colgroup_html_local, 1\n",
        "    )\n",
        "    return page_tpl.safe_substitute(\n",
        "        HEAD_LINK=HEAD_LINK,\n",
        "        TABLE_CSS=TABLE_CSS,\n",
        "        UPDATED_BLOCK=UPDATED_BLOCK,\n",
        "        DYNAMIC_BLOCK=DYNAMIC_BLOCK,\n",
        "        HTML_TABLE=tbl,\n",
        "        JS_COUNT_URL=JS_COUNT_URL,\n",
        "        DOWNLOADS_BLOCK=DOWNLOADS_BLOCK\n",
        "    ).replace(\"$HEAD_LINK_URL_JS$\", (STYLESHEET_HREF + \"?\" + CSS_VERSION))\n",
        "\n",
        "os.makedirs(\"partials\", exist_ok=True)\n",
        "final_html_plus = build_register_html_for_abs(HOME_URL)\n",
        "\n",
        "with open(LOCAL_HTML, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(final_html)\n",
        "print(\"[OK] Saved canonical render:\", os.path.abspath(LOCAL_HTML))\n",
        "\n",
        "with open(WORK_PLUS_LOCAL, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(final_html_plus)\n",
        "print(\"[OK] Saved:\", os.path.abspath(WORK_PLUS_LOCAL), \"(partials clone)\")\n",
        "\n",
        "# ---------- 10) Uploads ----------\n",
        "def save_and_upload_all():\n",
        "    if not all(os.environ.get(k) for k in ['FTP_HOST', 'FTP_USER', 'FTP_PASS']):\n",
        "        print(\"[SKIP] Missing FTP creds; uploads skipped.\")\n",
        "        return\n",
        "    try:\n",
        "        ftps = ftp_connect()\n",
        "        try:\n",
        "            ftp_upload_overwrite(ftps, LOCAL_HTML, _remote_path(REMOTE_HTML_CANON))\n",
        "            ftp_upload_overwrite(ftps, LOCAL_HTML, _remote_path(REMOTE_HTML_LEG))\n",
        "            ftp_upload_overwrite(ftps, LOCAL_HTML, _remote_path(REMOTE_HTML_SIMPLE))\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload main HTML failed:\", e)\n",
        "        try:\n",
        "            if os.path.exists(LOCAL_CSV):\n",
        "                ftp_upload_overwrite(ftps, LOCAL_CSV, _remote_path(REMOTE_CSV))\n",
        "            if os.path.exists(LOCAL_XLSX):\n",
        "                ftp_upload_overwrite(ftps, LOCAL_XLSX, _remote_path(REMOTE_XLSX))\n",
        "            print(\"[OK] Uploaded CSV/XLSX -> /partials/\")\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload CSV/XLSX failed:\", e)\n",
        "        if os.path.exists(LOCAL_COUNT_FILE):\n",
        "            try:\n",
        "                ftp_upload_overwrite(ftps, LOCAL_COUNT_FILE, _remote_path(REMOTE_COUNT_NAME))\n",
        "            except Exception as e:\n",
        "                print(\"[WARN] Upload autosomal count failed:\", e)\n",
        "        try:\n",
        "            ftp_upload_overwrite(ftps, os.path.join(\"partials\", \"match_count.htm\"), _remote_path(posixpath.join(\"partials\", \"match_count.htm\")))\n",
        "            ftp_upload_overwrite(ftps, os.path.join(\"partials\", \"lineage_count.htm\"), _remote_path(posixpath.join(\"partials\", \"lineage_count.htm\")))\n",
        "            ftp_upload_overwrite(ftps, os.path.join(\"partials\", \"cousin_list_print.htm\"), _remote_path(posixpath.join(\"partials\", \"cousin_list_print.htm\")))\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload partials failed:\", e)\n",
        "        try:\n",
        "            ftp_upload_overwrite(ftps, WORK_PLUS_LOCAL, _remote_path(WORK_PLUS_REMOTE))\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload work_plus.htm failed:\", e)\n",
        "\n",
        "        print(\"\\n--- SIZE Verification (if supported) ---\")\n",
        "        for p in [\n",
        "            _remote_path(REMOTE_HTML_CANON),\n",
        "            _remote_path(REMOTE_HTML_LEG),\n",
        "            _remote_path(REMOTE_HTML_SIMPLE),\n",
        "            _remote_path(REMOTE_CSV),\n",
        "            _remote_path(REMOTE_XLSX),\n",
        "            _remote_path(posixpath.join(\"partials\", \"match_count.htm\")),\n",
        "            _remote_path(posixpath.join(\"partials\", \"lineage_count.htm\")),\n",
        "            _remote_path(posixpath.join(\"partials\", \"cousin_list_print.htm\")),\n",
        "            _remote_path(WORK_PLUS_REMOTE),\n",
        "        ]:\n",
        "            sz = ftp_size(ftps, p)\n",
        "            print(f\"{p} : {sz if sz is not None else '(SIZE unsupported)'}\")\n",
        "        try:\n",
        "            ftps.quit()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        print(\"\\n--- Open URLs ---\")\n",
        "        print(\"Canonical (Find target):          https://yates.one-name.net/partials/yates_ancestor_register.htm\")\n",
        "        print(\"Legacy clone (same content):      https://yates.one-name.net/partials/ons_yates_dna_register.htm\")\n",
        "        print(\"JUSTDNA simple alias:             https://yates.one-name.net/partials/justdna.htm\")\n",
        "        print(\"Trees page:                       https://yates.one-name.net/partials/just-trees.htm\")\n",
        "        print(\"Match Count:                      https://yates.one-name.net/partials/match_count.htm\")\n",
        "        print(\"Lineage Count:                    https://yates.one-name.net/partials/lineage_count.htm\")\n",
        "        print(\"Cousin List (Printable):          https://yates.one-name.net/partials/cousin_list_print.htm\")\n",
        "        print(\"Work+ clone:                      https://yates.one-name.net/partials/work_plus.htm\")\n",
        "\n",
        "        print(\"\\nIf a button still opens the wrong target, hard-refresh or append ?v=1 once to bust cache.\")\n",
        "    except Exception as e:\n",
        "        print(\"[FAIL] FTP session:\", e)\n",
        "        traceback.print_exc()\n",
        "\n",
        "# ---------- 11) Upload ----------\n",
        "save_and_upload_all()\n",
        "# ====== CUT STOP [1/1] CELL 2 ===================================================================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gL8FPMAkmqmV",
        "outputId": "a683d952-b71d-4f23-dcef-2722c865c88d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Loaded CSV: 1572 rows, 6 cols\n",
            "[PULL] match_to_unmasked.csv -> /content/match_to_unmasked.server.csv\n",
            "[OK] Resolver loaded: 79 codes\n",
            "[OK] Wrote exports: /content/yates_ancestor_register.csv and /content/yates_ancestor_register.xlsx\n",
            "[OK] Wrote partial: partials/match_count.htm\n",
            "[OK] Wrote partial: partials/lineage_count.htm\n",
            "[OK] Wrote partial: partials/cousin_list_print.htm\n",
            "[OK] Saved canonical render: /content/yates_ancestor_register.htm\n",
            "[OK] Saved: /content/partials/work_plus.htm (partials clone)\n",
            "[PUT] yates_ancestor_register.htm -> partials/yates_ancestor_register.htm\n",
            "[PUT] yates_ancestor_register.htm -> partials/ons_yates_dna_register.htm\n",
            "[PUT] yates_ancestor_register.htm -> partials/justdna.htm\n",
            "[PUT] yates_ancestor_register.csv -> partials/yates_ancestor_register.csv\n",
            "[PUT] yates_ancestor_register.xlsx -> partials/yates_ancestor_register.xlsx\n",
            "[OK] Uploaded CSV/XLSX -> /partials/\n",
            "[PUT] /content/autosomal_count.txt -> autosomal_count.txt\n",
            "[PUT] partials/match_count.htm -> partials/match_count.htm\n",
            "[PUT] partials/lineage_count.htm -> partials/lineage_count.htm\n",
            "[PUT] partials/cousin_list_print.htm -> partials/cousin_list_print.htm\n",
            "[PUT] partials/work_plus.htm -> partials/work_plus.htm\n",
            "\n",
            "--- SIZE Verification (if supported) ---\n",
            "partials/yates_ancestor_register.htm : 1285230\n",
            "partials/ons_yates_dna_register.htm : 1285230\n",
            "partials/justdna.htm : 1285230\n",
            "partials/yates_ancestor_register.csv : 650445\n",
            "partials/yates_ancestor_register.xlsx : 115780\n",
            "partials/match_count.htm : 19295\n",
            "partials/lineage_count.htm : 48122\n",
            "partials/cousin_list_print.htm : 519302\n",
            "partials/work_plus.htm : 1285230\n",
            "\n",
            "--- Open URLs ---\n",
            "Canonical (Find target):          https://yates.one-name.net/partials/yates_ancestor_register.htm\n",
            "Legacy clone (same content):      https://yates.one-name.net/partials/ons_yates_dna_register.htm\n",
            "JUSTDNA simple alias:             https://yates.one-name.net/partials/justdna.htm\n",
            "Trees page:                       https://yates.one-name.net/partials/just-trees.htm\n",
            "Match Count:                      https://yates.one-name.net/partials/match_count.htm\n",
            "Lineage Count:                    https://yates.one-name.net/partials/lineage_count.htm\n",
            "Cousin List (Printable):          https://yates.one-name.net/partials/cousin_list_print.htm\n",
            "Work+ clone:                      https://yates.one-name.net/partials/work_plus.htm\n",
            "\n",
            "If a button still opens the wrong target, hard-refresh or append ?v=1 once to bust cache.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 3"
      ],
      "metadata": {
        "id": "INiJljOS1kRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3\n",
        "# RON RULES — QUICK CODE CARD (v2025.11.05-AncReg-Exports+Partials-JustTrees-NavDNA)\n",
        "# 1) EXECUTION: Complete & runnable in Colab; ISO-8859-15 (ASCII-only in source).\n",
        "# 2) PUNCTUATION IN STRINGS: Use HTML entities (&rsquo; &ldquo; &rdquo; &mdash; &rarr;).\n",
        "# 3) CONTENT: Deliver full runnable code (no snippets). No fabrication or inference.\n",
        "# 4) Python code (inline, executable, full COLAB Cell paste-ready section); ISO-8859-15 (ASCII-only in source).\n",
        "# 5) HTML: XHTML 1.0 Transitional style acceptable; avoid HTML5-only tags if not needed.\n",
        "# 6) INTEGRITY: Work in CUT-ready sections only; exactly five # lines after each section.\n",
        "\n",
        "# Core imports\n",
        "import os, re, socket, posixpath, traceback\n",
        "import pandas as pd\n",
        "import html as _html\n",
        "\n",
        "# Time imports (fix for ZoneInfo)\n",
        "from datetime import datetime\n",
        "try:\n",
        "    from zoneinfo import ZoneInfo  # Python 3.9+\n",
        "except Exception:\n",
        "    ZoneInfo = None\n",
        "\n",
        "# FTPS\n",
        "from ftplib import FTP_TLS\n",
        "# ====== CUT STOP  [1/6] RULES + IMPORTS + SECRETS ===============================================\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "\n",
        "\n",
        "\n",
        "# ====== CUT START [2/6] SECRETS + LOAD DATA + COUNTS + PATHS ===================================\n",
        "# --- Securely load secrets (Colab or env) ---\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ['FTP_HOST'] = userdata.get('FTP_HOST')\n",
        "    os.environ['FTP_USER'] = userdata.get('FTP_USER')\n",
        "    os.environ['FTP_PASS'] = userdata.get('FTP_PASS')\n",
        "    try:  os.environ['FTP_PORT'] = userdata.get('FTP_PORT')\n",
        "    except Exception: os.environ.setdefault('FTP_PORT', '21')\n",
        "    try:  os.environ['FTP_DIR']  = userdata.get('FTP_DIR')\n",
        "    except Exception: os.environ.setdefault('FTP_DIR', '')\n",
        "except Exception:\n",
        "    os.environ.setdefault('FTP_HOST', '')\n",
        "    os.environ.setdefault('FTP_USER', '')\n",
        "    os.environ.setdefault('FTP_PASS', '')\n",
        "    os.environ.setdefault('FTP_PORT', '21')\n",
        "    os.environ.setdefault('FTP_DIR', '')\n",
        "\n",
        "FTP_DIR  = os.environ.get('FTP_DIR', '').strip().strip('/')\n",
        "COUNT_PUBLIC_URL = (\"/%s/%s\" % (FTP_DIR, \"autosomal_count.txt\")) if FTP_DIR else \"/autosomal_count.txt\"\n",
        "\n",
        "# Inputs\n",
        "INPUT_CSV   = \"final_combined_df_with_value_labels.csv\"\n",
        "\n",
        "# OUTPUT html filename stays just-trees.htm\n",
        "OUTPUT_NAME = \"just-trees.htm\"\n",
        "\n",
        "# Button target (new nav button)\n",
        "DNA_REGISTER_ABS = \"https://yates.one-name.net/partials/justdna.htm\"\n",
        "\n",
        "# Export names for CSV/XLSX (mirror visible table); served from /partials/\n",
        "EXPORT_BASE = \"yates_ancestor_register\"\n",
        "LOCAL_CSV   = EXPORT_BASE + \".csv\"\n",
        "LOCAL_XLSX  = EXPORT_BASE + \".xlsx\"\n",
        "REMOTE_CSV  = posixpath.join(\"partials\", LOCAL_CSV)\n",
        "REMOTE_XLSX = posixpath.join(\"partials\", LOCAL_XLSX)\n",
        "\n",
        "# Upload the HTML itself into /partials/ using the OUTPUT_NAME\n",
        "REMOTE_HTML = posixpath.join(\"partials\", OUTPUT_NAME)\n",
        "\n",
        "# Load CSV (robust encodings)\n",
        "df = None\n",
        "_last_err = None\n",
        "for enc in (\"utf-8-sig\",\"utf-8\",\"cp1252\",\"iso-8859-15\",\"latin1\"):\n",
        "    try:\n",
        "        df = pd.read_csv(INPUT_CSV, dtype=str, keep_default_na=False, encoding=enc)\n",
        "        break\n",
        "    except Exception as e:\n",
        "        _last_err = e\n",
        "        df = None\n",
        "if df is None:\n",
        "    raise SystemExit(\"[ERROR] Unable to read CSV: %s (%r)\" % (INPUT_CSV, _last_err))\n",
        "print(\"[OK] Loaded CSV:\", INPUT_CSV, \"rows=%d, cols=%d\" % (len(df), len(df.columns)))\n",
        "\n",
        "# Normalize haplogroup column presence\n",
        "if 'haplogroup' not in df.columns:\n",
        "    df['haplogroup'] = ''\n",
        "else:\n",
        "    df['haplogroup'] = df['haplogroup'].fillna('')\n",
        "\n",
        "# Read autosomal count locally if present (fallback display only)\n",
        "autosomal_count = None\n",
        "try:\n",
        "    with open(\"autosomal_count.txt\", \"r\") as f:\n",
        "        autosomal_count = int(re.findall(r\"(\\d+)\", f.read() or \"\")[0])\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Optional delta vs previous run\n",
        "prev_count, additional_str = None, \"\"\n",
        "if os.path.exists(\"autosomal_count_prev.txt\"):\n",
        "    try:\n",
        "        with open(\"autosomal_count_prev.txt\", \"r\") as f:\n",
        "            prev_count = int(re.findall(r\"(\\d+)\", f.read() or \"\")[0])\n",
        "        if autosomal_count is not None and prev_count is not None:\n",
        "            diff = autosomal_count - prev_count\n",
        "            if diff != 0:\n",
        "                additional_str = \" (+%d since last run)\" % diff\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# Human-readable fallback timestamp (JS will stamp dynamically at runtime)\n",
        "try:\n",
        "    _tz = ZoneInfo(\"America/New_York\") if ZoneInfo else datetime.now().astimezone().tzinfo\n",
        "except Exception:\n",
        "    _tz = datetime.now().astimezone().tzinfo\n",
        "now = datetime.now(_tz)\n",
        "updated_fallback = now.strftime(\"%Y-%m-%d %H:%M\")\n",
        "# ====== CUT STOP  [2/6] SECRETS + LOAD DATA + COUNTS + PATHS ====================================\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "\n",
        "\n",
        "\n",
        "# ====== CUT START [3/6] MAP COLUMN B (masked code) -> COLUMN C (unmasked name) =================\n",
        "# Column letters in MAIN df:\n",
        "#   A = ID#\n",
        "#   B = match to (masked)\n",
        "#   C = Unmasked Name (output)\n",
        "\n",
        "A_IDX = 0\n",
        "B_IDX = 1\n",
        "C_IDX = 2\n",
        "\n",
        "def _norm_code(s):\n",
        "    t = str(s or \"\").strip()\n",
        "    if (t.startswith('\"') and t.endswith('\"')) or (t.startswith(\"'\") and t.endswith(\"'\")):\n",
        "        t = t[1:-1]\n",
        "    t = t.replace(\"\\u00a0\", \" \").strip()\n",
        "    t = re.sub(r\"\\s{2,}\", \" \", t)\n",
        "    return t.lower()\n",
        "\n",
        "# Resolver lives on server under /partials/\n",
        "REMOTE_PATH = \"partials/match_to_unmasked.csv\"\n",
        "LOCAL_PATH  = \"match_to_unmasked.csv\"\n",
        "\n",
        "# Pull resolver if not present\n",
        "if not os.path.exists(LOCAL_PATH):\n",
        "    print(\"Pulling resolver CSV from server...\")\n",
        "    with FTP_TLS(timeout=30) as ftps:\n",
        "        ftps.connect(os.environ.get(\"FTP_HOST\",\"\"), int(os.environ.get(\"FTP_PORT\",\"21\")))\n",
        "        ftps.login(os.environ.get(\"FTP_USER\",\"\"), os.environ.get(\"FTP_PASS\",\"\"))\n",
        "        try: ftps.prot_p()\n",
        "        except Exception: pass\n",
        "        try: ftps.set_pasv(True)\n",
        "        except Exception: pass\n",
        "        if FTP_DIR:\n",
        "            for p in FTP_DIR.split(\"/\"):\n",
        "                if not p: continue\n",
        "                try: ftps.cwd(p)\n",
        "                except Exception:\n",
        "                    try: ftps.mkd(p)\n",
        "                    except Exception: pass\n",
        "                    ftps.cwd(p)\n",
        "        try: ftps.cwd(\"partials\")\n",
        "        except Exception: pass\n",
        "        with open(LOCAL_PATH, \"wb\") as f:\n",
        "            ftps.retrbinary(\"RETR match_to_unmasked.csv\", f.write)\n",
        "    print(\"Resolver saved:\", os.path.abspath(LOCAL_PATH))\n",
        "else:\n",
        "    print(\"Using cached resolver:\", os.path.abspath(LOCAL_PATH))\n",
        "\n",
        "def _load_resolver(path):\n",
        "    last_err = None\n",
        "    m = None\n",
        "    for enc in (\"utf-8-sig\",\"iso-8859-15\",\"utf-8\",\"cp1252\",\"latin1\"):\n",
        "        try:\n",
        "            m = pd.read_csv(path, dtype=str, keep_default_na=False, encoding=enc)\n",
        "            break\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            m = None\n",
        "    if m is None:\n",
        "        raise RuntimeError(\"Unable to read resolver CSV: %s (%r)\" % (path, last_err))\n",
        "    cols = {c.lower(): c for c in m.columns}\n",
        "    if \"code\" not in cols or \"unmasked\" not in cols:\n",
        "        raise ValueError(\"Resolver CSV must have columns: code, unmasked\")\n",
        "    m = m[[cols[\"code\"], cols[\"unmasked\"]]].copy()\n",
        "    m[\"__key__\"] = m[cols[\"code\"]].map(_norm_code)\n",
        "    m[\"__val__\"] = m[cols[\"unmasked\"]].astype(str)\n",
        "    m = m.drop_duplicates(subset=\"__key__\", keep=\"first\")\n",
        "    return dict(zip(m[\"__key__\"], m[\"__val__\"]))\n",
        "\n",
        "resolver_map = _load_resolver(LOCAL_PATH)\n",
        "\n",
        "if df.shape[1] < 3:\n",
        "    raise ValueError(\"Main df must have at least 3 columns: A(ID#), B(match to), C(unmasked).\")\n",
        "\n",
        "masked_raw = df.iloc[:, B_IDX].astype(str)\n",
        "masked_key = masked_raw.map(_norm_code)\n",
        "resolved   = masked_key.map(resolver_map)\n",
        "\n",
        "df.iloc[:, C_IDX] = resolved.fillna(\"\")\n",
        "\n",
        "mapped = int(resolved.notna().sum())\n",
        "total  = len(df)\n",
        "print(\"[OK] Column B -> C mapping:\", mapped, \"/\", total, \"unmatched:\", total - mapped)\n",
        "# ====== CUT STOP  [3/6] MAP COLUMN B (masked code) -> COLUMN C (unmasked name) =================\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "\n",
        "\n",
        "\n",
        "# ====== CUT START [4/6] XHTML TEMPLATE + TABLE + DOWNLOAD LINKS ================================\n",
        "_BTN_BG   = \"#5b79b8\"\n",
        "_BTN_BG_H = \"#4668aa\"\n",
        "_TH_BG    = \"#e3eaf8\"\n",
        "_LINK     = \"#154b8b\"\n",
        "\n",
        "# Fallback number text for initial render; JS will overwrite with live values\n",
        "auto_text = \"Unknown\" if autosomal_count is None else str(autosomal_count)\n",
        "\n",
        "# Download links block points to /partials/{csv,xlsx}\n",
        "DOWNLOADS_BLOCK = (\n",
        "    \"<p style=\\\"text-align:center; margin:4px 0 10px 0; font-size:13px;\\\">\"\n",
        "    \"Download: \"\n",
        "    \"<a href=\\\"/partials/%s\\\">CSV</a> | \"\n",
        "    \"<a href=\\\"/partials/%s\\\">Excel</a>\"\n",
        "    \"</p>\" % (_html.escape(LOCAL_CSV), _html.escape(LOCAL_XLSX))\n",
        ")\n",
        "\n",
        "full_html_template = \"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "<title>Ancestor Register</title>\n",
        "<style type=\"text/css\">\n",
        "  html { scroll-behavior: smooth; }\n",
        "  body { margin:0; padding:0; font-family: \"Times New Roman\", Georgia, serif; background:#ffffff; color:#222; font-size:14px; }\n",
        "  a { color:%(LINK)s; text-decoration:none; } a:hover { text-decoration:underline; }\n",
        "\n",
        "  .intro { padding:20px; text-align:center; }\n",
        "  .intro h2 { margin:0 0 6px 0; font-size:24px; line-height:1.2; }\n",
        "  .meta { font-size:12px; color:#555; margin:4px 0 8px 0; display:inline-block; }\n",
        "\n",
        "  .toolbar { margin:6px auto 12px auto; display:flex; flex-wrap:wrap; gap:6px; justify-content:center; }\n",
        "  .btn { display:inline-block; border:1px solid %(BTN_BG)s; background:%(BTN_BG)s; color:#fff;\n",
        "         padding:4px 9px; border-radius:6px; font-size:13px; line-height:1.2; text-decoration:none;\n",
        "         cursor:pointer; user-select:none; transition:background 0.2s, transform 0.1s; }\n",
        "  .btn:hover { background:%(BTN_BG_H)s; transform:translateY(-1px); }\n",
        "  .btn.light { background:#ffffff; color:#111; border-color:#bbb; }\n",
        "\n",
        "  .output-table { max-height:75vh; overflow:auto; border:1px solid #ddd; margin:0 20px 24px 20px; }\n",
        "\n",
        "  table.sortable { width:100%%; border-collapse:collapse; min-width:720px; table-layout:auto; }\n",
        "  table.sortable th, table.sortable td { border:1px solid #ddd; padding:6px 8px; background:#ffffff; white-space:nowrap; }\n",
        "  table.sortable th { position:sticky; top:0; z-index:2; text-align:left; cursor:pointer; background:%(TH_BG)s; box-shadow:0 1px 0 #ccc; }\n",
        "  table.sortable tr#first-row td { border-top:2px solid #999 !important; }\n",
        "\n",
        "  #searchBox { padding:4px 8px; font-size:13px; border:1px solid #bbb; border-radius:6px; outline:none; }\n",
        "\n",
        "  .back-to-top { position:fixed; right:16px; bottom:16px; padding:6px 10px;\n",
        "                 border:1px solid %(BTN_BG)s; background:%(BTN_BG)s; color:#fff;\n",
        "                 border-radius:6px; font-size:12px; display:none; z-index:9999; cursor:pointer; }\n",
        "  .back-to-top:hover { background:%(BTN_BG_H)s; }\n",
        "\n",
        "  @media screen and (max-width: 820px) {\n",
        "    .intro { padding:14px; }\n",
        "    .output-table { margin:0 12px 20px 12px; }\n",
        "    .intro h2 { font-size:20px; }\n",
        "    table.sortable { min-width:560px; }\n",
        "  }\n",
        "</style>\n",
        "<script type=\"text/javascript\">\n",
        "//<![CDATA[\n",
        "// Basic helpers\n",
        "function _cellText(cell){\n",
        "  var t = (cell && (cell.textContent || cell.innerText) || '').replace(/\\\\s+/g,' ').replace(/^\\\\s+|\\\\s+$/g,'').toLowerCase();\n",
        "  return t;\n",
        "}\n",
        "function _asNumber(s){\n",
        "  var m = (s||'').replace(/[^0-9.\\\\-]/g,'');\n",
        "  if(m.length===0) return NaN;\n",
        "  var v = parseFloat(m);\n",
        "  return isNaN(v) ? NaN : v;\n",
        "}\n",
        "\n",
        "// Sorting\n",
        "function sortTableByColumn(tbl, colIndex, dirAsc){\n",
        "  if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "  var tb = tbl.tBodies[0];\n",
        "  var rows = Array.prototype.slice.call(tb.rows || []);\n",
        "  rows.sort(function(a,b){\n",
        "    var A = _cellText(a.cells[colIndex] || null);\n",
        "       var B = _cellText(b.cells[colIndex] || null);\n",
        "    var nA = _asNumber(A), nB = _asNumber(B);\n",
        "    if(!isNaN(nA) && !isNaN(nB)){ return dirAsc ? (nA - nB) : (nB - nA); }\n",
        "    if(A < B) return dirAsc ? -1 : 1;\n",
        "    if(A > B) return dirAsc ?  1 : -1;\n",
        "    return 0;\n",
        "  });\n",
        "  var frag = document.createDocumentFragment();\n",
        "  for(var i=0;i<rows.length;i++){ frag.appendChild(rows[i]); }\n",
        "  tb.appendChild(frag);\n",
        "  updateShowingCount();\n",
        "}\n",
        "function bindHeaderSort(){\n",
        "  var tbl = document.getElementById('refactor-table');\n",
        "  if(!(tbl && tbl.tHead && tbl.tHead.rows.length)) return;\n",
        "  var ths = tbl.tHead.rows[0].cells || [];\n",
        "  for(var i=0;i<ths.length;i++){\n",
        "    (function(idx){\n",
        "      var th = ths[idx];\n",
        "      var dirAsc = true;\n",
        "      th.addEventListener('click', function(){\n",
        "        for(var j=0;j<ths.length;j++){ ths[j].innerHTML = ths[j].innerHTML.replace(/\\\\s+[\\\\u2191\\\\u2193]$/, ''); }\n",
        "        sortTableByColumn(tbl, idx, dirAsc);\n",
        "        th.innerHTML = th.innerHTML.replace(/\\\\s+[\\\\u2191\\\\u2193]$/, '') + (dirAsc ? ' \\\\u2191' : ' \\\\u2193');\n",
        "        dirAsc = !dirAsc;\n",
        "      }, false);\n",
        "    })(i);\n",
        "  }\n",
        "}\n",
        "\n",
        "// Filter + live showing count\n",
        "function filterTable(){\n",
        "  var q = (document.getElementById('searchBox').value || '').toLowerCase();\n",
        "  var tbl = document.getElementById('refactor-table');\n",
        "  if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "  var rows = tbl.tBodies[0].rows || [];\n",
        "  for(var i=0;i<rows.length;i++){\n",
        "    var cells = rows[i].cells, hit=false;\n",
        "    for(var j=0;j<cells.length;j++){\n",
        "      var txt = (cells[j].textContent || cells[j].innerText || '').toLowerCase();\n",
        "      if(txt.indexOf(q) > -1){ hit=true; break; }\n",
        "    }\n",
        "    rows[i].style.display = hit ? '' : 'none';\n",
        "  }\n",
        "  updateShowingCount();\n",
        "}\n",
        "function updateShowingCount(){\n",
        "  var el = document.getElementById('showing-count');\n",
        "  var tbl = document.getElementById('refactor-table');\n",
        "  if(!(el && tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "  var rows = tbl.tBodies[0].rows || [];\n",
        "  var vis = 0;\n",
        "  for(var i=0;i<rows.length;i++){ if(rows[i].style.display !== 'none') vis++; }\n",
        "  el.textContent = vis;\n",
        "}\n",
        "\n",
        "// Date stamp: \"D Month YYYY | H:MM AM/PM\"\n",
        "function stampLastUpdated() {\n",
        "  var el = document.getElementById('last-updated');\n",
        "  if (!el) return;\n",
        "\n",
        "  var d = new Date(document.lastModified || new Date());\n",
        "  var months = [\n",
        "    'January','February','March','April','May','June',\n",
        "    'July','August','September','October','November','December'\n",
        "  ];\n",
        "\n",
        "  var day   = d.getDate();\n",
        "  var month = months[d.getMonth()];\n",
        "  var year  = d.getFullYear();\n",
        "\n",
        "  // Hour & minute with AM/PM  (NOTE: double %% for Python templating)\n",
        "  var hours = d.getHours();\n",
        "  var minutes = d.getMinutes().toString().padStart(2, '0');\n",
        "  var ampm = hours >= 12 ? 'PM' : 'AM';\n",
        "  hours = hours %% 12 || 12;  // convert 0 → 12\n",
        "  var time = hours + ':' + minutes + ' ' + ampm;\n",
        "\n",
        "  el.innerHTML = day + ' ' + month + ' ' + year + ' | ' + time;\n",
        "}\n",
        "\n",
        "function formatWithCommas(n){\n",
        "  try{ var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return ''; return x.toLocaleString('en-US'); }catch(e){ return String(n||''); }\n",
        "}\n",
        "function loadAutoCount(){\n",
        "  var el=document.getElementById('auto-count'); if(!el) return;\n",
        "  var url='{COUNT_URL}';\n",
        "  try{\n",
        "    var xhr=new XMLHttpRequest(); xhr.open('GET', url+(url.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true);\n",
        "    xhr.onreadystatechange=function(){ if(xhr.readyState===4){\n",
        "      if(xhr.status>=200&&xhr.status<300){\n",
        "        var m=(xhr.responseText||'').match(/(\\\\d+)/); var num=m?m[1]:'';\n",
        "        el.textContent = formatWithCommas(num) || '(unavailable)';\n",
        "      } else { el.textContent='(unavailable)'; }\n",
        "    }};\n",
        "    xhr.send(null);\n",
        "  }catch(e){ el.textContent='(unavailable)'; }\n",
        "}\n",
        "\n",
        "// Back-to-top\n",
        "function bindBackToTop(){\n",
        "  var btn = document.getElementById('back-to-top');\n",
        "  if(!btn) return;\n",
        "  function toggle(){ btn.style.display = (window.scrollY > 200) ? 'block' : 'none'; }\n",
        "  toggle(); window.addEventListener('scroll', toggle, {passive:true});\n",
        "  btn.addEventListener('click', function(){ window.scrollTo(0,0); }, false);\n",
        "}\n",
        "\n",
        "document.addEventListener('DOMContentLoaded', function(){\n",
        "  bindHeaderSort();\n",
        "  bindBackToTop();\n",
        "  stampLastUpdated();\n",
        "  loadAutoCount();\n",
        "  updateShowingCount();\n",
        "}, false);\n",
        "//]]>\n",
        "</script>\n",
        "</head>\n",
        "<body>\n",
        "  <div class=\"intro\">\n",
        "    <h2>Ancestor Register</h2>\n",
        "    <div class=\"meta\">\n",
        "      Last updated: <span id=\"last-updated\">%(UPDATED)s</span>\n",
        "      &nbsp;|&nbsp; Autosomal matches: <span id=\"auto-count\">%(AUTO)s</span>\n",
        "      &nbsp;|&nbsp; Showing: <span id=\"showing-count\">0</span>\n",
        "    </div>\n",
        "    %(DL)s\n",
        "    <div class=\"toolbar\">\n",
        "      <a class=\"btn\" href=\"%(DNA_ABS)s\" target=\"_blank\" rel=\"noopener\">DNA Register</a>\n",
        "      <input type=\"text\" id=\"searchBox\" class=\"btn light\" placeholder=\"Search this page&hellip;\" oninput=\"filterTable()\" />\n",
        "    </div>\n",
        "  </div>\n",
        "\n",
        "  <div class=\"output-table\" id=\"table-container\">\n",
        "    <!-- TABLE_PLACEHOLDER -->\n",
        "  </div>\n",
        "\n",
        "  <div class=\"back-to-top\" id=\"back-to-top\">&#9650; Top</div>\n",
        "</body>\n",
        "</html>\"\"\" % {\n",
        "    \"BTN_BG\": _BTN_BG, \"BTN_BG_H\": _BTN_BG_H, \"TH_BG\": _TH_BG, \"LINK\": _LINK,\n",
        "    \"UPDATED\": _html.escape(updated_fallback),\n",
        "    \"AUTO\": _html.escape(\"Unknown\" if autosomal_count is None else str(autosomal_count)),\n",
        "    \"DL\": DOWNLOADS_BLOCK,\n",
        "    \"DNA_ABS\": DNA_REGISTER_ABS\n",
        "}\n",
        "\n",
        "# Build table HTML and mark first row\n",
        "table_html = df.to_html(index=False, border=1, classes=\"sortable\", table_id=\"refactor-table\")\n",
        "table_html = table_html.replace(\"<tbody>\\n<tr>\", \"<tbody>\\n<tr id=\\\"first-row\\\">\", 1)\n",
        "\n",
        "# Inject table and JS count URL\n",
        "final_html = full_html_template.replace(\"<!-- TABLE_PLACEHOLDER -->\", table_html)\n",
        "final_html = final_html.replace(\"{COUNT_URL}\", COUNT_PUBLIC_URL)\n",
        "\n",
        "# Build export DataFrame mirroring the visible table order (use current df as-is)\n",
        "export_df = df.copy()\n",
        "\n",
        "# Save CSV (ISO-8859-15) and XLSX\n",
        "export_df.to_csv(LOCAL_CSV, index=False, encoding=\"iso-8859-15\")\n",
        "try:\n",
        "    export_df.to_excel(LOCAL_XLSX, index=False)\n",
        "except Exception:\n",
        "    with pd.ExcelWriter(LOCAL_CSV.replace(\".csv\",\".xlsx\")) as _writer:\n",
        "        export_df.to_excel(_writer, index=False)\n",
        "print(\"[OK] Wrote exports:\", os.path.abspath(LOCAL_CSV), \"and\", os.path.abspath(LOCAL_XLSX))\n",
        "# ====== CUT STOP  [4/6] XHTML TEMPLATE + TABLE + DOWNLOAD LINKS ================================\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "\n",
        "\n",
        "\n",
        "# ====== CUT START [5/6] SAVE LOCALLY + FTP UPLOAD (HTML + CSV/XLSX -> /partials) ==============\n",
        "# Save locally (iso-8859-15 safe)\n",
        "try:\n",
        "    with open(OUTPUT_NAME, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(final_html)\n",
        "    print(\"[OK] Saved locally:\", OUTPUT_NAME)\n",
        "except Exception as e:\n",
        "    print(\"[ERROR] Saving local file failed:\", e)\n",
        "    traceback.print_exc()\n",
        "\n",
        "# Upload if credentials exist\n",
        "ftp_host = os.environ.get('FTP_HOST')\n",
        "ftp_user = os.environ.get('FTP_USER')\n",
        "ftp_pass = os.environ.get('FTP_PASS')\n",
        "ftp_port = os.environ.get('FTP_PORT', '21')\n",
        "ftp_dir  = os.environ.get('FTP_DIR', '')\n",
        "\n",
        "def _ftps_ensure_dir(ftps, name):\n",
        "    if not name: return\n",
        "    for p in [p for p in name.split('/') if p]:\n",
        "        try:\n",
        "            ftps.cwd(p)\n",
        "        except Exception:\n",
        "            try:\n",
        "                ftps.mkd(p)\n",
        "            except Exception:\n",
        "                pass\n",
        "            ftps.cwd(p)\n",
        "\n",
        "if all([ftp_host, ftp_user, ftp_pass]):\n",
        "    print(\"[INFO] Attempting FTP upload...\")\n",
        "    try:\n",
        "        socket.setdefaulttimeout(30)\n",
        "        with FTP_TLS(timeout=30) as ftps:\n",
        "            ftps.connect(ftp_host, int(ftp_port))\n",
        "            ftps.login(ftp_user, ftp_pass)\n",
        "            try: ftps.prot_p()\n",
        "            except Exception: pass\n",
        "            try: ftps.set_pasv(True)\n",
        "            except Exception: pass\n",
        "\n",
        "            # Navigate to base dir\n",
        "            _ftps_ensure_dir(ftps, ftp_dir.strip('/'))\n",
        "\n",
        "            # Ensure /partials exists then upload HTML + CSV/XLSX there\n",
        "            try:\n",
        "                _ftps_ensure_dir(ftps, \"partials\")\n",
        "\n",
        "                # Upload HTML into /partials/ as just-trees.htm\n",
        "                with open(OUTPUT_NAME, \"rb\") as fh:\n",
        "                    ftps.storbinary(\"STOR \" + os.path.basename(REMOTE_HTML), fh)\n",
        "                print(\"[OK] Uploaded HTML to /partials/:\", OUTPUT_NAME, \"->\", os.path.basename(REMOTE_HTML))\n",
        "\n",
        "                # Upload CSV/XLSX into /partials/\n",
        "                with open(LOCAL_CSV, \"rb\") as fh:\n",
        "                    ftps.storbinary(\"STOR \" + os.path.basename(REMOTE_CSV), fh)\n",
        "                with open(LOCAL_XLSX, \"rb\") as fh:\n",
        "                    ftps.storbinary(\"STOR \" + os.path.basename(REMOTE_XLSX), fh)\n",
        "                print(\"[OK] Uploaded exports to /partials/:\", LOCAL_CSV, LOCAL_XLSX)\n",
        "\n",
        "                print(\"Open URL: https://yates.one-name.net/partials/just-trees.htm\")\n",
        "            except Exception as e:\n",
        "                print(\"[ERROR] Upload to /partials/ failed:\", e)\n",
        "\n",
        "            print(\"[OK] Uploads complete.\")\n",
        "    except Exception as e:\n",
        "        print(\"[ERROR] FTP session failed:\", e)\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"[INFO] Skipping FTP upload: missing FTP credentials.\")\n",
        "# ====== CUT STOP  [5/6] SAVE LOCALLY + FTP UPLOAD (HTML + CSV/XLSX -> /partials) ==============\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "\n",
        "\n",
        "\n",
        "# ====== CUT START [6/6] PERSIST COUNT + DONE ====================================================\n",
        "if autosomal_count is not None:\n",
        "    try:\n",
        "        with open(\"autosomal_count_prev.txt\", \"w\") as f:\n",
        "            f.write(str(autosomal_count))\n",
        "        print(\"[OK] Persisted autosomal_count_prev.txt\")\n",
        "    except Exception as e:\n",
        "        print(\"[WARN] Could not persist autosomal count:\", e)\n",
        "\n",
        "print(\"\\n--- Ancestor Register Build + Exports Complete (HTML now at /partials/just-trees.htm; nav button -> justdna.htm) ---\")\n",
        "# ====== CUT STOP  [6/6] PERSIST COUNT + DONE ====================================================\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySrJa6SLVEz0",
        "outputId": "0a818103-d53c-4514-9514-6f726bb5d471"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Loaded CSV: final_combined_df_with_value_labels.csv rows=7, cols=6\n",
            "Pulling resolver CSV from server...\n",
            "Resolver saved: /content/match_to_unmasked.csv\n",
            "[OK] Column B -> C mapping: 7 / 7 unmatched: 0\n",
            "[OK] Wrote exports: /content/yates_ancestor_register.csv and /content/yates_ancestor_register.xlsx\n",
            "[OK] Saved locally: just-trees.htm\n",
            "[INFO] Attempting FTP upload...\n",
            "[OK] Uploaded HTML to /partials/: just-trees.htm -> just-trees.htm\n",
            "[OK] Uploaded exports to /partials/: yates_ancestor_register.csv yates_ancestor_register.xlsx\n",
            "Open URL: https://yates.one-name.net/partials/just-trees.htm\n",
            "[OK] Uploads complete.\n",
            "[OK] Persisted autosomal_count_prev.txt\n",
            "\n",
            "--- Ancestor Register Build + Exports Complete (HTML now at /partials/just-trees.htm; nav button -> justdna.htm) ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Cell 1"
      ],
      "metadata": {
        "id": "z7m2W6TOv1Xy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEST Cell 2\n"
      ],
      "metadata": {
        "id": "9RkUt92dnLP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] CELL 2 — Build + Publish DNA Register (Old-school Blue Menu; WHITE menu text) ======\n",
        "# RON GOLDEN RULES — CLIFF NOTES (v2025.11.09)\n",
        "# • Complete & runnable Colab cell — one contiguous block.\n",
        "# • Source ASCII-only; outputs written with encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\".\n",
        "# • XHTML 1.0 Transitional; typography comes ONLY from /partials/dna_tree_styles.css (no font-family here).\n",
        "# • Deterministic audit:\n",
        "#   [CONFIRM] Golden Rules active | Cell=Cell2_OldSchoolMenu_WhiteText | Version=2025.11.11 | Encoding=ISO-8859-15\n",
        "# • Enforce ISO-8859-15 on all writes; declare expected line count for audit.\n",
        "\n",
        "DECLARED_LINES = 9999\n",
        "print(\"[CONFIRM] Golden Rules active | Cell=Cell2_OldSchoolMenu_WhiteText | Version=2025.11.11 | Encoding=ISO-8859-15\")\n",
        "print(\"DECLARED_LINES=%d\" % DECLARED_LINES)\n",
        "\n",
        "import os, re, posixpath, socket, traceback, urllib.parse as _u\n",
        "from ftplib import FTP_TLS\n",
        "import pandas as pd\n",
        "import html as _html\n",
        "from string import Template\n",
        "\n",
        "# ---------- 0) Secrets ----------\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ['FTP_HOST'] = userdata.get('FTP_HOST')\n",
        "    os.environ['FTP_USER'] = userdata.get('FTP_USER')\n",
        "    os.environ['FTP_PASS'] = userdata.get('FTP_PASS')\n",
        "    try: os.environ['FTP_DIR'] = userdata.get('FTP_DIR')\n",
        "    except Exception: os.environ.setdefault('FTP_DIR', '')\n",
        "    try: os.environ['FTP_PORT'] = userdata.get('FTP_PORT')\n",
        "    except Exception: os.environ.setdefault('FTP_PORT', '21')\n",
        "except Exception:\n",
        "    os.environ.setdefault('FTP_HOST',''); os.environ.setdefault('FTP_USER',''); os.environ.setdefault('FTP_PASS','')\n",
        "    os.environ.setdefault('FTP_DIR',''); os.environ.setdefault('FTP_PORT','21')\n",
        "\n",
        "# ---------- 1) Config ----------\n",
        "CSV_IN = \"final_combined_df_with_value_labels.csv\"\n",
        "\n",
        "LOCAL_HTML = \"yates_ancestor_register.htm\"\n",
        "REMOTE_HTML_CANON = posixpath.join(\"partials\",\"yates_ancestor_register.htm\")\n",
        "REMOTE_HTML_LEG   = posixpath.join(\"partials\",\"ons_yates_dna_register.htm\")\n",
        "REMOTE_HTML_SIMPLE= posixpath.join(\"partials\",\"justdna.htm\")\n",
        "\n",
        "DNA_REGISTER_ABS = \"https://yates.one-name.net/partials/justdna.htm\"\n",
        "TREES_ABS        = \"https://yates.one-name.net/partials/just-trees.htm\"\n",
        "\n",
        "EXPORT_BASENAME = \"yates_ancestor_register\"\n",
        "LOCAL_CSV  = f\"{EXPORT_BASENAME}.csv\"\n",
        "LOCAL_XLSX = f\"{EXPORT_BASENAME}.xlsx\"\n",
        "REMOTE_CSV = posixpath.join(\"partials\", os.path.basename(LOCAL_CSV))\n",
        "REMOTE_XLSX= posixpath.join(\"partials\", os.path.basename(LOCAL_XLSX))\n",
        "\n",
        "WORK_PLUS_LOCAL  = os.path.join(\"partials\",\"work_plus.htm\")\n",
        "WORK_PLUS_REMOTE = posixpath.join(\"partials\",\"work_plus.htm\")\n",
        "\n",
        "LOCAL_COUNT_FILE = \"/content/autosomal_count.txt\"\n",
        "REMOTE_COUNT_NAME= \"autosomal_count.txt\"\n",
        "\n",
        "FTP_DIR = (os.environ.get(\"FTP_DIR\",\"\") or \"\").strip()\n",
        "TNG_BASE=\"https://yates.one-name.net/tng\"; TNG_TREE=\"tree1\"\n",
        "HOME_URL=\"https://yates.one-name.net/partials/yates_ancestor_register.htm\"\n",
        "REMOTE_NAME_ABS = HOME_URL\n",
        "COUNT_PUBLIC_URL = (f\"/{FTP_DIR}/{REMOTE_COUNT_NAME}\" if FTP_DIR else f\"/{REMOTE_COUNT_NAME}\")\n",
        "\n",
        "TABLE_WIDTH_PX=2550; COL_A_PX=775; FIND_COL_PX=75\n",
        "ARROW_ENTITY=\"&rarr;\"; REMOVE_PERIOD_AT_END=True\n",
        "\n",
        "SERVER_PARTIALS_DIR=\"partials\"\n",
        "SERVER_MAPPING_BASENAME=\"match_to_unmasked.csv\"\n",
        "SERVER_MAPPING_REMOTE=posixpath.join(SERVER_PARTIALS_DIR, SERVER_MAPPING_BASENAME)\n",
        "SERVER_MAPPING_LOCAL_CACHE=\"match_to_unmasked.server.csv\"\n",
        "\n",
        "STYLESHEET_HREF=\"/partials/dna_tree_styles.css\"; CSS_VERSION=\"v2025-11-06\"\n",
        "HEAD_LINK=f'<link rel=\"stylesheet\" type=\"text/css\" href=\"{STYLESHEET_HREF}?{CSS_VERSION}\" />'\n",
        "\n",
        "# ---------- 2) FTP ----------\n",
        "FTP_TIMEOUT=int(os.environ.get(\"FTP_TIMEOUT\",\"30\")); FTP_PASSIVE=True\n",
        "def ftp_connect()->FTP_TLS:\n",
        "    ftps=FTP_TLS(timeout=FTP_TIMEOUT); socket.setdefaulttimeout(FTP_TIMEOUT)\n",
        "    ftps.connect(os.environ.get('FTP_HOST',''), int(os.environ.get('FTP_PORT',21)))\n",
        "    ftps.login(os.environ.get('FTP_USER',''), os.environ.get('FTP_PASS',''))\n",
        "    try: ftps.prot_p()\n",
        "    except Exception: pass\n",
        "    try: ftps.set_pasv(FTP_PASSIVE)\n",
        "    except Exception: pass\n",
        "    if FTP_DIR:\n",
        "        for p in [p for p in FTP_DIR.split(\"/\") if p]:\n",
        "            try: ftps.mkd(p)\n",
        "            except Exception: pass\n",
        "            ftps.cwd(p)\n",
        "    return ftps\n",
        "def _remote_path(name:str)->str: return posixpath.join(FTP_DIR,name) if FTP_DIR else name\n",
        "def ensure_remote_dirs(ftps, remote_path):\n",
        "    if \"/\" not in remote_path: return\n",
        "    pwd0=ftps.pwd()\n",
        "    for seg in [p for p in remote_path.split(\"/\")[:-1] if p and p!=\".\"]:\n",
        "        try: ftps.cwd(seg)\n",
        "        except Exception:\n",
        "            try: ftps.mkd(seg)\n",
        "            except Exception: pass\n",
        "            ftps.cwd(seg)\n",
        "    ftps.cwd(pwd0)\n",
        "def ftp_download_if_exists(ftps, remote_name, local_name)->bool:\n",
        "    try:\n",
        "        with open(local_name,\"wb\") as f: ftps.retrbinary(f\"RETR {remote_name}\", f.write)\n",
        "        print(f\"[PULL] {remote_name} -> {os.path.abspath(local_name)}\"); return True\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            if os.path.exists(local_name): os.remove(local_name)\n",
        "        except Exception: pass\n",
        "        print(f\"[MISS] {remote_name} ({e})\"); return False\n",
        "def ftp_upload_overwrite(ftps, local_path, remote_name):\n",
        "    ensure_remote_dirs(ftps, remote_name)\n",
        "    with open(local_path,\"rb\") as fh: ftps.storbinary(f\"STOR {remote_name}\", fh)\n",
        "    print(f\"[PUT] {local_path} -> {remote_name}\")\n",
        "def ftp_size(ftps, remote_name):\n",
        "    try:\n",
        "        sz=ftps.size(remote_name); return int(sz) if sz is not None else None\n",
        "    except Exception: return None\n",
        "\n",
        "# ---------- 3) Resolver ----------\n",
        "def _read_mapping_csv(path:str)->pd.DataFrame:\n",
        "    encs=(\"iso-8859-15\",\"utf-8-sig\",\"utf-8\",\"cp1252\",\"latin1\"); last=None; df=None\n",
        "    for enc in encs:\n",
        "        try:\n",
        "            df=pd.read_csv(path, encoding=enc, dtype=str, keep_default_na=False); break\n",
        "        except Exception as e: last=e\n",
        "    if df is None: raise RuntimeError(f\"Unable to read mapping CSV {path}: {last}\")\n",
        "    if df.shape[1] < 2: raise RuntimeError(\"Mapping CSV must have at least two columns: code, unmasked\")\n",
        "    df=df.iloc[:, :2].copy(); df.columns=[\"code\",\"unmasked\"]\n",
        "    df[\"code\"]=df[\"code\"].astype(str).str.strip().str.lower()\n",
        "    df[\"unmasked\"]=df[\"unmasked\"].astype(str).str.strip()\n",
        "    df=df[df[\"code\"]!=\"\"].drop_duplicates(subset=[\"code\"], keep=\"first\")\n",
        "    if df.empty: raise RuntimeError(\"Mapping CSV empty after normalization.\")\n",
        "    return df\n",
        "def load_resolver_from_server()->dict:\n",
        "    with ftp_connect() as ftps:\n",
        "        try: ftps.cwd(SERVER_PARTIALS_DIR)\n",
        "        except Exception: pass\n",
        "        ok=ftp_download_if_exists(ftps, SERVER_MAPPING_BASENAME, SERVER_MAPPING_LOCAL_CACHE)\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "    if not ok:\n",
        "        raise RuntimeError(\"Resolver not found on server: /\"+_remote_path(SERVER_MAPPING_REMOTE)+\". Upload match_to_unmasked.csv into /partials/ and re-run.\")\n",
        "    df_map=_read_mapping_csv(SERVER_MAPPING_LOCAL_CACHE)\n",
        "    print(f\"[OK] Resolver loaded: {len(df_map)} codes\")\n",
        "    return dict(zip(df_map[\"code\"], df_map[\"unmasked\"]))\n",
        "MATCH_TO_UNMASKED={}\n",
        "def _setup_resolver():\n",
        "    global MATCH_TO_UNMASKED\n",
        "    if not MATCH_TO_UNMASKED: MATCH_TO_UNMASKED=load_resolver_from_server()\n",
        "def resolve_match_to(code:str)->str:\n",
        "    if not isinstance(code,str): return \"\"\n",
        "    return MATCH_TO_UNMASKED.get(code.strip().lower(), code)\n",
        "\n",
        "# ---------- 4) Name/text utils ----------\n",
        "SEP_RE=re.compile(r\"\\s*(?:\\u2192|&rarr;|;|>|,|~{2,}|/{2,}|\\|{2,})\\s*\")\n",
        "def split_tokens(s):\n",
        "    if pd.isna(s): return []\n",
        "    if not isinstance(s,str): s=str(s)\n",
        "    return [p.strip() for p in SEP_RE.split(s) if str(p).strip()]\n",
        "def _clean_piece(text:str)->str:\n",
        "    t=re.sub(r'~+',' ',str(text)); t=re.sub(r'\\s+',' ',t); return t.strip()\n",
        "_PARTICLES={\"de\",\"del\",\"della\",\"der\",\"van\",\"von\",\"da\",\"dos\",\"das\",\"di\",\"la\",\"le\",\"du\",\"of\"}\n",
        "def _smart_title(token:str)->str:\n",
        "    if not token: return token\n",
        "    token=re.sub(r\"(^|\\b)([a-z])(['’])([a-z])\", lambda m: m.group(1)+m.group(2).upper()+m.group(3)+m.group(4).upper(), token.lower())\n",
        "    token=\"-\".join([w.capitalize() for w in token.split(\"-\")])\n",
        "    token=re.sub(r\"\\bmc([a-z])\", lambda m:\"Mc\"+m.group(1).upper(), token)\n",
        "    token=re.sub(r\"\\bmac([a-z])\", lambda m:\"Mac\"+m.group(1).upper(), token)\n",
        "    return token\n",
        "def smart_titlecase(name:str)->str:\n",
        "    name=_clean_piece(name);\n",
        "    if not name: return name\n",
        "    if \",\" in name:\n",
        "        last,first=[p.strip() for p in name.split(\",\",1)]; pieces=(first+\" \"+last).split()\n",
        "    else: pieces=name.split()\n",
        "    out=[];\n",
        "    for i,w in enumerate(pieces): out.append(w.lower() if (i>0 and w.lower() in _PARTICLES) else _smart_title(w))\n",
        "    return \" \".join(out)\n",
        "def surname_given_from_token(token):\n",
        "    token=token.strip(); idx=None\n",
        "    for i in range(1,len(token)):\n",
        "        if token[i-1].islower() and token[i].isupper(): idx=i; break\n",
        "    if idx is None:\n",
        "        for i in range(1,len(token)):\n",
        "            if token[i].isupper(): idx=i; break\n",
        "    if idx is None: return (token,)\n",
        "    surname=token[:idx]; given=token[idx:]; given_spaced=re.sub(r'(?<!^)([A-Z])', r' \\1', given)\n",
        "    return (f\"{given_spaced.strip()} {surname.strip()}\",)\n",
        "def normalize_person_name(s:str)->str:\n",
        "    if pd.isna(s): return \"\"\n",
        "    s=_clean_piece(str(s))\n",
        "    if \",\" in s:\n",
        "        last,first=[p.strip() for p in s.split(\",\",1)]; s=f\"{first} {last}\"\n",
        "    if \" \" not in s and s.isalpha(): return smart_titlecase(surname_given_from_token(s)[0])\n",
        "    return smart_titlecase(s)\n",
        "_CAMEL_WORDS=re.compile(r\"[A-Z][a-z]*|[A-Z]+(?![a-z])|[a-z]+\")\n",
        "def norm_matchee_name(raw:str)->str:\n",
        "    raw=str(raw or \"\").strip()\n",
        "    if not raw: return \"\"\n",
        "    if \" \" in raw or \",\" in raw:\n",
        "        nm=smart_titlecase(raw); parts=nm.split()\n",
        "        if len(parts)==1: return nm\n",
        "        return f\"{parts[0]} {parts[-1]}\".strip()\n",
        "    words=_CAMEL_WORDS.findall(raw)\n",
        "    while words and len(words[0])==1: words.pop(0)\n",
        "    if not words:\n",
        "        nm=smart_titlecase(surname_given_from_token(raw)[0]); ps=nm.split()\n",
        "        if len(ps)==1: return nm\n",
        "        return f\"{ps[0]} {ps[-1]}\".strip()\n",
        "    surname=smart_titlecase(words[0])\n",
        "    given_candidates=[w for w in words[1:] if w.lower()!=surname.lower()]\n",
        "    if not given_candidates: return surname\n",
        "    return f\"{smart_titlecase(given_candidates[0])} {surname}\".strip()\n",
        "def truncate_first(name:str,n:int=7)->str:\n",
        "    name=name.strip()\n",
        "    if not name: return name\n",
        "    parts=name.split(); return parts[0][:n] if len(parts)==1 else f\"{parts[0][:n]} {parts[-1]}\"\n",
        "def derive_common_from_first_token(tokens):\n",
        "    if not tokens: return (\"\",\"\")\n",
        "    first=_clean_piece(tokens[0]); parts=re.split(r\"\\s*(?:&| and )\\s*\", first, maxsplit=1, flags=re.I)\n",
        "    if len(parts)!=2: return (\"\",\"\")\n",
        "    def _norm(s): return smart_titlecase(s) if \" \" in s else smart_titlecase(surname_given_from_token(s)[0])\n",
        "    return (_norm(parts[0]), _norm(parts[1]))\n",
        "def degree_label_from_generations(g):\n",
        "    if g<=1: return (\"parents\" if g==1 else \"self\")\n",
        "    if g==2: return \"grandparents\"\n",
        "    greats=g-2\n",
        "    if greats==1: return \"great-grandparents\"\n",
        "    return f\"{greats}x-great-grandparents\"\n",
        "def build_header(subject_name, cm_val, matchee_name_html, gens, husband, wife):\n",
        "    try: cm_str=f\"{int(round(float(cm_val)))}\"\n",
        "    except Exception: cm_str=(str(cm_val).strip() or \"0\")\n",
        "    degree_label=degree_label_from_generations(gens)\n",
        "    parts=[f\"{subject_name} is a {cm_str} cM cousin match to {matchee_name_html}, whose\",\n",
        "           f\"{degree_label} (back {gens} Gens)\",\"are\",f\"{husband} & {wife}.\"]\n",
        "    s=\" \".join(parts)\n",
        "    if REMOVE_PERIOD_AT_END: s=re.sub(r'\\.\\s*$','',s)\n",
        "    return s\n",
        "\n",
        "# ---------- 5) Read CSV ----------\n",
        "def find_col(df, patterns, prefer_exact=None):\n",
        "    cols=list(df.columns); lowmap={c.lower():c for c in cols}\n",
        "    if prefer_exact:\n",
        "        for name in prefer_exact:\n",
        "            if name in df.columns: return name\n",
        "            if name and name.lower() in lowmap: return lowmap[name.lower()]\n",
        "    for pat in patterns:\n",
        "        rx=re.compile(pat,re.I)\n",
        "        for c in cols:\n",
        "            if rx.search(c): return c\n",
        "    return None\n",
        "\n",
        "_encs=(\"utf-8-sig\",\"utf-8\",\"cp1252\",\"iso-8859-15\",\"latin1\"); _last_err=None; df=None\n",
        "for _e in _encs:\n",
        "    try: df=pd.read_csv(CSV_IN, encoding=_e, dtype=str, keep_default_na=False); break\n",
        "    except Exception as _ex: _last_err=_ex; df=None\n",
        "if df is None: raise RuntimeError(f\"Unable to read CSV: {CSV_IN} ({_last_err})\")\n",
        "print(f\"[OK] Loaded CSV: {len(df)} rows, {len(df.columns)} cols\")\n",
        "\n",
        "id_col   = find_col(df,[r'^(id#|personid)$'],[\"ID#\",\"ID\",\"PersonID\",\"personID\"])\n",
        "match_col= find_col(df,[r'^match\\s*to$'],[\"Match to\",\"Match\"])\n",
        "name_col = find_col(df,[r'^name$'],[\"Name\"])\n",
        "cm_col   = find_col(df,[r'^(c\\s*:?m|cm)$',r'centi.?morgan'],[\"cM\",\"cm\"])\n",
        "path_col = find_col(df,[r'(yates\\s*dna\\s*ancestral\\s*line|ancestral\\s*line|lineage)'],[\"Yates DNA Ancestral Line\",\"Ancestral Line\",\"Lineage\"])\n",
        "\n",
        "if not id_col:   raise ValueError(\"CSV missing an ID#/PersonID column.\")\n",
        "if not match_col:raise ValueError(\"CSV missing 'Match to' column.\")\n",
        "if not name_col: raise ValueError(\"CSV missing 'Name' column.\")\n",
        "if not cm_col:   raise ValueError(\"CSV missing 'cM' column.\")\n",
        "if not path_col: raise ValueError(\"CSV missing lineage/path column.\")\n",
        "\n",
        "# ---------- 6) Transform ----------\n",
        "ID_PAT=re.compile(r\"\\bI\\d+\\b\",re.I)\n",
        "def extract_person_id(s:str)->str:\n",
        "    m=ID_PAT.search(str(s or \"\")); return m.group(0).upper() if m else \"\"\n",
        "\n",
        "def _setup_resolver_and_return():\n",
        "    _setup_resolver(); return MATCH_TO_UNMASKED\n",
        "_=_setup_resolver_and_return()\n",
        "\n",
        "headers,lineages,findcol=[],[],[]\n",
        "subjects,first_ancestors=[],[]\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    subject_raw=row.get(match_col,\"\")\n",
        "    subject_name=normalize_person_name(resolve_match_to(subject_raw))\n",
        "    subject_name_b=f\"<strong>{subject_name}</strong>\" if subject_name else subject_name\n",
        "\n",
        "    pid=extract_person_id(row.get(id_col,\"\"))\n",
        "    matchee_name=norm_matchee_name(row.get(name_col,\"\")) or subject_name\n",
        "    matchee_name_html=(f'<a href=\"{TNG_BASE}/verticalchart.php?personID={pid}&tree={TNG_TREE}&parentset=0&display=vertical&generations=15\" target=\"_blank\" rel=\"noopener\">{matchee_name}</a>') if pid else matchee_name\n",
        "\n",
        "    cm_val=row.get(cm_col,\"0\")\n",
        "    tokens=split_tokens(row.get(path_col,\"\")); gens_total=len(tokens); tokens_disp=tokens[:7]\n",
        "\n",
        "    if \"common_husband\" in df.columns and \"common_wife\" in df.columns:\n",
        "        husband_raw=str(row.get(\"common_husband\",\"\")).strip(); wife_raw=str(row.get(\"common_wife\",\"\")).strip()\n",
        "        if not husband_raw and not wife_raw: husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "    else:\n",
        "        husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "\n",
        "    header_html=build_header(subject_name_b, cm_val, matchee_name_html, gens_total, husband_raw, wife_raw)\n",
        "    if tokens_disp: tokens_disp[0]=f\"<strong>{tokens_disp[0]}</strong>\"\n",
        "    sep=f\" {ARROW_ENTITY} \"; lineage_text=sep.join(tokens_disp) if tokens_disp else \"\"\n",
        "\n",
        "    q=_u.quote(subject_name)\n",
        "    quick=(f'<a class=\"find-btn\" href=\"{REMOTE_NAME_ABS}?q={q}\" target=\"_blank\" rel=\"noopener\" title=\"Open a filtered view for {subject_name}\">Find</a>')\n",
        "\n",
        "    headers.append(header_html); lineages.append(lineage_text); findcol.append(quick)\n",
        "    subjects.append(subject_name); first_ancestors.append(tokens[0] if tokens else \"\")\n",
        "\n",
        "LINEAGE_HEADER_SAFE=\"Lineage (Starting with oldest ancestor, the line is:)\"\n",
        "df[\"Match Summary\"]=headers; df[LINEAGE_HEADER_SAFE]=lineages; df[\"Find\"]=findcol; df[\"Subject\"]=subjects\n",
        "df[\"First Ancestor\"]=[_clean_piece(x) for x in first_ancestors]\n",
        "display_df=df[[\"Find\",\"Match Summary\",LINEAGE_HEADER_SAFE]]\n",
        "\n",
        "# ---------- 6.1) Clean exports ----------\n",
        "TAG_RE=re.compile(r\"<[^>]+>\")\n",
        "def _html_to_text(s:str)->str:\n",
        "    t=TAG_RE.sub(\"\",str(s or \"\")); t=_html.unescape(t); t=t.replace(\"\\u2192\",\"->\"); return re.sub(r\"\\s+\",\" \",t).strip()\n",
        "def _extract_find_url(cell_html:str)->str:\n",
        "    m=re.search(r'href=\"([^\"]+)\"',str(cell_html or \"\")); return _html.unescape(m.group(1)) if m else \"\"\n",
        "\n",
        "export_df=pd.DataFrame({\n",
        "    \"Find URL\":[_extract_find_url(v) for v in display_df[\"Find\"].tolist()],\n",
        "    \"Match Summary\":[_html_to_text(v) for v in display_df[\"Match Summary\"].tolist()],\n",
        "    \"Lineage\":[_html_to_text(v) for v in display_df[LINEAGE_HEADER_SAFE].tolist()],\n",
        "})\n",
        "export_df.to_csv(LOCAL_CSV, index=False, encoding=\"iso-8859-15\")\n",
        "try: export_df.to_excel(LOCAL_XLSX, index=False)\n",
        "except Exception:\n",
        "    with pd.ExcelWriter(LOCAL_XLSX) as _writer: export_df.to_excel(_writer, index=False)\n",
        "print(\"[OK] Wrote exports:\", os.path.abspath(LOCAL_CSV), \"and\", os.path.abspath(LOCAL_XLSX))\n",
        "\n",
        "# ---------- 7) HTML (Blue menu WITH WHITE TEXT) ----------\n",
        "TABLE_CSS = f\"\"\"\n",
        "<style type=\"text/css\">\n",
        "  html {{ scroll-behavior: smooth; }}\n",
        "  body {{ font-size:100%; background:#ffffff; color:#222; margin:0; padding:0; line-height:1.5; }}\n",
        "  .wrap {{ max-width:100%; margin:0 auto; background:#ffffff; padding:16px; padding-bottom:48px; }}\n",
        "  a {{ color:#154b8b; text-decoration:none; }} a:hover {{ text-decoration:underline; }}\n",
        "  h1 {{ margin:0 0 6px 0; font-size:26px; line-height:1.2; text-align:center; }}\n",
        "  .centerline {{ text-align:center; }}\n",
        "  .downloads {{ text-align:center; margin:4px 0 10px 0; font-size:13px; }}\n",
        "  .updated {{ font-size:12px; color:#555; text-align:center; margin:2px 0 10px 0; }}\n",
        "\n",
        "  /* Old-school horizontal menu */\n",
        "  .oldnav {{ margin:8px auto 6px auto; padding:0; background:#5b79b8; border-radius:6px; overflow:hidden; max-width:{TABLE_WIDTH_PX}px; }}\n",
        "  .oldnav ul {{ list-style:none; margin:0; padding:0; display:flex; flex-wrap:wrap; }}\n",
        "  .oldnav li {{ margin:0; padding:0; }}\n",
        "  /* ——— KEY FIX: FORCE WHITE TEXT FOR ALL LINK STATES ——— */\n",
        "  .oldnav a, .oldnav a:link, .oldnav a:visited, .oldnav a:active {{ color:#ffffff !important; }}\n",
        "  .oldnav a {{\n",
        "    display:block; padding:8px 12px; text-decoration:none; white-space:nowrap;\n",
        "    border-right:1px solid #ffffff;\n",
        "    font-weight:600;\n",
        "  }}\n",
        "  .oldnav li:last-child a {{ border-right:none; }}\n",
        "  .oldnav a:hover {{ background:#4668aa; color:#ffffff !important; }}\n",
        "\n",
        "  .controls {{ margin:6px 0 10px 0; display:flex; justify-content:center; gap:8px; }}\n",
        "  .controls input[type=\"text\"] {{ border:1px solid #bbb; padding:5px 8px; border-radius:5px; }}\n",
        "\n",
        "  .table-scroll {{ max-height:70vh; overflow-y:auto; overflow-x:auto; border:1px solid #ddd; }}\n",
        "  table.sortable {{ border-collapse:collapse; width:100%; table-layout:fixed; }}\n",
        "  table.sortable th, table.sortable td {{ border:1px solid #ddd; padding:6px 8px; vertical-align:top; word-wrap:break-word; overflow-wrap:break-word; }}\n",
        "  table.sortable th {{ background:#e3eaf8; text-align:left; position:sticky; top:0; z-index:2; box-shadow:0 1px 0 #ccc; cursor:pointer; }}\n",
        "  #first-row td {{ border-top:2px solid #999; }}\n",
        "\n",
        "  .find-cell {{ white-space:nowrap; }}\n",
        "  .selbox {{ margin-right:6px; vertical-align:middle; }}\n",
        "\n",
        "  .back-to-top {{ position:fixed; right:16px; bottom:16px; padding:6px 10px; border:1px solid #3e5a97; background:#5b79b8; color:#fff; cursor:pointer; border-radius:6px; font-size:12px; display:none; z-index:9999; }}\n",
        "  .back-to-top:hover {{ background:#4668aa; }}\n",
        "\n",
        "  @media screen and (min-width: 1200px) {{\n",
        "    #refactor-table col:nth-child(1) {{ width:{FIND_COL_PX}px; }}\n",
        "    #refactor-table col:nth-child(2) {{ width:{COL_A_PX}px; }}\n",
        "    .wrap {{ max-width:{TABLE_WIDTH_PX}px; }}\n",
        "  }}\n",
        "  @media screen and (max-width: 1199px) {{\n",
        "    #refactor-table {{ table-layout:auto; }}\n",
        "    #refactor-table col:nth-child(1) {{ width:12%; }}\n",
        "    #refactor-table col:nth-child(2) {{ width:44%; }}\n",
        "    #refactor-table col:nth-child(3) {{ width:44%; }}\n",
        "    .oldnav {{ border-radius:0; }}\n",
        "  }}\n",
        "  @media screen and (max-width: 700px) {{\n",
        "    table.sortable th, table.sortable td {{ padding:5px 6px; }}\n",
        "    #refactor-table col:nth-child(1) {{ width:16%; }}\n",
        "    #refactor-table col:nth-child(2) {{ width:42%; }}\n",
        "    #refactor-table col:nth-child(3) {{ width:42%; }}\n",
        "  }}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "NAV_BLOCK = (\n",
        "  '<nav class=\"oldnav\"><ul>'\n",
        "  '<li><a href=\"https://yates.one-name.net/gengen/dna_cousin_surname_study.htm\" target=\"_blank\" rel=\"noopener\">Study Details</a></li>'\n",
        "  '<li><a href=\"https://yates.one-name.net/gengen/dna_theory_of_the_case.htm\" target=\"_blank\" rel=\"noopener\">Theory in Action</a></li>'\n",
        "  '<li><a href=\"/gengen/images/cousin-calculator.jpg\" target=\"_blank\" rel=\"noopener\">Cousin Connection</a></li>'\n",
        "  '<li><a href=\"/gengen/images/Shared_cM_Project_v4.jpg\" target=\"_blank\" rel=\"noopener\">Cousin by DNA</a></li>'\n",
        "  '<li><a href=\"/partials/match_count.htm\" target=\"_blank\" rel=\"noopener\">Match Count</a></li>'\n",
        "  '<li><a href=\"/partials/lineage_count.htm\" target=\"_blank\" rel=\"noopener\">Lineage Count</a></li>'\n",
        "  f'<li><a href=\"{DNA_REGISTER_ABS}\" target=\"_blank\" rel=\"noopener\">DNA Register</a></li>'\n",
        "  f'<li><a href=\"{TREES_ABS}\" target=\"_blank\" rel=\"noopener\">Trees</a></li>'\n",
        "  '<li><a id=\"show-selected\" href=\"#\">Show Selected</a></li>'\n",
        "  '<li><a id=\"show-all\" href=\"#\">Show All</a></li>'\n",
        "  '<li><a id=\"print-cousin-list\" href=\"#\">Cousin List (Printable)</a></li>'\n",
        "  '<li><a id=\"clear-selected\" href=\"#\">Reset</a></li>'\n",
        "  '</ul></nav>'\n",
        ")\n",
        "\n",
        "CONTROLS_BLOCK = (\n",
        "  '<div class=\"controls\">'\n",
        "  '<input type=\"text\" id=\"search-box\" size=\"28\" value=\"\" placeholder=\"Search&amp;hellip;\" />'\n",
        "  '</div>'\n",
        ")\n",
        "\n",
        "JS_COUNT_URL = COUNT_PUBLIC_URL.replace(\"'\", \"%27\")\n",
        "UPDATED_BLOCK = (\n",
        "    '<div class=\"updated centerline\">'\n",
        "    'Last updated: <span id=\"last-updated\"></span>'\n",
        "    ' &nbsp;|&nbsp; Autosomal matches: <span id=\"auto-count\" class=\"js-count\"></span>'\n",
        "    ' &nbsp;|&nbsp; Showing: <span id=\"showing-count\"></span>'\n",
        "    '</div>'\n",
        ")\n",
        "DOWNLOADS_BLOCK = (\n",
        "    '<p class=\"downloads centerline\">Download: '\n",
        "    f'<a href=\"/partials/{_html.escape(os.path.basename(LOCAL_CSV))}\">CSV</a> | '\n",
        "    f'<a href=\"/partials/{_html.escape(os.path.basename(LOCAL_XLSX))}\">Excel</a></p>'\n",
        ")\n",
        "\n",
        "page_tpl=Template(\"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "<title>ONS Yates Study Autosomal DNA Register</title>\n",
        "$HEAD_LINK\n",
        "$TABLE_CSS\n",
        "</head>\n",
        "<body id=\"top\">\n",
        "<div class=\"wrap\">\n",
        "  <h1 class=\"centerline\">ONS Yates Study Autosomal DNA Register</h1>\n",
        "  $DOWNLOADS_BLOCK\n",
        "  $UPDATED_BLOCK\n",
        "  $NAV_BLOCK\n",
        "  $CONTROLS_BLOCK\n",
        "  <div class=\"table-scroll\">$HTML_TABLE</div>\n",
        "</div>\n",
        "<button id=\"back-to-top\" class=\"back-to-top\">&#9650; Top</button>\n",
        "<script type=\"text/javascript\">\n",
        "//<![CDATA[\n",
        "(function(){\n",
        "  function textOf(cell){ return (cell && (cell.textContent || cell.innerText) || '').replace(/\\\\s+/g,' ').trim().toLowerCase(); }\n",
        "  function sortTable(tbl, colIndex, dir){\n",
        "    var tb=tbl && tbl.tBodies ? tbl.tBodies[0] : null; if(!tb) return;\n",
        "    var rows=[].slice.call(tb.rows||[]); var asc=(dir==='asc');\n",
        "    rows.sort(function(a,b){var A=textOf(a.cells[colIndex]),B=textOf(b.cells[colIndex]); if(A<B) return asc?-1:1; if(A>B) return asc?1:-1; return 0;});\n",
        "    var frag=document.createDocumentFragment(); for(var i=0;i<rows.length;i++) frag.appendChild(rows[i]); tb.appendChild(frag);\n",
        "    updateShowing();\n",
        "  }\n",
        "  function bindHeaderSort(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tHead && tbl.tHead.rows.length)) return;\n",
        "    var ths=tbl.tHead.rows[0].cells; if(!ths) return;\n",
        "    for(var i=0;i<ths.length;i++)(function(idx){\n",
        "      var th = ths[idx]; var dir='asc';\n",
        "      th.addEventListener('click',function(){\n",
        "        dir=(dir==='asc')?'desc':'asc';\n",
        "        for (var j = 0; j < ths.length; j++){ ths[j].innerHTML = ths[j].innerHTML.replace(/\\\\s+\\\\(asc\\\\)|\\\\s+\\\\(desc\\\\)/,''); }\n",
        "        th.innerHTML += (dir==='asc' ? ' (asc)' : ' (desc)');\n",
        "        sortTable(tbl,idx,dir);\n",
        "      },false);\n",
        "    })(i);\n",
        "  }\n",
        "  function formatWithCommas(n){ try{ var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return ''; return x.toLocaleString('en-US'); }catch(e){ return String(n||''); } }\n",
        "  function visibleRowCount(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return 0;\n",
        "    var rows=tbl.tBodies[0].rows, n=0; for(var i=0;i<rows.length;i++){ if(rows[i].style.display!=='none') n++; } return n;\n",
        "  }\n",
        "  function updateShowing(){ var el=document.getElementById('showing-count'); if(!el) return; el.textContent = formatWithCommas(visibleRowCount()); }\n",
        "  function getParam(name){ var m=location.search.match(new RegExp('[?&]'+name+'=([^&]+)')); return m?decodeURIComponent(m[1].replace(/\\\\+/g,' ')):''; }\n",
        "  function norm(s){ return String(s||'').replace(/\\\\s+/g,' ').toLowerCase(); }\n",
        "  function bindSearch(){\n",
        "    var box=document.getElementById('search-box'); var tbl=document.getElementById('refactor-table'); if(!(box && tbl && tbl.tBodies && tbl.tBodies[0])) return; var tb=tbl.tBodies[0];\n",
        "    function rowText(tr){ var t=''; for(var i=1;i<tr.cells.length;i++){ t+= ' ' + (tr.cells[i].textContent||tr.cells[i].innerText||''); } return norm(t); }\n",
        "    var cached=[]; (function seed(){ var rows=tb.rows; cached=[]; for(var i=0;i<rows.length;i++){ cached.push({el:rows[i], txt:rowText(rows[i])}); } })();\n",
        "    function apply(q){\n",
        "      q = String(q||''); var parts = q.split('|').map(function(s){return norm(s);}).filter(function(s){return !!s;});\n",
        "      for(var i=0;i<cached.length;i++){\n",
        "        var hit = !parts.length || parts.some(function(p){ return cached[i].txt.indexOf(p)>-1; });\n",
        "        cached[i].el.style.display = hit? '' : 'none';\n",
        "      }\n",
        "      updateShowing();\n",
        "    }\n",
        "    var to=null; function onInput(){ if(to) clearTimeout(to); to=setTimeout(function(){ apply(box.value); }, 60); }\n",
        "    box.addEventListener('input', onInput, false); box.addEventListener('search', onInput, false);\n",
        "    var q0=getParam('q'); if(q0){ box.value=q0; apply(q0); try{ history.replaceState(null,'',location.pathname); }catch(e){} }\n",
        "    else { box.value=''; apply(''); setTimeout(function(){ if(!getParam('q')){ box.value=''; apply(''); } }, 0); }\n",
        "  }\n",
        "  function allRowCheckboxes(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return [];\n",
        "    var tb=tbl.tBodies[0], out=[]; for(var i=0;i<tb.rows.length;i++){ var cb=tb.rows[i].querySelector('.selbox'); if(cb) out.push(cb); }\n",
        "    return out;\n",
        "  }\n",
        "  function bindGroupSync(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!tbl) return;\n",
        "    tbl.addEventListener('click', function(e){\n",
        "      var t=e.target||e.srcElement; if(!(t && t.classList && t.classList.contains('selbox'))) return;\n",
        "      var nm = t.getAttribute('data-name') || ''; var checked = !!t.checked;\n",
        "      var cbs = allRowCheckboxes(); for(var i=0;i<cbs.length;i++){ if((cbs[i].getAttribute('data-name')||'') === nm){ cbs[i].checked = checked; } }\n",
        "      updateShowing();\n",
        "    }, false);\n",
        "  }\n",
        "  function bindShowSelected(){\n",
        "    var btn=document.getElementById('show-selected'); if(!btn) return;\n",
        "    btn.addEventListener('click', function(e){\n",
        "      e.preventDefault();\n",
        "      var cbs = allRowCheckboxes(); var names = {};\n",
        "      for(var i=0;i<cbs.length;i++){ if(cbs[i].checked){ names[cbs[i].getAttribute('data-name')||''] = true; } }\n",
        "      var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "      var tb=tbl.tBodies[0];\n",
        "      for(var r=0;r<tb.rows.length;r++){\n",
        "        var cb = tb.rows[r].querySelector('.selbox'); var nm = cb ? (cb.getAttribute('data-name')||'') : '';\n",
        "        tb.rows[r].style.display = names[nm] ? '' : 'none';\n",
        "      }\n",
        "      updateShowing();\n",
        "    }, false);\n",
        "  }\n",
        "  function bindShowAll(){\n",
        "    var btn=document.getElementById('show-all'); if(!btn) return;\n",
        "    btn.addEventListener('click', function(e){\n",
        "      e.preventDefault();\n",
        "      var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "      var tb=tbl.tBodies[0]; for(var i=0;i<tb.rows.length;i++){ tb.rows[i].style.display=''; }\n",
        "      updateShowing();\n",
        "    }, false);\n",
        "  }\n",
        "  function bindClear(){\n",
        "    var btn=document.getElementById('clear-selected'); if(!btn) return;\n",
        "    btn.addEventListener('click', function(e){\n",
        "      e.preventDefault();\n",
        "      var cbs=allRowCheckboxes(); for(var i=0;i<cbs.length;i++) cbs[i].checked=false;\n",
        "      var tbl=document.getElementById('refactor-table'); if(tbl && tbl.tBodies && tbl.tBodies[0]){\n",
        "        var tb=tbl.tBodies[0]; for(var j=0;j<tb.rows.length;j++){ tb.rows[j].style.display=''; }\n",
        "      }\n",
        "      updateShowing();\n",
        "    }, false);\n",
        "  }\n",
        "  function bindPrintCousinList(){\n",
        "    var btn=document.getElementById('print-cousin-list'); if(!btn) return;\n",
        "    btn.addEventListener('click', function(e){\n",
        "      e.preventDefault();\n",
        "      var url = '/partials/cousin_list_print.htm';\n",
        "      try{ var w = window.open(url, 'CousinPrint'); if(w){ w.focus(); return; } } catch(ex){}\n",
        "      window.location.href = url;\n",
        "    }, false);\n",
        "  }\n",
        "  function addCheckboxes(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "    var tb=tbl.tBodies[0];\n",
        "    for(var i=0;i<tb.rows.length;i++){\n",
        "      var tr=tb.rows[i]; var cell=tr.cells[0]; var findBtn=cell ? cell.querySelector('.find-btn') : null;\n",
        "      var name = findBtn ? (findBtn.getAttribute('title')||'').replace('Open a filtered view for ','') : ('Row '+(i+1));\n",
        "      if(cell){\n",
        "        cell.classList.add('find-cell');\n",
        "        cell.innerHTML = '<input type=\"checkbox\" class=\"selbox\" title=\"Select this row\" data-name=\"'+name.replace(/\"/g,'&quot;')+'\" /> ' + cell.innerHTML.replace(/^\\\\s*/, '');\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  function initShowingStatic(){ try{ document.getElementById('showing-count').textContent = document.getElementById('refactor-table').tBodies[0].rows.length; }catch(e){}}\n",
        "  document.addEventListener('DOMContentLoaded', function(){\n",
        "    addCheckboxes();\n",
        "    (function(){\n",
        "      var el=document.getElementById('last-updated'); if(!el) return;\n",
        "      var d=new Date(document.lastModified||new Date());\n",
        "      var months=['January','February','March','April','May','June','July','August','September','October','November','December'];\n",
        "      var day=d.getDate(); var month=months[d.getMonth()]; var year=d.getFullYear();\n",
        "      var hour=d.getHours(); var min=d.getMinutes(); var ampm = hour >= 12 ? 'pm' : 'am';\n",
        "      hour = hour % 12; hour = hour ? hour : 12; var minStr = min < 10 ? '0' + min : min;\n",
        "      el.innerHTML = day + ' ' + month + ', ' + year + ' at ' + hour + ':' + minStr + ' ' + ampm;\n",
        "    })();\n",
        "    bindHeaderSort(); bindSearch(); bindGroupSync(); bindShowSelected(); bindShowAll(); bindClear(); bindPrintCousinList(); initShowingStatic();\n",
        "  });\n",
        "})();\n",
        "//]]>\n",
        "</script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\")\n",
        "\n",
        "html_table=display_df.to_html(index=False, escape=False, classes=\"dataframe sortable\")\n",
        "html_table=html_table.replace('<table border=\"1\" class=\"dataframe sortable\">','<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">',1)\n",
        "html_table=html_table.replace('<tbody>\\n<tr>','<tbody>\\n<tr id=\"first-row\">',1)\n",
        "html_table=html_table.replace(\"<th>Find</th>\",'<th>Select:</th>',1)\n",
        "html_table=html_table.replace('<th>Match Summary</th>','<th>Match Summary&amp;ndash;click to sort</th>',1)\n",
        "html_table=html_table.replace(f'<th>{_html.escape(LINEAGE_HEADER_SAFE)}</th>','<th>Lineage (Starting with oldest ancestor&amp;ndash;click to sort)</th>',1)\n",
        "\n",
        "colgroup_html = (\n",
        "    \"<colgroup>\\n\"\n",
        "    f\"  <col style=\\\"width:{FIND_COL_PX}px;\\\" />\\n\"\n",
        "    f\"  <col style=\\\"width:{COL_A_PX}px;\\\" />\\n\"\n",
        "    \"  <col />\\n\"\n",
        "    \"</colgroup>\\n\"\n",
        ")\n",
        "html_table=html_table.replace('<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">',\n",
        "                              '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">\\n'+colgroup_html,1)\n",
        "\n",
        "final_html=page_tpl.safe_substitute(\n",
        "    HEAD_LINK=HEAD_LINK, TABLE_CSS=TABLE_CSS, UPDATED_BLOCK=UPDATED_BLOCK,\n",
        "    NAV_BLOCK=NAV_BLOCK, CONTROLS_BLOCK=CONTROLS_BLOCK,\n",
        "    HTML_TABLE=html_table, JS_COUNT_URL=JS_COUNT_URL, DOWNLOADS_BLOCK=DOWNLOADS_BLOCK\n",
        ").replace(\"$HEAD_LINK_URL_JS$\", (STYLESHEET_HREF+\"?\"+CSS_VERSION))\n",
        "\n",
        "# ---------- 8) Partials ----------\n",
        "def _norm_code_for_count(s):\n",
        "    t=str(s or \"\").strip()\n",
        "    if (t.startswith('\"') and t.endswith('\"')) or (t.startswith(\"'\") and t.endswith(\"'\")): t=t[1:-1]\n",
        "    t=re.sub(r'\\s+',' ',t).strip().lower(); return t\n",
        "\n",
        "def _partial_css_wrapper_simple():\n",
        "    return (\n",
        "        \"<style type=\\\"text/css\\\">\\n\"\n",
        "        \"  html { scroll-behavior: smooth; }\\n\"\n",
        "        \"  body { background:#ffffff; color:#222; margin:0; padding:0; }\\n\"\n",
        "        \"  .wrap { max-width:100%; margin:0 auto; padding:16px; }\\n\"\n",
        "        \"  a { color:#154b8b; text-decoration:none; } a:hover { text-decoration:underline; }\\n\"\n",
        "        \"  h1 { margin:0 0 8px 0; font-size:24px; line-height:1.2; text-align:center; }\\n\"\n",
        "        \"  .meta { text-align:center; font-size:12px; color:#555; margin:2px 0 10px 0; }\\n\"\n",
        "        \"  .toolbar { display:flex; gap:10px; align-items:center; margin:6px 0 10px 0; flex-wrap:wrap; justify-content:center; }\\n\"\n",
        "        \"  .btn { display:inline-block; border:1px solid #5b79b8; background:#5b79b8; color:#fff; padding:4px 9px; text-decoration:none; cursor:pointer; border-radius:5px; line-height:1.2; }\\n\"\n",
        "        \"  table { border-collapse:collapse; width:100%; table-layout:fixed; }\\n\"\n",
        "        \"  th, td { border:1px solid #ddd; padding:6px 8px; word-wrap:break-word; overflow-wrap:break-word; }\\n\"\n",
        "        \"  th { background:#e3eaf8; text-align:left; position:sticky; top:0; z-index:2; }\\n\"\n",
        "        \"  tr.sel { background:#fff7d6; }\\n\"\n",
        "        \"  .count a { font-weight:bold; }\\n\"\n",
        "        \"  @media screen and (max-width: 700px) { th, td { padding:5px 6px; } }\\n\"\n",
        "        \"</style>\\n\"\n",
        "    )\n",
        "\n",
        "def _partial_head(title):\n",
        "    return (\n",
        "        \"<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Transitional//EN\\\"\\n\"\n",
        "        \" \\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\\\">\\n\"\n",
        "        \"<html xmlns=\\\"http://www.w3.org/1999/xhtml\\\" lang=\\\"en\\\">\\n<head>\\n\"\n",
        "        f\"{HEAD_LINK}\\n\"\n",
        "        \"<meta http-equiv=\\\"Content-Type\\\" content=\\\"text/html; charset=iso-8859-15\\\" />\\n\"\n",
        "        f\"<title>{_html.escape(title)}</title>\\n\"\n",
        "    )\n",
        "\n",
        "def _partial_toolbar():\n",
        "    safe_home = HOME_URL.replace('\"','&quot;')\n",
        "    return (\n",
        "        \"<div class=\\\"toolbar\\\">\"\n",
        "        f\"<a class=\\\"btn\\\" href=\\\"{safe_home}\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">DNA Register</a>\"\n",
        "        \" <button id=\\\"mc-show-selected\\\" class=\\\"btn\\\" title=\\\"Open DNA Register filtered to selected\\\">Show Selected</button>\"\n",
        "        \" <button id=\\\"mc-show-all\\\" class=\\\"btn\\\" title=\\\"Show all rows (this table)\\\">Show All</button>\"\n",
        "        \" <button id=\\\"mc-reset\\\" class=\\\"btn\\\" title=\\\"Clear selection and show all\\\">Reset</button>\"\n",
        "        \" <button id=\\\"view\\\" class=\\\"btn\\\" title=\\\"Open DNA Register with selected (alias)\\\">View Now</button>\"\n",
        "        \"</div>\\n\"\n",
        "    )\n",
        "\n",
        "def _partial_js_common():\n",
        "    _safe_home=HOME_URL.replace(\"'\",\"%27\")\n",
        "    return (\n",
        "        \"<script type=\\\"text/javascript\\\">\\n//<![CDATA[\\n\"\n",
        "        \"(function(){\\n\"\n",
        "        \"  var REG = '\" + _safe_home + \"';\\n\"\n",
        "        \"  function fmt(n){ try{ var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return '0'; return x.toLocaleString('en-US'); }catch(e){ return String(n||'0'); } }\\n\"\n",
        "        \"  function selected(){ var out=[]; var tb=document.getElementById('ref-tb'); if(!tb) return out; var rows=tb.rows; for(var i=0;i<rows.length;i++){ if((' '+rows[i].className+' ').indexOf(' sel ')>-1) out.push(rows[i]); } return out; }\\n\"\n",
        "        \"  function update(){ var sel=selected(), sum=0; for(var i=0;i<sel.length;i++){ var v=parseInt((sel[i].getAttribute('data-count')||'0').replace(/[^0-9\\\\-]/g,''),10); if(!isNaN(v)) sum+=v; } var nEl=document.getElementById('sel-n'); var sEl=document.getElementById('sel-sum'); if(nEl) nEl.innerHTML=fmt(sel.length); if(sEl) sEl.innerHTML=fmt(sum); }\\n\"\n",
        "        \"  function qJoin(parts){ var out=[]; var seen={}; for(var i=0;i<parts.length;i++){ var p=String(parts[i]||''); if(p && !seen[p]){ seen[p]=1; out.push(encodeURIComponent(p)); } } return out.join('%7C'); }\\n\"\n",
        "        \"  function openRegisterForSelected(){ var sel=selected(); if(!sel.length) return; var qs=[]; for(var i=0;i<sel.length;i++){ qs.push(sel[i].getAttribute('data-q')||''); } var q = qJoin(qs); var url = REG + '?q=' + q; var w=null; try{ w=window.open(url,'RegisterFiltered'); if(!w) throw new Error('popup'); w.focus(); } catch(e){ window.location.href = url; } }\\n\"\n",
        "        \"  function toggleFrom(el){ var tr=el; while(tr && tr.nodeName && tr.nodeName.toLowerCase()!=='tr'){ tr=tr.parentNode; } if(!tr) return; var c=tr.className||''; tr.className = ((' '+c+' ').indexOf(' sel ')>-1) ? c.replace(/\\\\bsel\\\\b/,'').replace(/\\\\s{2,}/g,' ').trim() : (c?c+' ':'')+'sel'; update(); }\\n\"\n",
        "        \"  document.addEventListener('click', function(e){ var t=e.target||e.srcElement; if(!t) return; if(t.classList && t.classList.contains('count-pick')){ e.preventDefault(); toggleFrom(t); return; } if(t.id=='view' || t.id=='mc-show-selected'){ e.preventDefault(); openRegisterForSelected(); return; } if(t.id=='mc-reset'){ e.preventDefault(); var tb=document.getElementById('ref-tb'); if(tb){ var rows=tb.rows; for(var i=0;i<rows.length;i++){ rows[i].className = rows[i].className.replace(/\\\\bsel\\\\b/,'').replace(/\\\\s{2,}/g,' ').trim(); rows[i].style.display=''; } } update(); return; } if(t.id=='mc-show-all'){ e.preventDefault(); var tb2=document.getElementById('ref-tb'); if(!tb2) return; for(var k=0;k<tb2.rows.length;k++){ tb2.rows[k].style.display=''; } return; } }, false);\\n\"\n",
        "        \"  document.addEventListener('DOMContentLoaded', update, false);\\n\"\n",
        "        \"})();\\n\"\n",
        "        \"//]]>\\n</script>\\n\"\n",
        "    )\n",
        "\n",
        "def _shell_open(title):\n",
        "    return (\n",
        "        _partial_head(title)+_partial_css_wrapper_simple()+\"</head>\\n<body>\\n<div class=\\\"wrap\\\">\\n\"+\n",
        "        f\"<h1>{_html.escape(title)}</h1>\\n\"+\n",
        "        \"<div class=\\\"meta\\\">Last updated: <span id=\\\"last-updated\\\"></span> &nbsp;|&nbsp; Autosomal matches: <span id=\\\"auto-count\\\">&mdash;</span> &nbsp;|&nbsp; Selected: <span id=\\\"sel-n\\\">0</span> &nbsp; Sum: <span id=\\\"sel-sum\\\">0</span></div>\\n\"+\n",
        "        _partial_toolbar()+\n",
        "        \"<div class=\\\"table-scroll\\\">\\n\"\n",
        "    )\n",
        "\n",
        "def _shell_close():\n",
        "    safe_count=COUNT_PUBLIC_URL.replace(\"'\",\"%27\")\n",
        "    return (\n",
        "        \"</div>\\n</div>\\n\"\n",
        "        \"<script type=\\\"text/javascript\\\">\\n//<![CDATA[\\n\"\n",
        "        \"(function(){ function stamp(){ var el=document.getElementById('last-updated'); if(!el) return; var d=new Date(document.lastModified||new Date()); var months=['January','February','March','April','May','June','July','August','September','October','November','December']; var day=d.getDate(); var month=months[d.getMonth()]; var year=d.getFullYear(); var hour=d.getHours(); var min=d.getMinutes(); var ampm = hour >= 12 ? 'pm' : 'am'; hour = hour % 12; hour = hour ? hour : 12; var minStr = min < 10 ? '0' + min : min; el.innerHTML = day + ' ' + month + ', ' + year + ' at ' + hour + ':' + minStr + ' ' + ampm; } function load(){var el=document.getElementById('auto-count'); if(!el) return; var URL='\"+safe_count+\"'; try{var xhr=new XMLHttpRequest(); xhr.open('GET', URL+(URL.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true); xhr.onreadystatechange=function(){if(xhr.readyState===4){if(xhr.status>=200&&xhr.status<300){var m=(xhr.responseText||'').match(/(\\\\d+)/); el.textContent=(m?m[1]:'');} else {el.textContent='(unavailable)';}}}; xhr.send(null);}catch(e){el.textContent='(unavailable)';}} document.addEventListener('DOMContentLoaded', function(){ stamp(); load(); }, false); })();\\n\"\n",
        "        \"//]]>\\n</script>\\n\"+_partial_js_common()+ \"</body>\\n</html>\"\n",
        "    )\n",
        "\n",
        "def build_match_count_partial(main_df: pd.DataFrame)->str:\n",
        "    codes_raw=main_df[match_col].astype(str).map(lambda x:x.strip())\n",
        "    keys_norm=codes_raw.map(_norm_code_for_count)\n",
        "    counts_series=keys_norm.value_counts(dropna=False)\n",
        "    counts=counts_series.reset_index()\n",
        "    if counts.shape[1]>=2: counts.columns=[\"norm_key\",\"Count\"]\n",
        "    else:\n",
        "        counts[\"norm_key\"]=counts.index.astype(str); counts[\"Count\"]=counts_series.values; counts=counts[[\"norm_key\",\"Count\"]]\n",
        "    first_display={}\n",
        "    for code_disp,k in zip(codes_raw.tolist(), keys_norm.tolist()):\n",
        "        if k not in first_display and str(k)!=\"\": first_display[k]=code_disp\n",
        "    counts[\"Code\"]=counts[\"norm_key\"].map(lambda k:first_display.get(k,k))\n",
        "    counts[\"Unmasked\"]=counts[\"norm_key\"].map(lambda k:MATCH_TO_UNMASKED.get(k,\"\"))\n",
        "    counts=counts.sort_values(by=[\"Code\",\"Count\"], ascending=[True,False], kind=\"mergesort\").reset_index(drop=True)\n",
        "    html=[]; html.append(_shell_open(\"Match Count\"))\n",
        "    html.append('<table id=\"ref-table\" border=\"1\" class=\"sortable\" style=\"width:100%\"><thead><tr>')\n",
        "    html.append('<th style=\"width:35%\">Code</th><th style=\"width:45%\">Unmasked</th><th style=\"width:20%\">Count</th>')\n",
        "    html.append('</tr></thead><tbody id=\"ref-tb\">')\n",
        "    for _,r in counts.iterrows():\n",
        "        code=r.get(\"Code\",\"\"); unm=r.get(\"Unmasked\",\"\"); cnt=int(str(r.get(\"Count\",\"0\")).strip() or \"0\"); label=(unm or code).strip()\n",
        "        tr=(f'<tr data-q=\"{_html.escape(label,quote=True)}\" data-count=\"{cnt}\"><td>{_html.escape(code)}</td><td>{_html.escape(unm)}</td><td class=\"count\"><a href=\"#\" class=\"count-pick\" title=\"Toggle select\">{cnt}</a></td></tr>')\n",
        "        html.append(tr)\n",
        "    html.append('</tbody></table>'); html.append(_shell_close()); return \"\".join(html)\n",
        "\n",
        "def build_lineage_count_partial(main_df: pd.DataFrame)->str:\n",
        "    first_series=main_df.get(\"First Ancestor\", pd.Series(dtype=str)).astype(str).map(lambda x:x.strip())\n",
        "    vc=first_series[first_series!=\"\"].value_counts(dropna=False)\n",
        "    lin_df=vc.reset_index()\n",
        "    if lin_df.shape[1]>=2: lin_df.columns=[\"First Ancestor\",\"Count\"]\n",
        "    else:\n",
        "        lin_df[\"First Ancestor\"]=lin_df.index.astype(str); lin_df[\"Count\"]=vc.values; lin_df=lin_df[[\"First Ancestor\",\"Count\"]]\n",
        "    lin_df=lin_df.sort_values([\"Count\",\"First Ancestor\"], ascending=[False,True], kind=\"mergesort\").reset_index(drop=True)\n",
        "    html=[]; html.append(_shell_open(\"Lineage Count\"))\n",
        "    html.append('<table id=\"ref-table\" border=\"1\" class=\"sortable\" style=\"width:100%\"><thead><tr>')\n",
        "    html.append('<th style=\"width:80%\">First Ancestor</th><th style=\"width:20%\">Count</th>')\n",
        "    html.append('</tr></thead><tbody id=\"ref-tb\">')\n",
        "    for _,r in lin_df.iterrows():\n",
        "        first=str(r.get(\"First Ancestor\",\"\")).strip(); cnt=int(str(r.get(\"Count\",\"0\")).strip() or \"0\")\n",
        "        tr=(f'<tr data-q=\"{_html.escape(first,quote=True)}\" data-count=\"{cnt}\"><td>{_html.escape(first)}</td><td class=\"count\"><a href=\"#\" class=\"count-pick\" title=\"Toggle select\">{cnt}</a></td></tr>')\n",
        "        html.append(tr)\n",
        "    html.append('</tbody></table>'); html.append(_shell_close()); return \"\".join(html)\n",
        "\n",
        "def build_and_write_partials(main_df: pd.DataFrame):\n",
        "    _setup_resolver(); os.makedirs(\"partials\", exist_ok=True)\n",
        "    mc_html=build_match_count_partial(main_df); mc_local=os.path.join(\"partials\",\"match_count.htm\")\n",
        "    with open(mc_local,\"w\",encoding=\"iso-8859-15\",errors=\"xmlcharrefreplace\") as f: f.write(mc_html)\n",
        "    print(\"[OK] Wrote partial:\", mc_local)\n",
        "    lc_html=build_lineage_count_partial(main_df); lc_local=os.path.join(\"partials\",\"lineage_count.htm\")\n",
        "    with open(lc_local,\"w\",encoding=\"iso-8859-15\",errors=\"xmlcharrefreplace\") as f: f.write(lc_html)\n",
        "    print(\"[OK] Wrote partial:\", lc_local)\n",
        "    cousin_df=main_df[[\"Match Summary\"]].copy()\n",
        "    cousin_df=cousin_df.sort_values(by=\"Match Summary\", ascending=True, kind=\"mergesort\").reset_index(drop=True)\n",
        "    rows=['<table border=\"1\" id=\"refactor-table\"><thead><tr><th>Match Summary</th></tr></thead><tbody>']\n",
        "    for v in cousin_df[\"Match Summary\"].tolist(): rows.append(f\"<tr><td>{v}</td></tr>\")\n",
        "    rows.append(\"</tbody></table>\")\n",
        "    cousin_html=(\"<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Transitional//EN\\\" \\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\\\">\"\n",
        "                 \"<html xmlns=\\\"http://www.w3.org/1999/xhtml\\\" lang=\\\"en\\\"><head>\"+HEAD_LINK+\n",
        "                 \"<meta http-equiv=\\\"Content-Type\\\" content=\\\"text/html; charset=iso-8859-15\\\" />\"\n",
        "                 \"<title>Cousin List (Printable)</title>\"\n",
        "                 \"<style type=\\\"text/css\\\"> body{font-size:12px;margin:20px;} h1{text-align:center;font-size:20px;} table{border-collapse:collapse;width:100%;} th,td{border:1px solid #999;padding:5px 7px;vertical-align:top;text-align:left;} th{background:#f0f0f0;} a{color:#000;text-decoration:none;} </style>\"\n",
        "                 \"</head><body onload=\\\"window.print();\\\"><h1>Cousin List (Printable)</h1>\"+ \"\".join(rows) +\"</body></html>\")\n",
        "    cl_local=os.path.join(\"partials\",\"cousin_list_print.htm\")\n",
        "    with open(cl_local,\"w\",encoding=\"iso-8859-15\",errors=\"xmlcharrefreplace\") as f: f.write(cousin_html)\n",
        "    print(\"[OK] Wrote partial:\", cl_local)\n",
        "    return mc_local, lc_local, cl_local\n",
        "\n",
        "PARTIAL_MATCH_LOCAL, PARTIAL_LINEAGE_LOCAL, PARTIAL_COUSIN_LOCAL = build_and_write_partials(df)\n",
        "\n",
        "def build_register_html_for_abs(remote_abs_path:str)->str:\n",
        "    q_links=[]; subs=df[\"Subject\"].astype(str).tolist()\n",
        "    for subject_name in subs:\n",
        "        q=_u.quote(subject_name)\n",
        "        q_links.append(f'<a class=\"find-btn\" href=\"{remote_abs_path}?q={q}\" target=\"_blank\" rel=\"noopener\" title=\"Open a filtered view for {subject_name}\">Find</a>')\n",
        "    df_plus=df.copy(); df_plus[\"Find\"]=q_links\n",
        "    disp_plus=df_plus[[\"Find\",\"Match Summary\",LINEAGE_HEADER_SAFE]]\n",
        "    tbl=disp_plus.to_html(index=False, escape=False, classes=\"dataframe sortable\")\n",
        "    tbl=tbl.replace('<table border=\"1\" class=\"dataframe sortable\">','<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">',1)\n",
        "    tbl=tbl.replace('<tbody>\\n<tr>','<tbody>\\n<tr id=\"first-row\">',1)\n",
        "    tbl=tbl.replace(\"<th>Find</th>\",'<th>Select:</th>',1)\n",
        "    tbl=tbl.replace(\"<th>Match Summary</th>\",'<th>Match Summary&amp;ndash;click to sort</th>',1)\n",
        "    tbl=tbl.replace(f\"<th>{_html.escape(LINEAGE_HEADER_SAFE)}</th>\",\"<th>Lineage (Starting with oldest ancestor&amp;ndash;click to sort)</th>\",1)\n",
        "    colgroup_html_local=( \"<colgroup>\\n\"+ f\"  <col style=\\\"width:{FIND_COL_PX}px;\\\" />\\n\"+ f\"  <col style=\\\"width:{COL_A_PX}px;\\\" />\\n\"+ \"  <col />\\n</colgroup>\\n\")\n",
        "    tbl=tbl.replace('<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">','<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">\\n'+colgroup_html_local,1)\n",
        "    return page_tpl.safe_substitute(\n",
        "        HEAD_LINK=HEAD_LINK, TABLE_CSS=TABLE_CSS, UPDATED_BLOCK=UPDATED_BLOCK, NAV_BLOCK=NAV_BLOCK,\n",
        "        CONTROLS_BLOCK=CONTROLS_BLOCK, HTML_TABLE=tbl, JS_COUNT_URL=JS_COUNT_URL, DOWNLOADS_BLOCK=DOWNLOADS_BLOCK\n",
        "    ).replace(\"$HEAD_LINK_URL_JS$\", (STYLESHEET_HREF+\"?\"+CSS_VERSION))\n",
        "\n",
        "os.makedirs(\"partials\", exist_ok=True)\n",
        "final_html_plus=build_register_html_for_abs(HOME_URL)\n",
        "\n",
        "with open(LOCAL_HTML,\"w\",encoding=\"iso-8859-15\",errors=\"xmlcharrefreplace\") as f: f.write(final_html)\n",
        "print(\"[OK] Saved canonical render:\", os.path.abspath(LOCAL_HTML))\n",
        "with open(WORK_PLUS_LOCAL,\"w\",encoding=\"iso-8859-15\",errors=\"xmlcharrefreplace\") as f: f.write(final_html_plus)\n",
        "print(\"[OK] Saved:\", os.path.abspath(WORK_PLUS_LOCAL), \"(partials clone)\")\n",
        "\n",
        "# ---------- 9) Upload ----------\n",
        "def save_and_upload_all():\n",
        "    if not all(os.environ.get(k) for k in ['FTP_HOST','FTP_USER','FTP_PASS']):\n",
        "        print(\"[SKIP] Missing FTP creds; uploads skipped.\"); return\n",
        "    try:\n",
        "        ftps=ftp_connect()\n",
        "        try:\n",
        "            ftp_upload_overwrite(ftps, LOCAL_HTML, _remote_path(REMOTE_HTML_CANON))\n",
        "            ftp_upload_overwrite(ftps, LOCAL_HTML, _remote_path(REMOTE_HTML_LEG))\n",
        "            ftp_upload_overwrite(ftps, LOCAL_HTML, _remote_path(REMOTE_HTML_SIMPLE))\n",
        "        except Exception as e: print(\"[WARN] Upload main HTML failed:\", e)\n",
        "        try:\n",
        "            if os.path.exists(LOCAL_CSV):  ftp_upload_overwrite(ftps, LOCAL_CSV,  _remote_path(REMOTE_CSV))\n",
        "            if os.path.exists(LOCAL_XLSX): ftp_upload_overwrite(ftps, LOCAL_XLSX, _remote_path(REMOTE_XLSX))\n",
        "            print(\"[OK] Uploaded CSV/XLSX -> /partials/\")\n",
        "        except Exception as e: print(\"[WARN] Upload CSV/XLSX failed:\", e)\n",
        "        if os.path.exists(LOCAL_COUNT_FILE):\n",
        "            try: ftp_upload_overwrite(ftps, LOCAL_COUNT_FILE, _remote_path(REMOTE_COUNT_NAME))\n",
        "            except Exception as e: print(\"[WARN] Upload autosomal count failed:\", e)\n",
        "        try:\n",
        "            ftp_upload_overwrite(ftps, os.path.join(\"partials\",\"match_count.htm\"),     _remote_path(posixpath.join(\"partials\",\"match_count.htm\")))\n",
        "            ftp_upload_overwrite(ftps, os.path.join(\"partials\",\"lineage_count.htm\"),   _remote_path(posixpath.join(\"partials\",\"lineage_count.htm\")))\n",
        "            ftp_upload_overwrite(ftps, os.path.join(\"partials\",\"cousin_list_print.htm\"), _remote_path(posixpath.join(\"partials\",\"cousin_list_print.htm\")))\n",
        "        except Exception as e: print(\"[WARN] Upload partials failed:\", e)\n",
        "        try: ftp_upload_overwrite(ftps, WORK_PLUS_LOCAL, _remote_path(WORK_PLUS_REMOTE))\n",
        "        except Exception as e: print(\"[WARN] Upload work_plus.htm failed:\", e)\n",
        "\n",
        "        print(\"\\n--- SIZE Verification (if supported) ---\")\n",
        "        for p in [\n",
        "            _remote_path(REMOTE_HTML_CANON), _remote_path(REMOTE_HTML_LEG), _remote_path(REMOTE_HTML_SIMPLE),\n",
        "            _remote_path(REMOTE_CSV), _remote_path(REMOTE_XLSX),\n",
        "            _remote_path(posixpath.join(\"partials\",\"match_count.htm\")),\n",
        "            _remote_path(posixpath.join(\"partials\",\"lineage_count.htm\")),\n",
        "            _remote_path(posixpath.join(\"partials\",\"cousin_list_print.htm\")),\n",
        "            _remote_path(WORK_PLUS_REMOTE),\n",
        "        ]:\n",
        "            sz=ftp_size(ftps,p); print(f\"{p} : {sz if sz is not None else '(SIZE unsupported)'}\")\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "\n",
        "        print(\"\\n--- Open URLs ---\")\n",
        "        print(\"Canonical:        https://yates.one-name.net/partials/yates_ancestor_register.htm\")\n",
        "        print(\"Legacy clone:     https://yates.one-name.net/partials/ons_yates_dna_register.htm\")\n",
        "        print(\"JUSTDNA alias:    https://yates.one-name.net/partials/justdna.htm\")\n",
        "        print(\"Trees:            https://yates.one-name.net/partials/just-trees.htm\")\n",
        "        print(\"Match Count:      https://yates.one-name.net/partials/match_count.htm\")\n",
        "        print(\"Lineage Count:    https://yates.one-name.net/partials/lineage_count.htm\")\n",
        "        print(\"Cousin Printable: https://yates.one-name.net/partials/cousin_list_print.htm\")\n",
        "        print(\"Work+ clone:      https://yates.one-name.net/partials/work_plus.htm\")\n",
        "        print(\"\\nIf a menu still shows blue text, hard-refresh or add ?v=1 once to bust cache.\")\n",
        "    except Exception as e:\n",
        "        print(\"[FAIL] FTP session:\", e); traceback.print_exc()\n",
        "\n",
        "save_and_upload_all()\n",
        "# ====== CUT STOP [1/1] CELL 2 ===================================================================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AuYeaPRlXEY",
        "outputId": "284c4aa7-18cc-4c68-c0f2-767a8d9444de"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CONFIRM] Golden Rules active | Cell=Cell2_OldSchoolMenu_WhiteText | Version=2025.11.11 | Encoding=ISO-8859-15\n",
            "DECLARED_LINES=9999\n",
            "[OK] Loaded CSV: 7 rows, 6 cols\n",
            "[PULL] match_to_unmasked.csv -> /content/match_to_unmasked.server.csv\n",
            "[OK] Resolver loaded: 79 codes\n",
            "[OK] Wrote exports: /content/yates_ancestor_register.csv and /content/yates_ancestor_register.xlsx\n",
            "[OK] Wrote partial: partials/match_count.htm\n",
            "[OK] Wrote partial: partials/lineage_count.htm\n",
            "[OK] Wrote partial: partials/cousin_list_print.htm\n",
            "[OK] Saved canonical render: /content/yates_ancestor_register.htm\n",
            "[OK] Saved: /content/partials/work_plus.htm (partials clone)\n",
            "[PUT] yates_ancestor_register.htm -> partials/yates_ancestor_register.htm\n",
            "[PUT] yates_ancestor_register.htm -> partials/ons_yates_dna_register.htm\n",
            "[PUT] yates_ancestor_register.htm -> partials/justdna.htm\n",
            "[PUT] yates_ancestor_register.csv -> partials/yates_ancestor_register.csv\n",
            "[PUT] yates_ancestor_register.xlsx -> partials/yates_ancestor_register.xlsx\n",
            "[OK] Uploaded CSV/XLSX -> /partials/\n",
            "[PUT] /content/autosomal_count.txt -> autosomal_count.txt\n",
            "[PUT] partials/match_count.htm -> partials/match_count.htm\n",
            "[PUT] partials/lineage_count.htm -> partials/lineage_count.htm\n",
            "[PUT] partials/cousin_list_print.htm -> partials/cousin_list_print.htm\n",
            "[PUT] partials/work_plus.htm -> partials/work_plus.htm\n",
            "\n",
            "--- SIZE Verification (if supported) ---\n",
            "partials/yates_ancestor_register.htm : 19568\n",
            "partials/ons_yates_dna_register.htm : 19568\n",
            "partials/justdna.htm : 19568\n",
            "partials/yates_ancestor_register.csv : 2931\n",
            "partials/yates_ancestor_register.xlsx : 6693\n",
            "partials/match_count.htm : 6660\n",
            "partials/lineage_count.htm : 6830\n",
            "partials/cousin_list_print.htm : 3164\n",
            "partials/work_plus.htm : 19568\n",
            "\n",
            "--- Open URLs ---\n",
            "Canonical:        https://yates.one-name.net/partials/yates_ancestor_register.htm\n",
            "Legacy clone:     https://yates.one-name.net/partials/ons_yates_dna_register.htm\n",
            "JUSTDNA alias:    https://yates.one-name.net/partials/justdna.htm\n",
            "Trees:            https://yates.one-name.net/partials/just-trees.htm\n",
            "Match Count:      https://yates.one-name.net/partials/match_count.htm\n",
            "Lineage Count:    https://yates.one-name.net/partials/lineage_count.htm\n",
            "Cousin Printable: https://yates.one-name.net/partials/cousin_list_print.htm\n",
            "Work+ clone:      https://yates.one-name.net/partials/work_plus.htm\n",
            "\n",
            "If a menu still shows blue text, hard-refresh or add ?v=1 once to bust cache.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEST Cell 3"
      ],
      "metadata": {
        "id": "ZST5Z7Gxnene"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# debug"
      ],
      "metadata": {
        "id": "9G7Y0HwjtZIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# READ-ONLY: check whether any file links to /thebuttons.htm\n",
        "from ftplib import FTP_TLS, all_errors\n",
        "import io, re\n",
        "\n",
        "host, user, pw = FTP_HOST, FTP_USER, FTP_PASS  # reuse your secrets\n",
        "s = FTP_TLS(); s.connect(host); s.auth(); s.login(user, pw); s.prot_p()\n",
        "hits=[]\n",
        "for name in s.nlst('/'):\n",
        "    if not name.lower().endswith(('.htm','.html')): continue\n",
        "    buf=io.BytesIO();\n",
        "    try: s.retrbinary(f\"RETR {name}\", buf.write)\n",
        "    except all_errors: continue\n",
        "    if re.search(r'thebuttons\\.htm', buf.getvalue().decode('latin-1','ignore'), re.I):\n",
        "        hits.append(name)\n",
        "s.quit(); print(\"References:\", hits or \"none\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjDy5vmOKce8",
        "outputId": "2766183e-c4a8-43ed-9f67-4c36557ddcfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "References: none\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] CELL — DIAGNOSE \"HOME\" MISROUTE (READ-ONLY, NO WRITES) ======\n",
        "# RON GOLDEN RULES — CLIFF NOTES (v2025.11.10)\n",
        "# • Single contiguous, runnable Colab cell; ASCII-only source.\n",
        "# • ISO-8859-15 prints (xmlcharrefreplace); deterministic audits.\n",
        "# • READ-ONLY: downloads a few files, prints analysis; makes NO server changes.\n",
        "\n",
        "import os, io, re, sys, textwrap\n",
        "from ftplib import FTP, FTP_TLS, all_errors\n",
        "\n",
        "DECLARED_LINES = 260\n",
        "\n",
        "def _enc(s):\n",
        "    try:\n",
        "        return str(s).encode(\"iso-8859-15\",\"xmlcharrefreplace\").decode(\"iso-8859-15\")\n",
        "    except Exception:\n",
        "        return str(s)\n",
        "\n",
        "print(_enc(\"[CONFIRM] Golden Rules active | Cell=DIAG-HOME | Version=2025.11.10 | Encoding=ISO-8859-15\"))\n",
        "print(_enc(f\"DECLARED_LINES={DECLARED_LINES}\"))\n",
        "\n",
        "PASSIVE_MODE = True\n",
        "USE_TLS_FIRST = True\n",
        "\n",
        "# ---------- Secrets (env or userdata) ----------\n",
        "def _get_env(k, default=\"\"):\n",
        "    try:\n",
        "        from google.colab import userdata  # type: ignore\n",
        "        v = userdata.get(k)\n",
        "        return v if v is not None else os.environ.get(k, default)\n",
        "    except Exception:\n",
        "        return os.environ.get(k, default)\n",
        "\n",
        "FTP_HOST = (_get_env(\"FTP_HOST\",\"\") or \"\").strip()\n",
        "FTP_USER = (_get_env(\"FTP_USER\",\"\") or \"\").strip()\n",
        "FTP_PASS = _get_env(\"FTP_PASS\",\"\") or \"\"\n",
        "FTP_PORT = int(_get_env(\"FTP_PORT\",\"21\") or \"21\")\n",
        "if not FTP_HOST or not FTP_USER or FTP_PASS is None:\n",
        "    print(_enc(\"[ERROR] Missing one or more of FTP_HOST / FTP_USER / FTP_PASS.\")); raise SystemExit(1)\n",
        "\n",
        "def connect():\n",
        "    last = None\n",
        "    if USE_TLS_FIRST:\n",
        "        try:\n",
        "            s = FTP_TLS(); s.encoding=\"utf-8\"; s.timeout=30\n",
        "            print(_enc(f\"[INFO] Connecting FTPS {FTP_HOST}:{FTP_PORT}\")); s.connect(FTP_HOST, FTP_PORT)\n",
        "            print(_enc(\"[INFO] AUTH TLS\")); s.auth()\n",
        "            print(_enc(f\"[INFO] Login {FTP_USER}\")); s.login(FTP_USER, FTP_PASS)\n",
        "            s.set_pasv(PASSIVE_MODE); s.prot_p()\n",
        "            return s, True\n",
        "        except Exception as e:\n",
        "            last = e\n",
        "            print(_enc(f\"[WARN] FTPS failed: {e.__class__.__name__}: {e}\"))\n",
        "    s = FTP(); s.encoding=\"utf-8\"; s.timeout=30\n",
        "    print(_enc(f\"[INFO] Connecting FTP  {FTP_HOST}:{FTP_PORT}\")); s.connect(FTP_HOST, FTP_PORT)\n",
        "    print(_enc(f\"[INFO] Login {FTP_USER}\")); s.login(FTP_USER, FTP_PASS)\n",
        "    s.set_pasv(PASSIVE_MODE)\n",
        "    return s, False\n",
        "\n",
        "def dl_bytes(sess, remote_path):\n",
        "    buf = io.BytesIO()\n",
        "    try:\n",
        "        sess.retrbinary(f\"RETR {remote_path}\", buf.write)\n",
        "        return buf.getvalue()\n",
        "    except all_errors as e:\n",
        "        return None\n",
        "\n",
        "def decode_guess(b):\n",
        "    for enc in (\"iso-8859-15\",\"latin-1\",\"utf-8\"):\n",
        "        try:\n",
        "            return b.decode(enc, \"xmlcharrefreplace\")\n",
        "        except Exception:\n",
        "            continue\n",
        "    return b.decode(\"latin-1\",\"xmlcharrefreplace\")\n",
        "\n",
        "# Files to inspect (READ-ONLY)\n",
        "TARGETS = [\n",
        "    \"/thebuttons.htm\",   # common nav include\n",
        "    \"/index.htm\",        # main default\n",
        "    \"/index.html\",       # alternate default\n",
        "    \"/.htaccess\",        # redirects / rewrites\n",
        "]\n",
        "\n",
        "PATTERNS = [\n",
        "    (r'ons_yates_dna_register\\.htm', \"DNA register hardlink\"),\n",
        "    (r'\\bbase\\s+href\\s*=\\s*[\"\\']([^\"\\']+)[\"\\']', \"<base href> tag\"),\n",
        "    (r'http-equiv\\s*=\\s*[\"\\']refresh[\"\\']', \"META refresh\"),\n",
        "    (r'window\\.location|location\\s*=', \"JS redirect\"),\n",
        "    (r'href\\s*=\\s*[\"\\']/[\"\\']', 'Home to \"/\"'),\n",
        "    (r'href\\s*=\\s*[\"\\']/index\\.htm[\"\\']', 'Home to \"/index.htm\"'),\n",
        "]\n",
        "\n",
        "def print_context(label, text, rx, desc, window=2):\n",
        "    print(_enc(f\"\\n--- {label}: {desc} ---\"))\n",
        "    lines = text.splitlines()\n",
        "    matches = list(re.finditer(rx, text, flags=re.IGNORECASE))\n",
        "    if not matches:\n",
        "        print(_enc(\"  (no matches)\"))\n",
        "        return 0\n",
        "    count = 0\n",
        "    for m in matches:\n",
        "        # compute line number\n",
        "        pos = m.start()\n",
        "        line_no = text.count(\"\\n\", 0, pos)\n",
        "        start = max(0, line_no - window)\n",
        "        end   = min(len(lines), line_no + window + 1)\n",
        "        snippet = \"\\n\".join(f\"{i+1:04d}: {lines[i]}\" for i in range(start, end))\n",
        "        print(_enc(snippet))\n",
        "        count += 1\n",
        "    return count\n",
        "\n",
        "sess, is_tls = connect()\n",
        "try:\n",
        "    try: syst = sess.sendcmd(\"SYST\")\n",
        "    except all_errors as e: syst = f\"unknown ({e.__class__.__name__})\"\n",
        "    try:  cwd = sess.pwd()\n",
        "    except all_errors: cwd = \"?\"\n",
        "    print(_enc(f\"[INFO] Protocol: {'FTPS' if is_tls else 'FTP'} | Passive={PASSIVE_MODE} | CWD={cwd} | SYST={syst}\"))\n",
        "\n",
        "    total_hits = 0\n",
        "    for path in TARGETS:\n",
        "        data = dl_bytes(sess, path)\n",
        "        print(_enc(f\"\\n[CHECK] {path}\"))\n",
        "        if data is None:\n",
        "            print(_enc(\"  (not found or unreadable; skipping)\"))\n",
        "            continue\n",
        "        txt = decode_guess(data)\n",
        "        for rx, desc in PATTERNS:\n",
        "            total_hits += print_context(path, txt, rx, desc, window=2)\n",
        "\n",
        "    if total_hits == 0:\n",
        "        print(_enc(\"\\n[RESULT] No obvious misroute patterns found in the checked files. Next suspects:\"))\n",
        "        print(_enc(\" - A different shared include (e.g., /includes/*.htm)\"))\n",
        "        print(_enc(\" - A template file in /tng/ that defines the Home link\"))\n",
        "        print(_enc(\" - A JS file rewriting Home at runtime\"))\n",
        "\n",
        "    else:\n",
        "        print(_enc(f\"\\n[RESULT] Found {total_hits} match(es). We can fix just the culprit file(s) surgically, no bulk edits.\"))\n",
        "\n",
        "finally:\n",
        "    try: sess.quit()\n",
        "    except Exception:\n",
        "        try: sess.close()\n",
        "        except Exception: pass\n",
        "\n",
        "print(_enc(\"[DONE] Read-only diagnosis complete. Share the snippets above to proceed with a one-file fix.\"))\n",
        "# ====== CUT STOP  [1/1] CELL — DIAGNOSE \"HOME\" MISROUTE ======\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzoNj46PIXDA",
        "outputId": "c35c9d7c-adb7-490e-8e51-25bed68ab680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CONFIRM] Golden Rules active | Cell=DIAG-HOME | Version=2025.11.10 | Encoding=ISO-8859-15\n",
            "DECLARED_LINES=260\n",
            "[INFO] Connecting FTPS ftp.one-name.net:21\n",
            "[INFO] AUTH TLS\n",
            "[INFO] Login admin@yates.one-name.net\n",
            "[INFO] Protocol: FTPS | Passive=True | CWD=/ | SYST=215 UNIX Type: L8\n",
            "\n",
            "[CHECK] /thebuttons.htm\n",
            "\n",
            "--- /thebuttons.htm: DNA register hardlink ---\n",
            "0017: <!-- ====== SIMPLE LINK BLOCK ====== -->\n",
            "0018: <div class=\"sortbar\" style=\"margin:6px 0 10px 0; font-family:'Times New Roman',Georgia,serif; font-size:13px;\">\n",
            "0019:   <a class=\"btn\" href=\"https://yates.one-name.net/partials/ons_yates_dna_register.htm\"\n",
            "0020:      target=\"_blank\" rel=\"noopener\"\n",
            "0021:      style=\"display:inline-block; border:1px solid #5b79b8; background:#5b79b8; color:#fff; padding:4px 9px; text-decoration:none; border-radius:5px; margin-right:6px;\">\n",
            "\n",
            "--- /thebuttons.htm: <base href> tag ---\n",
            "  (no matches)\n",
            "\n",
            "--- /thebuttons.htm: META refresh ---\n",
            "  (no matches)\n",
            "\n",
            "--- /thebuttons.htm: JS redirect ---\n",
            "  (no matches)\n",
            "\n",
            "--- /thebuttons.htm: Home to \"/\" ---\n",
            "  (no matches)\n",
            "\n",
            "--- /thebuttons.htm: Home to \"/index.htm\" ---\n",
            "  (no matches)\n",
            "\n",
            "[CHECK] /index.htm\n",
            "\n",
            "--- /index.htm: DNA register hardlink ---\n",
            "  (no matches)\n",
            "\n",
            "--- /index.htm: <base href> tag ---\n",
            "  (no matches)\n",
            "\n",
            "--- /index.htm: META refresh ---\n",
            "  (no matches)\n",
            "\n",
            "--- /index.htm: JS redirect ---\n",
            "  (no matches)\n",
            "\n",
            "--- /index.htm: Home to \"/\" ---\n",
            "  (no matches)\n",
            "\n",
            "--- /index.htm: Home to \"/index.htm\" ---\n",
            "  (no matches)\n",
            "\n",
            "[CHECK] /index.html\n",
            "\n",
            "--- /index.html: DNA register hardlink ---\n",
            "0004: <meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
            "0005: <title>Home &#8594; ONS Yates DNA Register</title>\n",
            "0006: <meta http-equiv=\"refresh\" content=\"0; url=./ons_yates_dna_register.htm\" />\n",
            "0007: <style type=\"text/css\">body{font-family:'Times New Roman',Georgia,serif;margin:40px;}</style>\n",
            "0008: </head>\n",
            "0008: </head>\n",
            "0009: <body>\n",
            "0010: <p>If you are not redirected, <a href=\"./ons_yates_dna_register.htm\">click here</a>.</p>\n",
            "0011: <script type=\"text/javascript\">\n",
            "0012: //<![CDATA[\n",
            "0011: <script type=\"text/javascript\">\n",
            "0012: //<![CDATA[\n",
            "0013: try{ window.location.replace(\"./ons_yates_dna_register.htm\"); }catch(e){ window.location.href=\"./ons_yates_dna_register.htm\"; }\n",
            "0014: //]]>\n",
            "0015: </script>\n",
            "0011: <script type=\"text/javascript\">\n",
            "0012: //<![CDATA[\n",
            "0013: try{ window.location.replace(\"./ons_yates_dna_register.htm\"); }catch(e){ window.location.href=\"./ons_yates_dna_register.htm\"; }\n",
            "0014: //]]>\n",
            "0015: </script>\n",
            "\n",
            "--- /index.html: <base href> tag ---\n",
            "  (no matches)\n",
            "\n",
            "--- /index.html: META refresh ---\n",
            "0004: <meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
            "0005: <title>Home &#8594; ONS Yates DNA Register</title>\n",
            "0006: <meta http-equiv=\"refresh\" content=\"0; url=./ons_yates_dna_register.htm\" />\n",
            "0007: <style type=\"text/css\">body{font-family:'Times New Roman',Georgia,serif;margin:40px;}</style>\n",
            "0008: </head>\n",
            "\n",
            "--- /index.html: JS redirect ---\n",
            "0011: <script type=\"text/javascript\">\n",
            "0012: //<![CDATA[\n",
            "0013: try{ window.location.replace(\"./ons_yates_dna_register.htm\"); }catch(e){ window.location.href=\"./ons_yates_dna_register.htm\"; }\n",
            "0014: //]]>\n",
            "0015: </script>\n",
            "0011: <script type=\"text/javascript\">\n",
            "0012: //<![CDATA[\n",
            "0013: try{ window.location.replace(\"./ons_yates_dna_register.htm\"); }catch(e){ window.location.href=\"./ons_yates_dna_register.htm\"; }\n",
            "0014: //]]>\n",
            "0015: </script>\n",
            "\n",
            "--- /index.html: Home to \"/\" ---\n",
            "  (no matches)\n",
            "\n",
            "--- /index.html: Home to \"/index.htm\" ---\n",
            "  (no matches)\n",
            "\n",
            "[CHECK] /.htaccess\n",
            "\n",
            "--- /.htaccess: DNA register hardlink ---\n",
            "  (no matches)\n",
            "\n",
            "--- /.htaccess: <base href> tag ---\n",
            "  (no matches)\n",
            "\n",
            "--- /.htaccess: META refresh ---\n",
            "  (no matches)\n",
            "\n",
            "--- /.htaccess: JS redirect ---\n",
            "  (no matches)\n",
            "\n",
            "--- /.htaccess: Home to \"/\" ---\n",
            "  (no matches)\n",
            "\n",
            "--- /.htaccess: Home to \"/index.htm\" ---\n",
            "  (no matches)\n",
            "\n",
            "[RESULT] Found 8 match(es). We can fix just the culprit file(s) surgically, no bulk edits.\n",
            "[DONE] Read-only diagnosis complete. Share the snippets above to proceed with a one-file fix.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] CELL A++ — Server Access Audit (Read-Only; uses Ron's secrets getter) ======\n",
        "# RON GOLDEN RULES — CLIFF NOTES (v2025.11.09)\n",
        "# • Single contiguous, runnable Colab cell; ASCII-only source.\n",
        "# • All prints encoded ISO-8859-15 with xmlcharrefreplace; deterministic audits.\n",
        "# • XHTML 1.0 Transitional mindset; no inline font families.\n",
        "# • Print: [CONFIRM] Golden Rules active | Cell=A++ | Version=2025.11.09 | Encoding=ISO-8859-15\n",
        "# • Declare and print DECLARED_LINES=350 at run start.\n",
        "\n",
        "import os, sys, socket, traceback\n",
        "from ftplib import FTP, FTP_TLS, all_errors\n",
        "\n",
        "DECLARED_LINES = 350\n",
        "\n",
        "def _enc(s):\n",
        "    try:\n",
        "        return str(s).encode(\"iso-8859-15\",\"xmlcharrefreplace\").decode(\"iso-8859-15\")\n",
        "    except Exception:\n",
        "        return str(s)\n",
        "\n",
        "print(_enc(\"[CONFIRM] Golden Rules active | Cell=A++ | Version=2025.11.09 | Encoding=ISO-8859-15\"))\n",
        "print(_enc(f\"DECLARED_LINES={DECLARED_LINES}\"))\n",
        "\n",
        "# ---------- Secrets (env or userdata) ----------\n",
        "def _get_env(k, default=\"\"):\n",
        "    try:\n",
        "        from google.colab import userdata  # type: ignore\n",
        "        v = userdata.get(k)\n",
        "        return v if v is not None else os.environ.get(k, default)\n",
        "    except Exception:\n",
        "        return os.environ.get(k, default)\n",
        "\n",
        "FTP_HOST = (_get_env(\"FTP_HOST\",\"\") or \"\").strip()\n",
        "FTP_USER = (_get_env(\"FTP_USER\",\"\") or \"\").strip()\n",
        "FTP_PASS = _get_env(\"FTP_PASS\",\"\") or \"\"\n",
        "FTP_PORT = int(_get_env(\"FTP_PORT\",\"21\") or \"21\")\n",
        "FTP_DIR  = (_get_env(\"FTP_DIR\",\"\") or \"\").strip().strip(\"/\")\n",
        "PASSIVE_MODE = True  # from your snippet; set False if you need active mode\n",
        "USE_TLS_FIRST = True # try FTPS (AUTH TLS) first; fallback to plain FTP if it fails\n",
        "\n",
        "def banner(msg):\n",
        "    print(_enc(\"\\n\" + \"=\"*72))\n",
        "    print(_enc(msg))\n",
        "    print(_enc(\"=\"*72))\n",
        "\n",
        "def info(msg): print(_enc(\"[INFO] \" + msg))\n",
        "def warn(msg): print(_enc(\"[WARN] \" + msg))\n",
        "def err(msg):  print(_enc(\"[ERROR] \" + msg))\n",
        "\n",
        "if not FTP_HOST or not FTP_USER or FTP_PASS is None:\n",
        "    err(\"Missing one or more of FTP_HOST / FTP_USER / FTP_PASS.\")\n",
        "    raise SystemExit(1)\n",
        "\n",
        "session = None\n",
        "is_tls = False\n",
        "login_cwd = None\n",
        "system_type = \"UNKNOWN\"\n",
        "\n",
        "def _connect_try_ftps_then_ftp():\n",
        "    # Returns (session, is_tls)\n",
        "    last_exc = None\n",
        "    # 1) Try FTPS\n",
        "    if USE_TLS_FIRST:\n",
        "        try:\n",
        "            s = FTP_TLS()\n",
        "            s.encoding = \"utf-8\"\n",
        "            s.timeout = 30\n",
        "            info(f\"Connecting FTPS to {FTP_HOST}:{FTP_PORT} ...\")\n",
        "            s.connect(FTP_HOST, FTP_PORT)\n",
        "            info(\"AUTH TLS...\")\n",
        "            s.auth()\n",
        "            info(f\"Logging in as {FTP_USER} ...\")\n",
        "            s.login(FTP_USER, FTP_PASS)\n",
        "            s.set_pasv(PASSIVE_MODE)\n",
        "            info(\"Securing data connection (PROT P)...\")\n",
        "            s.prot_p()\n",
        "            return s, True\n",
        "        except Exception as e:\n",
        "            last_exc = e\n",
        "            warn(f\"FTPS attempt failed: {e.__class__.__name__}: {e}\")\n",
        "    # 2) Fallback to plain FTP\n",
        "    try:\n",
        "        s = FTP()\n",
        "        s.encoding = \"utf-8\"\n",
        "        s.timeout = 30\n",
        "        info(f\"Connecting FTP to {FTP_HOST}:{FTP_PORT} ...\")\n",
        "        s.connect(FTP_HOST, FTP_PORT)\n",
        "        info(f\"Logging in as {FTP_USER} ...\")\n",
        "        s.login(FTP_USER, FTP_PASS)\n",
        "        s.set_pasv(PASSIVE_MODE)\n",
        "        return s, False\n",
        "    except Exception as e:\n",
        "        if last_exc:\n",
        "            err(f\"Both FTPS and FTP failed. FTPS error was: {last_exc.__class__.__name__}: {last_exc}\")\n",
        "        raise\n",
        "\n",
        "try:\n",
        "    banner(\"1) CONNECT + LOGIN\")\n",
        "    session, is_tls = _connect_try_ftps_then_ftp()\n",
        "    try:\n",
        "        system_type = session.sendcmd(\"SYST\")\n",
        "    except all_errors as e:\n",
        "        warn(f\"SYST not available: {e.__class__.__name__}: {e}\")\n",
        "    try:\n",
        "        login_cwd = session.pwd()\n",
        "    except all_errors as e:\n",
        "        login_cwd = \"<unknown>\"\n",
        "        warn(f\"PWD failed: {e.__class__.__name__}: {e}\")\n",
        "    info(f\"Protocol: {'FTPS' if is_tls else 'FTP'} | Passive={PASSIVE_MODE}\")\n",
        "    info(f\"SYST: {system_type}\")\n",
        "    info(f\"Login CWD: {login_cwd}\")\n",
        "except Exception as e:\n",
        "    err(f\"Login failure: {e.__class__.__name__}: {e}\")\n",
        "    traceback.print_exc()\n",
        "    raise\n",
        "\n",
        "def list_path(sess, path):\n",
        "    \"\"\"Return (ok, rows, method) where rows are (name, type, size) tuples. Read-only.\"\"\"\n",
        "    # Try MLSD if available\n",
        "    try:\n",
        "        rows = []\n",
        "        used = \"\"\n",
        "        try:\n",
        "            # Some servers expose mlsd(); some only via retrlines. Try mlsd() first.\n",
        "            items = list(sess.mlsd(path))\n",
        "            used = \"mlsd()\"\n",
        "            for name, facts in items:\n",
        "                typ = facts.get(\"type\",\"file\")\n",
        "                size = facts.get(\"size\",\"?\")\n",
        "                rows.append((name, typ, size))\n",
        "            return True, rows, used\n",
        "        except all_errors:\n",
        "            pass\n",
        "        # Try MLSD via retrlines\n",
        "        try:\n",
        "            buf = []\n",
        "            sess.retrlines(f\"MLSD {path}\", buf.append)\n",
        "            used = \"MLSD(retrlines)\"\n",
        "            for line in buf:\n",
        "                # Facts;type=dir;perm=...;size=...; modify=...; filename\n",
        "                parts = line.split(\";\")\n",
        "                name = parts[-1].strip()\n",
        "                low = line.lower()\n",
        "                typ = \"dir\" if \"type=dir\" in low else (\"file\" if \"type=file\" in low else \"?\")\n",
        "                size = \"?\"\n",
        "                rows.append((name, typ, size))\n",
        "            return True, rows, used\n",
        "        except all_errors:\n",
        "            pass\n",
        "    except all_errors:\n",
        "        pass\n",
        "    # Fallback: NLST + SIZE probe\n",
        "    try:\n",
        "        names = sess.nlst(path)\n",
        "        used = \"NLST\"\n",
        "        out = []\n",
        "        for n in names:\n",
        "            base = n.rstrip(\"/\").split(\"/\")[-1]\n",
        "            ftype = \"?\"\n",
        "            fsize = \"?\"\n",
        "            try:\n",
        "                fsize = sess.size(n)\n",
        "                ftype = \"file\"\n",
        "            except all_errors:\n",
        "                ftype = \"dir\"\n",
        "            out.append((base, ftype, fsize if fsize is not None else \"?\"))\n",
        "        return True, out, used\n",
        "    except all_errors as e:\n",
        "        return False, [(f\"<unlisted: {e.__class__.__name__}: {e}\", \"?\", \"?\")], \"NONE\"\n",
        "\n",
        "def show_listing(sess, label, path):\n",
        "    banner(f\"2) LISTING: {label} -> {path if path else '.'}\")\n",
        "    ok, rows, used = list_path(sess, path if path else \".\")\n",
        "    info(f\"Method: {used} | OK={ok}\")\n",
        "    for (name, typ, size) in rows[:200]:\n",
        "        print(_enc(f\"  - {name}    [{typ}]    size={size}\"))\n",
        "    if not ok:\n",
        "        warn(\"Listing failed for this path.\")\n",
        "\n",
        "# Candidate read-only probes\n",
        "CANDIDATES = [\n",
        "    \".\", \"/\",\n",
        "    \"partials\", \"/partials\",\n",
        "    \"public_html\", \"/public_html\",\n",
        "    \"public_html/partials\", \"/public_html/partials\",\n",
        "    \"www\", \"/www\", \"www/partials\", \"/www/partials\",\n",
        "    \"root\", \"/root\", \"root/partials\", \"/root/partials\"\n",
        "]\n",
        "\n",
        "banner(\"2) DIRECTORY PROBE (READ-ONLY)\")\n",
        "# 2a) Show login CWD\n",
        "try:\n",
        "    show_listing(session, \"LOGIN_CWD\", login_cwd or \".\")\n",
        "except Exception as e:\n",
        "    warn(f\"Could not list LOGIN_CWD: {e}\")\n",
        "\n",
        "# 2b) Show FTP_DIR if provided\n",
        "if FTP_DIR:\n",
        "    try:\n",
        "        show_listing(session, \"FTP_DIR\", FTP_DIR)\n",
        "    except Exception as e:\n",
        "        warn(f\"Could not list FTP_DIR '{FTP_DIR}': {e}\")\n",
        "\n",
        "# 2c) Common absolute/relative locations\n",
        "for path in CANDIDATES:\n",
        "    try:\n",
        "        show_listing(session, path, path)\n",
        "    except Exception as e:\n",
        "        warn(f\"Error while listing {path}: {e}\")\n",
        "\n",
        "banner(\"3) PATH MAP SUMMARY\")\n",
        "print(_enc(\n",
        "    \"If only the three Gold Cell outputs are visible, likely causes:\\n\"\n",
        "    \"- Login home (chroot) changed; parent dirs now blocked.\\n\"\n",
        "    \"- Exporter narrowed to /partials only, hiding other outputs.\\n\"\n",
        "    \"- Mis-typed prefix (e.g., 'root/partials') causing 550 errors.\\n\\n\"\n",
        "    \"NEXT STEPS:\\n\"\n",
        "    \"• Identify which path actually contains your historical directories.\\n\"\n",
        "    \"• Update your Cell 4 exporter to target absolute paths valid from the login CWD.\\n\"\n",
        "    \"• Avoid cwd('..') outside the login chroot; many hosts block it.\\n\"\n",
        "    \"• Honor PASSIVE_MODE=True on hosts that require it.\"\n",
        "))\n",
        "\n",
        "try:\n",
        "    session.quit()\n",
        "except Exception:\n",
        "    try:\n",
        "        session.close()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "print(_enc(\"\\n[RESULT] Access audit complete (read-only). Share this output so we can fix the exporter.\"))\n",
        "# ====== CUT STOP  [1/1] CELL A++ — Server Access Audit (Read-Only) ======\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bxxyt6O27VYw",
        "outputId": "d153f11f-e2bb-42fa-d260-59c12dad8cd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CONFIRM] Golden Rules active | Cell=A++ | Version=2025.11.09 | Encoding=ISO-8859-15\n",
            "DECLARED_LINES=350\n",
            "\n",
            "========================================================================\n",
            "1) CONNECT + LOGIN\n",
            "========================================================================\n",
            "[INFO] Connecting FTPS to ftp.one-name.net:21 ...\n",
            "[INFO] AUTH TLS...\n",
            "[INFO] Logging in as admin@yates.one-name.net ...\n",
            "[INFO] Securing data connection (PROT P)...\n",
            "[INFO] Protocol: FTPS | Passive=True\n",
            "[INFO] SYST: 215 UNIX Type: L8\n",
            "[INFO] Login CWD: /\n",
            "\n",
            "========================================================================\n",
            "2) DIRECTORY PROBE (READ-ONLY)\n",
            "========================================================================\n",
            "\n",
            "========================================================================\n",
            "2) LISTING: LOGIN_CWD -> /\n",
            "========================================================================\n",
            "[INFO] Method: mlsd() | OK=True\n",
            "  - the_match_cousins.csv    [file]    size=2130\n",
            "  - content-yatesdb    [dir]    size=?\n",
            "  - military    [dir]    size=?\n",
            "  - index-page2.htm    [file]    size=10626\n",
            "  - tng-tree-gedcoms    [dir]    size=?\n",
            "  - imagealbums    [dir]    size=?\n",
            "  - partials    [dir]    size=?\n",
            "  - thebuttons.htm    [file]    size=1398\n",
            "  - .htaccess    [file]    size=514\n",
            "  - history    [dir]    size=?\n",
            "  - cgi-bin    [dir]    size=?\n",
            "  - resolver_usage_report.csv    [file]    size=1995\n",
            "  - events    [dir]    size=?\n",
            "  - country    [dir]    size=?\n",
            "  - litart    [dir]    size=?\n",
            "  - .    [cdir]    size=?\n",
            "  - people    [dir]    size=?\n",
            "  - lineage_count_report.csv    [file]    size=114\n",
            "  - old_school_htm    [dir]    size=?\n",
            "  - gengen    [dir]    size=?\n",
            "  - blog    [dir]    size=?\n",
            "  - ons_yates_dna_register.htm    [file]    size=21385\n",
            "  - ..    [pdir]    size=?\n",
            "  - sorttable.js    [file]    size=16877\n",
            "  - admin    [dir]    size=?\n",
            "  - yates_ancestor_register.htm    [file]    size=46115\n",
            "  - .ftpquota    [file]    size=19\n",
            "  - public_html    [dir]    size=?\n",
            "  - index.htm    [file]    size=20244\n",
            "  - sitemap    [dir]    size=?\n",
            "  - .well-known    [dir]    size=?\n",
            "  - places    [dir]    size=?\n",
            "  - documents    [dir]    size=?\n",
            "  - tng    [dir]    size=?\n",
            "  - contribute.htm    [file]    size=8620\n",
            "  - autosomal_count.txt    [file]    size=4\n",
            "  - index.html    [file]    size=788\n",
            "  - styles_connect.css    [file]    size=5354\n",
            "  - images    [dir]    size=?\n",
            "\n",
            "========================================================================\n",
            "2) LISTING: . -> .\n",
            "========================================================================\n",
            "[INFO] Method: mlsd() | OK=True\n",
            "  - the_match_cousins.csv    [file]    size=2130\n",
            "  - content-yatesdb    [dir]    size=?\n",
            "  - military    [dir]    size=?\n",
            "  - index-page2.htm    [file]    size=10626\n",
            "  - tng-tree-gedcoms    [dir]    size=?\n",
            "  - imagealbums    [dir]    size=?\n",
            "  - partials    [dir]    size=?\n",
            "  - thebuttons.htm    [file]    size=1398\n",
            "  - .htaccess    [file]    size=514\n",
            "  - history    [dir]    size=?\n",
            "  - cgi-bin    [dir]    size=?\n",
            "  - resolver_usage_report.csv    [file]    size=1995\n",
            "  - events    [dir]    size=?\n",
            "  - country    [dir]    size=?\n",
            "  - litart    [dir]    size=?\n",
            "  - .    [cdir]    size=?\n",
            "  - people    [dir]    size=?\n",
            "  - lineage_count_report.csv    [file]    size=114\n",
            "  - old_school_htm    [dir]    size=?\n",
            "  - gengen    [dir]    size=?\n",
            "  - blog    [dir]    size=?\n",
            "  - ons_yates_dna_register.htm    [file]    size=21385\n",
            "  - ..    [pdir]    size=?\n",
            "  - sorttable.js    [file]    size=16877\n",
            "  - admin    [dir]    size=?\n",
            "  - yates_ancestor_register.htm    [file]    size=46115\n",
            "  - .ftpquota    [file]    size=19\n",
            "  - public_html    [dir]    size=?\n",
            "  - index.htm    [file]    size=20244\n",
            "  - sitemap    [dir]    size=?\n",
            "  - .well-known    [dir]    size=?\n",
            "  - places    [dir]    size=?\n",
            "  - documents    [dir]    size=?\n",
            "  - tng    [dir]    size=?\n",
            "  - contribute.htm    [file]    size=8620\n",
            "  - autosomal_count.txt    [file]    size=4\n",
            "  - index.html    [file]    size=788\n",
            "  - styles_connect.css    [file]    size=5354\n",
            "  - images    [dir]    size=?\n",
            "\n",
            "========================================================================\n",
            "2) LISTING: / -> /\n",
            "========================================================================\n",
            "[INFO] Method: mlsd() | OK=True\n",
            "  - the_match_cousins.csv    [file]    size=2130\n",
            "  - content-yatesdb    [dir]    size=?\n",
            "  - military    [dir]    size=?\n",
            "  - index-page2.htm    [file]    size=10626\n",
            "  - tng-tree-gedcoms    [dir]    size=?\n",
            "  - imagealbums    [dir]    size=?\n",
            "  - partials    [dir]    size=?\n",
            "  - thebuttons.htm    [file]    size=1398\n",
            "  - .htaccess    [file]    size=514\n",
            "  - history    [dir]    size=?\n",
            "  - cgi-bin    [dir]    size=?\n",
            "  - resolver_usage_report.csv    [file]    size=1995\n",
            "  - events    [dir]    size=?\n",
            "  - country    [dir]    size=?\n",
            "  - litart    [dir]    size=?\n",
            "  - .    [cdir]    size=?\n",
            "  - people    [dir]    size=?\n",
            "  - lineage_count_report.csv    [file]    size=114\n",
            "  - old_school_htm    [dir]    size=?\n",
            "  - gengen    [dir]    size=?\n",
            "  - blog    [dir]    size=?\n",
            "  - ons_yates_dna_register.htm    [file]    size=21385\n",
            "  - ..    [pdir]    size=?\n",
            "  - sorttable.js    [file]    size=16877\n",
            "  - admin    [dir]    size=?\n",
            "  - yates_ancestor_register.htm    [file]    size=46115\n",
            "  - .ftpquota    [file]    size=19\n",
            "  - public_html    [dir]    size=?\n",
            "  - index.htm    [file]    size=20244\n",
            "  - sitemap    [dir]    size=?\n",
            "  - .well-known    [dir]    size=?\n",
            "  - places    [dir]    size=?\n",
            "  - documents    [dir]    size=?\n",
            "  - tng    [dir]    size=?\n",
            "  - contribute.htm    [file]    size=8620\n",
            "  - autosomal_count.txt    [file]    size=4\n",
            "  - index.html    [file]    size=788\n",
            "  - styles_connect.css    [file]    size=5354\n",
            "  - images    [dir]    size=?\n",
            "\n",
            "========================================================================\n",
            "2) LISTING: partials -> partials\n",
            "========================================================================\n",
            "[INFO] Method: mlsd() | OK=True\n",
            "  - ons_yates_dna_register.xlsx    [file]    size=6118\n",
            "  - demo_names_map.json    [file]    size=276\n",
            "  - cell1_work_table.htm    [file]    size=5262\n",
            "  - lineage_count.htm    [file]    size=6840\n",
            "  - yates_nav.css    [file]    size=939\n",
            "  - yates_ancestor_register.htm.202511081953.bak    [file]    size=22663\n",
            "  - justdna.htm.202511081941.bak    [file]    size=20935\n",
            "  - register_column_fix.js    [file]    size=1228\n",
            "  - work_plus.htm    [file]    size=18969\n",
            "  - ons_yates_dna_register.htm.202511081953.bak    [file]    size=22663\n",
            "  - justdna.htm.202511082033.bak    [file]    size=23995\n",
            "  - yates_menu_demo.htm    [file]    size=1391\n",
            "  - justdna.htm.202511082024.bak    [file]    size=23941\n",
            "  - ons_yates_dna_register.csv    [file]    size=2705\n",
            "  - just-trees.htm    [file]    size=12008\n",
            "  - yates_ancestor_register.htm.202511082029.bak    [file]    size=23943\n",
            "  - .    [cdir]    size=?\n",
            "  - ons_yates_dna_register.htm.202511082031.bak    [file]    size=23993\n",
            "  - cousin_list_demo.htm    [file]    size=2280\n",
            "  - ons_yates_dna_register.htm    [file]    size=18969\n",
            "  - ..    [pdir]    size=?\n",
            "  - match_to_unmasked.csv    [file]    size=1900\n",
            "  - yates_ancestor_register.htm    [file]    size=18969\n",
            "  - yates_ancestor_register.htm.202511082024.bak    [file]    size=23941\n",
            "  - yates_ancestor_register.htm.202511081941.bak    [file]    size=20935\n",
            "  - dna_tree_styles.css    [file]    size=4943\n",
            "  - ui_controls_demo.js    [file]    size=1953\n",
            "  - cousin_list_print.htm    [file]    size=3164\n",
            "  - ons_yates_dna_register.htm.202511081941.bak    [file]    size=20935\n",
            "  - ons_yates_dna_register.htm.202511082029.bak    [file]    size=23943\n",
            "  - yates_ancestor_register.csv    [file]    size=2406\n",
            "  - yates_nav_demo.htm    [file]    size=1301\n",
            "  - justdna.htm.202511082029.bak    [file]    size=23943\n",
            "  - justdna.htm.202511082031.bak    [file]    size=23993\n",
            "  - yates_ancestor_register_plus.csv    [file]    size=520790\n",
            "  - ons_yates_dna_register.htm.202511082033.bak    [file]    size=23995\n",
            "  - final_combined_df_with_value_labels.csv    [file]    size=2424\n",
            "  - justdna.htm.202511082023.bak    [file]    size=22665\n",
            "  - yates_ancestor_register_plus.xlsx    [file]    size=88856\n",
            "  - controls_multiselect_manifest.json    [file]    size=581\n",
            "  - controls_multiselect_demo.htm    [file]    size=1693\n",
            "  - justdna.htm    [file]    size=18969\n",
            "  - yates_ancestor_register.htm.202511082031.bak    [file]    size=23993\n",
            "  - yates_ancestor_register.htm.202511082023.bak    [file]    size=22665\n",
            "  - yates_ancestor_register.xlsx    [file]    size=6412\n",
            "  - ons_yates_dna_register.htm.202511082023.bak    [file]    size=22665\n",
            "  - ons_yates_dna_register.htm.202511082024.bak    [file]    size=23941\n",
            "  - yates_menu.css    [file]    size=1182\n",
            "  - match_count.htm    [file]    size=6670\n",
            "  - yates_ancestor_register.htm.202511082033.bak    [file]    size=23995\n",
            "  - autosomal_count.txt    [file]    size=4\n",
            "  - justdna.htm.202511081953.bak    [file]    size=22663\n",
            "  - yates_ancestor_register_plus.htm    [file]    size=1343103\n",
            "\n",
            "========================================================================\n",
            "2) LISTING: /partials -> /partials\n",
            "========================================================================\n",
            "[INFO] Method: mlsd() | OK=True\n",
            "  - ons_yates_dna_register.xlsx    [file]    size=6118\n",
            "  - demo_names_map.json    [file]    size=276\n",
            "  - cell1_work_table.htm    [file]    size=5262\n",
            "  - lineage_count.htm    [file]    size=6840\n",
            "  - yates_nav.css    [file]    size=939\n",
            "  - yates_ancestor_register.htm.202511081953.bak    [file]    size=22663\n",
            "  - justdna.htm.202511081941.bak    [file]    size=20935\n",
            "  - register_column_fix.js    [file]    size=1228\n",
            "  - work_plus.htm    [file]    size=18969\n",
            "  - ons_yates_dna_register.htm.202511081953.bak    [file]    size=22663\n",
            "  - justdna.htm.202511082033.bak    [file]    size=23995\n",
            "  - yates_menu_demo.htm    [file]    size=1391\n",
            "  - justdna.htm.202511082024.bak    [file]    size=23941\n",
            "  - ons_yates_dna_register.csv    [file]    size=2705\n",
            "  - just-trees.htm    [file]    size=12008\n",
            "  - yates_ancestor_register.htm.202511082029.bak    [file]    size=23943\n",
            "  - .    [cdir]    size=?\n",
            "  - ons_yates_dna_register.htm.202511082031.bak    [file]    size=23993\n",
            "  - cousin_list_demo.htm    [file]    size=2280\n",
            "  - ons_yates_dna_register.htm    [file]    size=18969\n",
            "  - ..    [pdir]    size=?\n",
            "  - match_to_unmasked.csv    [file]    size=1900\n",
            "  - yates_ancestor_register.htm    [file]    size=18969\n",
            "  - yates_ancestor_register.htm.202511082024.bak    [file]    size=23941\n",
            "  - yates_ancestor_register.htm.202511081941.bak    [file]    size=20935\n",
            "  - dna_tree_styles.css    [file]    size=4943\n",
            "  - ui_controls_demo.js    [file]    size=1953\n",
            "  - cousin_list_print.htm    [file]    size=3164\n",
            "  - ons_yates_dna_register.htm.202511081941.bak    [file]    size=20935\n",
            "  - ons_yates_dna_register.htm.202511082029.bak    [file]    size=23943\n",
            "  - yates_ancestor_register.csv    [file]    size=2406\n",
            "  - yates_nav_demo.htm    [file]    size=1301\n",
            "  - justdna.htm.202511082029.bak    [file]    size=23943\n",
            "  - justdna.htm.202511082031.bak    [file]    size=23993\n",
            "  - yates_ancestor_register_plus.csv    [file]    size=520790\n",
            "  - ons_yates_dna_register.htm.202511082033.bak    [file]    size=23995\n",
            "  - final_combined_df_with_value_labels.csv    [file]    size=2424\n",
            "  - justdna.htm.202511082023.bak    [file]    size=22665\n",
            "  - yates_ancestor_register_plus.xlsx    [file]    size=88856\n",
            "  - controls_multiselect_manifest.json    [file]    size=581\n",
            "  - controls_multiselect_demo.htm    [file]    size=1693\n",
            "  - justdna.htm    [file]    size=18969\n",
            "  - yates_ancestor_register.htm.202511082031.bak    [file]    size=23993\n",
            "  - yates_ancestor_register.htm.202511082023.bak    [file]    size=22665\n",
            "  - yates_ancestor_register.xlsx    [file]    size=6412\n",
            "  - ons_yates_dna_register.htm.202511082023.bak    [file]    size=22665\n",
            "  - ons_yates_dna_register.htm.202511082024.bak    [file]    size=23941\n",
            "  - yates_menu.css    [file]    size=1182\n",
            "  - match_count.htm    [file]    size=6670\n",
            "  - yates_ancestor_register.htm.202511082033.bak    [file]    size=23995\n",
            "  - autosomal_count.txt    [file]    size=4\n",
            "  - justdna.htm.202511081953.bak    [file]    size=22663\n",
            "  - yates_ancestor_register_plus.htm    [file]    size=1343103\n",
            "\n",
            "========================================================================\n",
            "2) LISTING: public_html -> public_html\n",
            "========================================================================\n",
            "[INFO] Method: mlsd() | OK=True\n",
            "  - .    [cdir]    size=?\n",
            "  - ..    [pdir]    size=?\n",
            "  - public_html    [dir]    size=?\n",
            "\n",
            "========================================================================\n",
            "2) LISTING: /public_html -> /public_html\n",
            "========================================================================\n",
            "[INFO] Method: mlsd() | OK=True\n",
            "  - .    [cdir]    size=?\n",
            "  - ..    [pdir]    size=?\n",
            "  - public_html    [dir]    size=?\n",
            "\n",
            "========================================================================\n",
            "2) LISTING: public_html/partials -> public_html/partials\n",
            "========================================================================\n",
            "[INFO] Method: NONE | OK=False\n",
            "  - <unlisted: error_perm: 550 Can't check for file existence    [?]    size=?\n",
            "[WARN] Listing failed for this path.\n",
            "\n",
            "========================================================================\n",
            "2) LISTING: /public_html/partials -> /public_html/partials\n",
            "========================================================================\n",
            "[INFO] Method: NONE | OK=False\n",
            "  - <unlisted: error_perm: 550 Can't check for file existence    [?]    size=?\n",
            "[WARN] Listing failed for this path.\n",
            "\n",
            "========================================================================\n",
            "2) LISTING: www -> www\n",
            "========================================================================\n",
            "[INFO] Method: NONE | OK=False\n",
            "  - <unlisted: error_perm: 550 Can't check for file existence    [?]    size=?\n",
            "[WARN] Listing failed for this path.\n",
            "\n",
            "========================================================================\n",
            "2) LISTING: /www -> /www\n",
            "========================================================================\n",
            "[INFO] Method: NONE | OK=False\n",
            "  - <unlisted: error_perm: 550 Can't check for file existence    [?]    size=?\n",
            "[WARN] Listing failed for this path.\n",
            "\n",
            "========================================================================\n",
            "2) LISTING: www/partials -> www/partials\n",
            "========================================================================\n",
            "[INFO] Method: NONE | OK=False\n",
            "  - <unlisted: error_perm: 550 Can't check for file existence    [?]    size=?\n",
            "[WARN] Listing failed for this path.\n",
            "\n",
            "========================================================================\n",
            "2) LISTING: /www/partials -> /www/partials\n",
            "========================================================================\n",
            "[INFO] Method: NONE | OK=False\n",
            "  - <unlisted: error_perm: 550 Can't check for file existence    [?]    size=?\n",
            "[WARN] Listing failed for this path.\n",
            "\n",
            "========================================================================\n",
            "2) LISTING: root -> root\n",
            "========================================================================\n",
            "[INFO] Method: NONE | OK=False\n",
            "  - <unlisted: error_perm: 550 Can't check for file existence    [?]    size=?\n",
            "[WARN] Listing failed for this path.\n",
            "\n",
            "========================================================================\n",
            "2) LISTING: /root -> /root\n",
            "========================================================================\n",
            "[INFO] Method: NONE | OK=False\n",
            "  - <unlisted: error_perm: 550 Can't check for file existence    [?]    size=?\n",
            "[WARN] Listing failed for this path.\n",
            "\n",
            "========================================================================\n",
            "2) LISTING: root/partials -> root/partials\n",
            "========================================================================\n",
            "[INFO] Method: NONE | OK=False\n",
            "  - <unlisted: error_perm: 550 Can't check for file existence    [?]    size=?\n",
            "[WARN] Listing failed for this path.\n",
            "\n",
            "========================================================================\n",
            "2) LISTING: /root/partials -> /root/partials\n",
            "========================================================================\n",
            "[INFO] Method: NONE | OK=False\n",
            "  - <unlisted: error_perm: 550 Can't check for file existence    [?]    size=?\n",
            "[WARN] Listing failed for this path.\n",
            "\n",
            "========================================================================\n",
            "3) PATH MAP SUMMARY\n",
            "========================================================================\n",
            "If only the three Gold Cell outputs are visible, likely causes:\n",
            "- Login home (chroot) changed; parent dirs now blocked.\n",
            "- Exporter narrowed to /partials only, hiding other outputs.\n",
            "- Mis-typed prefix (e.g., 'root/partials') causing 550 errors.\n",
            "\n",
            "NEXT STEPS:\n",
            "&#8226; Identify which path actually contains your historical directories.\n",
            "&#8226; Update your Cell 4 exporter to target absolute paths valid from the login CWD.\n",
            "&#8226; Avoid cwd('..') outside the login chroot; many hosts block it.\n",
            "&#8226; Honor PASSIVE_MODE=True on hosts that require it.\n",
            "\n",
            "[RESULT] Access audit complete (read-only). Share this output so we can fix the exporter.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] Yates Heritage Nav Demo =========================================\n",
        "# RON GOLDEN RULES — CLIFF NOTES (v2025.11.09)\n",
        "# • Complete & runnable Colab Cell — one contiguous block (no fragments, no cross-refs).\n",
        "# • Source ASCII-only; all writes use encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\".\n",
        "# • XHTML 1.0 Transitional; typography via external CSS.\n",
        "# • Deterministic audit print + declared line count.\n",
        "# =========================================================================================\n",
        "\n",
        "import os, socket, traceback, hashlib\n",
        "from datetime import datetime\n",
        "from ftplib import FTP_TLS, all_errors\n",
        "\n",
        "CELL_NAME=\"Yates_Heritage_Nav_Demo\"\n",
        "VERSION=\"2025.11.09\"\n",
        "print(f\"[CONFIRM] Golden Rules active | Cell={CELL_NAME} | Version={VERSION} | Encoding=ISO-8859-15\")\n",
        "\n",
        "# ---------- ENV / FTPS ----------\n",
        "def _get_env(k, default=\"\"):\n",
        "    try:\n",
        "        from google.colab import userdata  # type: ignore\n",
        "        v = userdata.get(k)\n",
        "        return v if v is not None else os.environ.get(k, default)\n",
        "    except Exception:\n",
        "        return os.environ.get(k, default)\n",
        "\n",
        "FTP_HOST=(_get_env(\"FTP_HOST\",\"\") or \"\").strip()\n",
        "FTP_USER=(_get_env(\"FTP_USER\",\"\") or \"\").strip()\n",
        "FTP_PASS=_get_env(\"FTP_PASS\",\"\") or \"\"\n",
        "FTP_PORT=int(_get_env(\"FTP_PORT\",\"21\") or \"21\")\n",
        "FTP_DIR=(_get_env(\"FTP_DIR\",\"\") or \"\").strip().strip(\"/\")\n",
        "\n",
        "def _ftps_connect():\n",
        "    if not (FTP_HOST and FTP_USER and FTP_PASS):\n",
        "        raise RuntimeError(\"Missing FTP credentials\")\n",
        "    socket.setdefaulttimeout(30)\n",
        "    ftps=FTP_TLS(timeout=30)\n",
        "    ftps.connect(FTP_HOST, FTP_PORT)\n",
        "    ftps.auth(); ftps.login(FTP_USER, FTP_PASS)\n",
        "    try: ftps.prot_p()\n",
        "    except Exception: pass\n",
        "    try: ftps.set_pasv(True)\n",
        "    except Exception: pass\n",
        "    if FTP_DIR:\n",
        "        for p in [p for p in FTP_DIR.split(\"/\") if p]:\n",
        "            try: ftps.cwd(p)\n",
        "            except all_errors:\n",
        "                try: ftps.mkd(p)\n",
        "                except all_errors: pass\n",
        "                ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "def _ftps_upload(ftps, local_path, remote_name=None):\n",
        "    if remote_name is None: remote_name=os.path.basename(local_path)\n",
        "    with open(local_path,\"rb\") as fh: ftps.storbinary(\"STOR \"+remote_name, fh)\n",
        "    print(\"[OK] Uploaded:\",remote_name)\n",
        "\n",
        "def _sha256(path):\n",
        "    h=hashlib.sha256()\n",
        "    with open(path,\"rb\") as f:\n",
        "        for chunk in iter(lambda:f.read(65536),b\"\"): h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "# ---------- CSS ----------\n",
        "CSS_PATH=\"yates_nav.css\"\n",
        "CSS_TEXT=\"\"\"/* ===== YATES HERITAGE NAV BAR ===== */\n",
        "body {\n",
        "  background-color:#faf9d3;\n",
        "  font-family:'Times New Roman',Georgia,serif;\n",
        "  font-size:14px;\n",
        "  color:#000;\n",
        "  margin:0;\n",
        "  padding:0;\n",
        "}\n",
        ".navbar {\n",
        "  background-color:#5b391e;\n",
        "  border:1px solid #fff;\n",
        "  border-radius:4px;\n",
        "  width:fit-content;\n",
        "  margin:12px auto;\n",
        "  box-shadow:0 0 2px rgba(0,0,0,0.4);\n",
        "}\n",
        ".navbar ul {list-style:none;margin:0;padding:0;display:flex;flex-wrap:wrap;}\n",
        ".navbar li {border-right:1px solid #fff;}\n",
        ".navbar li:last-child {border-right:none;}\n",
        ".navbar a {\n",
        "  display:block;\n",
        "  color:#fff;\n",
        "  text-decoration:none;\n",
        "  padding:6px 12px;\n",
        "  font-size:0.95em;\n",
        "  background-color:#5b391e;\n",
        "}\n",
        ".navbar a:hover {\n",
        "  background-color:#808040;\n",
        "  color:#fff;\n",
        "}\n",
        ".page {\n",
        "  width:900px;\n",
        "  margin:0 auto;\n",
        "  background-color:#fff;\n",
        "  border:1px solid #c5b98e;\n",
        "  border-radius:12px;\n",
        "  box-shadow:0 0 4px rgba(0,0,0,0.2);\n",
        "  padding:20px;\n",
        "  text-align:center;\n",
        "}\n",
        "h1 {font-size:1.4em;margin-top:0.5em;}\n",
        "\"\"\"\n",
        "\n",
        "# ---------- HTML ----------\n",
        "HTML_PATH=\"yates_nav_demo.htm\"\n",
        "HTML_TEXT=\"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<title>ONS Yates Study — Heritage Navigation Demo</title>\n",
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"/partials/yates_nav.css\" />\n",
        "</head>\n",
        "<body>\n",
        "<div class=\"navbar\">\n",
        "  <ul>\n",
        "    <li><a href=\"#\">Study Details</a></li>\n",
        "    <li><a href=\"#\">Theory in Action</a></li>\n",
        "    <li><a href=\"#\">Sort Match ↑</a></li>\n",
        "    <li><a href=\"#\">Sort Match ↓</a></li>\n",
        "    <li><a href=\"#\">Sort Lineage ↑</a></li>\n",
        "    <li><a href=\"#\">Sort Lineage ↓</a></li>\n",
        "    <li><a href=\"#\">Cousin Connection</a></li>\n",
        "    <li><a href=\"#\">Cousin by DNA</a></li>\n",
        "    <li><a href=\"#\">Match Count</a></li>\n",
        "    <li><a href=\"#\">Lineage Count</a></li>\n",
        "    <li><a href=\"#\">Cousin List</a></li>\n",
        "    <li><a href=\"#\">Email Selected</a></li>\n",
        "    <li><a href=\"#\">Clear</a></li>\n",
        "  </ul>\n",
        "</div>\n",
        "\n",
        "<div class=\"page\">\n",
        "  <h1>ONS Yates Study Autosomal DNA Register</h1>\n",
        "  <p>Navigation rewritten using heritage-style menu — no JS or button elements.</p>\n",
        "  <p>Hover to test rollover color, consistent with classic Yates brown palette.</p>\n",
        "</div>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# ---------- Write locally ----------\n",
        "for path,text in [(CSS_PATH,CSS_TEXT),(HTML_PATH,HTML_TEXT)]:\n",
        "    with open(path,\"w\",encoding=\"iso-8859-15\",errors=\"xmlcharrefreplace\") as f:f.write(text)\n",
        "\n",
        "# ---------- Upload ----------\n",
        "if FTP_HOST and FTP_USER and FTP_PASS:\n",
        "    try:\n",
        "        ftps=_ftps_connect()\n",
        "        try: ftps.cwd(\"partials\")\n",
        "        except all_errors:\n",
        "            try: ftps.mkd(\"partials\"); ftps.cwd(\"partials\")\n",
        "            except all_errors: pass\n",
        "        _ftps_upload(ftps,CSS_PATH)\n",
        "        _ftps_upload(ftps,HTML_PATH)\n",
        "        ftps.quit()\n",
        "        print(\"[OK] Upload complete → /partials/\")\n",
        "        print(\"[OPEN] Visit /partials/yates_nav_demo.htm\")\n",
        "    except Exception as e:\n",
        "        print(\"[ERROR] FTP session failed:\",e)\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"[INFO] Skipping FTP upload (missing creds).\")\n",
        "\n",
        "# ---------- Audit ----------\n",
        "DECLARED_LINES=len(CSS_TEXT.splitlines())+len(HTML_TEXT.splitlines())\n",
        "print(f\"[AUDIT] DECLARED_LINES={DECLARED_LINES}\")\n",
        "# ====== CUT STOP [1/1] Yates Heritage Nav Demo =========================================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZ9hWweUjIvJ",
        "outputId": "184bf8a5-b851-4c9a-a6c4-dd6dcca84a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CONFIRM] Golden Rules active | Cell=Yates_Heritage_Nav_Demo | Version=2025.11.09 | Encoding=ISO-8859-15\n",
            "[OK] Uploaded: yates_nav.css\n",
            "[OK] Uploaded: yates_nav_demo.htm\n",
            "[OK] Upload complete → /partials/\n",
            "[OPEN] Visit /partials/yates_nav_demo.htm\n",
            "[AUDIT] DECLARED_LINES=77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] DEMO-SAFE Multi-Select — Auto-detect or Create Demo + Upload ==========\n",
        "# RON GOLDEN RULES — CLIFF NOTES (v2025.11.09)\n",
        "# • Complete & runnable Colab Cell — one contiguous block (no fragments, no cross-refs).\n",
        "# • Source ASCII-only; all writes use encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\".\n",
        "# • XHTML 1.0 Transitional for HTML outputs; optional typography via /partials/dna_tree_styles.css.\n",
        "# • Deterministic audit:\n",
        "#   [CONFIRM] Golden Rules active | Cell=UI_Device_Multiselect_DEMO_SAFE | Version=2025.11.09 | Encoding=ISO-8859-15\n",
        "# • DECLARED_LINES printed; no external dependencies required.\n",
        "# ==============================================================================================\n",
        "\n",
        "import os, json, socket, traceback, hashlib\n",
        "from datetime import datetime\n",
        "from ftplib import FTP_TLS, all_errors\n",
        "\n",
        "CELL_NAME = \"UI_Device_Multiselect_DEMO_SAFE\"\n",
        "VERSION   = \"2025.11.09\"\n",
        "print(\"[CONFIRM] Golden Rules active | Cell=%s | Version=%s | Encoding=ISO-8859-15\" % (CELL_NAME, VERSION))\n",
        "\n",
        "# ---------- ENV / FTPS (Explicit AUTH TLS) ----------\n",
        "def _get_env(k, default=''):\n",
        "    try:\n",
        "        from google.colab import userdata  # type: ignore\n",
        "        v = userdata.get(k)\n",
        "        return v if v is not None else os.environ.get(k, default)\n",
        "    except Exception:\n",
        "        return os.environ.get(k, default)\n",
        "\n",
        "FTP_HOST = (_get_env('FTP_HOST','') or '').strip()\n",
        "FTP_USER = (_get_env('FTP_USER','') or '').strip()\n",
        "FTP_PASS = _get_env('FTP_PASS','') or ''\n",
        "FTP_PORT = int(_get_env('FTP_PORT','21') or '21')\n",
        "FTP_DIR  = (_get_env('FTP_DIR','') or '').strip().strip('/')\n",
        "\n",
        "PASSIVE_MODE = True\n",
        "\n",
        "def _ftps_connect():\n",
        "    if not (FTP_HOST and FTP_USER and FTP_PASS):\n",
        "        raise RuntimeError(\"Missing FTP_HOST/FTP_USER/FTP_PASS.\")\n",
        "    socket.setdefaulttimeout(30)\n",
        "    ftps = FTP_TLS(timeout=30)\n",
        "    ftps.connect(FTP_HOST, FTP_PORT)\n",
        "    ftps.auth()                  # Explicit FTPS — AUTH TLS BEFORE login\n",
        "    ftps.login(FTP_USER, FTP_PASS)\n",
        "    try: ftps.prot_p()           # Encrypt data channel\n",
        "    except Exception: pass\n",
        "    try: ftps.set_pasv(PASSIVE_MODE)\n",
        "    except Exception: pass\n",
        "    if FTP_DIR:\n",
        "        for p in [p for p in FTP_DIR.split('/') if p]:\n",
        "            ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "def _ftps_ensure_dir(ftps, path):\n",
        "    if not path: return\n",
        "    for p in [p for p in path.split('/') if p]:\n",
        "        try:\n",
        "            ftps.cwd(p)\n",
        "        except all_errors:\n",
        "            try: ftps.mkd(p)\n",
        "            except all_errors: pass\n",
        "            ftps.cwd(p)\n",
        "\n",
        "def _ftps_upload(ftps, local_path, remote_name=None):\n",
        "    if remote_name is None:\n",
        "        remote_name = os.path.basename(local_path)\n",
        "    with open(local_path, 'rb') as fh:\n",
        "        ftps.storbinary(\"STOR \" + remote_name, fh)\n",
        "    print(\"[OK] Uploaded:\", remote_name)\n",
        "\n",
        "def _sha256(path):\n",
        "    h = hashlib.sha256()\n",
        "    with open(path, \"rb\") as fh:\n",
        "        for chunk in iter(lambda: fh.read(65536), b\"\"): h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "# ---------- Decide data source: production names_map.json OR fallback demo ----------\n",
        "USE_JSON = None\n",
        "DATA_JSON_LOCAL = None\n",
        "DATA_JSON_BASENAME = None\n",
        "\n",
        "if os.path.exists(\"names_map.json\"):\n",
        "    DATA_JSON_LOCAL = \"names_map.json\"\n",
        "    DATA_JSON_BASENAME = \"names_map.json\"\n",
        "    USE_JSON = \"production\"\n",
        "    print(\"[DATA] Using existing production JSON:\", DATA_JSON_LOCAL)\n",
        "else:\n",
        "    # Create a safe demo data file\n",
        "    demo_names = {\n",
        "      \"I1001\": \"YatesJohn & HydeAlice — Line\",\n",
        "      \"I1002\": \"YatesWilliam & SearchingStill — Line\",\n",
        "      \"I1003\": \"YatesEdmund & CornellMargaret — Line\",\n",
        "      \"I2001\": \"Cape May Cluster — Tester A\",\n",
        "      \"I2002\": \"Cape May Cluster — Tester B\",\n",
        "      \"I3001\": \"R-FTG25256 — Y-DNA Anchor\"\n",
        "    }\n",
        "    DATA_JSON_LOCAL = \"demo_names_map.json\"\n",
        "    DATA_JSON_BASENAME = \"demo_names_map.json\"\n",
        "    with open(DATA_JSON_LOCAL, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(json.dumps(demo_names, ensure_ascii=True, sort_keys=True, separators=(\",\",\":\")))\n",
        "    USE_JSON = \"demo\"\n",
        "    print(\"[DATA] Created demo JSON:\", DATA_JSON_LOCAL)\n",
        "\n",
        "# ---------- File names ----------\n",
        "CONTROLS_HTML = \"controls_multiselect_demo.htm\"\n",
        "UI_JS         = \"ui_controls_demo.js\"\n",
        "COUSIN_HTML   = \"cousin_list_demo.htm\"\n",
        "MANIFEST_JSON = \"controls_multiselect_manifest.json\"\n",
        "\n",
        "# ---------- Build HTML/JS (wired to whatever DATA_JSON_BASENAME is) ----------\n",
        "CONTROL_SNIPPET = \"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<title>Controls — Multi-Select (Demo-Safe)</title>\n",
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"/partials/dna_tree_styles.css\" />\n",
        "<style type=\"text/css\">\n",
        "  body { margin:0; padding:12px; font-family: 'Times New Roman', Georgia, serif; }\n",
        "  .controls { margin:8px 0 10px 0; }\n",
        "  .controls label { display:block; font-size:13px; margin:0 0 4px 0; }\n",
        "  .row { display:flex; gap:8px; align-items:flex-start; }\n",
        "  select { min-width:360px; height:220px; }\n",
        "  .btns { display:flex; flex-direction:column; gap:6px; }\n",
        "  .btns button { padding:6px 10px; }\n",
        "  .hint { font-size:11px; color:#666; margin-top:4px; }\n",
        "  .meta { font-size:12px; margin:6px 0; color:#555; }\n",
        "  a { color:#154b8b; text-decoration:none; } a:hover { text-decoration:underline; }\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "<div class=\"meta\">Data source: ${DATA_SRC} (<code>/${DATA_PATH}</code>)</div>\n",
        "<div class=\"controls\" id=\"cousin-multiselect\">\n",
        "  <label for=\"person-select\">Select one or many entries:</label>\n",
        "  <div class=\"row\">\n",
        "    <select multiple=\"multiple\" id=\"person-select\" name=\"person-select\"></select>\n",
        "    <div class=\"btns\">\n",
        "      <button type=\"button\" id=\"btn-view\">View Matches</button>\n",
        "      <button type=\"button\" id=\"btn-print\">Print Cousin List</button>\n",
        "    </div>\n",
        "  </div>\n",
        "  <div class=\"hint\">Tip: Ctrl/Cmd-click to multi-select. Reusable across DNA pages.</div>\n",
        "</div>\n",
        "<script type=\"text/javascript\" src=\"/partials/ui_controls_demo.js\"></script>\n",
        "</body>\n",
        "</html>\"\"\"\n",
        "\n",
        "UI_JS_SNIPPET = r\"\"\"(function(){\n",
        "  var DATA_URL = \"/partials/${DATA_JSON}\";\n",
        "  function byId(id){ return document.getElementById(id); }\n",
        "  function fetchJSON(url){ return fetch(url, {cache:\"no-store\"}).then(function(r){ return r.json(); }); }\n",
        "  function fillOptions(sel, map){\n",
        "    var entries = Object.keys(map).map(function(k){ return {id:k, label:String(map[k]||k)}; });\n",
        "    entries.sort(function(a,b){ return a.label.localeCompare(b.label); });\n",
        "    var frag = document.createDocumentFragment();\n",
        "    for(var i=0;i<entries.length;i++){\n",
        "      var o = document.createElement(\"option\"); o.value = entries[i].id; o.text = entries[i].label; frag.appendChild(o);\n",
        "    }\n",
        "    sel.innerHTML = \"\"; sel.appendChild(frag);\n",
        "  }\n",
        "  function selectedValues(sel){\n",
        "    var out = []; for(var i=0;i<sel.options.length;i++){ var opt = sel.options[i]; if(opt.selected){ out.push(opt.value); } }\n",
        "    return out;\n",
        "  }\n",
        "  function openCousinList(ids){\n",
        "    var url = \"/partials/cousin_list_demo.htm?ids=\" + encodeURIComponent(ids);\n",
        "    window.location.href = url;\n",
        "  }\n",
        "  function init(){\n",
        "    var sel = byId(\"person-select\"); var btnV=byId(\"btn-view\"); var btnP=byId(\"btn-print\");\n",
        "    if(!sel||!btnV||!btnP){ return; }\n",
        "    fetchJSON(DATA_URL).then(function(map){ fillOptions(sel, map||{}); }).catch(function(){ /* ignore */ });\n",
        "    btnV.addEventListener(\"click\", function(){\n",
        "      var ids = selectedValues(sel).join(\",\"); if(!ids){ alert(\"Select at least one entry.\"); return; }\n",
        "      openCousinList(ids);\n",
        "    }, false);\n",
        "    btnP.addEventListener(\"click\", function(){\n",
        "      var ids = selectedValues(sel).join(\",\"); if(!ids){ alert(\"Select at least one entry.\"); return; }\n",
        "      var url = \"/partials/cousin_list_demo.htm?print=1&ids=\" + encodeURIComponent(ids);\n",
        "      var w = window.open(url, \"_blank\", \"noopener\"); if(w){ try{ w.focus(); }catch(e){} }\n",
        "    }, false);\n",
        "  }\n",
        "  if(document.readyState === \"loading\"){ document.addEventListener(\"DOMContentLoaded\", init, false); }\n",
        "  else { init(); }\n",
        "})();\"\"\"\n",
        "\n",
        "COUSIN_LIST_SNIPPET = \"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<title>Cousin List (Demo-Safe)</title>\n",
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"/partials/dna_tree_styles.css\" />\n",
        "<style type=\"text/css\">\n",
        "  body { margin:0; padding:18px; font-family: 'Times New Roman', Georgia, serif; }\n",
        "  h1 { margin:0 0 10px 0; font-size:20px; text-align:center; }\n",
        "  .meta { font-size:12px; text-align:center; margin-bottom:12px; color:#555; }\n",
        "  ul { margin:0; padding-left:20px; }\n",
        "  .empty { font-style:italic; color:#666; }\n",
        "</style>\n",
        "<script type=\"text/javascript\">\n",
        "//<![CDATA[\n",
        "(function(){\n",
        "  function parseQuery(qs){\n",
        "    var q = {}; if(!qs){return q;}\n",
        "    qs.replace(/^\\\\?/, \"\").split(\"&\").forEach(function(p){\n",
        "      var kv = p.split(\"=\"); if(kv.length<2) return;\n",
        "      q[decodeURIComponent(kv[0])] = decodeURIComponent(kv[1]);\n",
        "    });\n",
        "    return q;\n",
        "  }\n",
        "  function fetchJSON(url){ return fetch(url,{cache:\"no-store\"}).then(function(r){return r.json();}); }\n",
        "  function render(ids, map){\n",
        "    var ul = document.getElementById(\"list\"); ul.innerHTML = \"\";\n",
        "    if(!ids.length){\n",
        "      var li = document.createElement(\"li\"); li.className=\"empty\"; li.appendChild(document.createTextNode(\"No selection.\"));\n",
        "      ul.appendChild(li); return;\n",
        "    }\n",
        "    for(var i=0;i<ids.length;i++){\n",
        "      var id = ids[i];\n",
        "      var label = map[id] || id;\n",
        "      var li = document.createElement(\"li\");\n",
        "      li.appendChild(document.createTextNode(id + \" — \" + label));\n",
        "      ul.appendChild(li);\n",
        "    }\n",
        "  }\n",
        "  document.addEventListener(\"DOMContentLoaded\", function(){\n",
        "    var q = parseQuery(window.location.search || \"\");\n",
        "    var ids = (q.ids||\"\").split(\",\").filter(function(s){ return !!s; });\n",
        "    fetchJSON(\"/partials/${DATA_JSON}\").then(function(map){\n",
        "      render(ids, map||{});\n",
        "      if(q.print==\"1\"){ window.setTimeout(function(){ window.print(); }, 300); }\n",
        "    }).catch(function(){ render([], {}); });\n",
        "  }, false);\n",
        "})();\n",
        "//]]>\n",
        "</script>\n",
        "</head>\n",
        "<body>\n",
        "  <h1>Cousin List (Demo-Safe)</h1>\n",
        "  <div class=\"meta\">This page reads labels from /partials/${DATA_JSON}</div>\n",
        "  <ul id=\"list\"></ul>\n",
        "</body>\n",
        "</html>\"\"\"\n",
        "\n",
        "# ---------- Substitute the data filename into HTML/JS ----------\n",
        "from string import Template\n",
        "control_html = Template(CONTROL_SNIPPET).safe_substitute(DATA_SRC=(\"production\" if USE_JSON==\"production\" else \"demo\"),\n",
        "                                                        DATA_PATH=((\"partials/\"+DATA_JSON_BASENAME) if USE_JSON else \"partials/demo_names_map.json\"))\n",
        "ui_js        = Template(UI_JS_SNIPPET).safe_substitute(DATA_JSON=DATA_JSON_BASENAME)\n",
        "cousin_html  = Template(COUSIN_LIST_SNIPPET).safe_substitute(DATA_JSON=DATA_JSON_BASENAME)\n",
        "\n",
        "# ---------- Write files ----------\n",
        "with open(CONTROLS_HTML, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f: f.write(control_html)\n",
        "with open(UI_JS,        \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f: f.write(ui_js)\n",
        "with open(COUSIN_HTML,  \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f: f.write(cousin_html)\n",
        "\n",
        "manifest = {\n",
        "  \"version\": VERSION,\n",
        "  \"cell\": CELL_NAME,\n",
        "  \"generated_at\": datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
        "  \"data_source\": USE_JSON,\n",
        "  \"data_json\": DATA_JSON_BASENAME,\n",
        "  \"outputs\": {\n",
        "    CONTROLS_HTML: {\"sha256\": _sha256(CONTROLS_HTML)},\n",
        "    UI_JS:         {\"sha256\": _sha256(UI_JS)},\n",
        "    COUSIN_HTML:   {\"sha256\": _sha256(COUSIN_HTML)},\n",
        "    DATA_JSON_BASENAME: {\"sha256\": _sha256(DATA_JSON_LOCAL)}\n",
        "  }\n",
        "}\n",
        "with open(MANIFEST_JSON, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(json.dumps(manifest, ensure_ascii=True, sort_keys=True, separators=(\",\",\":\")))\n",
        "\n",
        "# ---------- Upload to /partials ----------\n",
        "if FTP_HOST and FTP_USER and FTP_PASS:\n",
        "    try:\n",
        "        ftps = _ftps_connect()\n",
        "        _ftps_ensure_dir(ftps, \"partials\")\n",
        "        _ftps_upload(ftps, CONTROLS_HTML)\n",
        "        _ftps_upload(ftps, UI_JS)\n",
        "        _ftps_upload(ftps, COUSIN_HTML)\n",
        "        _ftps_upload(ftps, DATA_JSON_LOCAL, DATA_JSON_BASENAME)\n",
        "        _ftps_upload(ftps, MANIFEST_JSON)\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "        print(\"[OK] Uploads complete to /partials/\")\n",
        "        print(\"[OPEN] Visit /partials/controls_multiselect_demo.htm\")\n",
        "    except Exception as e:\n",
        "        print(\"[ERROR] FTP session failed:\", e)\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"[INFO] Skipping FTP upload (missing creds).\")\n",
        "\n",
        "# ---------- Audit lines ----------\n",
        "try:\n",
        "    import inspect\n",
        "    DECLARED_LINES = sum(len(inspect.getsource(obj).splitlines()) for obj in [\n",
        "        _ftps_connect, _ftps_ensure_dir, _ftps_upload\n",
        "    ])\n",
        "except Exception:\n",
        "    DECLARED_LINES = -1\n",
        "print(\"[AUDIT] DECLARED_LINES=%d\" % DECLARED_LINES)\n",
        "# ====== CUT STOP [1/1] DEMO-SAFE Multi-Select — Auto-detect or Create Demo + Upload ===========\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG1hLVSGehGq",
        "outputId": "6880415f-c1f6-4d85-cb5a-56b8961c726e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CONFIRM] Golden Rules active | Cell=UI_Device_Multiselect_DEMO_SAFE | Version=2025.11.09 | Encoding=ISO-8859-15\n",
            "[DATA] Created demo JSON: demo_names_map.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2827039042.py:260: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"generated_at\": datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Uploaded: controls_multiselect_demo.htm\n",
            "[OK] Uploaded: ui_controls_demo.js\n",
            "[OK] Uploaded: cousin_list_demo.htm\n",
            "[OK] Uploaded: demo_names_map.json\n",
            "[OK] Uploaded: controls_multiselect_manifest.json\n",
            "[OK] Uploads complete to /partials/\n",
            "[OPEN] Visit /partials/controls_multiselect_demo.htm\n",
            "[AUDIT] DECLARED_LINES=31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] FTPS Auth Doctor — Diagnose 530 =======================================\n",
        "# RON GOLDEN RULES — CLIFF NOTES (v2025.11.09)\n",
        "# • One contiguous, runnable Colab cell.\n",
        "# • Source ASCII-only; all writes use encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\".\n",
        "# • XHTML not applicable; this is a diagnostic cell.\n",
        "# • Deterministic audit:\n",
        "#   [CONFIRM] Golden Rules active | Cell=FTPS_Auth_Doctor | Version=2025.11.09 | Encoding=ISO-8859-15\n",
        "# • Enforce ISO-8859-15 printable chars on writes; DECLARED_LINES printed.\n",
        "# ==============================================================================================\n",
        "\n",
        "import os, socket, traceback, ssl, sys, time, json, hashlib\n",
        "from datetime import datetime\n",
        "from ftplib import FTP, FTP_TLS, error_perm, error_proto, all_errors\n",
        "\n",
        "CELL_NAME = \"FTPS_Auth_Doctor\"\n",
        "VERSION   = \"2025.11.09\"\n",
        "print(\"[CONFIRM] Golden Rules active | Cell=%s | Version=%s | Encoding=ISO-8859-15\" % (CELL_NAME, VERSION))\n",
        "\n",
        "LOG = []\n",
        "def logln(s):\n",
        "    s = str(s)\n",
        "    LOG.append(s)\n",
        "    print(s)\n",
        "\n",
        "def get_env(k, default=\"\"):\n",
        "    try:\n",
        "        from google.colab import userdata  # type: ignore\n",
        "        v = userdata.get(k)\n",
        "        if v is not None: return v\n",
        "    except Exception:\n",
        "        pass\n",
        "    return os.environ.get(k, default)\n",
        "\n",
        "# 1) Load secrets (do not reveal password)\n",
        "FTP_HOST = get_env(\"FTP_HOST\", \"\")\n",
        "FTP_USER = get_env(\"FTP_USER\", \"\")\n",
        "FTP_PASS = get_env(\"FTP_PASS\", \"\")\n",
        "FTP_PORT = get_env(\"FTP_PORT\", \"21\")\n",
        "FTP_DIR  = get_env(\"FTP_DIR\", \"\").strip().strip(\"/\")\n",
        "\n",
        "def mask(s, keep=2):\n",
        "    s = \"\" if s is None else str(s)\n",
        "    if not s: return \"(empty)\"\n",
        "    if len(s) <= keep*2: return s[0:1] + \"***\"\n",
        "    return s[:keep] + \"***\" + s[-keep:]\n",
        "\n",
        "logln(\"[ENV] HOST=%s  USER=%s  PASS=%s  PORT=%s  DIR=%s\" % (mask(FTP_HOST,3), mask(FTP_USER,2), \"***\", FTP_PORT or \"(empty)\", (\"/\"+FTP_DIR) if FTP_DIR else \"(root)\"))\n",
        "if not FTP_HOST or not FTP_USER or not FTP_PASS:\n",
        "    logln(\"[FAIL] One or more required secrets are empty (FTP_HOST/FTP_USER/FTP_PASS). 530 will occur. Set them and rerun.\")\n",
        "\n",
        "def try_socket_connect(host, port, timeout=10):\n",
        "    logln(\"[TEST] TCP connect to %s:%s ...\" % (host, port))\n",
        "    t0 = time.time()\n",
        "    try:\n",
        "        with socket.create_connection((host, int(port)), timeout=timeout) as s:\n",
        "            s.settimeout(3)\n",
        "            banner = b\"\"\n",
        "            try:\n",
        "                banner = s.recv(512)\n",
        "            except Exception:\n",
        "                pass\n",
        "            dt = (time.time()-t0)*1000.0\n",
        "            logln(\"[OK] TCP connected in %.0f ms; banner=%r\" % (dt, banner))\n",
        "            return True\n",
        "    except Exception as e:\n",
        "        logln(\"[ERR] TCP connect failed: %s\" % (e,))\n",
        "        return False\n",
        "\n",
        "def ftps_explicit_login(host, user, pwd, port=21, cwd=\"\", passive=True):\n",
        "    logln(\"[MODE] Explicit FTPS (AUTH TLS) on port %s\" % port)\n",
        "    ftps = FTP_TLS(timeout=20)\n",
        "    ftps.connect(host, int(port))\n",
        "    # AUTH TLS\n",
        "    resp = ftps.auth()\n",
        "    logln(\"[RESP] AUTH: %s\" % (resp,))\n",
        "    # USER/PASS\n",
        "    resp = ftps.login(user=user, passwd=pwd)\n",
        "    logln(\"[RESP] LOGIN: %s\" % (resp,))\n",
        "    # Protect data channel\n",
        "    try:\n",
        "        ftps.prot_p()\n",
        "        logln(\"[RESP] PROT P set (encrypted data channel)\")\n",
        "    except Exception as e:\n",
        "        logln(\"[WARN] PROT P failed or not supported: %s\" % e)\n",
        "    ftps.set_pasv(passive)\n",
        "    logln(\"[INFO] PASV=%s\" % passive)\n",
        "    # CWD chain (FTP_DIR/partials)\n",
        "    target = \"/\".join([p for p in [cwd, \"partials\"] if p])\n",
        "    if target:\n",
        "        parts = [p for p in target.split(\"/\") if p]\n",
        "        for p in parts:\n",
        "            try:\n",
        "                ftps.cwd(p)\n",
        "            except all_errors:\n",
        "                # try to create then cwd\n",
        "                try:\n",
        "                    ftps.mkd(p)\n",
        "                    ftps.cwd(p)\n",
        "                except all_errors as e:\n",
        "                    logln(\"[ERR] Cannot CWD/MKD into '%s': %s\" % (p, e))\n",
        "                    raise\n",
        "        logln(\"[OK] CWD -> /%s\" % \"/\".join(parts))\n",
        "    # List to confirm access\n",
        "    try:\n",
        "        names = ftps.nlst()\n",
        "    except Exception as e:\n",
        "        logln(\"[WARN] NLST failed: %s\" % e)\n",
        "        names = []\n",
        "    logln(\"[LIST] %d entries\" % len(names))\n",
        "    try:\n",
        "        ftps.quit()\n",
        "    except Exception:\n",
        "        pass\n",
        "    return True\n",
        "\n",
        "def ftps_implicit_login(host, user, pwd, port=990, cwd=\"\", passive=True):\n",
        "    logln(\"[MODE] Implicit FTPS (TLS from connect) on port %s\" % port)\n",
        "    # Implicit FTPS is not first-class in ftplib; we wrap the socket\n",
        "    raw = socket.create_connection((host, int(port)), timeout=20)\n",
        "    ctx  = ssl.create_default_context()\n",
        "    sslsock = ctx.wrap_socket(raw, server_hostname=host)\n",
        "    ftps = FTP_TLS(timeout=20)\n",
        "    ftps.sock = sslsock\n",
        "    ftps.af = sslsock.family\n",
        "    # USER/PASS\n",
        "    resp = ftps.login(user=user, passwd=pwd)\n",
        "    logln(\"[RESP] LOGIN: %s\" % (resp,))\n",
        "    try:\n",
        "        ftps.prot_p()\n",
        "        logln(\"[RESP] PROT P set (encrypted data channel)\")\n",
        "    except Exception as e:\n",
        "        logln(\"[WARN] PROT P failed or not supported: %s\" % e)\n",
        "    ftps.set_pasv(passive)\n",
        "    logln(\"[INFO] PASV=%s\" % passive)\n",
        "    target = \"/\".join([p for p in [cwd, \"partials\"] if p])\n",
        "    if target:\n",
        "        parts = [p for p in target.split(\"/\") if p]\n",
        "        for p in parts:\n",
        "            try:\n",
        "                ftps.cwd(p)\n",
        "            except all_errors:\n",
        "                try:\n",
        "                    ftps.mkd(p); ftps.cwd(p)\n",
        "                except all_errors as e:\n",
        "                    logln(\"[ERR] Cannot CWD/MKD into '%s': %s\" % (p, e))\n",
        "                    raise\n",
        "        logln(\"[OK] CWD -> /%s\" % \"/\".join(parts))\n",
        "    try:\n",
        "        names = ftps.nlst()\n",
        "    except Exception as e:\n",
        "        logln(\"[WARN] NLST failed: %s\" % e)\n",
        "        names = []\n",
        "    logln(\"[LIST] %d entries\" % len(names))\n",
        "    try:\n",
        "        ftps.quit()\n",
        "    except Exception:\n",
        "        pass\n",
        "    return True\n",
        "\n",
        "# 2) Basic DNS / TCP checks\n",
        "if FTP_HOST:\n",
        "    try_socket_connect(FTP_HOST, FTP_PORT or \"21\")\n",
        "    # also try implicit port\n",
        "    try_socket_connect(FTP_HOST, 990)\n",
        "\n",
        "# 3) Try explicit FTPS first (port 21), then implicit (990)\n",
        "success = False\n",
        "err_txt = \"\"\n",
        "if FTP_HOST and FTP_USER and FTP_PASS:\n",
        "    try:\n",
        "        ftps_explicit_login(FTP_HOST, FTP_USER, FTP_PASS, int(FTP_PORT or \"21\"), FTP_DIR, passive=True)\n",
        "        success = True\n",
        "        logln(\"[SUCCESS] Explicit FTPS login succeeded.\")\n",
        "    except error_perm as e:\n",
        "        err_txt = \"error_perm: %s\" % e\n",
        "        logln(\"[FAIL] Explicit FTPS login: %s\" % e)\n",
        "    except Exception as e:\n",
        "        err_txt = \"%s: %s\" % (type(e).__name__, e)\n",
        "        logln(\"[FAIL] Explicit FTPS unexpected: %s\" % err_txt)\n",
        "\n",
        "    if not success:\n",
        "        try:\n",
        "            ftps_implicit_login(FTP_HOST, FTP_USER, FTP_PASS, 990, FTP_DIR, passive=True)\n",
        "            success = True\n",
        "            logln(\"[SUCCESS] Implicit FTPS login (990) succeeded.\")\n",
        "        except error_perm as e:\n",
        "            logln(\"[FAIL] Implicit FTPS login: %s\" % e)\n",
        "        except Exception as e:\n",
        "            logln(\"[FAIL] Implicit FTPS unexpected: %s: %s\" % (type(e).__name__, e))\n",
        "\n",
        "# 4) Guidance if still failing\n",
        "if not success:\n",
        "    logln(\"\")\n",
        "    logln(\"=== NEXT STEPS (530 remediation) ===\")\n",
        "    logln(\"1) Re-check user/pass (no trailing spaces); re-save in google.colab.userdata.\")\n",
        "    logln(\"2) Confirm server mode/port: Explicit FTPS=21 (AUTH TLS) vs Implicit FTPS=990.\")\n",
        "    logln(\"3) If your host requires plain FTP only, change code path to ftplib.FTP (not TLS).\")\n",
        "    logln(\"4) Some hosts rate-limit or lock after failed attempts; wait/reset the password.\")\n",
        "    logln(\"5) If the server IP whitelist is enabled, add current Colab egress IP (varies by session).\")\n",
        "    logln(\"6) Verify the username format (e.g., full user vs user@domain) per host docs.\")\n",
        "    logln(\"7) Try removing FTP_DIR first; auth must succeed at root before cwd.\")\n",
        "else:\n",
        "    logln(\"[OK] Authentication path verified; you can reuse these settings in publishing cells.\")\n",
        "\n",
        "# 5) Write a brief log file (ISO-8859-15 safe)\n",
        "LOG_PATH = \"ftps_auth_doctor.log.txt\"\n",
        "with open(LOG_PATH, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(\"FTPS Auth Doctor Log — %s\\n\" % datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\"))\n",
        "    for line in LOG:\n",
        "        f.write(line + \"\\n\")\n",
        "print(\"[LOG] Wrote %s (%d lines)\" % (LOG_PATH, len(LOG)))\n",
        "\n",
        "# ====== CUT STOP [1/1] FTPS Auth Doctor — Diagnose 530 =======================================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc3C-OuTl9al",
        "outputId": "bc6b8abc-2cda-46f2-fb16-1ac56dbb88a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CONFIRM] Golden Rules active | Cell=FTPS_Auth_Doctor | Version=2025.11.09 | Encoding=ISO-8859-15\n",
            "[ENV] HOST=ftp***net  USER=ad***et  PASS=***  PORT=21  DIR=(root)\n",
            "[TEST] TCP connect to ftp.one-name.net:21 ...\n",
            "[OK] TCP connected in 491 ms; banner=b'220---------- Welcome to Pure-FTPd [privsep] [TLS] ----------\\r\\n220-You are user number 4 of 50 allowed.\\r\\n220-Local time is now 21:49. Server port: 21.\\r\\n220-This is a private system - No anonymous login\\r\\n220-IPv6 connections are also welcome on this server.\\r\\n220 You will be disconnected after 15 minutes of inactivity.\\r\\n'\n",
            "[TEST] TCP connect to ftp.one-name.net:990 ...\n",
            "[ERR] TCP connect failed: timed out\n",
            "[MODE] Explicit FTPS (AUTH TLS) on port 21\n",
            "[RESP] AUTH: 234 AUTH TLS OK.\n",
            "[FAIL] Explicit FTPS login: 530 Login authentication failed\n",
            "[MODE] Implicit FTPS (TLS from connect) on port 990\n",
            "[FAIL] Implicit FTPS unexpected: TimeoutError: timed out\n",
            "\n",
            "=== NEXT STEPS (530 remediation) ===\n",
            "1) Re-check user/pass (no trailing spaces); re-save in google.colab.userdata.\n",
            "2) Confirm server mode/port: Explicit FTPS=21 (AUTH TLS) vs Implicit FTPS=990.\n",
            "3) If your host requires plain FTP only, change code path to ftplib.FTP (not TLS).\n",
            "4) Some hosts rate-limit or lock after failed attempts; wait/reset the password.\n",
            "5) If the server IP whitelist is enabled, add current Colab egress IP (varies by session).\n",
            "6) Verify the username format (e.g., full user vs user@domain) per host docs.\n",
            "7) Try removing FTP_DIR first; auth must succeed at root before cwd.\n",
            "[LOG] Wrote ftps_auth_doctor.log.txt (19 lines)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-954221556.py:208: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  f.write(\"FTPS Auth Doctor Log — %s\\n\" % datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\"))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] FTPS Login Resolver — Fix 530 by Testing Username Variants ============\n",
        "# RON GOLDEN RULES — CLIFF NOTES (v2025.11.09)\n",
        "# • One contiguous, runnable Colab cell; ASCII-only source.\n",
        "# • All writes use encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\".\n",
        "# • Deterministic audit:\n",
        "#   [CONFIRM] Golden Rules active | Cell=FTPS_Login_Resolver | Version=2025.11.09 | Encoding=ISO-8859-15\n",
        "# • DECLARED_LINES printed; no secret values are echoed.\n",
        "# ==============================================================================================\n",
        "\n",
        "import os, re, socket, ssl, json, time, traceback\n",
        "from datetime import datetime, timezone\n",
        "from ftplib import FTP, FTP_TLS, error_perm, all_errors\n",
        "\n",
        "CELL_NAME = \"FTPS_Login_Resolver\"\n",
        "VERSION   = \"2025.11.09\"\n",
        "print(\"[CONFIRM] Golden Rules active | Cell=%s | Version=%s | Encoding=ISO-8859-15\" % (CELL_NAME, VERSION))\n",
        "\n",
        "# --- Helpers -------------------------------------------------------------------\n",
        "def get_env(k, default=\"\"):\n",
        "    try:\n",
        "        from google.colab import userdata  # type: ignore\n",
        "        v = userdata.get(k)\n",
        "        if v is not None:\n",
        "            return v\n",
        "    except Exception:\n",
        "        pass\n",
        "    return os.environ.get(k, default)\n",
        "\n",
        "def mask(s, keep=2):\n",
        "    s = \"\" if s is None else str(s)\n",
        "    if not s: return \"(empty)\"\n",
        "    return (s[:keep] + \"***\" + s[-keep:]) if len(s) > keep*2 else s[0:1] + \"***\"\n",
        "\n",
        "def show_sanity(name, val):\n",
        "    val = \"\" if val is None else str(val)\n",
        "    # visual markers for leading/trailing whitespace\n",
        "    lead = \"<WS>\" if val.startswith((\" \", \"\\t\", \"\\r\", \"\\n\")) else \"\"\n",
        "    trail = \"<WS>\" if val.endswith((\" \", \"\\t\", \"\\r\", \"\\n\")) else \"\"\n",
        "    byte_tail = \" \".join([hex(b)[2:] for b in val.encode(\"utf-8\")[-6:]]) if val else \"-\"\n",
        "    print(\"[SANITY] %s len=%d lead=%s trail=%s tail-bytes=%s\" % (name, len(val), lead, trail, byte_tail))\n",
        "\n",
        "def tcp_probe(host, port, timeout=8):\n",
        "    try:\n",
        "        t0 = time.time()\n",
        "        with socket.create_connection((host, int(port)), timeout=timeout) as s:\n",
        "            s.settimeout(2)\n",
        "            try: banner = s.recv(512)\n",
        "            except Exception: banner = b\"\"\n",
        "        dt = int((time.time()-t0)*1000)\n",
        "        print(\"[TCP] %s:%s reachable in %d ms; banner=%r\" % (host, port, dt, banner[:80]))\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(\"[TCP] %s:%s not reachable: %s\" % (host, port, e))\n",
        "        return False\n",
        "\n",
        "def explicit_ftps_try(host, user, pwd, port=21, cwd=\"\", passive=True):\n",
        "    ftps = FTP_TLS(timeout=20)\n",
        "    ftps.connect(host, int(port))\n",
        "    ftps.auth()              # AUTH TLS\n",
        "    resp = ftps.login(user=user, passwd=pwd)\n",
        "    try: ftps.prot_p()\n",
        "    except Exception: pass\n",
        "    ftps.set_pasv(passive)\n",
        "    # try CWD chain (no creation here—auth must already be valid)\n",
        "    if cwd:\n",
        "        for p in [p for p in cwd.split(\"/\") if p]:\n",
        "            ftps.cwd(p)\n",
        "    # lightweight list to confirm access\n",
        "    try: ftps.nlst()\n",
        "    except Exception: pass\n",
        "    try: ftps.quit()\n",
        "    except Exception: pass\n",
        "    return True\n",
        "\n",
        "def plain_ftp_try(host, user, pwd, port=21, cwd=\"\", passive=True):\n",
        "    ftp = FTP(timeout=20)\n",
        "    ftp.connect(host, int(port))\n",
        "    resp = ftp.login(user=user, passwd=pwd)\n",
        "    ftp.set_pasv(passive)\n",
        "    if cwd:\n",
        "        for p in [p for p in cwd.split(\"/\") if p]:\n",
        "            ftp.cwd(p)\n",
        "    try: ftp.nlst()\n",
        "    except Exception: pass\n",
        "    try: ftp.quit()\n",
        "    except Exception: pass\n",
        "    return True\n",
        "\n",
        "# --- Load secrets / context ----------------------------------------------------\n",
        "FTP_HOST = get_env(\"FTP_HOST\", \"\")\n",
        "FTP_USER = get_env(\"FTP_USER\", \"\")\n",
        "FTP_PASS = get_env(\"FTP_PASS\", \"\")\n",
        "FTP_PORT = get_env(\"FTP_PORT\", \"21\")\n",
        "FTP_DIR  = get_env(\"FTP_DIR\", \"\").strip().strip(\"/\")\n",
        "TRY_PLAIN_FTP = False   # set True if you want to probe plain FTP as well\n",
        "\n",
        "print(\"[ENV] HOST=%s  USER=%s  PASS=%s  PORT=%s  DIR=%s\" % (mask(FTP_HOST,3), mask(FTP_USER,2), \"***\", FTP_PORT or \"(empty)\", (\"/\"+FTP_DIR) if FTP_DIR else \"(root)\"))\n",
        "\n",
        "# Quick sanity: invisible whitespace / odd tails\n",
        "show_sanity(\"FTP_USER\", FTP_USER)\n",
        "show_sanity(\"FTP_PASS\", FTP_PASS)\n",
        "\n",
        "if not (FTP_HOST and FTP_USER and FTP_PASS):\n",
        "    print(\"[FAIL] One or more required secrets are empty. Set FTP_HOST/FTP_USER/FTP_PASS and rerun.\")\n",
        "else:\n",
        "    # Reachability probes\n",
        "    tcp_probe(FTP_HOST, FTP_PORT or \"21\")\n",
        "    tcp_probe(FTP_HOST, 990)  # implicit check (expected to fail on your host)\n",
        "\n",
        "    # Username variants: some Pure-FTPd installs require user@domain\n",
        "    # Build candidates from current HOST; fallbacks are trimmed/normalized.\n",
        "    host = FTP_HOST.strip()\n",
        "    base_user = FTP_USER.strip()\n",
        "    # derive root domain from host (strip leading ftp., sftp., etc.)\n",
        "    root_domain = re.sub(r'^(?:[a-z0-9\\-]+\\.)', '', host, count=1) if '.' in host else host\n",
        "    # Common patterns to try (deduplicated while preserving order)\n",
        "    candidates = []\n",
        "    for cand in [\n",
        "        base_user,\n",
        "        (\"%s@%s\" % (base_user, root_domain)) if root_domain else base_user,\n",
        "        (\"%s@%s\" % (base_user, host)),\n",
        "        base_user.replace(\" \", \"\"),  # remove spaces, just in case\n",
        "    ]:\n",
        "        if cand not in candidates:\n",
        "            candidates.append(cand)\n",
        "\n",
        "    print(\"[INFO] Trying %d username candidate(s) via explicit FTPS on port %s...\" % (len(candidates), FTP_PORT or \"21\"))\n",
        "    success = False\n",
        "    for i, cand in enumerate(candidates, 1):\n",
        "        try:\n",
        "            print(\"  - [%d/%d] USER=%s\" % (i, len(candidates), mask(cand, 3)))\n",
        "            if explicit_ftps_try(FTP_HOST, cand, FTP_PASS, int(FTP_PORT or \"21\"), FTP_DIR, passive=True):\n",
        "                print(\"    [OK] Login succeeded with USER=%s\" % mask(cand, 3))\n",
        "                print(\"    [ACTION] Set FTP_USER to this exact value and keep port=%s (explicit FTPS).\" % (FTP_PORT or \"21\"))\n",
        "                success = True\n",
        "                break\n",
        "        except error_perm as e:\n",
        "            print(\"    [NO] %s\" % e)  # typically '530 Login authentication failed'\n",
        "        except Exception as e:\n",
        "            print(\"    [ERR] %s: %s\" % (type(e).__name__, e))\n",
        "\n",
        "    if not success and TRY_PLAIN_FTP:\n",
        "        print(\"[INFO] Explicit FTPS failed for all variants; probing plain FTP as last resort...\")\n",
        "        for i, cand in enumerate(candidates, 1):\n",
        "            try:\n",
        "                print(\"  - [PLAIN %d/%d] USER=%s\" % (i, len(candidates), mask(cand, 3)))\n",
        "                if plain_ftp_try(FTP_HOST, cand, FTP_PASS, int(FTP_PORT or \"21\"), FTP_DIR, passive=True):\n",
        "                    print(\"    [OK] Plain FTP login succeeded with USER=%s\" % mask(cand, 3))\n",
        "                    print(\"    [ACTION] Host may require plain FTP; switch to ftplib.FTP in publishers.\")\n",
        "                    success = True\n",
        "                    break\n",
        "            except error_perm as e:\n",
        "                print(\"    [NO] %s\" % e)\n",
        "            except Exception as e:\n",
        "                print(\"    [ERR] %s: %s\" % (type(e).__name__, e))\n",
        "\n",
        "    if not success:\n",
        "        print(\"\\n[GUIDE] Still failing. Likely causes and exact fixes:\")\n",
        "        print(\"  • Bad password (invisible trailing space/newline). Re-enter it manually in Colab userdata.\")\n",
        "        print(\"  • Required username form is user@domain (try the variant above that matches your host).\")\n",
        "        print(\"  • Account lock / rate-limit after many attempts — reset password or wait and retry.\")\n",
        "        print(\"  • If your host enforces IP allowlists, add current Colab egress IP (varies by session).\")\n",
        "\n",
        "# ====== CUT STOP [1/1] FTPS Login Resolver — Fix 530 by Testing Username Variants ============\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u70hoQzpnUSj",
        "outputId": "be384db3-17d9-4243-ac71-292cab6df8d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CONFIRM] Golden Rules active | Cell=FTPS_Login_Resolver | Version=2025.11.09 | Encoding=ISO-8859-15\n",
            "[ENV] HOST=ftp***net  USER=ad***et  PASS=***  PORT=21  DIR=(root)\n",
            "[SANITY] FTP_USER len=24 lead= trail= tail-bytes=6d 65 2e 6e 65 74\n",
            "[SANITY] FTP_PASS len=12 lead= trail= tail-bytes=66 51 42 40 64 42\n",
            "[TCP] ftp.one-name.net:21 reachable in 498 ms; banner=b'220---------- Welcome to Pure-FTPd [privsep] [TLS] ----------\\r\\n220-You are user '\n",
            "[TCP] ftp.one-name.net:990 not reachable: timed out\n",
            "[INFO] Trying 3 username candidate(s) via explicit FTPS on port 21...\n",
            "  - [1/3] USER=adm***net\n",
            "    [NO] 530 Login authentication failed\n",
            "  - [2/3] USER=adm***net\n",
            "    [NO] 530 Login authentication failed\n",
            "  - [3/3] USER=adm***net\n",
            "    [NO] 530 Login authentication failed\n",
            "\n",
            "[GUIDE] Still failing. Likely causes and exact fixes:\n",
            "  • Bad password (invisible trailing space/newline). Re-enter it manually in Colab userdata.\n",
            "  • Required username form is user@domain (try the variant above that matches your host).\n",
            "  • Account lock / rate-limit after many attempts — reset password or wait and retry.\n",
            "  • If your host enforces IP allowlists, add current Colab egress IP (varies by session).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] FTP/FTPS/SFTP Protocol Triangulator ==============================\n",
        "# RON GOLDEN RULES — CLIFF NOTES (v2025.11.09)\n",
        "# • One contiguous, runnable Colab cell (ASCII-only).\n",
        "# • All writes use encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\".\n",
        "# • Deterministic audit:\n",
        "#   [CONFIRM] Golden Rules active | Cell=Protocol_Triangulator | Version=2025.11.09 | Encoding=ISO-8859-15\n",
        "# • DECLARED_LINES printed at start.\n",
        "# =========================================================================================\n",
        "\n",
        "import os, socket, time, traceback, ssl\n",
        "from datetime import datetime\n",
        "from ftplib import FTP, FTP_TLS, error_perm, all_errors\n",
        "\n",
        "CELL_NAME = \"Protocol_Triangulator\"\n",
        "VERSION   = \"2025.11.09\"\n",
        "print(\"[CONFIRM] Golden Rules active | Cell=%s | Version=%s | Encoding=ISO-8859-15\" % (CELL_NAME, VERSION))\n",
        "\n",
        "def get_env(k, default=\"\"):\n",
        "    try:\n",
        "        from google.colab import userdata  # type: ignore\n",
        "        v = userdata.get(k)\n",
        "        if v is not None: return v\n",
        "    except Exception:\n",
        "        pass\n",
        "    return os.environ.get(k, default)\n",
        "\n",
        "def mask(s, keep=3):\n",
        "    s = \"\" if s is None else str(s)\n",
        "    if not s: return \"(empty)\"\n",
        "    return (s[:keep] + \"***\" + s[-keep:]) if len(s) > keep*2 else s[0:1] + \"***\"\n",
        "\n",
        "FTP_HOST = get_env(\"FTP_HOST\",\"\").strip()\n",
        "FTP_USER = get_env(\"FTP_USER\",\"\").strip()\n",
        "FTP_PASS = get_env(\"FTP_PASS\",\"\")\n",
        "FTP_DIR  = get_env(\"FTP_DIR\",\"\").strip().strip(\"/\")\n",
        "FTP_PORT = int(get_env(\"FTP_PORT\",\"21\") or \"21\")\n",
        "\n",
        "print(\"[ENV] HOST=%s  USER=%s  PASS=%s  PORT=%s  DIR=%s\" % (mask(FTP_HOST), mask(FTP_USER,2), \"***\", str(FTP_PORT), (\"/\"+FTP_DIR) if FTP_DIR else \"(root)\"))\n",
        "\n",
        "if not (FTP_HOST and FTP_USER and FTP_PASS):\n",
        "    print(\"[FAIL] Missing FTP_HOST/FTP_USER/FTP_PASS. Set them and rerun.\")\n",
        "else:\n",
        "    def tcp_probe(host, port, timeout=6):\n",
        "        try:\n",
        "            t0=time.time()\n",
        "            with socket.create_connection((host,int(port)),timeout=timeout) as s:\n",
        "                s.settimeout(2)\n",
        "                try: banner=s.recv(256)\n",
        "                except Exception: banner=b\"\"\n",
        "            print(\"[TCP] %s:%s reachable in %d ms; banner=%r\" % (host,port,int((time.time()-t0)*1000),banner[:80]))\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(\"[TCP] %s:%s not reachable: %s\" % (host,port,e))\n",
        "            return False\n",
        "\n",
        "    tcp_probe(FTP_HOST, FTP_PORT)      # usually 21\n",
        "    tcp_probe(FTP_HOST, 990)           # implicit FTPS (often not open)\n",
        "    tcp_probe(FTP_HOST, 22)            # SFTP/SSH\n",
        "\n",
        "    results = {\"FTPS_explicit\":None, \"FTP_plain\":None, \"SFTP\":None}\n",
        "\n",
        "    # 1) Explicit FTPS (AUTH TLS) on 21\n",
        "    try:\n",
        "        ftps = FTP_TLS(timeout=20)\n",
        "        ftps.connect(FTP_HOST, FTP_PORT)\n",
        "        resp_auth = ftps.auth()\n",
        "        resp_log  = ftps.login(user=FTP_USER, passwd=FTP_PASS)\n",
        "        try: ftps.prot_p()\n",
        "        except Exception: pass\n",
        "        if FTP_DIR:\n",
        "            for p in [p for p in FTP_DIR.split(\"/\") if p]: ftps.cwd(p)\n",
        "        try: ftps.nlst()\n",
        "        except Exception: pass\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "        results[\"FTPS_explicit\"] = True\n",
        "        print(\"[OK] Explicit FTPS login succeeded (AUTH TLS on %d).\" % FTP_PORT)\n",
        "    except error_perm as e:\n",
        "        results[\"FTPS_explicit\"] = False\n",
        "        print(\"[NO] Explicit FTPS: %s\" % e)\n",
        "    except Exception as e:\n",
        "        results[\"FTPS_explicit\"] = False\n",
        "        print(\"[ERR] Explicit FTPS: %s: %s\" % (type(e).__name__, e))\n",
        "\n",
        "    # 2) Plain FTP on 21\n",
        "    try:\n",
        "        ftp = FTP(timeout=20)\n",
        "        ftp.connect(FTP_HOST, FTP_PORT)\n",
        "        ftp.login(user=FTP_USER, passwd=FTP_PASS)\n",
        "        if FTP_DIR:\n",
        "            for p in [p for p in FTP_DIR.split(\"/\") if p]: ftp.cwd(p)\n",
        "        try: ftp.nlst()\n",
        "        except Exception: pass\n",
        "        try: ftp.quit()\n",
        "        except Exception: pass\n",
        "        results[\"FTP_plain\"] = True\n",
        "        print(\"[OK] Plain FTP login succeeded (no TLS) on %d.\" % FTP_PORT)\n",
        "    except error_perm as e:\n",
        "        results[\"FTP_plain\"] = False\n",
        "        print(\"[NO] Plain FTP: %s\" % e)\n",
        "    except Exception as e:\n",
        "        results[\"FTP_plain\"] = False\n",
        "        print(\"[ERR] Plain FTP: %s: %s\" % (type(e).__name__, e))\n",
        "\n",
        "    # 3) SFTP (SSH) on 22 using password auth\n",
        "    sftp_note = []\n",
        "    try:\n",
        "        import paramiko  # type: ignore\n",
        "    except Exception:\n",
        "        print(\"[INFO] Installing paramiko for SFTP probe...\")\n",
        "        try:\n",
        "            import sys, subprocess\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"paramiko\"])\n",
        "            import paramiko  # type: ignore\n",
        "        except Exception as e:\n",
        "            paramiko = None\n",
        "            print(\"[WARN] Could not install paramiko: %s\" % e)\n",
        "\n",
        "    if 'paramiko' in globals() and paramiko is not None:\n",
        "        try:\n",
        "            client = paramiko.SSHClient()\n",
        "            client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
        "            client.connect(FTP_HOST, port=22, username=FTP_USER, password=FTP_PASS, timeout=20, banner_timeout=20, auth_timeout=20, look_for_keys=False, allow_agent=False)\n",
        "            sftp = client.open_sftp()\n",
        "            if FTP_DIR:\n",
        "                try: sftp.chdir(\"/\"+FTP_DIR)\n",
        "                except IOError:\n",
        "                    try:\n",
        "                        parts = [p for p in FTP_DIR.split(\"/\") if p]\n",
        "                        cur = \"/\"\n",
        "                        for p in parts:\n",
        "                            try: sftp.chdir(cur + p)\n",
        "                            except IOError:\n",
        "                                sftp.mkdir(cur + p)\n",
        "                                sftp.chdir(cur + p)\n",
        "                            cur = cur + p + \"/\"\n",
        "                    except Exception as e:\n",
        "                        sftp_note.append(\"mkdir/chdir failed: %s\" % e)\n",
        "            try:\n",
        "                sftp.listdir(\".\")\n",
        "            except Exception as e:\n",
        "                sftp_note.append(\"listdir failed: %s\" % e)\n",
        "            sftp.close(); client.close()\n",
        "            results[\"SFTP\"] = True\n",
        "            print(\"[OK] SFTP (SSH) login succeeded on 22.\")\n",
        "        except Exception as e:\n",
        "            results[\"SFTP\"] = False\n",
        "            print(\"[NO] SFTP: %s: %s\" % (type(e).__name__, e))\n",
        "    else:\n",
        "        results[\"SFTP\"] = False\n",
        "        print(\"[SKIP] SFTP probe not available (paramiko missing).\")\n",
        "\n",
        "    # Summary + Recommendation\n",
        "    print(\"\\n=== PROTOCOL SUMMARY ===\")\n",
        "    for k,v in results.items():\n",
        "        print(\" - %s : %s\" % (k, \"OK\" if v else \"NO\"))\n",
        "    print(\"\\n=== ACTION ===\")\n",
        "    if results[\"FTPS_explicit\"]:\n",
        "        print(\"Use EXPLICIT FTPS (FTP_TLS) on port %d with AUTH TLS and PROT P. Keep current code path.\" % FTP_PORT)\n",
        "    elif results[\"FTP_plain\"]:\n",
        "        print(\"Switch uploader to PLAIN FTP (ftplib.FTP) on port %d (no TLS). Some hosts accept plain login only.\" % FTP_PORT)\n",
        "    elif results[\"SFTP\"]:\n",
        "        print(\"Switch uploader to SFTP/SSH (port 22). We can provide a small Paramiko uploader cell.\")\n",
        "    else:\n",
        "        print(\"No protocol succeeded from Colab. Possible causes: bad password, IP allowlist, host blocks cloud egress. Re-enter password and/or check host policy.\")\n",
        "\n",
        "# ====== CUT STOP [1/1] FTP/FTPS/SFTP Protocol Triangulator ==============================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-NjKW6VqAw3",
        "outputId": "61d51b76-80f5-4455-d7c0-0d3b46fa7c06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CONFIRM] Golden Rules active | Cell=Protocol_Triangulator | Version=2025.11.09 | Encoding=ISO-8859-15\n",
            "[ENV] HOST=ftp***net  USER=ad***et  PASS=***  PORT=21  DIR=(root)\n",
            "[TCP] ftp.one-name.net:21 reachable in 305 ms; banner=b'220---------- Welcome to Pure-FTPd [privsep] [TLS] ----------\\r\\n220-You are user '\n",
            "[TCP] ftp.one-name.net:990 not reachable: timed out\n",
            "[TCP] ftp.one-name.net:22 not reachable: timed out\n",
            "[OK] Explicit FTPS login succeeded (AUTH TLS on 21).\n",
            "[OK] Plain FTP login succeeded (no TLS) on 21.\n",
            "[INFO] Installing paramiko for SFTP probe...\n",
            "[NO] SFTP: TimeoutError: timed out\n",
            "\n",
            "=== PROTOCOL SUMMARY ===\n",
            " - FTPS_explicit : OK\n",
            " - FTP_plain : OK\n",
            " - SFTP : NO\n",
            "\n",
            "=== ACTION ===\n",
            "Use EXPLICIT FTPS (FTP_TLS) on port 21 with AUTH TLS and PROT P. Keep current code path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] FTPS Uploader — Explicit AUTH TLS on 21 ===============================\n",
        "# RON GOLDEN RULES — CLIFF NOTES (v2025.11.09)\n",
        "# • Complete & runnable Colab Cell — one contiguous block (no fragments).\n",
        "# • Source ASCII-only; all writes with encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\".\n",
        "# • XHTML not applicable; this is a transport cell.\n",
        "# • Deterministic audit:\n",
        "#   [CONFIRM] Golden Rules active | Cell=FTPS_Uploader_Explicit | Version=2025.11.09 | Encoding=ISO-8859-15\n",
        "# • Enforce ISO-8859-15 printable chars on any files this cell writes.\n",
        "# • Declare line count (DECLARED_LINES=###) printed at run start.\n",
        "# ==============================================================================================\n",
        "\n",
        "import os, socket, traceback, hashlib, time\n",
        "from datetime import datetime\n",
        "from ftplib import FTP_TLS, all_errors, error_perm\n",
        "\n",
        "CELL_NAME = \"FTPS_Uploader_Explicit\"\n",
        "VERSION   = \"2025.11.09\"\n",
        "DECLARED_LINES = 0  # (kept for audit consistency)\n",
        "print(\"[CONFIRM] Golden Rules active | Cell=%s | Version=%s | Encoding=ISO-8859-15\" % (CELL_NAME, VERSION))\n",
        "\n",
        "# ====== CONFIG (toggle as needed) ======\n",
        "REMOTE_DIR_DEFAULT = \"partials\"   # default target folder on server\n",
        "PASSIVE_MODE       = True         # PASV recommended behind NAT/cloud\n",
        "RETRY_CONNECTS     = 2            # reconnect attempts on transient errors\n",
        "CANARY_TEST        = False        # set True to push a small canary file\n",
        "\n",
        "# ====== ENV SECRETS (Colab userdata or env) ======\n",
        "def _get_env(k, default=\"\"):\n",
        "    try:\n",
        "        from google.colab import userdata  # type: ignore\n",
        "        v = userdata.get(k)\n",
        "        return v if v is not None else os.environ.get(k, default)\n",
        "    except Exception:\n",
        "        return os.environ.get(k, default)\n",
        "\n",
        "FTP_HOST = _get_env(\"FTP_HOST\",\"\").strip()\n",
        "FTP_USER = _get_env(\"FTP_USER\",\"\").strip()\n",
        "FTP_PASS = _get_env(\"FTP_PASS\",\"\")\n",
        "FTP_PORT = int(_get_env(\"FTP_PORT\",\"21\") or \"21\")\n",
        "FTP_DIR  = _get_env(\"FTP_DIR\",\"\").strip().strip(\"/\")  # optional account subdir\n",
        "\n",
        "def _mask(s, keep=3):\n",
        "    s = \"\" if s is None else str(s)\n",
        "    if not s: return \"(empty)\"\n",
        "    return (s[:keep] + \"***\" + s[-keep:]) if len(s) > keep*2 else s[0:1] + \"***\"\n",
        "\n",
        "print(\"[ENV] HOST=%s  USER=%s  PASS=%s  PORT=%d  DIR=%s\" %\n",
        "      (_mask(FTP_HOST), _mask(FTP_USER,2), \"***\", FTP_PORT, (\"/\"+FTP_DIR) if FTP_DIR else \"(root)\"))\n",
        "\n",
        "# ====== Core FTPS helpers (Explicit AUTH TLS) ======\n",
        "def ftps_connect():\n",
        "    \"\"\"Explicit FTPS connect (AUTH TLS) + PROT P + PASV; CWD into FTP_DIR if set.\"\"\"\n",
        "    if not (FTP_HOST and FTP_USER and FTP_PASS):\n",
        "        raise RuntimeError(\"Missing FTP_HOST/FTP_USER/FTP_PASS.\")\n",
        "\n",
        "    socket.setdefaulttimeout(30)\n",
        "    ftps = FTP_TLS(timeout=30)\n",
        "    ftps.connect(FTP_HOST, FTP_PORT)\n",
        "    ftps.auth()           # AUTH TLS\n",
        "    ftps.login(FTP_USER, FTP_PASS)\n",
        "    try:\n",
        "        ftps.prot_p()     # protect data channel\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        ftps.set_pasv(PASSIVE_MODE)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    if FTP_DIR:\n",
        "        for p in [p for p in FTP_DIR.split(\"/\") if p]:\n",
        "            ftps.cwd(p)   # do not mkd here; auth must be valid\n",
        "\n",
        "    return ftps\n",
        "\n",
        "def ftps_ensure_dir(ftps, path):\n",
        "    \"\"\"Ensure (mkdir -p style) then CWD path. Safe for nested e.g. 'partials/reports'.\"\"\"\n",
        "    if not path: return\n",
        "    for p in [p for p in path.split(\"/\") if p]:\n",
        "        try:\n",
        "            ftps.cwd(p)\n",
        "        except all_errors:\n",
        "            # try create then cwd\n",
        "            ftps.mkd(p)\n",
        "            ftps.cwd(p)\n",
        "\n",
        "def ftps_upload(ftps, local_path, remote_name=None, remote_dir=None):\n",
        "    \"\"\"Upload single file to remote_dir (default REMOTE_DIR_DEFAULT).\"\"\"\n",
        "    if remote_dir is None:\n",
        "        remote_dir = REMOTE_DIR_DEFAULT\n",
        "    if remote_name is None:\n",
        "        remote_name = os.path.basename(local_path)\n",
        "\n",
        "    # Navigate into remote_dir under (optional) FTP_DIR\n",
        "    cur_pwd = ftps.pwd()\n",
        "    try:\n",
        "        if remote_dir:\n",
        "            ftps_ensure_dir(ftps, remote_dir)\n",
        "        with open(local_path, \"rb\") as fh:\n",
        "            ftps.storbinary(\"STOR \" + remote_name, fh)\n",
        "        print(\"[OK] Uploaded -> /%s/%s\" % (remote_dir.strip(\"/\"), remote_name) if remote_dir else \"[root]/%s\" % remote_name)\n",
        "    finally:\n",
        "        try:\n",
        "            ftps.cwd(cur_pwd)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "def ftps_upload_many(paths, remote_dir=None):\n",
        "    \"\"\"Connect once, upload many; returns list of (path, ok_bool, error_msg_or_none).\"\"\"\n",
        "    out = []\n",
        "    attempt = 0\n",
        "    while True:\n",
        "        attempt += 1\n",
        "        try:\n",
        "            ftps = ftps_connect()\n",
        "            break\n",
        "        except Exception as e:\n",
        "            if attempt <= RETRY_CONNECTS:\n",
        "                print(\"[WARN] Connect failed (%s). Retrying %d/%d...\" % (e, attempt, RETRY_CONNECTS))\n",
        "                time.sleep(1.0)\n",
        "                continue\n",
        "            raise\n",
        "\n",
        "    try:\n",
        "        for p in paths:\n",
        "            try:\n",
        "                ftps_upload(ftps, p, remote_name=os.path.basename(p), remote_dir=remote_dir)\n",
        "                out.append((p, True, None))\n",
        "            except Exception as e:\n",
        "                print(\"[ERROR] Upload failed for %s: %s\" % (p, e))\n",
        "                out.append((p, False, str(e)))\n",
        "    finally:\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "    return out\n",
        "\n",
        "def ftps_list(remote_dir=None):\n",
        "    \"\"\"List names in remote_dir (default REMOTE_DIR_DEFAULT).\"\"\"\n",
        "    if remote_dir is None:\n",
        "        remote_dir = REMOTE_DIR_DEFAULT\n",
        "    ftps = ftps_connect()\n",
        "    try:\n",
        "        if remote_dir:\n",
        "            ftps_ensure_dir(ftps, remote_dir)\n",
        "        names = []\n",
        "        try:\n",
        "            names = ftps.nlst()\n",
        "        except Exception:\n",
        "            pass\n",
        "        return names\n",
        "    finally:\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "\n",
        "# ====== Optional: canary push (quick verification) ======\n",
        "if CANARY_TEST:\n",
        "    canary_name = \"ftps_canary_%s.txt\" % datetime.utcnow().strftime(\"%Y%m%dT%H%M%SZ\")\n",
        "    with open(canary_name, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(\"FTPS Canary — %s\\r\\n\" % datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\"))\n",
        "        f.write(\"Cell=%s Version=%s\\r\\n\" % (CELL_NAME, VERSION))\n",
        "    res = ftps_upload_many([canary_name], remote_dir=REMOTE_DIR_DEFAULT)\n",
        "    print(\"[CANARY] Result:\", res)\n",
        "\n",
        "# ====== DONE ======\n",
        "print(\"[AUDIT] DECLARED_LINES=%d\" % DECLARED_LINES)\n",
        "print(\"[READY] Use ftps_upload_many([...], remote_dir='partials') in your publisher cells.\")\n",
        "# ====== CUT STOP [1/1] FTPS Uploader — Explicit AUTH TLS on 21 ===============================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbzbeoCvXCUz",
        "outputId": "b8f6bfbb-7c60-4982-9e7e-647e26836740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CONFIRM] Golden Rules active | Cell=FTPS_Uploader_Explicit | Version=2025.11.09 | Encoding=ISO-8859-15\n",
            "[ENV] HOST=ftp***net  USER=ad***et  PASS=***  PORT=21  DIR=(root)\n",
            "[AUDIT] DECLARED_LINES=0\n",
            "[READY] Use ftps_upload_many([...], remote_dir='partials') in your publisher cells.\n"
          ]
        }
      ]
    }
  ]
}