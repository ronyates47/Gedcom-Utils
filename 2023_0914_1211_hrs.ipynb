{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUuVmwqmI3d2rlCGRIlfJM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronyates47/Gedcom-Utils/blob/main/2023_0914_1211_hrs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# total script\n",
        "\n",
        "# Cell 1: Import libraries\n",
        "import glob\n",
        "from gedcom.element.individual import IndividualElement\n",
        "from gedcom.parser import Parser\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Cell 2: Initialize Global Variables\n",
        "\n",
        "# Declare global variables at the top of the script (not indented)\n",
        "global name, cM, sort\n",
        "name = None\n",
        "cM = None\n",
        "sort = None\n",
        "\n",
        "\n",
        "\n",
        "# Your other code that uses or modifies `name`, `cM`, `sort`\n",
        "\n",
        "\n",
        "\n",
        "# Reset the global variables\n",
        "find_parents_new_counter = 0\n",
        "last_pair_counter = 0\n",
        "visited_pairs = set()\n",
        "\n",
        "# Initialize the last_prime_surname variable\n",
        "last_prime_surname = 'Yates'\n",
        "\n",
        "def select_gedcom_file():\n",
        "    gedcom_files = glob.glob('*.ged')\n",
        "    if not gedcom_files:\n",
        "        print(\"No GEDCOM files found in the Colab contents.\")\n",
        "        return None\n",
        "\n",
        "    print(\"List of GEDCOM files:\")\n",
        "    for i, file_name in enumerate(gedcom_files, 1):\n",
        "        print(f\"{i}. {file_name}\")\n",
        "\n",
        "    # Auto-select the first file\n",
        "    print(\"Auto-selected the first GEDCOM file.\")\n",
        "    return gedcom_files[0]\n",
        "\n",
        "def extract_id(record):\n",
        "    import re  # Importing the regex module\n",
        "    match = re.search(r'@(\\d+)@', record)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return None  # Return None if no ID is found\n",
        "\n",
        "# Cell 3: Define Gedcom Class\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Gedcom Class Definition\n",
        "class Gedcom:\n",
        "    def __init__(self, file_name):\n",
        "        self.file_name = file_name\n",
        "        self.gedcom_datasets = []\n",
        "        self.filter_pool = []\n",
        "        self.parse_gedcom()\n",
        "        self.filter_individuals()\n",
        "\n",
        "    def parse_gedcom(self):\n",
        "        with open(self.file_name, 'r', encoding='utf-8-sig') as f:\n",
        "            gedcom_lines = f.readlines()\n",
        "\n",
        "        current_dataset = None\n",
        "        for line in gedcom_lines:\n",
        "            parts = line.strip().split(' ', 2)\n",
        "            level = int(parts[0])\n",
        "            tag = parts[1]\n",
        "            value = parts[2] if len(parts) > 2 else None\n",
        "\n",
        "            if level == 0 and tag.startswith('@') and tag.endswith('@') and value == 'INDI':\n",
        "                current_dataset = GedcomDataset(tag.strip('@'))\n",
        "                self.gedcom_datasets.append(current_dataset)\n",
        "            elif current_dataset is not None:\n",
        "                if level == 1 and tag in ['NAME', 'FAMC']:\n",
        "                    current_key = tag\n",
        "                    current_dataset.add_extractable_detail(current_key, value)\n",
        "                elif level == 2 and tag == 'NPFX':\n",
        "                    current_dataset.add_extractable_detail(tag, value)\n",
        "\n",
        "\n",
        "        # Debug print statements\n",
        "#            print(f\"Debug: Added extractable detail for {tag}.\")\n",
        "#            print(f\"Debug: Current details in current_dataset: {current_dataset.extractable_detail if current_dataset else None}\")\n",
        "\n",
        "    def filter_individuals(self):\n",
        "        new_gedcom_datasets = []  # Initialize here to ensure it exists even if the file is not present\n",
        "\n",
        "        if os.path.exists('/content/shortged.xlsx'):\n",
        "            df = pd.read_excel('/content/shortged.xlsx')\n",
        "            allowed_individual_ids = df.iloc[:, 0].dropna().str.strip().tolist()\n",
        "            print(\"Allowed IDs from Excel file:\", allowed_individual_ids)\n",
        "\n",
        "            not_allowed_ids = []  # Initialize this here; you can also move it outside the if block if you use it later\n",
        "\n",
        "            for dataset in self.gedcom_datasets:\n",
        "                stripped_id = dataset.individual_id.strip()\n",
        "                if stripped_id in allowed_individual_ids:\n",
        "                    new_gedcom_datasets.append(dataset)\n",
        "                else:\n",
        "                    not_allowed_ids.append(stripped_id)\n",
        "\n",
        "        self.gedcom_datasets = new_gedcom_datasets  # Now safe to assign whether the file exists or not\n",
        "\n",
        "\n",
        "        print('Records Moved into short_pool:', len(self.gedcom_datasets))\n",
        "\n",
        "        for dataset in self.gedcom_datasets:\n",
        "            print(type(dataset))\n",
        "\n",
        "            if dataset.get_extractable_NPFX():\n",
        "                self.filter_pool.append(dataset)\n",
        "\n",
        "        print(\"Before_2023-09-12-1750_clearing ancestral_line:\")\n",
        "        for dataset in self.gedcom_datasets:\n",
        "            print(dataset.ancestral_line)\n",
        "\n",
        "        for dataset in self.gedcom_datasets:\n",
        "            dataset.ancestral_line = []\n",
        "\n",
        "class GedcomDataset:\n",
        "    def __init__(self, individual_id):\n",
        "        self.individual_id = individual_id\n",
        "        self.extractable_detail = {}\n",
        "        self.anchor_gen1 = None\n",
        "        self.ancestral_line = []\n",
        "\n",
        "    def get_anchor_gen1(self):\n",
        "        return self.anchor_gen1\n",
        "\n",
        "    def add_extractable_detail(self, key, value):\n",
        "        self.extractable_detail[key] = value\n",
        "\n",
        "    def get_gen_person(self):\n",
        "        global name, anchor_gen1  # Declare as global variables\n",
        "        name = self.extractable_detail.get('NAME', '')\n",
        "        first_name, last_name = name.split('/', 1)\n",
        "        first_name = first_name.split(' ')[0]\n",
        "        last_name = last_name.rstrip('/')\n",
        "        anchor_gen1 = last_name.replace(\" \", \"\") + first_name.replace(\" \", \"\")\n",
        "        self.anchor_gen1 = anchor_gen1  # Set the instance variable\n",
        "#        print(f\"Debug: anchor_gen1 is set to {anchor_gen1}\")  # Debug print\n",
        "        return self.individual_id.strip('@')\n",
        "\n",
        "    def get_extractable_cm(self):\n",
        "        global cM  # Declare cM as a global variable\n",
        "        npfx_value = self.extractable_detail.get('NPFX', '')\n",
        "        if '&' in npfx_value:\n",
        "            cm_value = npfx_value.split('&')[0].strip()\n",
        "        else:\n",
        "            cm_value = npfx_value.strip()\n",
        "        try:\n",
        "            int(cm_value)\n",
        "            return cm_value\n",
        "        except ValueError:\n",
        "            return 'error'\n",
        "\n",
        "    def get_extractable_sort(self):\n",
        "        npfx_value = self.extractable_detail.get('NPFX', '')\n",
        "        if '&' in npfx_value:\n",
        "            sort_value = npfx_value.split('&')[1].strip()\n",
        "            return sort_value\n",
        "        else:\n",
        "            return ''\n",
        "\n",
        "    def get_extractable_NPFX(self):\n",
        "        return self.extractable_detail.get('NPFX', '')\n",
        "\n",
        "def input_prime_surname(last_prime_surname=None):\n",
        "    global surname  # Declare surname as a global variable\n",
        "    if last_prime_surname:\n",
        "        last_name = last_prime_surname  # Use the default last_prime_surname\n",
        "    else:\n",
        "        last_name = \"Unknown\"  # Or some other default value when last_prime_surname is not available\n",
        "\n",
        "    surname = last_name  # Assign the value of last_name to the global surname variable\n",
        "    return last_name\n",
        "\n",
        "# Initialize last_prime_surname with a value, if you have one. Otherwise, it will be None.\n",
        "last_prime_surname = None\n",
        "\n",
        "# Call the function to get prime_surname\n",
        "prime_surname = input_prime_surname(last_prime_surname)\n",
        "\n",
        "# Store the value of prime_surname for later use\n",
        "last_prime_surname = prime_surname\n",
        "\n",
        "gedcom_file_path = select_gedcom_file()\n",
        "\n",
        "if gedcom_file_path:\n",
        "    # Use the selected GEDCOM file path to create an instance of the Gedcom class\n",
        "    gedcom_instance = Gedcom(gedcom_file_path)\n",
        "    gedcom_instance.parse_gedcom()\n",
        "\n",
        "# Initialize the list of individuals\n",
        "    individuals = []\n",
        "\n",
        "# Debug code to check if filter_pool has duplicates\n",
        "filter_pool_ids = [dataset.individual_id for dataset in gedcom_instance.filter_pool]\n",
        "if len(filter_pool_ids) != len(set(filter_pool_ids)):\n",
        "    print(\"Warning: Duplicates found in filter_pool.\")\n",
        "\n",
        "# Iterate over the filter_pool list and add each individual's last name and ID to the individuals list\n",
        "for dataset in gedcom_instance.filter_pool:\n",
        "    individual_id = dataset.get_gen_person()\n",
        "#    print(f\"0913-2019-Getting individual_id: {individual_id}\")  # Debug print\n",
        "\n",
        "    last_name = dataset.anchor_gen1  # Directly use the anchor_gen1 attribute\n",
        "#    print(f\"0913-2019-Getting last_name: {last_name}\")  # Debug print\n",
        "\n",
        "    npfx = dataset.extractable_detail.get('NPFX', 'No NPFX Found')  # Get the NPFX detail\n",
        "#    print(f\"0913-2019-Getting NPFX: {npfx}\")  # Debug print\n",
        "\n",
        "    cm = dataset.extractable_detail.get('cM', 'No cM Found')  # Get the cM detail\n",
        "#    print(f\"0913-2019-Getting cM: {cm}\")  # Debug print\n",
        "\n",
        "    sort_value = dataset.extractable_detail.get('Sort', 'No Sort Found')  # Get the Sort detail\n",
        "#    print(f\"0913-2019-Getting Sort: {sort_value}\")  # Debug print\n",
        "\n",
        "    individuals.append((last_name, individual_id))\n",
        "\n",
        "\n",
        "#    print(f'Records Moved into Samaller Pile {len(individuals)}')\n",
        "\n",
        "    # Read the GEDCOM file and split it into individual and family records\n",
        "    with open(gedcom_file_path, 'r') as file:\n",
        "        data = file.read()\n",
        "    data = data.split('\\n0 ')\n",
        "    records = {extract_id(record): record for record in data}\n",
        "\n",
        "# cell 12\n",
        "\n",
        "parent_pairs = []\n",
        "children = {}\n",
        "last_pair_counter = 0\n",
        "last_pair_counter = 0\n",
        "find_parents_new_counter = 0\n",
        "\n",
        "parent_pairs = []\n",
        "children = {}\n",
        "ancestral_lines = {}\n",
        "\n",
        "def find_parents_new(individual_id, generation, records, parent_pairs, children, ancestral_lines, current_line=None):\n",
        "    if current_line is None:\n",
        "        current_line = []\n",
        "\n",
        "    if individual_id not in records:\n",
        "        return\n",
        "    record = records[individual_id]\n",
        "    famc_start = record.find('1 FAMC @') + 8\n",
        "    famc_end = record.find('@', famc_start)\n",
        "    famc_id = record[famc_start:famc_end]\n",
        "    if famc_id not in records:\n",
        "        return\n",
        "\n",
        "    fam_record = records[famc_id]\n",
        "    wife_start = fam_record.find('1 WIFE @') + 8\n",
        "    wife_end = fam_record.find('@', wife_start)\n",
        "    mother_id = fam_record[wife_start:wife_end]\n",
        "\n",
        "    husb_start = fam_record.find('1 HUSB @') + 8\n",
        "    husb_end = fam_record.find('@', husb_start)\n",
        "    father_id = fam_record[husb_start:husb_end]\n",
        "\n",
        "    if mother_id and mother_id in records:\n",
        "        mother_record = records[mother_id]\n",
        "        mother_name = extract_name(mother_record)\n",
        "        if mother_name not in children:\n",
        "            children[mother_name] = []\n",
        "        children[mother_name].append(individual_id)\n",
        "    else:\n",
        "        mother_name = None\n",
        "\n",
        "    if father_id and father_id in records:\n",
        "        father_record = records[father_id]\n",
        "        father_name = extract_name(father_record)\n",
        "        if father_name not in children:\n",
        "            children[father_name] = []\n",
        "        children[father_name].append(individual_id)\n",
        "    else:\n",
        "        father_name = None\n",
        "\n",
        "    if mother_name is not None and father_name is not None:\n",
        "        parent_pair = father_name + \"&\" + mother_name\n",
        "        current_line.append((generation, parent_pair))\n",
        "        if parent_pair not in visited_pairs:\n",
        "            visited_pairs.add(parent_pair)\n",
        "            if has_both_parents(records, mother_id, father_id):\n",
        "                parent_pairs.append((generation, parent_pair))\n",
        "                ancestral_lines[parent_pair] = list(current_line)\n",
        "\n",
        "    if mother_id:\n",
        "        find_parents_new(mother_id, generation + 1, records, parent_pairs, children, ancestral_lines, current_line)\n",
        "\n",
        "    if father_id:\n",
        "        find_parents_new(father_id, generation + 1, records, parent_pairs, children, ancestral_lines, current_line)\n",
        "\n",
        "\n",
        "\n",
        "    if current_line:  # Check if the list is not empty\n",
        "        current_line.pop()\n",
        "\n",
        "ancestral_lines = {}\n",
        "find_parents_new(individual_id, 1, records, parent_pairs, children, ancestral_lines)\n",
        "\n",
        "for last_pair, ancestral_line in ancestral_lines.items():\n",
        "#    print(f'Head of Branch line (100 each surname) {last_pair}:')\n",
        "    for generation, parent_pair in ancestral_line:\n",
        "#        print(f'  Descendants of this branch line (1 each surname) {generation}: {parent_pair}')\n",
        "\n",
        "# Count the total number of parent pairs found\n",
        "        parent_pair_count = len(parent_pairs)\n",
        "#        print(f'{parent_pair_count} parent pairs were found')\n",
        "\n",
        "# NEW LINE: Count the total number of last pairs found\n",
        "last_pair_count = len(ancestral_lines)  # Count the number of keys in the dictionary\n",
        "print(f'{last_pair_count} (20230908-1438) last pairs were found')  # Print the count\n",
        "\n",
        "def process_individual_new(individual_id, gedcom_instance):\n",
        "    # Initialize individual_data at the start\n",
        "    individual_data = {}\n",
        "\n",
        "    global generation_table\n",
        "    generation_table = pd.DataFrame(columns=['Generation', 'Parent Pair'])\n",
        "    global visited_pairs\n",
        "    visited_pairs = set()\n",
        "\n",
        "    parent_pairs = []\n",
        "    children = {}\n",
        "    ancestral_lines = {}\n",
        "\n",
        "    # Changed records to gedcom_instance.gedcom_datasets\n",
        "    find_parents_new(individual_id, 1, gedcom_instance.gedcom_datasets, parent_pairs, children, ancestral_lines)\n",
        "\n",
        "    anchor_gen1 = None  # Initialize as None to ensure it gets a value later\n",
        "\n",
        "    # Here you populate individual_data (now that it's already initialized)\n",
        "    for dataset in gedcom_instance.filter_pool:\n",
        "        if dataset.get_gen_person() == individual_id:\n",
        "            anchor_gen1 = dataset.get_anchor_gen1()\n",
        "            individual_data['cM'] = dataset.get_extractable_cm()\n",
        "            individual_data['Sort'] = dataset.get_extractable_sort()\n",
        "            break\n",
        "\n",
        "    # Add anchor_gen1 to the beginning of each ancestral line\n",
        "    for last_pair, ancestral_line in ancestral_lines.items():\n",
        "        if anchor_gen1 is not None:  # Check if anchor_gen1 has been assigned a value\n",
        "            ancestral_line.insert(0, (1, anchor_gen1))\n",
        "\n",
        "    # Commented out this line to keep 'cM' and 'Sort' in individual_data\n",
        "    # individual_data = {}\n",
        "\n",
        "    individual_data['Last Pairs'] = ancestral_lines\n",
        "    individual_data['anchor_gen1'] = anchor_gen1  # Add anchor_gen1 to individual_data\n",
        "\n",
        "    return individual_data\n",
        "\n",
        "individual_data = process_individual_new(individual_id, gedcom_instance)\n",
        "last_pairs = individual_data['Last Pairs']\n",
        "\n",
        "\n",
        "def trace_children(individual_id, parent_pairs, children, visited=None):\n",
        "    # Create a list to store the children of the individual\n",
        "    individual_children = []\n",
        "\n",
        "    # Create a set to keep track of visited individuals\n",
        "    if visited is None:\n",
        "        visited = set()\n",
        "\n",
        "    # Check if the individual has already been visited\n",
        "    if individual_id in visited:\n",
        "        # If the individual has already been visited, stop the recursion and return an empty list\n",
        "        return individual_children\n",
        "\n",
        "    # Add the individual to the set of visited individuals\n",
        "    visited.add(individual_id)\n",
        "\n",
        "    # Find the name of the individual\n",
        "    individual_name = None\n",
        "    for pair in parent_pairs:\n",
        "        if \"lastpair\" in pair[1]:\n",
        "            names = pair[1].split('&')\n",
        "            if individual_id in children[names[0]]:\n",
        "                individual_name = names[0]\n",
        "            elif individual_id in children[names[1]]:\n",
        "                individual_name = names[1]\n",
        "            break\n",
        "\n",
        "    # Check if the individual has any children\n",
        "    if individual_name in children:\n",
        "        # Add the children of the individual to the list\n",
        "        individual_children.extend(children[individual_name])\n",
        "\n",
        "        # Recursively find the children of the individual's children\n",
        "        for child_id in children[individual_name]:\n",
        "            child_children = trace_children(child_id, parent_pairs, children, visited)\n",
        "            individual_children.extend(child_children)\n",
        "\n",
        "    return individual_children\n",
        "\n",
        "descendants = trace_children(individual_id, parent_pairs, children)\n",
        "print(f'The line # 371 ancestors of individual {individual_id} are: {descendants}')\n",
        "\n",
        "import pandas as pd  # If you haven't already imported it\n",
        "\n",
        "# user enters the surname=target surname\n",
        "target_surname = surname\n",
        "\n",
        "# Initialize a counter for the sub-branches\n",
        "branch_sub_counter = 0\n",
        "\n",
        "# Initialize your dictionary here\n",
        "branch_surname_count = {}\n",
        "formatted_lines_list = []  # This list will hold all your formatted ancestral lines for writing to Excel\n",
        "\n",
        "# Initialize variables to keep track of the highest worth and its corresponding branch line number\n",
        "highest_worth = 0\n",
        "highest_worth_reference = None\n",
        "\n",
        "# Initialize a dictionary to store the formatted_ancestral_line for each unique_reference\n",
        "formatted_lines = {}\n",
        "\n",
        "# Print statements to show initial state\n",
        "print(\"0913-1835_Initial state of branch_surname_count:\", branch_surname_count)\n",
        "print(\"0913-1835_Initial state of formatted_lines_list:\", formatted_lines_list)\n",
        "print(\"0913-1835_Initial state of highest_worth:\", highest_worth)\n",
        "print(\"0913-1835_Initial state of highest_worth_reference:\", highest_worth_reference)\n",
        "print(\"0913-1835_Initial state of formatted_lines:\", formatted_lines)\n",
        "\n",
        "# Loop through each ancestral line and print the details\n",
        "for last_pair, ancestral_line in ancestral_lines.items():\n",
        "\n",
        "    # Increment the branch sub counter\n",
        "    branch_sub_counter += 1\n",
        "\n",
        "    # Create a unique reference for this branch\n",
        "    unique_reference = f\"branch line number: {branch_sub_counter}\"\n",
        "\n",
        "    # Initialize counters for this specific branch\n",
        "    head_count = 0\n",
        "    descendant_count = 0\n",
        "    generations = len(ancestral_line)  # Count the number of generations for the tiebreaker\n",
        "\n",
        "    if target_surname in last_pair:\n",
        "        head_count += 1\n",
        "\n",
        "    # Reverse the order of the ancestral line so that it goes from oldest to newest\n",
        "    reversed_ancestral_line = reversed(ancestral_line)\n",
        "\n",
        "    # Create the formatted ancestral line string\n",
        "    formatted_ancestral_line = \"|\".join([pair for gen, pair in reversed_ancestral_line])\n",
        "\n",
        "    # Add the formatted line to the list\n",
        "    formatted_lines_list.append(formatted_ancestral_line)\n",
        "\n",
        "    # Store this formatted_ancestral_line in our dictionary\n",
        "    formatted_lines[unique_reference] = formatted_ancestral_line\n",
        "\n",
        "    # Now use last_pair_in_line as the head of the branch line\n",
        "\n",
        "    if target_surname in last_pair:  # I've assumed you meant the last pair in the ancestral line\n",
        "            descendant_count += 1  # Increment the counter for 'Descendant'\n",
        "\n",
        "    # Calculate the total worth for this branch\n",
        "    total_worth = (head_count * 100) + descendant_count\n",
        "\n",
        "    # Tie-breaking logic\n",
        "    if total_worth > highest_worth or (total_worth == highest_worth and generations > branch_surname_count.get(highest_worth_reference, {}).get('Generations', 0)):\n",
        "        highest_worth = total_worth\n",
        "        highest_worth_reference = unique_reference\n",
        "\n",
        "    # Store the counts in our dictionary\n",
        "    branch_surname_count[unique_reference] = {'Head': head_count, 'Descendant': descendant_count, 'Total Worth': total_worth, 'Generations': generations}\n",
        "\n",
        "# After the loop, highest_worth_reference holds the unique_reference of the branch line with the highest worth\n",
        "# Assign the formatted_ancestral_line of the highest worth branch to dnaline\n",
        "\n",
        "# Check if highest_worth_reference exists in formatted_lines, otherwise set a default value for dnaline\n",
        "if highest_worth_reference in formatted_lines:\n",
        "    dnaline = formatted_lines[highest_worth_reference]\n",
        "else:\n",
        "    dnaline = \"No Ancestral Line Found\"  # Default value\n",
        "\n",
        "dnaline_dict = {}\n",
        "\n",
        "# Insert this line before populating dnaline_dict to debug\n",
        "print(f\"Contents of dnaline_dict before adding {individual_id}: {dnaline_dict}\")\n",
        "\n",
        "dnaline_dict[individual_id] = dnaline  # <-- This line saves dnaline to dnaline_dict for the current individual_id\n",
        "\n",
        "# Insert this line after populating dnaline_dict to debug\n",
        "print(f\"Contents of dnaline_dict after adding {individual_id}: {dnaline_dict}\")\n",
        "\n",
        "import pandas as pd  # Make sure to import pandas\n",
        "\n",
        "# Initialize combined_df_rows as an empty list before your loop\n",
        "combined_df_rows = []\n",
        "\n",
        "#  PRINTS DNA ANCESTRAL LINES\n",
        "\n",
        "#dnaline = formatted_lines[highest_worth_reference]\n",
        "#print(f\"The branch with the highest worth is {highest_worth_reference}, and its DNA line is {dnaline}\")\n",
        "\n",
        "# This should be placed after you define 'dnaline = formatted_lines[highest_worth_reference]'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd  # Make sure to import pandas\n",
        "\n",
        "# Print the contents of dnaline_dict to debug\n",
        "if not dnaline_dict:\n",
        "    print(\"HEY! THERE IS NOTHING IN dnaline_dict!\")\n",
        "else:\n",
        "    print(\"Contents of dnaline_dict:\", dnaline_dict)\n",
        "\n",
        "# THIS PREPARES THE OUTPUT USING THE SPECIAL DNALINE ANCESTRAL LINE\n",
        "# Loop through individuals\n",
        "for name, individual_id in individuals:\n",
        "    individual_data = process_individual_new(individual_id, gedcom_instance)\n",
        "\n",
        "    cM = individual_data['cM']\n",
        "    sort = individual_data['Sort']\n",
        "    anchor_gen1 = individual_data['anchor_gen1']\n",
        "\n",
        "    # Assuming dnaline is a string like 'ancestor1|ancestor2|ancestor3'\n",
        "    dnaline_value = dnaline if dnaline else \"N/A\"  # Use the value of dnaline or \"N/A\" if it's empty\n",
        "\n",
        "    # Extract the most distant ancestor from the dnaline_value\n",
        "    most_distant_ancestor = dnaline_value.split('|')[0] if dnaline_value != \"N/A\" else \"N/A\"\n",
        "\n",
        "    # Print columns for debugging\n",
        "#    print(\"Current columns in combined_df:\", combined_df.columns)\n",
        "\n",
        "    # Append a row to combined_df_rows\n",
        "    combined_df_rows.append([individual_id, anchor_gen1, sort, cM, most_distant_ancestor, dnaline_value])\n",
        "\n",
        "# Create DataFrame\n",
        "combined_df = pd.DataFrame(combined_df_rows, columns=['ID#', 'Name', 'Match to', 'cM', 'most_distant_ancestor', 'dnaline'])\n",
        "\n",
        "\n",
        "# Adjust index\n",
        "combined_df.index = combined_df.index + 1\n",
        "\n",
        "# Print DataFrame\n",
        "print(combined_df)\n",
        "\n",
        "# Export to Excel\n",
        "combined_df.to_excel('/content/output.xlsx', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWVoQon0RNPJ",
        "outputId": "f8b5cbec-f8d8-4b4e-dcba-7804bdb9011b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of GEDCOM files:\n",
            "1. yates-one-name-study.ged\n",
            "Auto-selected the first GEDCOM file.\n",
            "Allowed IDs from Excel file: ['I45949', 'I31861', 'I48331', 'I48337', 'I48354', 'I48375', 'I48384', 'I48391', 'I48403']\n",
            "Records Moved into short_pool: 9\n",
            "<class '__main__.GedcomDataset'>\n",
            "<class '__main__.GedcomDataset'>\n",
            "<class '__main__.GedcomDataset'>\n",
            "<class '__main__.GedcomDataset'>\n",
            "<class '__main__.GedcomDataset'>\n",
            "<class '__main__.GedcomDataset'>\n",
            "<class '__main__.GedcomDataset'>\n",
            "<class '__main__.GedcomDataset'>\n",
            "<class '__main__.GedcomDataset'>\n",
            "Before_2023-09-12-1750_clearing ancestral_line:\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "0 (20230908-1438) last pairs were found\n",
            "The line # 371 ancestors of individual I48403 are: []\n",
            "0913-1835_Initial state of branch_surname_count: {}\n",
            "0913-1835_Initial state of formatted_lines_list: []\n",
            "0913-1835_Initial state of highest_worth: 0\n",
            "0913-1835_Initial state of highest_worth_reference: None\n",
            "0913-1835_Initial state of formatted_lines: {}\n",
            "Contents of dnaline_dict before adding I48403: {}\n",
            "Contents of dnaline_dict after adding I48403: {'I48403': 'No Ancestral Line Found'}\n",
            "Contents of dnaline_dict: {'I48403': 'No Ancestral Line Found'}\n",
            "      ID#             Name         Match to  cM    most_distant_ancestor  \\\n",
            "1  I31861      ChurchDebra  yates,patricial  19  No Ancestral Line Found   \n",
            "2  I45949   HerndonKathryn      yates,nancy  14  No Ancestral Line Found   \n",
            "3  I48331  HamptonAbbigail  yates,patricial  20  No Ancestral Line Found   \n",
            "4  I48337   DavisChristine  yates,patricial   1  No Ancestral Line Found   \n",
            "5  I48354      RigginsSara  yates,patricial  16  No Ancestral Line Found   \n",
            "6  I48375     SheltonDiana  yates,patricial  10  No Ancestral Line Found   \n",
            "7  I48384       YatesBryan  yates,patricial  15  No Ancestral Line Found   \n",
            "8  I48391      YatesMarion  yates,patricial  13  No Ancestral Line Found   \n",
            "9  I48403      GodseyDaisy  yates,patricial  10  No Ancestral Line Found   \n",
            "\n",
            "                   dnaline  \n",
            "1  No Ancestral Line Found  \n",
            "2  No Ancestral Line Found  \n",
            "3  No Ancestral Line Found  \n",
            "4  No Ancestral Line Found  \n",
            "5  No Ancestral Line Found  \n",
            "6  No Ancestral Line Found  \n",
            "7  No Ancestral Line Found  \n",
            "8  No Ancestral Line Found  \n",
            "9  No Ancestral Line Found  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8TPGSNN6wGg",
        "outputId": "47890ddd-793b-4890-a4d6-8edaabb3b452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Collecting python-gedcom\n",
            "  Downloading python_gedcom-1.0.0-py2.py3-none-any.whl (35 kB)\n",
            "Installing collected packages: python-gedcom\n",
            "Successfully installed python-gedcom-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install python-gedcom"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W-qd3moK6FP5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}