{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXcLpwOMDaguzXlmu+99Tp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronyates47/Gedcom-Utils/blob/main/EXP_Gold__1_2%2C_3_%26_4_20251027.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT5s4n9S5ZpZ",
        "outputId": "542af0a3-1fc7-4ece-9e46-fdcc15ccdff3",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: python-gedcom in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.12/dist-packages (3.2.9)\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.12/dist-packages (0.23.4)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (1.16.2)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (1.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (1.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.1->mlxtend) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.17.0)\n",
            "ERROR: unknown command \"caas_jupyter_tools\"\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install python-gedcom\n",
        "!pip install openpyxl\n",
        "!pip install xlsxwriter\n",
        "!pip install mlxtend\n",
        "!pip caas_jupyter_tools"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#credentials\n",
        "\n",
        "import os\n",
        "\n",
        "# Gmail SMTP creds\n",
        "os.environ['GMAIL_USER']         = 'yatesvilleron@gmail.com'\n",
        "os.environ['GMAIL_APP_PASSWORD'] = 'qtziwiblytgrlzvx'\n",
        "\n",
        "# FTPS upload creds — make sure FTP_PASS is exactly your password, no < or >\n",
        "os.environ['FTP_HOST']       = 'ftp.one-name.net'\n",
        "os.environ['FTP_PORT']       = '21'\n",
        "os.environ['FTP_USER']       = 'admin@yates.one-name.net'\n",
        "os.environ['FTP_PASS']       = 'v(i83lfQB@dB'\n"
      ],
      "metadata": {
        "id": "971jlPTnBVfk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1 20250513-cell2 is good to use; adding more lineage functionality next\n",
        "#!/usr/bin/env python\n",
        "\"\"\"\n",
        "GEDCOM Composite Score Script using:\n",
        " - Chunk-based Parallel Processing for Speed (Stage 1: genealogical line creation)\n",
        " - A Trie-based approach, then final \"Value\" = 5 * (number of couples with node.count >=2) + (total couples)\n",
        "\n",
        "For ancestral lines where none of the couples are repeated (a one-off line), the Value is still computed.\n",
        "Now, instead of composite scoring, two new columns are added:\n",
        "  - Value Range (the numeric bracket)\n",
        "  - Value Label (a descriptive label)\n",
        "\n",
        "Exports final CSV/HTML sorted by \"Yates DNA Ancestral Line\", including a 'haplogroup' column.\n",
        "\"\"\"\n",
        "import csv\n",
        "import glob\n",
        "import logging\n",
        "import functools\n",
        "import os\n",
        "from datetime import datetime\n",
        "from collections import defaultdict, Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from tqdm import tqdm\n",
        "from IPython.display import display, Javascript\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "###############################################################################\n",
        "# Global Variables\n",
        "###############################################################################\n",
        "anchor_gen1 = None\n",
        "visited_pairs = set()\n",
        "generation_table = []\n",
        "\n",
        "###############################################################################\n",
        "# Trie Data Structure\n",
        "###############################################################################\n",
        "class TrieNode:\n",
        "    \"\"\"A simple Trie node for storing a couple and counting how many lines pass here.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.count = 0\n",
        "        self.children = {}\n",
        "\n",
        "class Trie:\n",
        "    def __init__(self):\n",
        "        self.root = TrieNode()\n",
        "\n",
        "    def insert_line(self, couples_list):\n",
        "        current = self.root\n",
        "        for couple in couples_list:\n",
        "            if couple not in current.children:\n",
        "                current.children[couple] = TrieNode()\n",
        "            current = current.children[couple]\n",
        "            current.count += 1\n",
        "\n",
        "    def get_couple_count(self, couples_list):\n",
        "        counts = []\n",
        "        current = self.root\n",
        "        for couple in couples_list:\n",
        "            if couple in current.children:\n",
        "                current = current.children[couple]\n",
        "                counts.append(current.count)\n",
        "            else:\n",
        "                counts.append(0)\n",
        "                break\n",
        "        return counts\n",
        "\n",
        "###############################################################################\n",
        "# Utility: chunk generator\n",
        "###############################################################################\n",
        "def chunks(lst, n):\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]\n",
        "\n",
        "###############################################################################\n",
        "# GedcomDataset\n",
        "###############################################################################\n",
        "class GedcomDataset:\n",
        "    def __init__(self, gen_person):\n",
        "        self.gen_person = gen_person\n",
        "        self.extractable_detail = {}\n",
        "        self.anchor_gen1 = None\n",
        "\n",
        "    def add_extractable_detail(self, key, value):\n",
        "        self.extractable_detail[key] = value\n",
        "\n",
        "    def get_gen_person(self):\n",
        "        name = self.extractable_detail.get('NAME', '')\n",
        "        parts = name.split('/', 1)\n",
        "        first_name = parts[0].split(' ')[0]\n",
        "        last_name = parts[1].rstrip('/') if len(parts) > 1 else \"\"\n",
        "        self.anchor_gen1 = last_name.replace(\" \", \"\") + first_name.replace(\" \", \"\")\n",
        "        global anchor_gen1\n",
        "        anchor_gen1 = self.anchor_gen1\n",
        "        return self.gen_person.strip('@')\n",
        "\n",
        "    def get_extractable_NPFX(self):\n",
        "        return self.extractable_detail.get('NPFX', '')\n",
        "\n",
        "    def get_extractable_cm(self):\n",
        "        npfx_value = self.extractable_detail.get('NPFX', '')\n",
        "        if '&' in npfx_value:\n",
        "            cm_value = npfx_value.split('&')[0].strip()\n",
        "        elif '**' in npfx_value:\n",
        "            cm_value = npfx_value.split('**')[0].strip()\n",
        "        else:\n",
        "            cm_value = npfx_value.strip()\n",
        "        try:\n",
        "            int(cm_value)\n",
        "            return cm_value\n",
        "        except ValueError:\n",
        "            return ''\n",
        "\n",
        "    def get_extractable_sort(self):\n",
        "        npfx_value = self.extractable_detail.get('NPFX', '')\n",
        "        if '&' in npfx_value:\n",
        "            sort_part = npfx_value.split('&')[1]\n",
        "            if '**' in sort_part:\n",
        "                sort_value = sort_part.split('**')[0].strip()\n",
        "            else:\n",
        "                sort_value = sort_part.strip()\n",
        "            return sort_value\n",
        "        return ''\n",
        "\n",
        "    def get_extractable_YDNA(self):\n",
        "        npfx_value = self.extractable_detail.get('NPFX', '')\n",
        "        if '**' in npfx_value:\n",
        "            ydna_value = npfx_value.split('**')[1].strip()\n",
        "            return ydna_value\n",
        "        return ''\n",
        "\n",
        "    def get_extractable_FAMC(self):\n",
        "        return self.extractable_detail.get('FAMC', '').strip('@')\n",
        "\n",
        "###############################################################################\n",
        "# Gedcom Class\n",
        "###############################################################################\n",
        "class Gedcom:\n",
        "    def __init__(self, file_name):\n",
        "        self.file_name = file_name\n",
        "        self.gedcom_datasets = []\n",
        "        self.filter_pool = []\n",
        "\n",
        "    def parse_gedcom(self):\n",
        "        with open(self.file_name, 'r', encoding='utf-8-sig') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        current_dataset = None\n",
        "        npfx_count = 0\n",
        "        ydna_count = 0\n",
        "        total_count = 0\n",
        "\n",
        "        for line in lines:\n",
        "            parts = line.strip().split(' ', 2)\n",
        "            level = int(parts[0])\n",
        "            tag = parts[1]\n",
        "            value = parts[2] if len(parts) > 2 else None\n",
        "\n",
        "            if level == 0 and tag.startswith('@') and tag.endswith('@') and value == 'INDI':\n",
        "                total_count += 1\n",
        "                current_dataset = GedcomDataset(tag)\n",
        "                self.gedcom_datasets.append(current_dataset)\n",
        "            elif current_dataset is not None:\n",
        "                if level == 1 and tag in ['NAME', 'FAMC']:\n",
        "                    current_dataset.add_extractable_detail(tag, value)\n",
        "                elif level == 2 and tag == 'NPFX':\n",
        "                    npfx_count += 1\n",
        "                    current_dataset.add_extractable_detail(tag, value)\n",
        "                    if '**' in value:\n",
        "                        ydna_count += 1\n",
        "\n",
        "        autosomal_count = npfx_count - ydna_count\n",
        "        print(f\"GEDCOM contained {total_count} total records\")\n",
        "        print(f\"Records tagged and filtered by NPFX: {npfx_count}\")\n",
        "        print(f\"Records with YDNA information: {ydna_count}\")\n",
        "        print(f\"Autosomal matches: {autosomal_count}\")\n",
        "\n",
        "        for ds in self.gedcom_datasets:\n",
        "            if ds.get_extractable_NPFX():\n",
        "                self.filter_pool.append(ds)\n",
        "\n",
        "        manual_filter_activated = True\n",
        "        if manual_filter_activated:\n",
        "            try:\n",
        "                df = pd.read_excel('filtered_ids.xlsx')\n",
        "            except FileNotFoundError:\n",
        "                logger.warning(\"filtered_ids.xlsx not found. Skipping second-level manual filter.\")\n",
        "            else:\n",
        "                manual_filtered_ids = set(df['ID'])\n",
        "                self.filter_pool = [d for d in self.filter_pool if d.get_gen_person() in manual_filtered_ids]\n",
        "                print(f\"After manual filter, total records: {len(self.filter_pool)}\")\n",
        "                logger.info(f\"After manual filter, total records: {len(self.filter_pool)}\")\n",
        "\n",
        "        return autosomal_count\n",
        "\n",
        "###############################################################################\n",
        "# quick_extract_name\n",
        "###############################################################################\n",
        "def quick_extract_name(full_text):\n",
        "    name_marker = \"\\n1 NAME \"\n",
        "    idx = full_text.find(name_marker)\n",
        "    if idx == -1:\n",
        "        if full_text.startswith(\"1 NAME \"):\n",
        "            idx = 0\n",
        "        else:\n",
        "            return \"UnknownName\"\n",
        "    start = idx + len(name_marker)\n",
        "    end = full_text.find('\\n', start)\n",
        "    if end == -1:\n",
        "        end = len(full_text)\n",
        "    name_line = full_text[start:end].strip()\n",
        "    if '/' not in name_line:\n",
        "        return name_line[:10].replace(\" \", \"\")\n",
        "    first_name, last_name = name_line.split('/', 1)\n",
        "    last_name = last_name.replace(\"/\", \"\").strip()\n",
        "    return last_name[:10].replace(\" \", \"\") + first_name[:10].replace(\" \", \"\")\n",
        "\n",
        "###############################################################################\n",
        "# Parents & Ancestors\n",
        "###############################################################################\n",
        "def find_parents(individual_id, generation, parents_map):\n",
        "    global visited_pairs, generation_table\n",
        "    if individual_id not in parents_map:\n",
        "        return\n",
        "    father_id, mother_id = parents_map[individual_id]\n",
        "    if not father_id and not mother_id:\n",
        "        return\n",
        "    pair = (father_id, mother_id)\n",
        "    if pair not in visited_pairs:\n",
        "        visited_pairs.add(pair)\n",
        "        generation_table.append((generation, pair))\n",
        "    if father_id:\n",
        "        find_parents(father_id, generation+1, parents_map)\n",
        "    if mother_id:\n",
        "        find_parents(mother_id, generation+1, parents_map)\n",
        "\n",
        "def find_distant_ancestors(individual_id, parents_map, path=None):\n",
        "    if path is None:\n",
        "        path = []\n",
        "    path.append(individual_id)\n",
        "    if individual_id not in parents_map:\n",
        "        return [path]\n",
        "    father_id, mother_id = parents_map[individual_id]\n",
        "    if not father_id and not mother_id:\n",
        "        return [path]\n",
        "    paths = []\n",
        "    if father_id:\n",
        "        paths.extend(find_distant_ancestors(father_id, parents_map, path[:]))\n",
        "    if mother_id:\n",
        "        paths.extend(find_distant_ancestors(mother_id, parents_map, path[:]))\n",
        "    return paths if paths else [path]\n",
        "\n",
        "###############################################################################\n",
        "# filter_ancestral_line\n",
        "###############################################################################\n",
        "def filter_ancestral_line(winning_path_ids, generation_table_local, names_map):\n",
        "    matching_table = []\n",
        "    for generation, pair in generation_table_local:\n",
        "        id1, id2 = pair\n",
        "        if id1 in winning_path_ids or id2 in winning_path_ids:\n",
        "            matching_table.append((generation, pair))\n",
        "    matching_table.sort(key=lambda x: x[0])\n",
        "    lines = []\n",
        "    for gen, pair in matching_table:\n",
        "        name_pair = [names_map.get(pid, \"UnknownName\") for pid in pair]\n",
        "        lines.append(f\"{name_pair[0]}&{name_pair[1]}\")\n",
        "    lines.reverse()\n",
        "    return \"~~~\".join(lines)\n",
        "\n",
        "###############################################################################\n",
        "# process_record_wrapper (parallel) - STAGE 1\n",
        "###############################################################################\n",
        "def process_record_wrapper(individual_id, gedcom_instance, parents_map, names_map):\n",
        "    global generation_table, visited_pairs, anchor_gen1\n",
        "    generation_table = []\n",
        "    visited_pairs = set()\n",
        "\n",
        "    find_parents(individual_id, 1, parents_map)\n",
        "    distant_anc_paths = find_distant_ancestors(individual_id, parents_map)\n",
        "\n",
        "    best_score = None\n",
        "    best_path = None\n",
        "    for path in distant_anc_paths:\n",
        "        name_path = [names_map.get(pid, \"UnknownName\") for pid in path]\n",
        "        score = sum((idx+1) for idx, nm in enumerate(name_path) if 'Yates' in nm)\n",
        "        if best_score is None or score > best_score:\n",
        "            best_score = score\n",
        "            best_path = path\n",
        "\n",
        "    if not best_path:\n",
        "        best_path = []\n",
        "\n",
        "    best_path_cleaned = [pid for pid in best_path if pid != individual_id]\n",
        "    line_str = filter_ancestral_line(set(best_path_cleaned), generation_table, names_map)\n",
        "\n",
        "    cm_value = ''\n",
        "    sort_value = ''\n",
        "    ydna_value = ''\n",
        "    for ds in gedcom_instance.filter_pool:\n",
        "        if ds.get_gen_person() == individual_id:\n",
        "            cm_value = ds.get_extractable_cm()\n",
        "            sort_value = ds.get_extractable_sort()\n",
        "            ydna_value = ds.get_extractable_YDNA()\n",
        "            break\n",
        "\n",
        "    short_name = names_map.get(individual_id, \"UnknownName\")\n",
        "    # Return columns: ID#, Match to, Name, cM, Yates DNA Ancestral Line, haplogroup\n",
        "    return [individual_id, sort_value, short_name, cm_value, line_str, ydna_value]\n",
        "\n",
        "###############################################################################\n",
        "# main()\n",
        "###############################################################################\n",
        "def main():\n",
        "    def select_gedcom():\n",
        "        files = glob.glob(\"*.ged\")\n",
        "        if not files:\n",
        "            print(\"No GEDCOM files found.\")\n",
        "            return None\n",
        "        print(\"Automatically selecting the first GEDCOM file.\")\n",
        "        return files[0]\n",
        "\n",
        "    gedcom_file_path = select_gedcom()\n",
        "    if not gedcom_file_path:\n",
        "        print(\"No GEDCOM file selected; exiting.\")\n",
        "        return\n",
        "\n",
        "    ged = Gedcom(gedcom_file_path)\n",
        "    autosomal_count = ged.parse_gedcom()\n",
        "    filter_count = len(ged.filter_pool)\n",
        "\n",
        "    with open(\"autosomal_count.txt\", \"w\") as f:\n",
        "        f.write(str(autosomal_count))\n",
        "\n",
        "    print(\"Records tagged and filtered by NPFX:\", filter_count)\n",
        "\n",
        "    with open(gedcom_file_path, 'r', encoding='utf-8') as f:\n",
        "        raw_data = f.read()\n",
        "\n",
        "    blocks = raw_data.split('\\n0 ')\n",
        "    all_records = {}\n",
        "    for blk in blocks:\n",
        "        blk = blk.strip()\n",
        "        if not blk:\n",
        "            continue\n",
        "        flend = blk.find('\\n')\n",
        "        if flend == -1:\n",
        "            flend = len(blk)\n",
        "        first_line = blk[:flend]\n",
        "        if '@' in first_line:\n",
        "            start = first_line.find('@') + 1\n",
        "            end = first_line.find('@', start)\n",
        "            rec_id = first_line[start:end].strip()\n",
        "            all_records[rec_id] = blk\n",
        "\n",
        "    parents_map = {}\n",
        "    names_map = {}\n",
        "    for rec_id, txt in all_records.items():\n",
        "        nm = quick_extract_name(\"\\n\" + txt)\n",
        "        names_map[rec_id] = nm\n",
        "\n",
        "    families = {}\n",
        "    for rec_id, txt in all_records.items():\n",
        "        if 'FAM' in txt[:50]:\n",
        "            father_idx = txt.find('1 HUSB @')\n",
        "            husb_id = txt[father_idx+len('1 HUSB @'):txt.find('@', father_idx+len('1 HUSB @'))] if father_idx != -1 else None\n",
        "            wife_idx = txt.find('1 WIFE @')\n",
        "            wife_id = txt[wife_idx+len('1 WIFE @'):txt.find('@', wife_idx+len('1 WIFE @'))] if wife_idx != -1 else None\n",
        "            kids = [ln.split('@')[1] for ln in txt.split('\\n') if ln.strip().startswith('1 CHIL @')]\n",
        "            families[rec_id] = (husb_id, wife_id, kids)\n",
        "\n",
        "    for fam_id, (f_id, m_id, k_list) in families.items():\n",
        "        for kid in k_list:\n",
        "            parents_map[kid] = (f_id, m_id)\n",
        "\n",
        "    individual_ids = [d.get_gen_person() for d in ged.filter_pool]\n",
        "    print(f\"Processing {len(individual_ids)} individuals with chunk-based parallel...\")\n",
        "\n",
        "    combined_rows = []\n",
        "    chunk_size = 50\n",
        "    max_workers = os.cpu_count() or 4\n",
        "    logger.info(\"Starting chunk-based parallel processing with %d workers.\", max_workers)\n",
        "\n",
        "    with ProcessPoolExecutor(max_workers=max_workers) as executor, tqdm(total=len(individual_ids), desc=\"Building Yates Lines (Stage 1)\") as pbar:\n",
        "        for chunk in chunks(individual_ids, chunk_size):\n",
        "            func = functools.partial(process_record_wrapper, gedcom_instance=ged, parents_map=parents_map, names_map=names_map)\n",
        "            results = list(executor.map(func, chunk))\n",
        "            combined_rows.extend(results)\n",
        "            pbar.update(len(chunk))\n",
        "\n",
        "    columns = [\"ID#\", \"Match to\", \"Name\", \"cM\", \"Yates DNA Ancestral Line\", \"haplogroup\"]\n",
        "    df = pd.DataFrame(combined_rows, columns=columns)\n",
        "    df.index += 1\n",
        "\n",
        "    def remove_specific_prefix(row):\n",
        "        prefix = \"YatesJohn&SearchingStill~~~YatesWilliam&SearchingStill~~~YatesWilliam&SearchingStill~~~YatesEdmund&CornellMargaret~~~YatesRichard&AshendonJoan~~~YatesJohn&HydeAlice~~~YatesThomas&FauconerElizabeth~~~\"\n",
        "        if row[\"Yates DNA Ancestral Line\"].startswith(prefix):\n",
        "            row[\"Yates DNA Ancestral Line\"] = row[\"Yates DNA Ancestral Line\"][len(prefix):]\n",
        "        return row\n",
        "\n",
        "    df = df.apply(remove_specific_prefix, axis=1)\n",
        "\n",
        "    logger.info(\"Building Trie from reversed lines...\")\n",
        "    trie = Trie()\n",
        "    for _, row in df.iterrows():\n",
        "        line_str = row[\"Yates DNA Ancestral Line\"]\n",
        "        if pd.notna(line_str) and line_str.strip():\n",
        "            trie.insert_line([x.strip() for x in line_str.split(\"~~~\") if x.strip()])\n",
        "\n",
        "    values, prefix_counts = [], []\n",
        "    logger.info(\"Computing 'Value' = 5*(#couples with node.count >=2) + (total couples) ...\")\n",
        "    for _, row in df.iterrows():\n",
        "        line_str = row[\"Yates DNA Ancestral Line\"]\n",
        "        if pd.isna(line_str) or not line_str.strip():\n",
        "            values.append(0)\n",
        "            prefix_counts.append(0)\n",
        "        else:\n",
        "            couples_list = [x.strip() for x in line_str.split(\"~~~\") if x.strip()]\n",
        "            node_counts = trie.get_couple_count(couples_list)\n",
        "            prefix_count = sum(1 for c in node_counts if c >= 2)\n",
        "            values.append(5 * prefix_count + len(couples_list))\n",
        "            prefix_counts.append(prefix_count)\n",
        "\n",
        "    df[\"Value\"], df[\"PrefixCount\"] = values, prefix_counts\n",
        "\n",
        "    def assign_value_range_label(val):\n",
        "        try:\n",
        "            v = float(val)\n",
        "        except:\n",
        "            return \"\", \"\"\n",
        "        if v >= 60: return \">=60\", \"1-likely correct\"\n",
        "        if 47 <= v <= 59: return \"59~47\", \"2-lines forming\"\n",
        "        if 34 <= v <= 46: return \"46~34\", \"3-patterns emerging\"\n",
        "        if 21 <= v <= 33: return \"33~21\", \"4-notable patterns\"\n",
        "        if 8 <= v <= 20: return \"20~8\", \"5-patterns stable\"\n",
        "        if 1 <= v <= 7:  return f\"{v:.0f}\", \"6-need research\"\n",
        "        return f\"{v:.0f}\", \"0-uncategorized\"\n",
        "\n",
        "    ranges, labels = zip(*(assign_value_range_label(v) for v in df[\"Value\"]))\n",
        "    df[\"Value Range\"], df[\"Value Label\"] = ranges, labels\n",
        "\n",
        "    df.sort_values(by=[\"Yates DNA Ancestral Line\"], inplace=True)\n",
        "    df.drop(\"PrefixCount\", axis=1, inplace=True)\n",
        "\n",
        "    csv_name = \"final_combined_df_with_value_labels.csv\"\n",
        "    df.to_csv(csv_name, index=False)\n",
        "    logger.info(\"Exported final DataFrame to '%s'.\", csv_name)\n",
        "\n",
        "    html_name = \"HTML_combined_df_with_value_labels.html\"\n",
        "    css_style = \"\"\"\n",
        "    <style>\n",
        "    table { width: 100%; border-collapse: collapse; margin: 20px 0; }\n",
        "    table, th, td { border: 1px solid #333; }\n",
        "    th, td { padding: 8px 12px; text-align: center; }\n",
        "    th { background-color: #f2f2f2; }\n",
        "    /* Left-align the last column */\n",
        "    td:nth-child(7) { text-align: left; }\n",
        "    </style>\n",
        "    \"\"\"\n",
        "    final_cols = [\"ID#\", \"cM\", \"haplogroup\", \"Match to\", \"Value Range\", \"Value Label\", \"Yates DNA Ancestral Line\"]\n",
        "    html_content = css_style + df.to_html(index=False, columns=final_cols, escape=False)\n",
        "    with open(html_name, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(html_content)\n",
        "    logger.info(\"Exported HTML to '%s'.\", html_name)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "    try:\n",
        "        display(Javascript('alert(\"✅ GEDCOM processing (and HTML export) is complete!\");'))\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import smtplib, ssl\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "def send_email(subject, body, to_addr):\n",
        "    smtp_server = 'smtp.gmail.com'\n",
        "    port = 465\n",
        "    sender = os.environ['GMAIL_USER']\n",
        "    password = os.environ['GMAIL_APP_PASSWORD']\n",
        "    msg = MIMEText(body)\n",
        "    msg['Subject'] = subject\n",
        "    msg['From'] = sender\n",
        "    msg['To'] = to_addr\n",
        "    context = ssl.create_default_context()\n",
        "    with smtplib.SMTP_SSL(smtp_server, port, context=context) as server:\n",
        "        server.login(sender, password)\n",
        "        server.send_message(msg)\n",
        "\n",
        "# Email summary (only total lines)\n",
        "df_summary = pd.read_csv(\"final_combined_df_with_value_labels.csv\")\n",
        "total = len(df_summary)\n",
        "summary = f\"GEDCOM processing complete!\\n\\nTotal lines: {total}\"\n",
        "\n",
        "send_email(\n",
        "    subject=\"✅ Cell #1 Report Ready\",\n",
        "    body=summary,\n",
        "    to_addr=os.environ['GMAIL_USER']\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "Qh13Q-WUmVu3",
        "outputId": "6a3fe8ea-b0c8-4693-f15d-dcc9766d3dd2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically selecting the first GEDCOM file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:filtered_ids.xlsx not found. Skipping second-level manual filter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GEDCOM contained 62184 total records\n",
            "Records tagged and filtered by NPFX: 1556\n",
            "Records with YDNA information: 1\n",
            "Autosomal matches: 1555\n",
            "Records tagged and filtered by NPFX: 1556\n",
            "Processing 1556 individuals with chunk-based parallel...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Yates Lines (Stage 1): 100%|██████████| 1556/1556 [11:50<00:00,  2.19it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "alert(\"✅ GEDCOM processing (and HTML export) is complete!\");"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gold 2 — create the Report Card (mobile-friendly, sortable)\n",
        "\n",
        "# ====== CUT START [A] REFACTOR-Gold 2 — Config + FTP + Constants + Rules =========================\n",
        "import os\n",
        "import posixpath\n",
        "import socket\n",
        "from ftplib import FTP_TLS\n",
        "\n",
        "# ---------- Script identity ----------\n",
        "SCRIPT_NAME = \"REFACTOR-Gold 2\"\n",
        "SECTION_NAME = \"[A] Config + FTP + Constants + Rules\"\n",
        "DOM_ID_PREFIX = \"g2-\"  # all HTML ids/classes must begin with \"g2-\"\n",
        "NS_PREFIX = \"G2_\"      # Python-visible constant/function prefix\n",
        "\n",
        "# ---------- Encoding ----------\n",
        "ENC = \"iso-8859-15\"\n",
        "\n",
        "# ---------- Environment / FTP ----------\n",
        "FTP_HOST = os.getenv(\"FTP_HOST\", \"\")\n",
        "FTP_USER = os.getenv(\"FTP_USER\", \"\")\n",
        "FTP_PASS = os.getenv(\"FTP_PASS\", \"\")\n",
        "FTP_DIR  = os.getenv(\"FTP_DIR\", \"/gengen/\")\n",
        "FTP_TIMEOUT = int(os.getenv(\"FTP_TIMEOUT\", \"45\"))\n",
        "FTP_TLS_REQUIRED = True  # enforce FTPS\n",
        "\n",
        "# ---------- File naming (Gold 2: Register) ----------\n",
        "LOCAL_NAME  = os.getenv(\"G2_LOCAL_NAME\",  \"ons_yates_dna_register.htm\")\n",
        "REMOTE_NAME = os.getenv(\"G2_REMOTE_NAME\", \"ons_yates_dna_register.htm\")\n",
        "\n",
        "# Partials unique to Gold 2\n",
        "PARTIAL_MATCH_COUNT   = os.getenv(\"G2_PARTIAL_MATCH_COUNT\",   \"partials/match_count.htm\")\n",
        "PARTIAL_LINEAGE_COUNT = os.getenv(\"G2_PARTIAL_LINEAGE_COUNT\", \"partials/lineage_count.htm\")\n",
        "PARTIAL_PRINTABLE     = os.getenv(\"G2_PARTIAL_PRINTABLE\",     \"partials/cousin_list_print.htm\")\n",
        "\n",
        "# Optional counters/diagnostics (distinct from Gold 3)\n",
        "COUNT_PUBLIC_URL = os.getenv(\"G2_COUNT_PUBLIC_URL\", \"\")\n",
        "LOCAL_COUNT_FILE = os.getenv(\"G2_LOCAL_COUNT_FILE\", \"autosomal_count.txt\")\n",
        "REMOTE_COUNT_NAME = os.getenv(\"G2_REMOTE_COUNT_NAME\", \"autosomal_count.txt\")\n",
        "\n",
        "# ---------- Paths ----------\n",
        "def _remote_path(name: str) -> str:\n",
        "    \"\"\"Join FTP_DIR and name with posix semantics.\"\"\"\n",
        "    base = FTP_DIR.rstrip(\"/\")\n",
        "    return f\"{base}/{name.lstrip('/')}\"\n",
        "\n",
        "# ---------- FTP helpers (namespaced logic, no side effects on import) ----------\n",
        "def ftp_connect() -> FTP_TLS:\n",
        "    \"\"\"Return a logged-in FTPS handle with passive mode and timeout.\"\"\"\n",
        "    if not FTP_HOST or not FTP_USER or not FTP_PASS:\n",
        "        raise RuntimeError(\"FTP credentials are not set in environment variables.\")\n",
        "    ftps = FTP_TLS(timeout=FTP_TIMEOUT)\n",
        "    ftps.connect(host=FTP_HOST, port=21)\n",
        "    ftps.auth()  # upgrade to TLS\n",
        "    ftps.prot_p()  # secure data connection\n",
        "    ftps.login(user=FTP_USER, passwd=FTP_PASS)\n",
        "    ftps.set_pasv(True)\n",
        "    # Best-effort hostname note (for diagnostics)\n",
        "    try:\n",
        "        ftps.hostname = socket.gethostbyname(FTP_HOST)  # type: ignore[attr-defined]\n",
        "    except Exception:\n",
        "        pass\n",
        "    return ftps\n",
        "\n",
        "def ftp_upload_overwrite(ftps: FTP_TLS, local_path: str, remote_name: str) -> None:\n",
        "    \"\"\"Upload file to FTP_DIR/remote_name, overwriting if exists.\"\"\"\n",
        "    remote = _remote_path(remote_name)\n",
        "    # Ensure remote directory exists (best-effort, ignore failures on nested)\n",
        "    parts = remote.split(\"/\")\n",
        "    dir_parts, filename = parts[:-1], parts[-1]\n",
        "    cwd = \"/\"\n",
        "    try:\n",
        "        ftps.cwd(\"/\")\n",
        "    except Exception:\n",
        "        pass\n",
        "    for d in dir_parts:\n",
        "        if not d:\n",
        "            continue\n",
        "        cwd = posixpath.join(cwd, d)\n",
        "        try:\n",
        "            ftps.mkd(cwd)\n",
        "        except Exception:\n",
        "            pass\n",
        "    with open(local_path, \"rb\") as fh:\n",
        "        ftps.storbinary(f\"STOR {remote}\", fh)\n",
        "\n",
        "# ---------- Guardrails ----------\n",
        "# This script must not import or reference any G3_* symbols.\n",
        "# All DOM ids, classes, and JS functions created by this script must use the \"g2-\" prefix.\n",
        "# All files written by this script must use the Gold 2 filenames defined above.\n",
        "# ====== CUT STOP  [A] REFACTOR-Gold 2 — Add 5 returns for spacing ================\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "# ====== CUT START [B] REFACTOR-Gold 2 — Helpers / Resolver (root-level /partials + utilities) ====\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import os, io, re, csv, posixpath\n",
        "from typing import Dict, Tuple, List, Optional\n",
        "\n",
        "try:\n",
        "    import pandas as pd\n",
        "except Exception:\n",
        "    pd = None\n",
        "\n",
        "# ---------- Display / DOM / TNG defaults (Gold 2 only) ----------\n",
        "DOM_ID_PREFIX = globals().get(\"DOM_ID_PREFIX\", \"g2-\")\n",
        "NS_PREFIX     = globals().get(\"NS_PREFIX\", \"G2_\")\n",
        "\n",
        "# Column A width (Match Summary) and total table width (pixels)\n",
        "COL_A_PX       = int(os.getenv(\"G2_COL_A_PX\", \"520\"))\n",
        "TABLE_WIDTH_PX = int(os.getenv(\"G2_TABLE_WIDTH_PX\", \"1200\"))\n",
        "\n",
        "# Text headers/entities\n",
        "LINEAGE_HEADER  = \"Lineage (Starting with oldest ancestor, the line is:)\"\n",
        "ARROW_ENTITY    = \"&rarr;\"\n",
        "\n",
        "# TNG linking (used in [4/6])\n",
        "TNG_BASE = os.getenv(\"TNG_BASE\", \"https://yates.one-name.net/tng\")\n",
        "TNG_TREE = os.getenv(\"TNG_TREE\", \"yates\")\n",
        "\n",
        "# Side artifact CSV (Column A export) used by [4/6] and [6/6]\n",
        "MATCH_COUSINS_CSV = os.getenv(\"G2_MATCH_COUSINS_CSV\", \"the_match_cousins.csv\")\n",
        "\n",
        "# ---------- Absolute root-level /partials support (Resolver) ----------\n",
        "# Primary location: /partials/match_to_unmasked.csv (absolute from server root)\n",
        "# Fallback location: /gengen/partials/match_to_unmasked.csv (under FTP_DIR)\n",
        "SERVER_PARTIALS_DIR     = os.getenv(\"G2_SERVER_PARTIALS_DIR\", \"/partials\")\n",
        "SERVER_MAPPING_BASENAME = os.getenv(\"G2_SERVER_MAPPING_BASENAME\", \"match_to_unmasked.csv\")\n",
        "LOCAL_MAPPING_CACHE     = os.getenv(\"G2_LOCAL_MAPPING_CACHE\", \"match_to_unmasked.csv\")\n",
        "\n",
        "def _remote_abs(*parts: str) -> str:\n",
        "    \"\"\"Join into an absolute POSIX path that DOES NOT prepend FTP_DIR.\"\"\"\n",
        "    cleaned = [str(p).strip(\"/\") for p in parts if p is not None]\n",
        "    return \"/\" + \"/\".join([p for p in cleaned if p])\n",
        "\n",
        "def _remote_under_ftpdir(name: str) -> str:\n",
        "    \"\"\"Fallback to FTP_DIR-prefixed path (e.g., /gengen/partials/...).\"\"\"\n",
        "    base = str(globals().get(\"FTP_DIR\", \"/\")).rstrip(\"/\")\n",
        "    return f\"{base}/{name.lstrip('/')}\"\n",
        "\n",
        "def _ftps_fetch_to_local(ftps, remote_path: str, local_path: str) -> Tuple[bool, str]:\n",
        "    \"\"\"Try to RETR a remote file to local_path. Return (ok, error_text).\"\"\"\n",
        "    try:\n",
        "        parent = os.path.dirname(local_path)\n",
        "        if parent and not os.path.isdir(parent):\n",
        "            os.makedirs(parent, exist_ok=True)\n",
        "        with open(local_path, \"wb\") as fh:\n",
        "            ftps.retrbinary(f\"RETR {remote_path}\", fh.write)\n",
        "        return True, \"\"\n",
        "    except Exception as e:\n",
        "        return False, f\"{type(e).__name__}: {e}\"\n",
        "\n",
        "def _detect_cols(df) -> Tuple[str, str]:\n",
        "    \"\"\"Pick code and unmasked columns from a DataFrame by heuristics.\"\"\"\n",
        "    cols = [str(c) for c in df.columns]\n",
        "    code_candidates = [\"Match to\", \"match_to\", \"match to\", \"code\", \"Code\"]\n",
        "    name_candidates = [\"Unmasked\", \"unmasked\", \"name\", \"Name\", \"Unmask\", \"unmask\"]\n",
        "    def pick(cands):\n",
        "        for c in cols:\n",
        "            cl = c.lower().replace(\" \", \"\")\n",
        "            for k in cands:\n",
        "                if cl == k.replace(\" \", \"\").lower():\n",
        "                    return c\n",
        "        return None\n",
        "    code_col = pick(code_candidates) or (cols[0] if cols else \"\")\n",
        "    name_col = pick(name_candidates) or (cols[1] if len(cols) > 1 else cols[0] if cols else \"\")\n",
        "    return code_col, name_col\n",
        "\n",
        "def _read_resolver_csv(local_path: str) -> Dict[str, str]:\n",
        "    \"\"\"Load resolver csv to {code: unmasked} with minimal normalization.\"\"\"\n",
        "    if pd is not None:\n",
        "        df = pd.read_csv(local_path, dtype=str, encoding=\"iso-8859-15\", keep_default_na=False)\n",
        "        code_col, name_col = _detect_cols(df)\n",
        "        mapping = {}\n",
        "        for _, row in df.iterrows():\n",
        "            k = str(row.get(code_col, \"\")).strip()\n",
        "            v = str(row.get(name_col, \"\")).strip()\n",
        "            if k:\n",
        "                mapping[k] = v\n",
        "        return mapping\n",
        "    # Fallback without pandas\n",
        "    mapping = {}\n",
        "    with open(local_path, \"r\", encoding=\"iso-8859-15\", errors=\"replace\", newline=\"\") as fh:\n",
        "        reader = csv.reader(fh)\n",
        "        rows = list(reader)\n",
        "    if not rows:\n",
        "        return mapping\n",
        "    header = rows[0]\n",
        "    if len(header) >= 2 and not header[0].strip().isdigit():\n",
        "        data_rows = rows[1:]\n",
        "        code_idx = 0\n",
        "        name_idx = 1\n",
        "    else:\n",
        "        data_rows = rows\n",
        "        code_idx = 0\n",
        "        name_idx = 1 if len(rows[0]) > 1 else 0\n",
        "    for r in data_rows:\n",
        "        if not r:\n",
        "            continue\n",
        "        k = (r[code_idx] if len(r) > code_idx else \"\").strip()\n",
        "        v = (r[name_idx] if len(r) > name_idx else \"\").strip()\n",
        "        if k:\n",
        "            mapping[k] = v\n",
        "    return mapping\n",
        "\n",
        "def load_resolver_from_server() -> Dict[str, str]:\n",
        "    \"\"\"Load resolver CSV from root-level /partials first, then fallback to /gengen/partials.\"\"\"\n",
        "    if \"ftp_connect\" not in globals():\n",
        "        raise RuntimeError(\"ftp_connect() is not available; ensure Section [A] is loaded first.\")\n",
        "    ftps = ftp_connect()\n",
        "    try:\n",
        "        primary  = _remote_abs(SERVER_PARTIALS_DIR, SERVER_MAPPING_BASENAME)  # /partials/match_to_unmasked.csv\n",
        "        ok, err  = _ftps_fetch_to_local(ftps, primary, LOCAL_MAPPING_CACHE)\n",
        "        if not ok:\n",
        "            fallback = _remote_under_ftpdir(posixpath.join(\"partials\", SERVER_MAPPING_BASENAME))\n",
        "            ok2, err2 = _ftps_fetch_to_local(ftps, fallback, LOCAL_MAPPING_CACHE)\n",
        "            if not ok2:\n",
        "                raise RuntimeError(\n",
        "                    \"Resolver not found on server at either location:\\n\"\n",
        "                    f\"  1) {primary}\\n\"\n",
        "                    f\"  2) {fallback}\\n\"\n",
        "                    \"Action: Upload match_to_unmasked.csv to /partials/ (root) or to /gengen/partials/ and re-run.\\n\"\n",
        "                    f\"Details: primary error: {err}; fallback error: {err2}\"\n",
        "                )\n",
        "        mapping = _read_resolver_csv(LOCAL_MAPPING_CACHE)\n",
        "        return mapping\n",
        "    finally:\n",
        "        try:\n",
        "            ftps.quit()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "# Global resolver dict (available to other sections)\n",
        "MATCH_TO_UNMASKED = load_resolver_from_server()\n",
        "\n",
        "# ---------- Published helpers to other sections ----------\n",
        "\n",
        "def resolve_match_to(code_value: str) -> str:\n",
        "    \"\"\"Return unmasked name for a resolver 'Match to' code, or empty string if unknown.\"\"\"\n",
        "    if not code_value and code_value != 0:\n",
        "        return \"\"\n",
        "    code = str(code_value).strip()\n",
        "    if not code:\n",
        "        return \"\"\n",
        "    return MATCH_TO_UNMASKED.get(code, \"\")\n",
        "\n",
        "def html_escape(s: str) -> str:\n",
        "    import html as _h\n",
        "    return _h.escape(\"\" if s is None else str(s), quote=True)\n",
        "\n",
        "def smart_titlecase(s: str) -> str:\n",
        "    \"\"\"Title-case with a few surname niceties; ASCII/iso-8859-15 safe.\"\"\"\n",
        "    if not isinstance(s, str):\n",
        "        return \"\"\n",
        "    s = re.sub(r\"\\s+\", \" \", s.strip())\n",
        "    if not s:\n",
        "        return \"\"\n",
        "    parts = s.split(\" \")\n",
        "    out = []\n",
        "    for p in parts:\n",
        "        if not p:\n",
        "            out.append(\"\")\n",
        "            continue\n",
        "        # O'Neill, O'CONNOR\n",
        "        m = re.match(r\"^([Oo]')([A-Za-z]+)$\", p)\n",
        "        if m:\n",
        "            out.append(m.group(1).capitalize() + m.group(2).capitalize())\n",
        "            continue\n",
        "        # Mc/Mac\n",
        "        m = re.match(r\"^(Mc|MC)([A-Za-z]+)$\", p)\n",
        "        if m:\n",
        "            out.append(\"Mc\" + m.group(2).capitalize())\n",
        "            continue\n",
        "        if \"-\" in p:\n",
        "            out.append(\"-\".join([x.capitalize() for x in p.split(\"-\")]))\n",
        "        else:\n",
        "            out.append(p.capitalize())\n",
        "    return \" \".join(out)\n",
        "\n",
        "def truncate_first(name: str, n: int = 7) -> str:\n",
        "    \"\"\"Truncate the first token to n letters, keep the rest as-is.\"\"\"\n",
        "    if not isinstance(name, str):\n",
        "        return \"\"\n",
        "    name = smart_titlecase(name)\n",
        "    toks = name.split()\n",
        "    if not toks:\n",
        "        return \"\"\n",
        "    first = re.sub(r\"[^A-Za-z]\", \"\", toks[0])[:max(1, n)]\n",
        "    return \" \".join([first] + toks[1:]) if len(toks) > 1 else first\n",
        "\n",
        "_CAMEL_WORDS = re.compile(r\"[A-Z][a-z]*|[A-Z]+(?![a-z])|[a-z]+\")\n",
        "\n",
        "def surname_given_from_token(tok: str) -> Tuple[str, str, str]:\n",
        "    \"\"\"\n",
        "    Parse glued or CamelCase tokens like 'RosenbalmJessica' or 'ReedLindaGai'.\n",
        "    Returns (full_name, surname, given). Full name is 'Given Surname'.\n",
        "    Falls back to simple titlecase of tok if nothing reliable found.\n",
        "    \"\"\"\n",
        "    raw = str(tok or \"\").strip()\n",
        "    if not raw:\n",
        "        return (\"\", \"\", \"\")\n",
        "    # Already spaced or comma\n",
        "    if \" \" in raw or \",\" in raw:\n",
        "        nm = smart_titlecase(raw)\n",
        "        parts = nm.split()\n",
        "        if len(parts) == 1:\n",
        "            return (nm, parts[0], \"\")\n",
        "        given = parts[0]\n",
        "        surname = parts[-1]\n",
        "        return (f\"{given} {surname}\", surname, given)\n",
        "    # Camel extraction\n",
        "    words = _CAMEL_WORDS.findall(raw)\n",
        "    while words and len(words[0]) == 1:\n",
        "        words.pop(0)\n",
        "    if not words:\n",
        "        nm = smart_titlecase(raw)\n",
        "        ps = nm.split()\n",
        "        if len(ps) == 1:\n",
        "            return (nm, ps[0], \"\")\n",
        "        return (f\"{ps[0]} {ps[-1]}\", ps[-1], ps[0])\n",
        "    surname = smart_titlecase(words[0])\n",
        "    given_candidates = [w for w in words[1:] if w.lower() != surname.lower()]\n",
        "    if not given_candidates:\n",
        "        return (surname, surname, \"\")\n",
        "    given = smart_titlecase(given_candidates[0])\n",
        "    return (f\"{given} {surname}\", surname, given)\n",
        "\n",
        "def split_tokens(path_str: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Split lineage path into tokens (oldest → youngest).\n",
        "    Supports '→', '->', '&rarr;', ' > ' and single '>' as separators.\n",
        "    \"\"\"\n",
        "    s = str(path_str or \"\")\n",
        "    if not s.strip():\n",
        "        return []\n",
        "    s = s.replace(\"&rarr;\", \"→\")\n",
        "    s = re.sub(r\"\\s*->\\s*\", \" → \", s)\n",
        "    s = re.sub(r\"\\s*>\\s*\", \" → \", s)\n",
        "    parts = [p.strip() for p in s.split(\"→\")]\n",
        "    return [p for p in parts if p]\n",
        "\n",
        "def derive_common_from_first_token(tokens: List[str]) -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Given lineage tokens, return (husband, wife) from the first token.\n",
        "    Supports 'A & B' as well as glued 'YatesStephen&ParsonsLydia' variants.\n",
        "    \"\"\"\n",
        "    if not tokens:\n",
        "        return (\"\", \"\")\n",
        "    t0 = tokens[0].strip()\n",
        "    if \"&\" in t0:\n",
        "        a, b = [smart_titlecase(p.strip()) for p in t0.split(\"&\", 1)]\n",
        "        return (a, b)\n",
        "    # Try to split glued halves around last uppercase run\n",
        "    m = re.match(r\"^(.*?)([A-Z][a-zA-Z]+)&([A-Z][a-zA-Z].*)$\", t0)\n",
        "    if m:\n",
        "        return (smart_titlecase(m.group(2)), smart_titlecase(m.group(3)))\n",
        "    # Fallback: best-effort two-name recovery using commas or spaces\n",
        "    bits = re.split(r\"\\s*,\\s*|\\s+and\\s+|\\s*\\+\\s*|\\s*/\\s*\", t0, maxsplit=1)\n",
        "    if len(bits) == 2:\n",
        "        return (smart_titlecase(bits[0]), smart_titlecase(bits[1]))\n",
        "    return (smart_titlecase(t0), \"\")\n",
        "\n",
        "def build_header(\n",
        "    subject_name_b_html: str,\n",
        "    cm_val: str,\n",
        "    matchee_html: str,\n",
        "    gens_total: int,\n",
        "    common_husband_short: str,\n",
        "    common_wife_short: str\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Compose the Match Summary sentence (HTML). Inputs should already be escaped where needed.\n",
        "    \"\"\"\n",
        "    cm_txt   = html_escape(cm_val)\n",
        "    gens_txt = f\"{int(gens_total)}\" if str(gens_total).isdigit() else html_escape(gens_total)\n",
        "    pair_txt = \"\"\n",
        "    if common_husband_short or common_wife_short:\n",
        "        a = html_escape(common_husband_short or \"\")\n",
        "        b = html_escape(common_wife_short or \"\")\n",
        "        if a and b:\n",
        "            pair_txt = f\" &mdash; oldest DISTANT common ancestors: {a} &amp; {b}\"\n",
        "        else:\n",
        "            pair_txt = f\" &mdash; oldest DISTANT common ancestor: {a or b}\"\n",
        "    return (\n",
        "        f\"{subject_name_b_html} shares <strong>{cm_txt} cM</strong> with {matchee_html} \"\n",
        "        f\"across a documented path of <strong>{gens_txt}</strong> steps.{pair_txt}\"\n",
        "    )\n",
        "\n",
        "def normalize_person_name(s: str) -> str:\n",
        "    \"\"\"Return a title-cased person name with safe punctuation for XHTML/iso-8859-15.\"\"\"\n",
        "    if not isinstance(s, str):\n",
        "        return \"\"\n",
        "    s = s.strip()\n",
        "    if not s:\n",
        "        return \"\"\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return html_escape(smart_titlecase(s))\n",
        "\n",
        "# ---------- General helpers used by [3]/[4]/[5]/[6] ----------\n",
        "\n",
        "def find_col(df, regex_list: Optional[List[str]] = None, fallback_list: Optional[List[str]] = None) -> Optional[str]:\n",
        "    \"\"\"Find a column by regex OR fallback names; returns the first match or None.\"\"\"\n",
        "    if df is None or getattr(df, \"columns\", None) is None:\n",
        "        return None\n",
        "    regex_list = regex_list or []\n",
        "    fallback_list = fallback_list or []\n",
        "    cols = list(df.columns)\n",
        "\n",
        "    for pattern in regex_list:\n",
        "        try:\n",
        "            rx = re.compile(pattern, flags=re.IGNORECASE)\n",
        "        except Exception:\n",
        "            continue\n",
        "        for c in cols:\n",
        "            if rx.search(str(c)):\n",
        "                return c\n",
        "\n",
        "    for name in fallback_list:\n",
        "        target = str(name).strip().lower()\n",
        "        for c in cols:\n",
        "            if str(c).strip().lower() == target:\n",
        "                return c\n",
        "\n",
        "    return cols[0] if cols else None\n",
        "\n",
        "def find_cols(df, patterns_or_names: List[str]) -> List[str]:\n",
        "    \"\"\"Return all columns that match any regex or exact name (case-insensitive).\"\"\"\n",
        "    hits = []\n",
        "    if df is None or getattr(df, \"columns\", None) is None:\n",
        "        return hits\n",
        "    cols = list(df.columns)\n",
        "    for token in patterns_or_names:\n",
        "        is_regex = bool(re.search(r\"[\\\\^$.*+?()\\\\[\\\\]|]\", token))\n",
        "        if is_regex:\n",
        "            try:\n",
        "                rx = re.compile(token, flags=re.IGNORECASE)\n",
        "            except Exception:\n",
        "                continue\n",
        "            for c in cols:\n",
        "                if rx.search(str(c)):\n",
        "                    hits.append(c)\n",
        "        else:\n",
        "            low = token.strip().lower()\n",
        "            for c in cols:\n",
        "                if str(c).strip().lower() == low:\n",
        "                    hits.append(c)\n",
        "    seen, uniq = set(), []\n",
        "    for c in hits:\n",
        "        if c not in seen:\n",
        "            uniq.append(c); seen.add(c)\n",
        "    return uniq\n",
        "\n",
        "def normalize_colnames(df):\n",
        "    \"\"\"Return a copy with normalized lowercase, single-space column names (no mutation).\"\"\"\n",
        "    if df is None or getattr(df, \"columns\", None) is None:\n",
        "        return df\n",
        "    new = df.copy()\n",
        "    new.columns = [re.sub(r\"\\s+\", \" \", str(c)).strip().lower() for c in df.columns]\n",
        "    return new\n",
        "\n",
        "def coalesce_col(df, candidates: List[str]) -> Optional[str]:\n",
        "    \"\"\"Return the first existing column from candidates (exact match).\"\"\"\n",
        "    if df is None or getattr(df, \"columns\", None) is None:\n",
        "        return None\n",
        "    cols = set([str(c) for c in df.columns])\n",
        "    for c in candidates:\n",
        "        if c in cols:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def comma_int(n) -> str:\n",
        "    try:\n",
        "        return f\"{int(float(str(n).replace(',', ''))):,}\"\n",
        "    except Exception:\n",
        "        return str(n)\n",
        "\n",
        "def is_htmlish(s: str) -> bool:\n",
        "    if not isinstance(s, str):\n",
        "        return False\n",
        "    return (\"<a \" in s) or (\"<span\" in s) or (\"<div\" in s) or (\"<br\" in s) or (\"</\" in s)\n",
        "\n",
        "def safe_get(row, col, default=\"\"):\n",
        "    try:\n",
        "        return row.get(col, default)\n",
        "    except Exception:\n",
        "        try:\n",
        "            return row[col]\n",
        "        except Exception:\n",
        "            return default\n",
        "\n",
        "def slugify(s: str) -> str:\n",
        "    s = re.sub(r\"[^A-Za-z0-9]+\", \"-\", str(s)).strip(\"-\")\n",
        "    s = re.sub(r\"-{2,}\", \"-\", s)\n",
        "    return s.lower()\n",
        "\n",
        "# ====== CUT STOP  [B] REFACTOR-Gold 2 — Add 5 returns for spacing ===============================\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "# ====== CUT START [3/6] REFACTOR-Gold 2 — CSV Load + Column Detection + Row Helpers ================\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import os, re, pandas as pd, urllib.parse as _u\n",
        "\n",
        "# Use the path defined earlier; default to expected file\n",
        "CSV_IN = os.environ.get(\"CSV_IN\", CSV_PATH if 'CSV_PATH' in globals() else \"/content/final_combined_df_with_value_labels.csv\")\n",
        "\n",
        "# ---- Load CSV (robust encodings) ----\n",
        "_encs = (\"utf-8-sig\", \"utf-8\", \"cp1252\", \"iso-8859-15\", \"latin1\")\n",
        "_last_err = None\n",
        "df = None\n",
        "for _e in _encs:\n",
        "    try:\n",
        "        df = pd.read_csv(CSV_IN, encoding=_e, dtype=str, keep_default_na=False)\n",
        "        break\n",
        "    except Exception as _ex:\n",
        "        _last_err = _ex\n",
        "        df = None\n",
        "if df is None:\n",
        "    raise RuntimeError(f\"Unable to read CSV: {CSV_IN} ({_last_err})\")\n",
        "print(f\"✅ Loaded CSV — {len(df)} rows, {len(df.columns)} columns from {os.path.abspath(CSV_IN)}\")\n",
        "\n",
        "# ---- Locate columns (names vary slightly across exports) ----\n",
        "# relies on find_col() from [2/6]\n",
        "id_col = find_col(\n",
        "    df,\n",
        "    [r'^(id#|personid)$', r'^\\s*id\\s*#?\\s*$', r'^person\\s*id$'],\n",
        "    [\"ID#\", \"ID\", \"PersonID\", \"personID\", \"person id\", \"id #\"]\n",
        ")\n",
        "match_to_col  = find_col(df, [r'^match\\s*to$'], [\"Match to\",\"Match\"])\n",
        "name_col      = find_col(df, [r'^name$'], [\"Name\"])\n",
        "cm_col        = find_col(df, [r'^(c\\s*:?m|cm)$', r'centi.?morgan'], [\"cM\",\"cm\"])\n",
        "path_col      = find_col(df, [r'(yates\\s*dna\\s*ancestral\\s*line|ancestral\\s*line|lineage)'],\n",
        "                         [\"Yates DNA Ancestral Line\",\"Ancestral Line\",\"Lineage\"])\n",
        "\n",
        "if not match_to_col: raise ValueError(\"CSV missing 'Match to' column.\")\n",
        "if not name_col:     raise ValueError(\"CSV missing 'Name' column.\")\n",
        "if not cm_col:       raise ValueError(\"CSV missing 'cM' column.\")\n",
        "if not path_col:     raise ValueError(\"CSV missing lineage/path column.\")\n",
        "\n",
        "# --- Back-compat aliases: ensure literal \"ID#\" and \"id#\" both exist to stop KeyErrors in legacy paths ---\n",
        "if id_col and id_col in df.columns:\n",
        "    if \"ID#\" not in df.columns:\n",
        "        df[\"ID#\"] = df[id_col]\n",
        "    if \"id#\" not in df.columns:\n",
        "        df[\"id#\"] = df[id_col]\n",
        "else:\n",
        "    # No detectable id column: create empty aliases so any legacy access won't crash\n",
        "    if \"ID#\" not in df.columns:\n",
        "        df[\"ID#\"] = \"\"\n",
        "    if \"id#\" not in df.columns:\n",
        "        df[\"id#\"] = \"\"\n",
        "\n",
        "# ---- Row helpers (match ID, camel-case names, etc.) ----\n",
        "ID_PAT = re.compile(r\"\\bI\\d+\\b\", re.I)\n",
        "_CAMEL_WORDS = re.compile(r\"[A-Z][a-z]*|[A-Z]+(?![a-z])|[a-z]+\")\n",
        "\n",
        "def extract_person_id(s: str) -> str:\n",
        "    \"\"\"Return TNG-style personID like 'I1234' if present, else ''.\"\"\"\n",
        "    m = ID_PAT.search(str(s or \"\"))\n",
        "    return m.group(0).upper() if m else \"\"\n",
        "\n",
        "def _truncate_alpha(s: str, n: int) -> str:\n",
        "    \"\"\"Keep only letters, truncate to n.\"\"\"\n",
        "    return re.sub(r\"[^A-Za-z]\", \"\", s)[:n]\n",
        "\n",
        "def norm_matchee_name(raw: str) -> str:\n",
        "    \"\"\"\n",
        "    Normalize single-token CSV names like 'RosenbalmJessica' or 'ReedLindaGai'\n",
        "    into 'Jessica Rosenbalm' / 'Linda Reed', with given-name truncated to 7.\n",
        "    Uses smart_titlecase()/surname_given_from_token() from [2/6].\n",
        "    \"\"\"\n",
        "    raw = str(raw or \"\").strip()\n",
        "    if not raw:\n",
        "        return \"\"\n",
        "    # If already spaced/comma, just titlecase and use first token as given, last as surname\n",
        "    if \" \" in raw or \",\" in raw:\n",
        "        nm = smart_titlecase(raw)\n",
        "        parts = nm.split()\n",
        "        if len(parts) == 1:\n",
        "            return nm\n",
        "        given = parts[0]\n",
        "        surname = parts[-1]\n",
        "        return f\"{_truncate_alpha(given, 7)} {surname}\".strip()\n",
        "    # CamelCase (or glued lowercase tail) token\n",
        "    words = _CAMEL_WORDS.findall(raw)\n",
        "    while words and len(words[0]) == 1:\n",
        "        words.pop(0)  # drop leading initials\n",
        "    if not words:\n",
        "        nm = smart_titlecase(surname_given_from_token(raw)[0])\n",
        "        ps = nm.split()\n",
        "        if len(ps) == 1:\n",
        "            return nm\n",
        "        return f\"{_truncate_alpha(ps[0], 7)} {ps[-1]}\".strip()\n",
        "    surname = smart_titlecase(words[0])\n",
        "    given_candidates = [w for w in words[1:] if w.lower() != surname.lower()]\n",
        "    if not given_candidates:\n",
        "        return surname\n",
        "    given = smart_titlecase(given_candidates[0])\n",
        "    return f\"{_truncate_alpha(given, 7)} {surname}\".strip()\n",
        "\n",
        "print(\"✅ Columns:\", {\n",
        "    \"ID (detected)\": id_col or \"(none; using 'ID#' alias)\",\n",
        "    \"Match to\": match_to_col,\n",
        "    \"Name\": name_col,\n",
        "    \"cM\": cm_col,\n",
        "    \"Lineage\": path_col\n",
        "})\n",
        "# ====== CUT STOP [3/6] REFACTOR-Gold 2 — CSV Load + Column Detection + Row Helpers =================\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ====== CUT START [4/6] REFACTOR-Gold 2 — Transform & Column A (build display_df) ==================\n",
        "import urllib.parse as _u\n",
        "\n",
        "# ---------- Build the three display columns ----------\n",
        "headers  = []\n",
        "lineages = []\n",
        "findcol  = []\n",
        "\n",
        "# Allow absolute link to this page: /{REMOTE_NAME}?q=...\n",
        "REMOTE_NAME_ABS = \"/\" + (REMOTE_NAME if 'REMOTE_NAME' in globals() else \"ons_yates_dna_register.htm\")\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    # Subject: the resolver code in \"Match to\" → unmasked name (bolded in sentence)\n",
        "    subject_raw  = row.get(match_to_col, \"\")\n",
        "    subject_name = normalize_person_name(resolve_match_to(subject_raw))\n",
        "    subject_name_b = f\"<strong>{subject_name}</strong>\" if subject_name else subject_name\n",
        "\n",
        "    # Matchee: name from CSV (normalized) + TNG hotlink if personID present\n",
        "    pid = extract_person_id(row.get(id_col, \"\"))\n",
        "    matchee_name = norm_matchee_name(row.get(name_col, \"\")) or subject_name\n",
        "    if pid:\n",
        "        matchee_html = (\n",
        "            f'<a href=\"{TNG_BASE}/verticalchart.php?personID={pid}&tree={TNG_TREE}&parentset=0&display=vertical&generations=15\" '\n",
        "            f'target=\"_blank\">{matchee_name}</a>'\n",
        "        )\n",
        "    else:\n",
        "        matchee_html = matchee_name\n",
        "\n",
        "    # cM value\n",
        "    cm_val = row.get(cm_col, \"0\")\n",
        "\n",
        "    # Lineage path (tokens oldest→youngest); first token is common couple\n",
        "    tokens     = split_tokens(row.get(path_col, \"\"))\n",
        "    gens_total = len(tokens)\n",
        "    tokens_disp = tokens[:7]  # show first 7 pairs\n",
        "\n",
        "    # Husband & Wife from first token unless explicit columns exist\n",
        "    if \"common_husband\" in df.columns and \"common_wife\" in df.columns:\n",
        "        husband_raw = str(row.get(\"common_husband\", \"\")).strip()\n",
        "        wife_raw    = str(row.get(\"common_wife\", \"\")).strip()\n",
        "        if not husband_raw and not wife_raw:\n",
        "            husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "    else:\n",
        "        husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "\n",
        "    # Build the sentence header (truncate first names to 7 chars for readability)\n",
        "    header_html = build_header(\n",
        "        subject_name_b,\n",
        "        cm_val,\n",
        "        matchee_html,\n",
        "        gens_total,\n",
        "        truncate_first(husband_raw, 7) if husband_raw else \"\",\n",
        "        truncate_first(wife_raw, 7) if wife_raw else \"\"\n",
        "    )\n",
        "\n",
        "    # Bold the first pair in lineage view\n",
        "    if tokens_disp:\n",
        "        tokens_disp[0] = f\"<strong>{tokens_disp[0]}</strong>\"\n",
        "    sep = f\" {ARROW_ENTITY} \"\n",
        "    lineage_text = sep.join(tokens_disp) if tokens_disp else \"\"\n",
        "\n",
        "    # Per-row quick-open search button (?q=Subject Name)\n",
        "    q = _u.quote(subject_name)\n",
        "    quick = (f'<a class=\"find-btn\" href=\"{REMOTE_NAME_ABS}?q={q}\" target=\"_blank\" rel=\"noopener\" '\n",
        "             f'title=\"Open a filtered view for {subject_name}\">Find</a>')\n",
        "\n",
        "    headers.append(header_html)\n",
        "    lineages.append(lineage_text)\n",
        "    findcol.append(quick)\n",
        "\n",
        "# Ensure constant used for the lineage column heading exists\n",
        "LINEAGE_HEADER_SAFE = LINEAGE_HEADER if 'LINEAGE_HEADER' in globals() else \"Lineage (Starting with oldest ancestor, the line is:)\"\n",
        "\n",
        "# Assemble the display dataframe (GUARDED so “Find” always exists)\n",
        "df[\"Match Summary\"]             = headers\n",
        "df[LINEAGE_HEADER_SAFE]         = lineages\n",
        "df[\"Find\"]                      = findcol  # guarantees presence for [5/6]\n",
        "display_df = df[[\"Find\", \"Match Summary\", LINEAGE_HEADER_SAFE]]\n",
        "\n",
        "# Column A CSV for side-uses\n",
        "display_df[[\"Match Summary\"]].to_csv(MATCH_COUSINS_CSV, index=False, encoding=\"iso-8859-15\")\n",
        "print(\"✅ Wrote local CSV (Column A):\", os.path.abspath(MATCH_COUSINS_CSV))\n",
        "# ====== CUT STOP [4/6] REFACTOR-Gold 2 — Transform & Column A (build display_df) ===================\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ====== CUT START [5/6] REFACTOR-Gold 2 — HTML (table + CSS + JS, no uploads) ======================\n",
        "import html as _html\n",
        "\n",
        "# Use this as the Home link everywhere\n",
        "HOME_URL = \"https://yates.one-name.net/ons_yates_dna_register.htm\"\n",
        "\n",
        "# ---------- Build HTML table ----------\n",
        "# Assumes display_df + LINEAGE_HEADER_SAFE were prepared in earlier sections\n",
        "display_for_html = display_df\n",
        "\n",
        "html_table = display_for_html[[\"Find\", \"Match Summary\", LINEAGE_HEADER_SAFE]].to_html(\n",
        "    index=False, escape=False, classes=\"sortable\"\n",
        ")\n",
        "\n",
        "# tag table + first row\n",
        "html_table = html_table.replace(\n",
        "    '<table border=\"1\" class=\"dataframe sortable\">',\n",
        "    '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">', 1\n",
        ")\n",
        "html_table = html_table.replace('<tbody>\\n<tr>', '<tbody>\\n<tr id=\"first-row\">', 1)\n",
        "\n",
        "# widths via <colgroup>\n",
        "FIND_PX = 110  # width of Find column (checkbox + Email + Find). Adjust here.\n",
        "colgroup_html = (\n",
        "    \"<colgroup>\\n\"\n",
        "    f\"  <col style=\\\"width:{FIND_PX}px;\\\" />\\n\"\n",
        "    f\"  <col style=\\\"width:{COL_A_PX}px;\\\" />\\n\"\n",
        "    \"  <col />\\n\"\n",
        "    \"</colgroup>\\n\"\n",
        ")\n",
        "html_table = html_table.replace(\n",
        "    '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">',\n",
        "    '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">\\n' + colgroup_html, 1\n",
        ")\n",
        "\n",
        "# add Select-all checkbox to header cell “Find”\n",
        "html_table = html_table.replace(\n",
        "    \"<th>Find</th>\",\n",
        "    \"<th>Find&nbsp;<input type=\\\"checkbox\\\" id=\\\"sel-all\\\" title=\\\"Select all visible\\\" /></th>\",\n",
        "    1\n",
        ")\n",
        "\n",
        "html_table_scrolling = '<div class=\"table-scroll\">\\n' + html_table + '\\n</div>'\n",
        "\n",
        "# ---------- CSS ----------\n",
        "TABLE_CSS = (\n",
        "    \"<style type=\\\"text/css\\\">\\n\"\n",
        "    \"  html { scroll-behavior: smooth; }\\n\"\n",
        "    \"  body { font-family: Georgia, 'Times New Roman', serif; background:#ffffff; color:#222; margin:0; padding:0; line-height:1.5; }\\n\"\n",
        "    f\"  .wrap {{ max-width:{TABLE_WIDTH_PX}px; margin:0 auto; background:#ffffff; padding:20px; padding-bottom:48px; }}\\n\"\n",
        "    \"  a { color:#154b8b; text-decoration:none; } a:hover { text-decoration:underline; }\\n\"\n",
        "    \"  h1 { margin:0 0 6px 0; font-size:26px; line-height:1.2; text-align:center; }\\n\"\n",
        "    \"  .updated { font-size:12px; color:#555; text-align:center; margin:2px 0 10px 0; }\\n\"\n",
        "    \"  .sortbar { margin:6px 0 10px 0; font-size:13px; background:#ffffff; padding:6px 8px; border-radius:6px;\\n\"\n",
        "    \"             display:flex; flex-wrap:wrap; gap:5px; align-items:center; border:1px solid #ddd; }\\n\"\n",
        "    \"  .btn { display:inline-block; border:1px solid #5b79b8; background:#5b79b8; color:#fff; padding:4px 9px;\\n\"\n",
        "    \"         text-decoration:none; cursor:pointer; border-radius:5px; line-height:1.2; transition:background 0.2s, transform 0.1s; user-select:none; }\\n\"\n",
        "    \"  .btn:hover { background:#4668aa; transform:translateY(-1px); }\\n\"\n",
        "    \"  input.btn.search { background:#fff; color:#111; border-color:#bbb; }\\n\"\n",
        "    \"  .btn-mini { font-size:12px; padding:2px 6px; line-height:1.1; margin-left:6px; }\\n\"\n",
        "    \"  .find-cell { white-space:nowrap; }\\n\"\n",
        "    \"  .selbox { margin-right:6px; vertical-align:middle; }\\n\"\n",
        "    \"  .table-scroll { max-height:70vh; overflow-y:auto; overflow-x:auto; border:1px solid #ddd; }\\n\"\n",
        "    f\"  table.sortable {{ border-collapse:collapse; width:{TABLE_WIDTH_PX}px; table-layout:fixed; }}\\n\"\n",
        "    \"  table.sortable th, table.sortable td { border:1px solid #ddd; padding:6px 8px; vertical-align:top; }\\n\"\n",
        "    \"  table.sortable th { background:#e3eaf8; text-align:left; position:sticky; top:0; z-index:2; box-shadow:0 1px 0 #ccc; }\\n\"\n",
        "    \"  table.sortable td { word-wrap:break-word; overflow-wrap:break-word; }\\n\"\n",
        "    \"  #first-row td { border-top:2px solid #999; }\\n\"\n",
        "    \"  .back-to-top { position:fixed; right:16px; bottom:16px; padding:6px 10px; border:1px solid #3e5a97; background:#5b79b8; color:#fff;\\n\"\n",
        "    \"                 cursor:pointer; border-radius:6px; font-size:12px; display:none; z-index:9999; }\\n\"\n",
        "    \"  .back-to-top:hover { background:#4668aa; }\\n\"\n",
        "    \"  #dynamicContent { margin:10px 0 14px 0; }\\n\"\n",
        "    \"  @media screen and (max-width: 820px) { .wrap { padding:12px; } h1 { font-size:22px; } }\\n\"\n",
        "    \"</style>\\n\"\n",
        ")\n",
        "\n",
        "# ---------- Toolbar ----------\n",
        "DYNAMIC_BLOCK = (\n",
        "    \"<div class=\\\"sortbar\\\">\\n\"\n",
        "    \"  <a class=\\\"btn\\\" href=\\\"https://yates.one-name.net/gengen/dna_cousin_surname_study.htm\\\" target=\\\"_blank\\\">Study Details</a>\\n\"\n",
        "    \"  <a class=\\\"btn\\\" href=\\\"https://yates.one-name.net/gengen/dna_theory_of_the_case.htm\\\" target=\\\"_blank\\\">Theory in Action</a>\\n\"\n",
        "    \"  <span class=\\\"btn\\\" data-sort-col=\\\"1\\\" data-sort-dir=\\\"asc\\\">Sort Match &uarr;</span>\\n\"\n",
        "    \"  <span class=\\\"btn\\\" data-sort-col=\\\"1\\\" data-sort-dir=\\\"desc\\\">Sort Match &darr;</span>\\n\"\n",
        "    \"  <span class=\\\"btn\\\" data-sort-col=\\\"2\\\" data-sort-dir=\\\"asc\\\">Sort Lineage &uarr;</span>\\n\"\n",
        "    \"  <span class=\\\"btn\\\" data-sort-col=\\\"2\\\" data-sort-dir=\\\"desc\\\">Sort Lineage &darr;</span>\\n\"\n",
        "    \"  <a class=\\\"btn\\\" href=\\\"gengen/images/cousin-calculator.jpg\\\" target=\\\"_blank\\\">Cousin Connection</a>\\n\"\n",
        "    \"  <a class=\\\"btn\\\" href=\\\"gengen/images/Shared_cM_Project_v4.jpg\\\" target=\\\"_blank\\\">Cousin by DNA</a>\\n\"\n",
        "    \"  <a class=\\\"btn\\\" href=\\\"partials/match_count.htm\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">Match Count</a>\\n\"\n",
        "    \"  <a class=\\\"btn\\\" href=\\\"partials/lineage_count.htm\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">Lineage Count</a>\\n\"\n",
        "    \"  <a class=\\\"btn\\\" href=\\\"/partials/cousin_list_print.htm\\\" target=\\\"_blank\\\">Cousin List</a>\\n\"\n",
        "    \"  <span class=\\\"btn\\\" id=\\\"email-selected\\\">Email Selected</span>\\n\"\n",
        "    \"  <span class=\\\"btn\\\" id=\\\"clear-selected\\\">Clear</span>\\n\"\n",
        "    \"  <input type=\\\"text\\\" id=\\\"search-box\\\" class=\\\"btn search\\\" size=\\\"24\\\" value=\\\"\\\" placeholder=\\\"Search&hellip;\\\" \"\n",
        "    \"         autocomplete=\\\"off\\\" autocapitalize=\\\"off\\\" spellcheck=\\\"false\\\" inputmode=\\\"search\\\" enterkeyhint=\\\"search\\\" />\\n\"\n",
        "    \"</div>\\n\"\n",
        "    \"<div id=\\\"dynamicContent\\\"></div>\\n\"\n",
        ")\n",
        "\n",
        "# ---------- Full HTML (string only) ----------\n",
        "JS_COUNT_URL = COUNT_PUBLIC_URL.replace(\"'\", \"%27\")\n",
        "\n",
        "# Updated status line (top, dynamic) with Home link\n",
        "UPDATED_BLOCK = (\n",
        "    \"<div class=\\\"updated\\\">\"\n",
        "    f\"<a href=\\\"{HOME_URL}\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">Home</a>\"\n",
        "    \" &nbsp;|&nbsp; Last updated: <span id=\\\"last-updated\\\"></span>\"\n",
        "    \" &nbsp;|&nbsp; Autosomal matches: <span id=\\\"auto-count\\\" class=\\\"js-count\\\"></span>\"\n",
        "    \"</div>\"\n",
        ")\n",
        "\n",
        "TEMPLATE_HTML = \"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "<title>ONS Yates Study Autosomal DNA Register</title>\n",
        "{TABLE_CSS}\n",
        "</head>\n",
        "<body id=\"top\">\n",
        "<div class=\"wrap\">\n",
        "  <h1>ONS Yates Study Autosomal DNA Register</h1>\n",
        "  {UPDATED_BLOCK}\n",
        "  {DYNAMIC_BLOCK}\n",
        "{HTML_TABLE_SCROLLING}\n",
        "</div>\n",
        "<button id=\"back-to-top\" class=\"back-to-top\">&#9650; Top</button>\n",
        "<script type=\"text/javascript\">\n",
        "//<![CDATA[\n",
        "(function(){\n",
        "  function textOf(cell){ return (cell && (cell.textContent || cell.innerText) || '').replace(/\\\\s+/g,' ').trim().toLowerCase(); }\n",
        "  function sortTable(tbl, colIndex, dir){\n",
        "    var tb=tbl && tbl.tBodies ? tbl.tBodies[0] : null; if(!tb) return;\n",
        "    var rows=[].slice.call(tb.rows||[]);\n",
        "    var asc=(dir==='asc');\n",
        "    rows.sort(function(a,b){\n",
        "      var A=textOf(a.cells[colIndex]), B=textOf(b.cells[colIndex]);\n",
        "      if(A<B) return asc?-1:1; if(A>B) return asc?1:-1; return 0;\n",
        "    });\n",
        "    var frag=document.createDocumentFragment();\n",
        "    for(var i=0;i<rows.length;i++) frag.appendChild(rows[i]);\n",
        "    tb.appendChild(frag);\n",
        "    updateSelAll(); // keep master checkbox in sync after sort\n",
        "  }\n",
        "  function bindSortButtons(){\n",
        "    var tbl=document.getElementById('refactor-table'); var bar=document.querySelector('.sortbar'); if(!(tbl && bar)) return;\n",
        "    bar.addEventListener('click',function(e){\n",
        "      var btn=e.target && e.target.closest ? e.target.closest('.btn') : null; if(!btn) return;\n",
        "      var colAttr=btn.getAttribute('data-sort-col'); if(colAttr==null) return; var col=parseInt(colAttr,10); if(isNaN(col)) return;\n",
        "      var dir=btn.getAttribute('data-sort-dir')||'asc'; sortTable(tbl,col,dir); e.preventDefault(); return false;\n",
        "    },false);\n",
        "  }\n",
        "  function bindHeaderSort(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tHead && tbl.tHead.rows.length)) return; var ths=tbl.tHead.rows[0].cells;\n",
        "    for(var i=0;i<ths.length;i++)(function(idx){\n",
        "      var dir='asc'; ths[idx].addEventListener('click',function(){ dir=(dir==='asc')?'desc':'asc'; sortTable(tbl,idx,dir); },false);\n",
        "    })(i);\n",
        "  }\n",
        "\n",
        "  // partials\n",
        "  var PARTIAL_BASES=['/partials/','partials/','gengen/partials/','/gengen/partials/'];\n",
        "  function tryFetchSequential(urls,onOK,onFail){\n",
        "    if(!urls.length) return onFail('No valid locations'); var url=urls.shift();\n",
        "    fetch(url,{cache:'no-store'}).then(function(r){ if(!r.ok) throw new Error('HTTP '+r.status); return r.text();})\n",
        "      .then(onOK).catch(function(){ tryFetchSequential(urls,onOK,onFail);});\n",
        "  }\n",
        "  function bindPartials(){\n",
        "    var bar=document.querySelector('.sortbar'); if(!bar) return;\n",
        "    bar.addEventListener('click',function(e){\n",
        "      var btn=e.target && e.target.closest ? e.target.closest('.btn') : null; if(!btn) return;\n",
        "      var rel=btn.getAttribute('data-load-partial'); if(!rel) return;\n",
        "      var c=document.getElementById('dynamicContent'); if(!c) return; c.innerHTML='<p><em>Loading latest data&hellip;</em></p>';\n",
        "      var bust=encodeURIComponent(document.lastModified||(new Date()).toUTCString());\n",
        "      var bases=PARTIAL_BASES.slice(); var candidates=bases.map(function(b){return b+rel+'?v='+bust;});\n",
        "      tryFetchSequential(candidates.slice(), function(html){ c.innerHTML=html; }, function(){ c.innerHTML='<p style=\\\\\\\"color:#a00;\\\\\\\">Could not load content.</p>'; });\n",
        "    });\n",
        "  }\n",
        "\n",
        "  // updated stamp + count\n",
        "  function stampLastUpdated(){\n",
        "    var el=document.getElementById('last-updated'); if(!el) return;\n",
        "    var d=new Date(document.lastModified||new Date());\n",
        "    function z(n){return(n<10?'0':'')+n;}\n",
        "    el.innerHTML=d.getFullYear()+'-'+z(d.getMonth()+1)+'-'+z(d.getDate())+' '+z(d.getHours())+':'+z(d.getMinutes());\n",
        "  }\n",
        "  function formatWithCommas(n){\n",
        "    try{ var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return ''; return x.toLocaleString('en-US'); }catch(e){ return String(n||''); }\n",
        "  }\n",
        "  function loadAutoCount(){\n",
        "    var el=document.getElementById('auto-count'); if(!el) return;\n",
        "    var url='{COUNT_URL}';\n",
        "    try{\n",
        "      var xhr=new XMLHttpRequest(); xhr.open('GET', url+(url.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true);\n",
        "      xhr.onreadystatechange=function(){ if(xhr.readyState===4){ if(xhr.status>=200&&xhr.status<300){\n",
        "        var m=(xhr.responseText||'').match(/(\\\\d+)/); var num=m?m[1]:'';\n",
        "        el.textContent = formatWithCommas(num) || '(unavailable)';\n",
        "      } else { el.textContent='(unavailable)'; } } };\n",
        "      xhr.send(null);\n",
        "    }catch(e){ el.textContent='(unavailable)'; }\n",
        "  }\n",
        "\n",
        "  // search (filters rows; select-all respects visibility)\n",
        "  function getParam(name){ var m=location.search.match(new RegExp('[?&]'+name+'=([^&]+)')); return m?decodeURIComponent(m[1].replace(/\\\\+/g,' ')):''; }\n",
        "  function bindSearch(){\n",
        "    var box=document.getElementById('search-box'); var tbl=document.getElementById('refactor-table'); if(!(box && tbl && tbl.tBodies && tbl.tBodies[0])) return; var tb=tbl.tBodies[0];\n",
        "    function norm(s){ return String(s||'').replace(/\\\\s+/g,' ').toLowerCase(); }\n",
        "    function rowText(tr){ var t=''; for(var i=0;i<tr.cells.length;i++){ t+= ' ' + (tr.cells[i].textContent||tr.cells[i].innerText||''); } return norm(t); }\n",
        "    var cached=[]; (function seed(){ var rows=tb.rows; cached=[]; for(var i=0;i<rows.length;i++){ cached.push({el:rows[i], txt:rowText(rows[i])}); } })();\n",
        "    function apply(q){\n",
        "      q=norm(q);\n",
        "      for(var i=0;i<cached.length;i++){\n",
        "        var hit = !q || cached[i].txt.indexOf(q)>-1;\n",
        "        cached[i].el.style.display = hit? '' : 'none';\n",
        "      }\n",
        "      updateSelAll();\n",
        "    }\n",
        "    var to=null; function onInput(){ if(to) clearTimeout(to); to=setTimeout(function(){ apply(box.value); }, 60); }\n",
        "    box.addEventListener('input', onInput, false);\n",
        "    var q0=getParam('q');\n",
        "    if(q0){ box.value=q0; apply(q0); try{ history.replaceState(null, '', location.pathname); }catch(e){} }\n",
        "    else { box.value=''; apply(''); setTimeout(function(){ if(!getParam('q')){ box.value=''; apply(''); } }, 0); }\n",
        "  }\n",
        "\n",
        "  // --- selection controls ---\n",
        "  function visibleRowCheckboxes(){\n",
        "    var tbl=document.getElementById('refactor-table');\n",
        "    if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return [];\n",
        "    var tb=tbl.tBodies[0], out=[];\n",
        "    for(var i=0;i<tb.rows.length;i++){\n",
        "      var tr=tb.rows[i];\n",
        "      if(tr.style.display==='none') continue;\n",
        "      var cb = tr.cells[0] && tr.cells[0].querySelector('.selbox');\n",
        "      if(cb) out.push(cb);\n",
        "    }\n",
        "    return out;\n",
        "  }\n",
        "  function updateSelAll(){\n",
        "    var master=document.getElementById('sel-all'); if(!master) return;\n",
        "    var cbs=visibleRowCheckboxes();\n",
        "    if(!cbs.length){ master.indeterminate=false; master.checked=false; return; }\n",
        "    var checked=cbs.filter(function(cb){ return cb.checked; }).length;\n",
        "    master.checked = (checked===cbs.length);\n",
        "    master.indeterminate = (checked>0 && checked<cbs.length);\n",
        "  }\n",
        "  function bindSelectAll(){\n",
        "    var master=document.getElementById('sel-all'); if(!master) return;\n",
        "    master.addEventListener('change', function(){\n",
        "      var want=master.checked;\n",
        "      var cbs=visibleRowCheckboxes();\n",
        "      for(var i=0;i<cbs.length;i++) cbs[i].checked = want;\n",
        "      updateSelAll();\n",
        "    });\n",
        "  }\n",
        "  function pageBase(){ try{ return location.origin + location.pathname; }catch(e){ return location.pathname; } }\n",
        "  function encodeQS(s){ return encodeURIComponent(String(s||'')); }\n",
        "  function buildRowEmail(tr){\n",
        "    var cells = tr.cells; if(!cells || cells.length < 3) return null;\n",
        "    var summary = (cells[1].textContent||'').trim();\n",
        "    var lineage = (cells[2].textContent||'').trim();\n",
        "    var subj = 'ONS Yates Register: ' + summary.substring(0, 90);\n",
        "    var qMatch = (function(){ try{ var em = cells[1].querySelector('strong'); return (em?em.textContent:'').trim(); }catch(e){ return ''; } })();\n",
        "    var link = pageBase() + (qMatch? ('?q='+encodeQS(qMatch)) : '');\n",
        "    var body = summary + '\\\\n\\\\nLineage:\\\\n' + lineage + '\\\\n\\\\nLink: ' + link;\n",
        "    return {subject: subj, body: body};\n",
        "  }\n",
        "  function openMailto(subject, body){\n",
        "    var href = 'mailto:?subject=' + encodeQS(subject) + '&body=' + encodeQS(body);\n",
        "    window.location.href = href;\n",
        "  }\n",
        "  function injectRowControls(){\n",
        "    var tbl = document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return; var tb = tbl.tBodies[0];\n",
        "    for(var i=0;i<tb.rows.length;i++){\n",
        "      (function(tr){\n",
        "        var cell = tr.cells[0]; if(!cell) return; if(cell.className.indexOf('find-cell')===-1) cell.className += ' find-cell';\n",
        "        var existingFind = cell.querySelector('a.find-btn'); // preserve your “Find” link\n",
        "        var cb = document.createElement('input'); cb.type='checkbox'; cb.className='selbox'; cb.title='Select row';\n",
        "        cb.addEventListener('change', updateSelAll);\n",
        "        cell.insertBefore(cb, existingFind || cell.firstChild);\n",
        "        // optional per-row Email button\n",
        "        var emailBtn = document.createElement('a'); emailBtn.href='#'; emailBtn.className='btn btn-mini'; emailBtn.textContent='Email'; emailBtn.title='Email this row'; emailBtn.style.marginLeft='6px';\n",
        "        emailBtn.addEventListener('click', function(ev){ ev.preventDefault(); var payload = buildRowEmail(tr); if(payload){ openMailto(payload.subject, payload.body); } });\n",
        "        if(existingFind){ existingFind.insertAdjacentElement('afterend', emailBtn); } else { cell.appendChild(emailBtn); }\n",
        "      })(tb.rows[i]);\n",
        "    }\n",
        "  }\n",
        "  function bindBulkEmail(){\n",
        "    var btn = document.getElementById('email-selected'); if(!btn) return;\n",
        "    btn.addEventListener('click', function(){\n",
        "      var tbl = document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return; var tb = tbl.tBodies[0];\n",
        "      var parts = []; var count = 0;\n",
        "      for(var i=0;i<tb.rows.length;i++){\n",
        "        var tr = tb.rows[i]; if(tr.style.display==='none') continue;\n",
        "        var cb = tr.cells[0] && tr.cells[0].querySelector('.selbox');\n",
        "        if(cb && cb.checked){ var p = buildRowEmail(tr); if(p){ parts.push(p.body); count++; } }\n",
        "      }\n",
        "      if(!count){ alert('No rows selected. Tick the checkboxes in the Find column.'); return; }\n",
        "      var subject = 'ONS Yates Register: ' + count + ' selection' + (count>1?'s':'');\n",
        "      var body = parts.join('\\\\n\\\\n---\\\\n\\\\n');\n",
        "      openMailto(subject, body);\n",
        "    });\n",
        "    var clr = document.getElementById('clear-selected'); if(clr){ clr.addEventListener('click', function(){\n",
        "      var tbl = document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return; var tb = tbl.tBodies[0];\n",
        "      for(var i=0;i<tb.rows.length;i++){ var cb = tb.rows[i].cells[0] && tb.rows[i].cells[0].querySelector('.selbox'); if(cb) cb.checked=false; }\n",
        "      updateSelAll();\n",
        "    }); }\n",
        "  }\n",
        "\n",
        "  // misc UI\n",
        "  function setupBackToTop(){\n",
        "    var btt=document.getElementById('back-to-top'); var cont=document.querySelector('.table-scroll');\n",
        "    function onAny(){ var y=(window.scrollY||window.pageYOffset||0); var cy=cont?cont.scrollTop:0; btt.style.display=(y>200||cy>200)?'block':'none'; }\n",
        "    window.addEventListener('scroll',onAny,{passive:true}); if(cont) cont.addEventListener('scroll',onAny,{passive:true});\n",
        "    onAny(); if(btt){ btt.addEventListener('click',function(){ if(cont) cont.scrollTo({top:0,behavior:'smooth'}); window.scrollTo({top:0,behavior:'smooth'}); }); }\n",
        "  }\n",
        "\n",
        "  // init\n",
        "  function init(){\n",
        "    bindSortButtons(); bindHeaderSort(); bindPartials(); stampLastUpdated(); loadAutoCount();\n",
        "    setupBackToTop(); bindSearch();\n",
        "    injectRowControls(); bindSelectAll(); bindBulkEmail(); updateSelAll();\n",
        "  }\n",
        "  init();\n",
        "})();\n",
        "//]]>\n",
        "</script>\n",
        "</body></html>\n",
        "\"\"\"\n",
        "\n",
        "FULL_HTML = (TEMPLATE_HTML\n",
        "    .replace(\"{TABLE_CSS}\", TABLE_CSS)\n",
        "    .replace(\"{UPDATED_BLOCK}\", UPDATED_BLOCK)\n",
        "    .replace(\"{DYNAMIC_BLOCK}\", DYNAMIC_BLOCK)\n",
        "    .replace(\"{HTML_TABLE_SCROLLING}\", html_table_scrolling)\n",
        "    .replace(\"{COUNT_URL}\", JS_COUNT_URL)\n",
        ")\n",
        "# ====== CUT STOP [5/6] REFACTOR-Gold 2 — HTML (table + CSS + JS, no uploads) =======================\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ====== CUT START [6/6] REFACTOR-Gold 2 — Save + Upload + Reports + Partials + Printable ===========\n",
        "import os, re, posixpath\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "ENC          = \"iso-8859-15\"\n",
        "LOCAL_NAME   = globals().get(\"LOCAL_NAME\",  \"ons_yates_dna_register.htm\")\n",
        "REMOTE_NAME  = globals().get(\"REMOTE_NAME\", \"ons_yates_dna_register.htm\")\n",
        "HOME_URL     = \"https://yates.one-name.net/ons_yates_dna_register.htm\"\n",
        "\n",
        "# Safely embed the JS count URL (escape single quotes)\n",
        "JS_COUNT_URL = COUNT_PUBLIC_URL.replace(\"'\", \"%27\")\n",
        "\n",
        "# 1) Write main page HTML exactly as built upstream\n",
        "with open(LOCAL_NAME, \"w\", encoding=ENC, errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(FULL_HTML)\n",
        "print(f\"✅ Wrote HTML: {os.path.abspath(LOCAL_NAME)}\")\n",
        "\n",
        "# 2) Upload main page + optional assets\n",
        "with ftp_connect() as ftps:\n",
        "    try:\n",
        "        ftps.mkd(\"partials\")\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        ftps.delete(_remote_path(REMOTE_NAME))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    ftp_upload_overwrite(ftps, LOCAL_NAME, _remote_path(REMOTE_NAME))\n",
        "\n",
        "    if os.path.exists(MATCH_COUSINS_CSV):\n",
        "        ftp_upload_overwrite(ftps, MATCH_COUSINS_CSV, _remote_path(MATCH_COUSINS_CSV))\n",
        "\n",
        "    if os.path.exists(LOCAL_COUNT_FILE):\n",
        "        ftp_upload_overwrite(ftps, LOCAL_COUNT_FILE, _remote_path(REMOTE_COUNT_NAME))\n",
        "        print(f\"✅ Published autosomal count: {LOCAL_COUNT_FILE} → {COUNT_PUBLIC_URL}\")\n",
        "    else:\n",
        "        print(f\"⚠️ Count file not found locally: {LOCAL_COUNT_FILE}\")\n",
        "\n",
        "    try:\n",
        "        ftps.quit()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# 3) Build filtered data for reports\n",
        "SUPPRESS_PREFIXES = [\"y-dna\", \"dar\", \"sar\"]\n",
        "def _suppress_by_match_summary(ms: str) -> bool:\n",
        "    s = (str(ms) or \"\").strip().lower()\n",
        "    return bool(s) and any(s.startswith(prefix + \" is\") for prefix in SUPPRESS_PREFIXES)\n",
        "\n",
        "display_df_all = display_df.copy()\n",
        "_suppress_mask = display_df_all[\"Match Summary\"].map(_suppress_by_match_summary)\n",
        "display_df_filtered = display_df_all[~_suppress_mask].reset_index(drop=True)\n",
        "filtered_df_for_reports = df.loc[display_df_all.index[~_suppress_mask]].copy()\n",
        "\n",
        "# Bind resolver-code column name (i.e., \"Match to\") for safety\n",
        "subject_code_col = (\n",
        "    globals().get(\"subject_code_col\")\n",
        "    or globals().get(\"match_to_col\")\n",
        "    or (\"Match to\" if 'df' in globals() and \"Match to\" in df.columns else list(df.columns)[0])\n",
        ")\n",
        "\n",
        "\n",
        "# Resolver usage / counts\n",
        "used_series = filtered_df_for_reports[subject_code_col].astype(str).map(lambda x: str(x).strip().lower())\n",
        "counts = Counter([c for c in used_series if c and c != \"nan\"])\n",
        "\n",
        "rows = []\n",
        "all_keys = set(globals().get(\"MATCH_TO_UNMASKED\", {}).keys())\n",
        "for code in sorted(all_keys):\n",
        "    rows.append((code, globals()[\"MATCH_TO_UNMASKED\"].get(code, \"\"), counts.get(code, 0)))\n",
        "for code in sorted(set(counts.keys()) - all_keys):\n",
        "    rows.append((code, \"(unmapped)\", counts.get(code, 0)))\n",
        "\n",
        "usage_df = pd.DataFrame(rows, columns=[\"Match to (code)\", \"Unmasked\", \"Count\"]).sort_values(\n",
        "    [\"Match to (code)\"], ascending=[True]\n",
        ")\n",
        "usage_df_alpha = usage_df.reset_index(drop=True)\n",
        "\n",
        "RESOLVER_USAGE_CSV = \"resolver_usage_report.csv\"\n",
        "usage_df_alpha.to_csv(RESOLVER_USAGE_CSV, index=False, encoding=ENC)\n",
        "print(\"✅ Wrote resolver usage CSV:\", os.path.abspath(RESOLVER_USAGE_CSV))\n",
        "\n",
        "# Lineage Count\n",
        "def _escape_html(s: str) -> str:\n",
        "    return (str(s).replace(\"&\", \"&amp;\").replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\"))\n",
        "\n",
        "def _norm_key_component(fullname: str) -> str:\n",
        "    nm = smart_titlecase(str(fullname)); parts = nm.split()\n",
        "    if not parts: return \"\"\n",
        "    last   = re.sub(r\"[^A-Za-z]\", \"\", parts[-1])\n",
        "    firsts = re.sub(r\"[^A-Za-z]\", \"\", \"\".join(parts[:-1]))[:7]\n",
        "    return f\"{last}{firsts}\"\n",
        "\n",
        "def oldest_pair_key(token_list):\n",
        "    if not token_list: return \"\"\n",
        "    first = token_list[0]\n",
        "    a, b = derive_common_from_first_token([first])\n",
        "    if not a and not b:\n",
        "        parts = re.split(r\"\\s*&\\s*\", first)\n",
        "        a = parts[0] if parts else \"\"\n",
        "        b = parts[1] if len(parts) > 1 else \"\"\n",
        "    ka = _norm_key_component(a) if a else \"\"\n",
        "    kb = _norm_key_component(b) if b else \"\"\n",
        "    return f\"{ka}&{kb}\" if ka or kb else \"\"\n",
        "\n",
        "lc_counter = Counter()\n",
        "for _, row in filtered_df_for_reports.iterrows():\n",
        "    toks = split_tokens(row[path_col])\n",
        "    key = oldest_pair_key(toks)\n",
        "    if key: lc_counter[key] += 1\n",
        "\n",
        "lc_rows = sorted(lc_counter.items(), key=lambda x: (-x[1], x[0]))\n",
        "lineage_count_df = pd.DataFrame(lc_rows, columns=[\"Oldest Distant Ancestor (normalized Last+First7) pair\", \"Count\"])\n",
        "\n",
        "LINEAGE_COUNT_CSV = \"lineage_count_report.csv\"\n",
        "lineage_count_df.to_csv(LINEAGE_COUNT_CSV, index=False, encoding=ENC)\n",
        "print(\"✅ Wrote lineage count CSV:\", os.path.abspath(LINEAGE_COUNT_CSV))\n",
        "\n",
        "# Upload report CSVs\n",
        "try:\n",
        "    with ftp_connect() as ftps:\n",
        "        ftp_upload_overwrite(ftps, RESOLVER_USAGE_CSV, _remote_path(RESOLVER_USAGE_CSV))\n",
        "        ftp_upload_overwrite(ftps, LINEAGE_COUNT_CSV, _remote_path(LINEAGE_COUNT_CSV))\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "    print(\"✅ Published report CSVs.\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Upload of report CSVs failed: {e}\")\n",
        "\n",
        "# ---------- Helpers for Match Count partial ----------\n",
        "def _build_person_details_html(code_lc: str) -> str:\n",
        "    mask = filtered_df_for_reports[subject_code_col].astype(str).str.strip().str.lower() == code_lc\n",
        "    if not mask.any(): return \"<em>No rows for this person.</em>\"\n",
        "    rows_idx = filtered_df_for_reports[mask].index\n",
        "    mini = display_df.loc[rows_idx, [\"Find\", \"Match Summary\", LINEAGE_HEADER_SAFE]].copy()\n",
        "    return mini.to_html(index=False, escape=False, classes=\"mini-table\", border=0)\n",
        "\n",
        "# ---------- Match Count partial (tight wrapper + working toolbar) ----------\n",
        "def _render_match_count_full_html(usage_alpha: pd.DataFrame) -> str:\n",
        "    try:\n",
        "        total_persons = int(usage_alpha.shape[0])\n",
        "        total_matches = int(pd.to_numeric(usage_alpha[\"Count\"], errors=\"coerce\").fillna(0).sum())\n",
        "    except Exception:\n",
        "        total_persons, total_matches = usage_alpha.shape[0], 0\n",
        "\n",
        "    # Build rows\n",
        "    rows_html = []\n",
        "    for _, r in usage_alpha.iterrows():\n",
        "        code    = str(r[\"Match to (code)\"])\n",
        "        code_lc = code.strip().lower()\n",
        "        unm     = _escape_html(r[\"Unmasked\"])\n",
        "        cnt     = int(pd.to_numeric(r[\"Count\"], errors=\"coerce\")) if str(r[\"Count\"]).strip() else 0\n",
        "        rows_html.append(\n",
        "            \"<tr class='top-row' data-code='{code_lc}'>\"\n",
        "            \"<td class='sel'><input type='checkbox' class='selbox' data-code='{code_lc}' title='Select' /></td>\"\n",
        "            \"<td class='code'>{code}</td>\"\n",
        "            \"<td class='unmasked'>{unm}</td>\"\n",
        "            \"<td class='count'><a href='#' class='count-toggle' data-code='{code_lc}' aria-expanded='false'>{cnt}</a></td>\"\n",
        "            \"</tr>\".format(code_lc=_escape_html(code_lc), code=_escape_html(code), unm=unm, cnt=f\"{cnt:,}\")\n",
        "        )\n",
        "        rows_html.append(\n",
        "            \"<tr class='details-row' id='details-{code_lc}' style='display:none;'>\"\n",
        "            \"<td colspan='4'><div class='details-outer'>{detail}</div></td>\"\n",
        "            \"</tr>\".format(code_lc=_escape_html(code_lc), detail=_build_person_details_html(code_lc))\n",
        "        )\n",
        "\n",
        "    # CSS (avoid %-formatting; use concatenation for injected values)\n",
        "    style = (\n",
        "        \"<style>\"\n",
        "        \" body{font-family:Georgia,'Times New Roman',serif;background:#fff;color:#111;margin:0;padding:18px;line-height:1.6;font-size:15px}\"\n",
        "        \" .wrap{max-width:900px;margin:0 auto}\"\n",
        "        \" h2{font-size:20px;margin:0 0 10px 0;text-align:center;border-bottom:2px solid #5b79b8;padding-bottom:6px}\"\n",
        "        \" .updated{font-size:12px;color:#555;text-align:center;margin:2px 0 10px 0}\"\n",
        "        \" .stats{text-align:center;color:#444;font-size:13px;margin:6px 0 10px 0}\"\n",
        "        \" .toolbar{display:flex;flex-wrap:wrap;gap:8px;align-items:center;justify-content:flex-start;margin:8px 0 10px 0}\"\n",
        "        \" .btn{display:inline-block;border:1px solid #5b79b8;background:#5b79b8;color:#fff;padding:6px 12px;border-radius:6px;text-decoration:none;cursor:pointer}\"\n",
        "        \" .btn:hover{background:#4668aa}\"\n",
        "        \" .master{margin-left:auto;font-size:13px;color:#333}\"\n",
        "        \" table#mc-table{border-collapse:collapse;width:100%;table-layout:fixed}\"\n",
        "        \" #mc-table col.sel{width:72px} #mc-table col.code{width:26%} #mc-table col.unmasked{width:48%} #mc-table col.count{width:16%}\"\n",
        "        \" #mc-table th,#mc-table td{border:1px solid #ccc;padding:8px 10px;vertical-align:top;word-wrap:break-word;overflow-wrap:break-word}\"\n",
        "        \" #mc-table th{background:#e9eef9;position:sticky;top:0;z-index:1}\"\n",
        "        \" #mc-table td.count{text-align:right}\"\n",
        "        \" #mc-table a.count-toggle{display:inline-block;padding:2px 6px;background:#5b79b8;color:#fff;border-radius:4px;border:1px solid #3e5a97;text-decoration:none}\"\n",
        "        \" #mc-table a.count-toggle:hover{background:#4668aa}\"\n",
        "        \" .details-outer{background:#f9fbff;border:1px solid #d7e1fb;margin:8px 2px;padding:8px;border-radius:6px}\"\n",
        "        \" .mini-table{border-collapse:collapse;width:100%;table-layout:fixed}\"\n",
        "        \" .mini-table th,.mini-table td{border:1px solid #ddd;padding:6px 8px;vertical-align:top}\"\n",
        "        \" .mini-table th{background:#f2f6ff}\"\n",
        "        \" .mini-table col:nth-child(1){width:140px} \"\n",
        "        \" .mini-table col:nth-child(2){width:\" + str(COL_A_PX) + \"px} \"\n",
        "        \" .mini-table col:nth-child(3){width:auto}\"\n",
        "        \" @media screen and (max-width:900px){ body{padding:12px;font-size:14px} .toolbar{gap:6px} }\"\n",
        "        \"</style>\"\n",
        "    )\n",
        "\n",
        "    updated = (\n",
        "        \"<div class='updated'>\"\n",
        "        \"<a href='\" + HOME_URL + \"' target='_blank' rel='noopener'>Home</a>\"\n",
        "        \" &nbsp;|&nbsp; Last updated: <span id='last-updated'></span>\"\n",
        "        \" &nbsp;|&nbsp; Autosomal matches: <span id='auto-count' class='js-count'></span>\"\n",
        "        \"</div>\"\n",
        "    )\n",
        "\n",
        "    toolbar = (\n",
        "        \"<div class='toolbar'>\"\n",
        "        \" <button type='button' class='btn' id='btn-display'>Display Checked</button>\"\n",
        "        \" <button type='button' class='btn' id='btn-email'>Email Checked</button>\"\n",
        "        \" <button type='button' class='btn' id='btn-print'>Print Checked</button>\"\n",
        "        \" <label class='master'><input type='checkbox' id='sel-all' /> Select all</label>\"\n",
        "        \"</div>\"\n",
        "    )\n",
        "\n",
        "    html = (\n",
        "        \"<!DOCTYPE html><html lang='en'><head>\"\n",
        "        \"<meta charset='iso-8859-15' />\"\n",
        "        \"<meta name='viewport' content='width=device-width, initial-scale=1.0' />\"\n",
        "        \"<title>Match Count (by resolver code)</title>\"\n",
        "        + style +\n",
        "        \"</head><body>\"\n",
        "        \"<div class='wrap'>\"\n",
        "        \"<h2>Match Count (by resolver code, A&rightarrow;Z)</h2>\"\n",
        "        + updated +\n",
        "        \"<div class='stats'>Total distinct &ldquo;Match to&rdquo; persons: \" + f\"{total_persons:,}\" +\n",
        "        \" &nbsp;|&nbsp; Total matches counted: \" + f\"{total_matches:,}\" + \"</div>\"\n",
        "        + toolbar +\n",
        "        \"<table id='mc-table'>\"\n",
        "        \"<colgroup><col class='sel'><col class='code'><col class='unmasked'><col class='count'></colgroup>\"\n",
        "        \"<thead><tr><th>Select</th><th>Match to (code)</th><th>Unmasked</th><th>Count</th></tr></thead>\"\n",
        "        \"<tbody>\" + \"\".join(rows_html) + \"</tbody></table>\"\n",
        "        \"</div>\"\n",
        "        \"<script>(function(){\"\n",
        "        \" document.addEventListener('DOMContentLoaded', function(){\"\n",
        "        \"  function z(n){return(n<10?'0':'')+n;}\"\n",
        "        \"  function stamp(){var el=document.getElementById('last-updated'); if(!el) return; var d=new Date(document.lastModified||new Date());\"\n",
        "        \"   el.textContent=d.getFullYear()+'-'+z(d.getMonth()+1)+'-'+z(d.getDate())+' '+z(d.getHours())+':'+z(d.getMinutes());}\"\n",
        "        \"  function fmt(n){try{var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return ''; return x.toLocaleString('en-US');}catch(e){return String(n||'');}}\"\n",
        "        \"  function loadCnt(){var el=document.getElementById('auto-count'); if(!el) return; var url='\" + JS_COUNT_URL + \"';\"\n",
        "        \"   try{var xhr=new XMLHttpRequest(); xhr.open('GET', url+(url.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true);\"\n",
        "        \"    xhr.onreadystatechange=function(){ if(xhr.readyState===4){ if(xhr.status>=200&&xhr.status<300){ var m=(xhr.responseText||'').match(/(\\\\d+)/); el.textContent = fmt(m?m[1]:'') || '(unavailable)'; } else { el.textContent='(unavailable)'; } } };\"\n",
        "        \"    xhr.send(null);}catch(e){ el.textContent='(unavailable)'; }}\"\n",
        "        \"  stamp(); loadCnt();\"\n",
        "\n",
        "        \"  function toggleDetails(code, wantOpen){\"\n",
        "        \"    var row=document.getElementById('details-'+code); if(!row) return;\"\n",
        "        \"    row.style.display = wantOpen ? '' : 'none';\"\n",
        "        \"    var a=document.querySelector(\\\"a.count-toggle[data-code='\\\"+code+\\\"']\\\"); if(a){ a.setAttribute('aria-expanded', wantOpen?'true':'false'); }\"\n",
        "        \"  }\"\n",
        "        \"  function selectedCodes(){\"\n",
        "        \"    var out=[]; var cbs=document.querySelectorAll('#mc-table .selbox');\"\n",
        "        \"    for(var i=0;i<cbs.length;i++){ if(cbs[i].checked){ var c=cbs[i].getAttribute('data-code'); if(c) out.push(c); }}\"\n",
        "        \"    return out;\"\n",
        "        \"  }\"\n",
        "\n",
        "        \"  var master=document.getElementById('sel-all');\"\n",
        "        \"  if(master){ master.addEventListener('change', function(){\"\n",
        "        \"    var want=master.checked; var cbs=document.querySelectorAll('#mc-table .selbox');\"\n",
        "        \"    for(var i=0;i<cbs.length;i++){ cbs[i].checked = want; }\"\n",
        "        \"  }); }\"\n",
        "\n",
        "        \"  var btnDisp=document.getElementById('btn-display');\"\n",
        "        \"  if(btnDisp){ btnDisp.addEventListener('click', function(){\"\n",
        "        \"    var sel=selectedCodes();\"\n",
        "        \"    var all=document.querySelectorAll('tr.details-row'); for(var i=0;i<all.length;i++){ all[i].style.display='none'; }\"\n",
        "        \"    for(var j=0;j<sel.length;j++){ toggleDetails(sel[j], true); }\"\n",
        "        \"    if(sel.length){ try{ document.getElementById('details-'+sel[0]).scrollIntoView({behavior:'smooth',block:'start'});}catch(e){} }\"\n",
        "        \"  }); }\"\n",
        "\n",
        "        \"  function enc(s){ return encodeURIComponent(String(s||'')); }\"\n",
        "        \"  function textOf(el){ return (el && (el.textContent||el.innerText)||'').trim(); }\"\n",
        "\n",
        "        \"  var btnEmail=document.getElementById('btn-email');\"\n",
        "        \"  if(btnEmail){ btnEmail.addEventListener('click', function(){\"\n",
        "        \"    var sel=selectedCodes(); if(!sel.length){ alert('No persons selected.'); return; }\"\n",
        "        \"    function collectMatches(code){\"\n",
        "        \"      var out=[]; var host=document.getElementById('details-'+code); if(!host) return out;\"\n",
        "        \"      var rows=host.querySelectorAll('table.mini-table tbody tr');\"\n",
        "        \"      for(var i=0;i<rows.length;i++){\"\n",
        "        \"        var tds=rows[i].cells; if(!tds || tds.length<3) continue;\"\n",
        "        \"        var a=tds[0].querySelector('a'); var href=a ? a.href : '';\"\n",
        "        \"        var summary=textOf(tds[1]);\"\n",
        "        \"        out.push({summary:summary, href:href});\"\n",
        "        \"      }\"\n",
        "        \"      return out;\"\n",
        "        \"    }\"\n",
        "        \"    var lines=[], total=0;\"\n",
        "        \"    for(var k=0;k<sel.length;k++){\"\n",
        "        \"      var code=sel[k];\"\n",
        "        \"      var tr=document.querySelector(\\\"tr.top-row[data-code='\\\"+code+\\\"']\\\"); if(!tr) continue;\"\n",
        "        \"      var codeTxt=textOf(tr.querySelector('.code'));\"\n",
        "        \"      var unmTxt =textOf(tr.querySelector('.unmasked'));\"\n",
        "        \"      var cntTxt =textOf(tr.querySelector('.count a'));\"\n",
        "        \"      var header = codeTxt + (unmTxt? ' — '+unmTxt : '') + (cntTxt? ' ('+cntTxt+')' : '');\"\n",
        "        \"      lines.push('== ' + header + ' ==');\"\n",
        "        \"      var matches = collectMatches(code);\"\n",
        "        \"      if(!matches.length){\"\n",
        "        \"        lines.push('- (no inline rows available)');\"\n",
        "        \"      } else {\"\n",
        "        \"        total += matches.length;\"\n",
        "        \"        for(var m=0;m<matches.length;m++){\"\n",
        "        \"          var row = matches[m];\"\n",
        "        \"          lines.push('- ' + row.summary);\"\n",
        "        \"          if(row.href){ lines.push(row.href); }\"\n",
        "        \"        }\"\n",
        "        \"      }\"\n",
        "        \"      if(k < sel.length-1) lines.push('');\"\n",
        "        \"    }\"\n",
        "        \"    var subj='ONS Yates: ' + sel.length + ' person(s), ' + total + ' match row(s)';\"\n",
        "        \"    var body=lines.join('\\\\n');\"\n",
        "        \"    var href='mailto:?subject='+enc(subj)+'&body='+enc(body);\"\n",
        "        \"    window.location.href=href;\"\n",
        "        \"  }); }\"\n",
        "\n",
        "        \"  var btnPrint=document.getElementById('btn-print');\"\n",
        "        \"  if(btnPrint){ btnPrint.addEventListener('click', function(){\"\n",
        "        \"    var sel=selectedCodes(); if(!sel.length){ alert('No persons selected.'); return; }\"\n",
        "        \"    for(var i=0;i<sel.length;i++){ toggleDetails(sel[i], true); }\"\n",
        "        \"    setTimeout(function(){ window.print(); }, 100);\"\n",
        "        \"  }); }\"\n",
        "\n",
        "        \"  var tbl=document.getElementById('mc-table');\"\n",
        "        \"  if(tbl){ tbl.addEventListener('click',function(ev){\"\n",
        "        \"    var a=ev.target && ev.target.closest ? ev.target.closest('a.count-toggle') : null;\"\n",
        "        \"    if(!a) return; ev.preventDefault();\"\n",
        "        \"    var code=a.getAttribute('data-code'); if(!code) return;\"\n",
        "        \"    var row=document.getElementById('details-'+code); if(!row) return;\"\n",
        "        \"    var open=row.style.display!== 'none';\"\n",
        "        \"    row.style.display = open ? 'none' : '';\"\n",
        "        \"    a.setAttribute('aria-expanded', open?'false':'true');\"\n",
        "        \"    if(!open){ try{ row.scrollIntoView({behavior:'smooth',block:'start'});}catch(e){} }\"\n",
        "        \"  },false); }\"\n",
        "        \" });\"\n",
        "        \"})();</script>\"\n",
        "        \"</body></html>\"\n",
        "    )\n",
        "    return html\n",
        "\n",
        "match_partial_html = _render_match_count_full_html(usage_df_alpha)\n",
        "\n",
        "# ---------- Lineage Count partial (keeps dynamic header) ----------\n",
        "lineage_style = (\n",
        "    \"<style>\"\n",
        "    \" body{font-family:Georgia,'Times New Roman',serif;background:#fff;color:#111;margin:0;padding:18px;line-height:1.6;font-size:15px}\"\n",
        "    \" .wrap{max-width:1100px;margin:0 auto}\"\n",
        "    \" h2{font-size:20px;margin:0 0 10px 0;text-align:center;border-bottom:2px solid #5b79b8;padding-bottom:6px}\"\n",
        "    \" .updated{font-size:12px;color:#555;text-align:center;margin:2px 0 10px 0}\"\n",
        "    \" table.partial-table{border-collapse:collapse;width:100%;table-layout:auto}\"\n",
        "    \" table.partial-table th,table.partial-table td{border:1px solid #ccc;padding:8px 10px;vertical-align:top}\"\n",
        "    \" table.partial-table th{background:#e9eef9;position:sticky;top:0}\"\n",
        "    \" @media screen and (max-width:900px){ body{padding:12px;font-size:14px} }\"\n",
        "    \"</style>\"\n",
        ")\n",
        "lineage_updated = (\n",
        "    \"<div class='updated'>\"\n",
        "    \"<a href='\" + HOME_URL + \"' target='_blank' rel='noopener'>Home</a>\"\n",
        "    \" &nbsp;|&nbsp; Last updated: <span id='last-updated'></span>\"\n",
        "    \" &nbsp;|&nbsp; Autosomal matches: <span id='auto-count' class='js-count'></span>\"\n",
        "    \"</div>\"\n",
        ")\n",
        "lineage_js = (\n",
        "    \"<script>(function(){\"\n",
        "    \" document.addEventListener('DOMContentLoaded', function(){\"\n",
        "    \"  function z(n){return(n<10?'0':'')+n;}\"\n",
        "    \"  function stamp(){var el=document.getElementById('last-updated'); if(!el) return; var d=new Date(document.lastModified||new Date());\"\n",
        "    \"   el.textContent=d.getFullYear()+'-'+z(d.getMonth()+1)+'-'+z(d.getDate())+' '+z(d.getHours())+':'+z(d.getMinutes());}\"\n",
        "    \"  function fmt(n){try{var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return ''; return x.toLocaleString('en-US');}catch(e){return String(n||'');}}\"\n",
        "    \"  function loadCnt(){var el=document.getElementById('auto-count'); if(!el) return; var url='\" + JS_COUNT_URL + \"';\"\n",
        "    \"   try{var xhr=new XMLHttpRequest(); xhr.open('GET', url+(url.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true);\"\n",
        "    \"    xhr.onreadystatechange=function(){ if(xhr.readyState===4){ if(xhr.status>=200&&xhr.status<300){ var m=(xhr.responseText||'').match(/(\\\\d+)/); el.textContent = fmt(m?m[1]:'') || '(unavailable)'; } else { el.textContent='(unavailable)'; } } };\"\n",
        "    \"    xhr.send(null);}catch(e){ el.textContent='(unavailable)'; }}\"\n",
        "    \"  stamp(); loadCnt();\"\n",
        "    \" });\"\n",
        "    \"})();</script>\"\n",
        ")\n",
        "\n",
        "lineage_partial_html = (\n",
        "    \"<!DOCTYPE html><html lang='en'><head>\"\n",
        "    \"<meta charset='iso-8859-15' />\"\n",
        "    \"<meta name='viewport' content='width=device-width, initial-scale=1.0' />\"\n",
        "    \"<title>Lineage Count (by oldest distant ancestor pair)</title>\"\n",
        "    + lineage_style +\n",
        "    \"</head><body>\"\n",
        "    \"<div class='wrap'>\"\n",
        "    \"<h2>Lineage Count (by oldest distant ancestor pair)</h2>\"\n",
        "    + lineage_updated +\n",
        "    lineage_count_df.to_html(index=False, escape=False, classes='partial-table', border=0) +\n",
        "    \"</div>\"\n",
        "    + lineage_js +\n",
        "    \"</body></html>\"\n",
        ")\n",
        "\n",
        "# 4) Write & upload partials\n",
        "with open(\"match_count.htm\", \"w\", encoding=ENC, errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(match_partial_html)\n",
        "with open(\"lineage_count.htm\", \"w\", encoding=ENC, errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(lineage_partial_html)\n",
        "print(\"✅ Wrote partials locally: match_count.htm, lineage_count.htm\")\n",
        "\n",
        "try:\n",
        "    with ftp_connect() as ftps:\n",
        "        try: ftps.mkd(\"partials\")\n",
        "        except Exception: pass\n",
        "        ftp_upload_overwrite(ftps, \"match_count.htm\",   \"partials/match_count.htm\")\n",
        "        ftp_upload_overwrite(ftps, \"lineage_count.htm\", \"partials/lineage_count.htm\")\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "    print(\"✅ Published count partials to /partials/\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Upload of count partials failed: {e}\")\n",
        "\n",
        "# 5) Printable page (adds dynamic header)\n",
        "PRINT_PARTIAL_NAME  = \"cousin_list_print.htm\"\n",
        "PRINT_PARTIAL_LOCAL = PRINT_PARTIAL_NAME\n",
        "_print_table_html = (display_df_filtered if not display_df_filtered.empty else display_df_all).to_html(\n",
        "    index=False, escape=False, classes=\"print-table\", border=1\n",
        ")\n",
        "PRINT_PARTIAL_HTML = (\n",
        "    \"<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Transitional//EN\\\"\\n\"\n",
        "    \"  \\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\\\">\\n\"\n",
        "    \"<html xmlns=\\\"http://www.w3.org/1999/xhtml\\\" lang=\\\"en\\\">\\n\"\n",
        "    \"<head>\\n\"\n",
        "    \"<meta http-equiv=\\\"Content-Type\\\" content=\\\"text/html; charset=iso-8859-15\\\" />\\n\"\n",
        "    \"<meta name=\\\"viewport\\\" content=\\\"width=device-width, initial-scale=1.0\\\" />\\n\"\n",
        "    \"<title>ONS Yates Study &ndash; Cousin List (Printable)</title>\\n\"\n",
        "    \"<style type=\\\"text/css\\\">\\n\"\n",
        "    \"  body { font-family: Georgia, 'Times New Roman', serif; color:#000; background:#fff; margin:0; padding:16px; line-height:1.45; }\\n\"\n",
        "    \"  .wrap { max-width: 1100px; margin: 0 auto; }\\n\"\n",
        "    \"  h1 { font-size: 22px; margin: 0 0 8px 0; text-align:center; }\\n\"\n",
        "    \"  .updated { font-size:12px; color:#555; text-align:center; margin:2px 0 12px 0; }\\n\"\n",
        "    \"  .actions { text-align:center; margin: 10px 0 16px 0; }\\n\"\n",
        "    \"  .btn { display:inline-block; border:1px solid #444; background:#f4f4f4; color:#000; padding:6px 12px; text-decoration:none; }\\n\"\n",
        "    \"  table.print-table { border-collapse: collapse; width: 100%; table-layout: fixed; }\\n\"\n",
        "    \"  table.print-table th, table.print-table td { border:  1px solid #222; padding: 6px 8px; vertical-align: top; }\\n\"\n",
        "    \"  table.print-table th { background: #eee; }\\n\"\n",
        "    \"  @media print { .actions { display: none; } @page { margin: 0.6in; } }\\n\"\n",
        "    \"</style>\\n\"\n",
        "    \"</head>\\n\"\n",
        "    \"<body>\\n\"\n",
        "    \"  <div class=\\\"wrap\\\">\\n\"\n",
        "    \"    <h1>ONS Yates Study &ndash; Cousin List (Printable)</h1>\\n\"\n",
        "    \"    <div class=\\\"updated\\\"><a href=\\\"\" + HOME_URL + \"\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">Home</a>\"\n",
        "    \" &nbsp;|&nbsp; Last updated: <span id=\\\"last-updated\\\"></span>\"\n",
        "    \" &nbsp;|&nbsp; Autosomal matches: <span id=\\\"auto-count\\\" class=\\\"js-count\\\"></span></div>\\n\"\n",
        "    \"    <div class=\\\"actions\\\"><a class=\\\"btn\\\" href=\\\"#\\\" onclick=\\\"window.print();return false;\\\">Print this page</a></div>\\n\"\n",
        "    \"   \" + _print_table_html + \"\\n\"\n",
        "    \"    <div class=\\\"actions\\\" style=\\\"margin-top:16px;\\\"><a class=\\\"btn\\\" href=\\\"#\\\" onclick=\\\"window.print();return false;\\\">Print this page</a></div>\\n\"\n",
        "    \"  </div>\\n\"\n",
        "    \"<script>(function(){\"\n",
        "    \" document.addEventListener('DOMContentLoaded', function(){\"\n",
        "    \"  function z(n){return(n<10?'0':'')+n;}\"\n",
        "    \"  function stamp(){var el=document.getElementById('last-updated'); if(!el) return; var d=new Date(document.lastModified||new Date());\"\n",
        "    \"   el.textContent=d.getFullYear()+'-'+z(d.getMonth()+1)+'-'+z(d.getDate())+' '+z(d.getHours())+':'+z(d.getMinutes());}\"\n",
        "    \"  function fmt(n){try{var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return ''; return x.toLocaleString('en-US');}catch(e){return String(n||'');}}\"\n",
        "    \"  function loadCnt(){var el=document.getElementById('auto-count'); if(!el) return; var url='\" + JS_COUNT_URL + \"';\"\n",
        "    \"   try{var xhr=new XMLHttpRequest(); xhr.open('GET', url+(url.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true);\"\n",
        "    \"    xhr.onreadystatechange=function(){ if(xhr.readyState===4){ if(xhr.status>=200&&xhr.status<300){ var m=(xhr.responseText||'').match(/(\\\\d+)/); el.textContent = fmt(m?m[1]:'') || '(unavailable)'; } else { el.textContent='(unavailable)'; } } };\"\n",
        "    \"    xhr.send(null);}catch(e){ el.textContent='(unavailable)'; }}\"\n",
        "    \"  stamp(); loadCnt();\"\n",
        "    \" });\"\n",
        "    \"})();</script>\"\n",
        "    \"</body>\\n\"\n",
        "    \"</html>\\n\"\n",
        ")\n",
        "with open(PRINT_PARTIAL_LOCAL, \"w\", encoding=ENC, errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(PRINT_PARTIAL_HTML)\n",
        "\n",
        "try:\n",
        "    with ftp_connect() as ftps:\n",
        "        try: ftps.mkd(\"partials\")\n",
        "        except Exception: pass\n",
        "        ftp_upload_overwrite(ftps, PRINT_PARTIAL_LOCAL, \"partials/\" + PRINT_PARTIAL_NAME)\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "    print(f\"✅ Uploaded printable page: /partials/{PRINT_PARTIAL_NAME}\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Printable page upload failed: {e}\")\n",
        "\n",
        "print(f\"✅ HTML published at https://yates.one-name.net/{REMOTE_NAME}\")\n",
        "# ====== CUT STOP [6/6] REFACTOR-Gold 2 — Save + Upload + Reports + Partials + Printable ===========\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ====== CUT START [B] REFACTOR-Gold 2 — Helpers / Resolver (root-level /partials + utilities) ====\n",
        "import os\n",
        "import re\n",
        "import csv\n",
        "import posixpath\n",
        "from typing import Dict, Tuple, List, Optional\n",
        "\n",
        "try:\n",
        "    import pandas as pd\n",
        "except Exception:\n",
        "    pd = None\n",
        "\n",
        "# ---------- Absolute root-level /partials support (Resolver) ----------\n",
        "# Primary:   /partials/match_to_unmasked.csv   (absolute from server root)\n",
        "# Fallback:  /gengen/partials/match_to_unmasked.csv  (under FTP_DIR)\n",
        "SERVER_PARTIALS_DIR = os.getenv(\"G2_SERVER_PARTIALS_DIR\", \"/partials\")\n",
        "SERVER_MAPPING_BASENAME = os.getenv(\"G2_SERVER_MAPPING_BASENAME\", \"match_to_unmasked.csv\")\n",
        "LOCAL_MAPPING_CACHE = os.getenv(\"G2_LOCAL_MAPPING_CACHE\", \"match_to_unmasked.csv\")\n",
        "\n",
        "def _remote_abs(*parts: str) -> str:\n",
        "    \"\"\"Absolute POSIX path; DOES NOT prepend FTP_DIR.\"\"\"\n",
        "    cleaned = [str(p).strip(\"/\") for p in parts if p is not None]\n",
        "    return \"/\" + \"/\".join([p for p in cleaned if p])\n",
        "\n",
        "def _remote_under_ftpdir(name: str) -> str:\n",
        "    \"\"\"Fallback to FTP_DIR-prefixed path (e.g., /gengen/partials/...).\"\"\"\n",
        "    base = str(globals().get(\"FTP_DIR\", \"/\")).rstrip(\"/\")\n",
        "    return f\"{base}/{name.lstrip('/')}\"\n",
        "\n",
        "def _ftps_fetch_to_local(ftps, remote_path: str, local_path: str) -> Tuple[bool, str]:\n",
        "    \"\"\"Try to RETR a remote file to local_path. Return (ok, error_text).\"\"\"\n",
        "    try:\n",
        "        parent = os.path.dirname(local_path)\n",
        "        if parent and not os.path.isdir(parent):\n",
        "            os.makedirs(parent, exist_ok=True)\n",
        "        with open(local_path, \"wb\") as fh:\n",
        "            ftps.retrbinary(f\"RETR {remote_path}\", fh.write)\n",
        "        return True, \"\"\n",
        "    except Exception as e:\n",
        "        return False, f\"{type(e).__name__}: {e}\"\n",
        "\n",
        "def _detect_cols(df) -> Tuple[str, str]:\n",
        "    \"\"\"Pick code and unmasked columns from a DataFrame by heuristics.\"\"\"\n",
        "    cols = [str(c) for c in df.columns]\n",
        "    code_candidates = [\"Match to\", \"match_to\", \"match to\", \"code\", \"Code\"]\n",
        "    name_candidates = [\"Unmasked\", \"unmasked\", \"name\", \"Name\", \"Unmask\", \"unmask\"]\n",
        "    code_col = None\n",
        "    name_col = None\n",
        "    for c in cols:\n",
        "        if c.lower().replace(\" \", \"\") in [x.replace(\" \", \"\").lower() for x in code_candidates]:\n",
        "            code_col = c; break\n",
        "    for c in cols:\n",
        "        if c.lower().replace(\" \", \"\") in [x.replace(\" \", \"\").lower() for x in name_candidates]:\n",
        "            name_col = c; break\n",
        "    if code_col is None: code_col = cols[0]\n",
        "    if name_col is None: name_col = cols[1] if len(cols) > 1 else cols[0]\n",
        "    return code_col, name_col\n",
        "\n",
        "def _read_resolver_csv(local_path: str) -> Dict[str, str]:\n",
        "    \"\"\"Load resolver csv to {code: unmasked} with minimal normalization.\"\"\"\n",
        "    if pd is not None:\n",
        "        df = pd.read_csv(local_path, dtype=str, encoding=ENC, keep_default_na=False)\n",
        "        code_col, name_col = _detect_cols(df)\n",
        "        mapping = {}\n",
        "        for _, row in df.iterrows():\n",
        "            k = str(row.get(code_col, \"\")).strip()\n",
        "            v = str(row.get(name_col, \"\")).strip()\n",
        "            if k:\n",
        "                mapping[k] = v\n",
        "        return mapping\n",
        "    # Fallback without pandas\n",
        "    mapping = {}\n",
        "    with open(local_path, \"r\", encoding=ENC, errors=\"replace\", newline=\"\") as fh:\n",
        "        reader = csv.reader(fh)\n",
        "        rows = list(reader)\n",
        "    if not rows:\n",
        "        return mapping\n",
        "    header = rows[0]\n",
        "    if len(header) >= 2 and not header[0].strip().isdigit():\n",
        "        # Assume first row is header\n",
        "        data_rows = rows[1:]\n",
        "        code_idx = 0\n",
        "        name_idx = 1\n",
        "    else:\n",
        "        # No header\n",
        "        data_rows = rows\n",
        "        code_idx = 0\n",
        "        name_idx = 1 if len(rows[0]) > 1 else 0\n",
        "    for r in data_rows:\n",
        "        if not r:\n",
        "            continue\n",
        "        k = (r[code_idx] if len(r) > code_idx else \"\").strip()\n",
        "        v = (r[name_idx] if len(r) > name_idx else \"\").strip()\n",
        "        if k:\n",
        "            mapping[k] = v\n",
        "    return mapping\n",
        "\n",
        "def load_resolver_from_server() -> Dict[str, str]:\n",
        "    \"\"\"Load resolver from /partials first, then /gengen/partials. Cache locally.\"\"\"\n",
        "    if \"ftp_connect\" not in globals():\n",
        "        raise RuntimeError(\"ftp_connect() is not available; ensure Section [A] is loaded first.\")\n",
        "    ftps = ftp_connect()\n",
        "    try:\n",
        "        # Primary: absolute root /partials\n",
        "        primary = _remote_abs(SERVER_PARTIALS_DIR, SERVER_MAPPING_BASENAME)  # e.g., /partials/match_to_unmasked.csv\n",
        "        ok, err = _ftps_fetch_to_local(ftps, primary, LOCAL_MAPPING_CACHE)\n",
        "        if not ok:\n",
        "            # Fallback: FTP_DIR/partials (e.g., /gengen/partials/...)\n",
        "            fallback = _remote_under_ftpdir(posixpath.join(\"partials\", SERVER_MAPPING_BASENAME))\n",
        "            ok2, err2 = _ftps_fetch_to_local(ftps, fallback, LOCAL_MAPPING_CACHE)\n",
        "            if not ok2:\n",
        "                raise RuntimeError(\n",
        "                    \"Resolver not found on server at either location:\\n\"\n",
        "                    f\"  1) {primary}\\n\"\n",
        "                    f\"  2) {fallback}\\n\"\n",
        "                    \"Action: Upload match_to_unmasked.csv to /partials/ (root) or to /gengen/partials/ and re-run.\\n\"\n",
        "                    f\"Details: primary error: {err}; fallback error: {err2}\"\n",
        "                )\n",
        "        mapping = _read_resolver_csv(LOCAL_MAPPING_CACHE)\n",
        "        return mapping\n",
        "    finally:\n",
        "        try:\n",
        "            ftps.quit()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "# Global resolver dict (available to other sections)\n",
        "MATCH_TO_UNMASKED = load_resolver_from_server()\n",
        "\n",
        "# ---------- Resolver helpers exposed to other sections ----------\n",
        "def resolve_match_to(code_value: str) -> str:\n",
        "    \"\"\"Return unmapped name for a resolver 'Match to' code, or empty string if unknown.\"\"\"\n",
        "    if not code_value and code_value != 0:\n",
        "        return \"\"\n",
        "    code = str(code_value).strip()\n",
        "    if not code:\n",
        "        return \"\"\n",
        "    mapping = globals().get(\"MATCH_TO_UNMASKED\", {})\n",
        "    return mapping.get(code, \"\")\n",
        "\n",
        "def normalize_person_name(s: str) -> str:\n",
        "    \"\"\"Return a title-cased person name with safe punctuation for XHTML/iso-8859-15.\"\"\"\n",
        "    if not isinstance(s, str):\n",
        "        return \"\"\n",
        "    s = s.strip()\n",
        "    if not s:\n",
        "        return \"\"\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    def _title_token(tok: str) -> str:\n",
        "        if not tok:\n",
        "            return tok\n",
        "        if len(tok) == 1 and tok.isalpha():\n",
        "            return tok.upper() + \".\"\n",
        "        if \"-\" in tok:\n",
        "            return \"-\".join([p.capitalize() if p else \"\" for p in tok.split(\"-\")])\n",
        "        return tok.capitalize()\n",
        "    parts = s.split(\" \")\n",
        "    fixed = [_title_token(p) for p in parts]\n",
        "    name = \" \".join(fixed)\n",
        "    import html as _h\n",
        "    return _h.escape(name, quote=True)\n",
        "\n",
        "# ---------- General Helpers (used by later sections) ----------\n",
        "def find_col(df, regex_list: Optional[List[str]] = None, fallback_list: Optional[List[str]] = None) -> Optional[str]:\n",
        "    \"\"\"Find a column by regex OR fallback names; returns the first match or None.\"\"\"\n",
        "    if df is None or getattr(df, \"columns\", None) is None:\n",
        "        return None\n",
        "    regex_list = regex_list or []\n",
        "    fallback_list = fallback_list or []\n",
        "    cols = list(df.columns)\n",
        "\n",
        "    # Try regex matches\n",
        "    for pattern in regex_list:\n",
        "        try:\n",
        "            rx = re.compile(pattern, flags=re.IGNORECASE)\n",
        "        except Exception:\n",
        "            continue\n",
        "        for c in cols:\n",
        "            if rx.search(str(c)):\n",
        "                return c\n",
        "\n",
        "    # Try fallback exact, case-insensitive\n",
        "    for name in fallback_list:\n",
        "        target = str(name).strip().lower()\n",
        "        for c in cols:\n",
        "            if str(c).strip().lower() == target:\n",
        "                return c\n",
        "\n",
        "    # Last resort: first column if present\n",
        "    return cols[0] if cols else None\n",
        "\n",
        "def find_cols(df, patterns_or_names: List[str]) -> List[str]:\n",
        "    \"\"\"Return all columns that match any regex or exact name (case-insensitive).\"\"\"\n",
        "    hits = []\n",
        "    if df is None or getattr(df, \"columns\", None) is None:\n",
        "        return hits\n",
        "    cols = list(df.columns)\n",
        "    for token in patterns_or_names:\n",
        "        is_regex = bool(re.search(r\"[\\\\^$.*+?()\\\\[\\\\]|]\", token))\n",
        "        if is_regex:\n",
        "            try:\n",
        "                rx = re.compile(token, flags=re.IGNORECASE)\n",
        "            except Exception:\n",
        "                continue\n",
        "            for c in cols:\n",
        "                if rx.search(str(c)):\n",
        "                    hits.append(c)\n",
        "        else:\n",
        "            low = token.strip().lower()\n",
        "            for c in cols:\n",
        "                if str(c).strip().lower() == low:\n",
        "                    hits.append(c)\n",
        "    # de-dupe preserving order\n",
        "    seen = set()\n",
        "    uniq = []\n",
        "    for c in hits:\n",
        "        if c not in seen:\n",
        "            uniq.append(c)\n",
        "            seen.add(c)\n",
        "    return uniq\n",
        "\n",
        "def normalize_colnames(df):\n",
        "    \"\"\"Return a copy with normalized column names (no mutation).\"\"\"\n",
        "    if df is None or getattr(df, \"columns\", None) is None:\n",
        "        return df\n",
        "    new = df.copy()\n",
        "    new.columns = [re.sub(r\"\\s+\", \" \", str(c)).strip().lower() for c in df.columns]\n",
        "    return new\n",
        "\n",
        "def html_escape(s: str) -> str:\n",
        "    import html as _h\n",
        "    return _h.escape(\"\" if s is None else str(s), quote=True)\n",
        "\n",
        "def is_htmlish(s: str) -> bool:\n",
        "    if not isinstance(s, str):\n",
        "        return False\n",
        "    return (\"<a \" in s) or (\"<span\" in s) or (\"<div\" in s) or (\"<br\" in s) or (\"</\" in s)\n",
        "\n",
        "def comma_int(n) -> str:\n",
        "    try:\n",
        "        return f\"{int(n):,}\"\n",
        "    except Exception:\n",
        "        return str(n)\n",
        "\n",
        "def safe_get(row, col, default=\"\"):\n",
        "    try:\n",
        "        return row.get(col, default)\n",
        "    except Exception:\n",
        "        try:\n",
        "            return row[col]\n",
        "        except Exception:\n",
        "            return default\n",
        "\n",
        "def slugify(s: str) -> str:\n",
        "    s = re.sub(r\"[^A-Za-z0-9]+\", \"-\", str(s)).strip(\"-\")\n",
        "    s = re.sub(r\"-{2,}\", \"-\", s)\n",
        "    return s.lower()\n",
        "\n",
        "# ---- Gold 2 specific helpers needed by transform ----\n",
        "ID_PAT = re.compile(r\"\\bI\\d+\\b\", re.I)\n",
        "def extract_person_id(s: str) -> str:\n",
        "    m = ID_PAT.search(str(s or \"\"))\n",
        "    return m.group(0).upper() if m else \"\"\n",
        "\n",
        "_CAMEL_WORDS = re.compile(r\"[A-Z][a-z]*|[A-Z]+(?![a-z])|[a-z]+\")\n",
        "def smart_titlecase(s: str) -> str:\n",
        "    s = str(s or \"\").strip()\n",
        "    if not s: return \"\"\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    parts = [p.capitalize() for p in s.split(\" \") if p]\n",
        "    return \" \".join(parts)\n",
        "\n",
        "def surname_given_from_token(token: str) -> tuple:\n",
        "    token = str(token or \"\").strip()\n",
        "    if not token: return \"\", \"\"\n",
        "    words = _CAMEL_WORDS.findall(token)\n",
        "    if not words: return token, \"\"\n",
        "    return words[0].capitalize(), (\" \".join(words[1:])).capitalize()\n",
        "\n",
        "def _truncate_alpha(s: str, n: int) -> str:\n",
        "    return re.sub(r\"[^A-Za-z]\", \"\", str(s))[:n]\n",
        "\n",
        "def truncate_first(name: str, n: int = 7) -> str:\n",
        "    name = str(name or \"\").strip()\n",
        "    if not name: return \"\"\n",
        "    parts = name.split()\n",
        "    if not parts: return \"\"\n",
        "    parts[0] = _truncate_alpha(parts[0], n).capitalize()\n",
        "    return \" \".join(parts)\n",
        "\n",
        "def norm_matchee_name(raw: str) -> str:\n",
        "    raw = str(raw or \"\").strip()\n",
        "    if not raw:\n",
        "        return \"\"\n",
        "    if \" \" in raw or \",\" in raw:\n",
        "        nm = smart_titlecase(raw)\n",
        "        parts = nm.split()\n",
        "        if len(parts) == 1:\n",
        "            return nm\n",
        "        given = parts[0]\n",
        "        surname = parts[-1]\n",
        "        return f\"{_truncate_alpha(given, 7)} {surname}\".strip()\n",
        "    words = _CAMEL_WORDS.findall(raw)\n",
        "    while words and len(words[0]) == 1:\n",
        "        words.pop(0)\n",
        "    if not words:\n",
        "        nm = smart_titlecase(surname_given_from_token(raw)[0])\n",
        "        ps = nm.split()\n",
        "        if len(ps) == 1:\n",
        "            return nm\n",
        "        return f\"{_truncate_alpha(ps[0], 7)} {ps[-1]}\".strip()\n",
        "    surname = smart_titlecase(words[0])\n",
        "    given_candidates = [w for w in words[1:] if w.lower() != surname.lower()]\n",
        "    if not given_candidates:\n",
        "        return surname\n",
        "    given = smart_titlecase(given_candidates[0])\n",
        "    return f\"{_truncate_alpha(given, 7)} {surname}\".strip()\n",
        "\n",
        "def split_tokens(lineage: str) -> List[str]:\n",
        "    s = str(lineage or \"\").strip()\n",
        "    if not s: return []\n",
        "    # tokens separated by ' -> ' (plus a couple of safe fallbacks)\n",
        "    parts = [p.strip() for p in re.split(r\"\\s*->\\s*|\\s*\\u2192\\s*|\\s*&gt;\\s*\", s) if p.strip()]\n",
        "    return parts\n",
        "\n",
        "def derive_common_from_first_token(tokens: List[str]) -> tuple:\n",
        "    if not tokens: return \"\", \"\"\n",
        "    first = tokens[0]\n",
        "    parts = re.split(r\"\\s*&\\s*|\\s+and\\s+\", first)\n",
        "    a = parts[0].strip() if parts else \"\"\n",
        "    b = parts[1].strip() if len(parts) > 1 else \"\"\n",
        "    return a, b\n",
        "\n",
        "def build_header(subject_bold_html: str, cm_val: str, matchee_html: str, gens_total: int, husband: str, wife: str) -> str:\n",
        "    cm_txt = html_escape(cm_val) if cm_val else \"0\"\n",
        "    gens_txt = comma_int(gens_total)\n",
        "    pair = f\"{html_escape(husband)} &amp; {html_escape(wife)}\" if (husband or wife) else \"&hellip;\"\n",
        "    return (\n",
        "        f\"{subject_bold_html} is a DNA match to {matchee_html}. \"\n",
        "        f\"Shared DNA: <em>{cm_txt} cM</em>. \"\n",
        "        f\"Oldest distant ancestor couple: <em>{pair}</em>. \"\n",
        "        f\"Total generations in path: <em>{gens_txt}</em>.\"\n",
        "    )\n",
        "# ====== CUT STOP  [B] REFACTOR-Gold 2 — Add 5 returns for spacing ===============================\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "# ====== CUT START [3/6] REFACTOR-Gold 2 — CSV Load + Column Detection + Row Helpers ================\n",
        "import os\n",
        "import pandas as pd\n",
        "import urllib.parse as _u\n",
        "\n",
        "# Use the path defined in [A]; allow override via env\n",
        "CSV_IN = os.environ.get(\"CSV_IN\", CSV_PATH if 'CSV_PATH' in globals() else \"final_combined_df_with_value_labels.csv\")\n",
        "\n",
        "# ---- Load CSV (robust encodings) ----\n",
        "_encs = (\"utf-8-sig\", \"utf-8\", \"cp1252\", \"iso-8859-15\", \"latin1\")\n",
        "_last_err = None\n",
        "df = None\n",
        "for _e in _encs:\n",
        "    try:\n",
        "        df = pd.read_csv(CSV_IN, encoding=_e, dtype=str, keep_default_na=False)\n",
        "        break\n",
        "    except Exception as _ex:\n",
        "        _last_err = _ex\n",
        "        df = None\n",
        "if df is None:\n",
        "    raise RuntimeError(f\"Unable to read CSV: {CSV_IN} ({_last_err})\")\n",
        "print(f\"✅ Loaded CSV — {len(df)} rows, {len(df.columns)} columns from {os.path.abspath(CSV_IN)}\")\n",
        "\n",
        "# Normalize header spacing/case (but keep original values intact for content)\n",
        "df = normalize_colnames(df)\n",
        "\n",
        "# ---- Locate columns (names vary slightly across exports) ----\n",
        "id_col        = find_col(df, [r'^(id#|personid|id)$', r'person\\s*id'], [\"ID#\", \"ID\", \"PersonID\", \"personID\", \"id\"])\n",
        "match_to_col  = find_col(df, [r'^match\\s*to$', r'^matchto$'], [\"Match to\",\"Match\",\"match_to\"])\n",
        "name_col      = find_col(df, [r'^(name|full\\s*name)$'], [\"Name\",\"Full Name\"])\n",
        "cm_col        = find_col(df, [r'^(c\\s*:?m|cm)$', r'centi.?morgan'], [\"cM\",\"cm\",\"Centimorgans\"])\n",
        "path_col      = find_col(df, [r'(yates\\s*dna\\s*ancestral\\s*line|ancestral\\s*line|lineage)'],\n",
        "                         [\"Yates DNA Ancestral Line\",\"Ancestral Line\",\"Lineage\",\"lineage\"])\n",
        "subject_code_col = find_col(df, [r'^(subject\\s*code|subjectcode|code)$'], [\"Subject Code\",\"subject_code\",\"Code\",\"code\"])\n",
        "\n",
        "if not id_col:       raise ValueError(\"CSV missing an ID#/PersonID column.\")\n",
        "if not match_to_col: raise ValueError(\"CSV missing 'Match to' column.\")\n",
        "if not name_col:     raise ValueError(\"CSV missing 'Name' column.\")\n",
        "if not cm_col:       raise ValueError(\"CSV missing 'cM' column.\")\n",
        "if not path_col:     raise ValueError(\"CSV missing lineage/path column.\")\n",
        "# subject_code_col is optional but recommended; continue even if None\n",
        "\n",
        "print(\"✅ Columns:\", {\"ID\": id_col, \"Match to\": match_to_col, \"Name\": name_col, \"cM\": cm_col, \"Lineage\": path_col, \"SubjectCode\": subject_code_col})\n",
        "# ====== CUT STOP [3/6] REFACTOR-Gold 2 — CSV Load + Column Detection + Row Helpers =================\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ====== CUT START [4/6] REFACTOR-Gold 2 — Transform & Column A (build display_df) ==================\n",
        "import urllib.parse as _u\n",
        "import os\n",
        "\n",
        "# ---------- Safety checks for upstream dependencies ----------\n",
        "_required = [\n",
        "    \"df\", \"id_col\", \"match_to_col\", \"name_col\", \"cm_col\", \"path_col\",\n",
        "    \"normalize_person_name\", \"resolve_match_to\", \"extract_person_id\",\n",
        "    \"norm_matchee_name\", \"split_tokens\", \"derive_common_from_first_token\",\n",
        "    \"build_header\", \"truncate_first\",\n",
        "    \"TNG_BASE\", \"TNG_TREE\", \"ARROW_ENTITY\"\n",
        "]\n",
        "_missing = [x for x in _required if x not in globals()]\n",
        "if _missing:\n",
        "    raise RuntimeError(f\"[4/6] missing prerequisites from earlier sections: {_missing}\")\n",
        "\n",
        "# Defaults if not set in [A]\n",
        "REMOTE_NAME_ABS = \"/\" + (REMOTE_NAME if 'REMOTE_NAME' in globals() else \"ons_yates_dna_register.htm\")\n",
        "LINEAGE_HEADER_SAFE = globals().get(\"LINEAGE_HEADER\", \"Lineage (Starting with oldest ancestor, the line is:)\")\n",
        "MATCH_COUSINS_CSV_SAFE = globals().get(\"MATCH_COUSINS_CSV\", \"match_cousins_columnA.csv\")\n",
        "ENC_SAFE = globals().get(\"ENC\", \"iso-8859-15\")\n",
        "\n",
        "# ---------- Build the three display columns ----------\n",
        "headers: list[str]  = []\n",
        "lineages: list[str] = []\n",
        "findcol: list[str]  = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    # Subject: resolver code in \"Match to\" → unmasked name (bolded in sentence)\n",
        "    subject_raw  = row.get(match_to_col, \"\")\n",
        "    subject_name = normalize_person_name(resolve_match_to(subject_raw))\n",
        "    subject_name_b = f\"<strong>{subject_name}</strong>\" if subject_name else subject_name\n",
        "\n",
        "    # Matchee: name from CSV (normalized) + TNG hotlink if personID present\n",
        "    pid = extract_person_id(row.get(id_col, \"\"))\n",
        "    matchee_name = norm_matchee_name(row.get(name_col, \"\")) or subject_name or \"\"\n",
        "    if pid:\n",
        "        matchee_html = (\n",
        "            f'<a href=\"{TNG_BASE}/verticalchart.php?personID={pid}&tree={TNG_TREE}&parentset=0&display=vertical&generations=15\" '\n",
        "            f'target=\"_blank\" rel=\"noopener\">{matchee_name}</a>'\n",
        "        )\n",
        "    else:\n",
        "        matchee_html = matchee_name\n",
        "\n",
        "    # cM value\n",
        "    cm_val = row.get(cm_col, \"0\")\n",
        "\n",
        "    # Lineage path (tokens oldest→youngest)\n",
        "    tokens      = split_tokens(row.get(path_col, \"\"))\n",
        "    gens_total  = len(tokens)\n",
        "    tokens_disp = tokens[:7]  # show first 7 pairs\n",
        "\n",
        "    # Husband & Wife from first token unless explicit columns exist\n",
        "    if \"common_husband\" in df.columns and \"common_wife\" in df.columns:\n",
        "        husband_raw = str(row.get(\"common_husband\", \"\")).strip()\n",
        "        wife_raw    = str(row.get(\"common_wife\", \"\")).strip()\n",
        "        if not husband_raw and not wife_raw:\n",
        "            husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "    else:\n",
        "        husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "\n",
        "    # Build the sentence header (truncate first names to 7 chars for readability)\n",
        "    header_html = build_header(\n",
        "        subject_name_b,\n",
        "        cm_val,\n",
        "        matchee_html,\n",
        "        gens_total,\n",
        "        truncate_first(husband_raw, 7) if husband_raw else \"\",\n",
        "        truncate_first(wife_raw, 7) if wife_raw else \"\"\n",
        "    )\n",
        "\n",
        "    # Bold the first pair in lineage view\n",
        "    if tokens_disp:\n",
        "        tokens_disp[0] = f\"<strong>{tokens_disp[0]}</strong>\"\n",
        "\n",
        "    sep = f\" {ARROW_ENTITY} \"\n",
        "    lineage_text = sep.join(tokens_disp) if tokens_disp else \"\"\n",
        "\n",
        "    # Per-row quick-open search button (?q=Subject Name)\n",
        "    q = _u.quote(subject_name)\n",
        "    quick = (f'<a class=\"find-btn\" href=\"{REMOTE_NAME_ABS}?q={q}\" target=\"_blank\" rel=\"noopener\" '\n",
        "             f'title=\"Open a filtered view for {subject_name}\">Find</a>')\n",
        "\n",
        "    headers.append(header_html)\n",
        "    lineages.append(lineage_text)\n",
        "    findcol.append(quick)\n",
        "\n",
        "# ---------- Assemble the display dataframe ----------\n",
        "df[\"Find\"]               = findcol\n",
        "df[\"Match Summary\"]      = headers\n",
        "df[LINEAGE_HEADER_SAFE]  = lineages\n",
        "\n",
        "display_df = df[[\"Find\", \"Match Summary\", LINEAGE_HEADER_SAFE]].copy()\n",
        "\n",
        "# ---------- Column A CSV (side artifact used by other tooling) ----------\n",
        "try:\n",
        "    display_df[[\"Match Summary\"]].to_csv(MATCH_COUSINS_CSV_SAFE, index=False, encoding=ENC_SAFE)\n",
        "    print(\"✅ Wrote local CSV (Column A):\", os.path.abspath(MATCH_COUSINS_CSV_SAFE))\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Could not write Column A CSV ({MATCH_COUSINS_CSV_SAFE}): {e}\")\n",
        "\n",
        "print(\"✅ Built display_df with\", len(display_df), \"rows.\")\n",
        "# ====== CUT STOP [4/6] REFACTOR-Gold 2 — Transform & Column A (build display_df) ==================\n",
        "\n",
        "\n",
        "\n",
        "# ====== CUT START [5/6] REFACTOR-Gold 2 — HTML (table + CSS + JS, no uploads) ======================\n",
        "import html as _html\n",
        "\n",
        "# ---------- Preconditions ----------\n",
        "_needed = [\"display_df\", \"LINEAGE_HEADER_SAFE\", \"TABLE_WIDTH_PX\", \"COL_A_PX\",\n",
        "           \"COUNT_PUBLIC_URL\", \"ARROW_ENTITY\"]\n",
        "_missing = [x for x in _needed if x not in globals()]\n",
        "if _missing:\n",
        "    raise RuntimeError(f\"[5/6] missing prerequisites from earlier sections: {_missing}\")\n",
        "\n",
        "# ---------- Constants / page prefs ----------\n",
        "HOME_URL = \"https://yates.one-name.net/ons_yates_dna_register.htm\"\n",
        "DOM_ID_PREFIX = \"g2-\"  # enforce Gold 2 namespace for DOM\n",
        "\n",
        "# ---------- Build HTML table ----------\n",
        "_display = display_df[[\"Find\", \"Match Summary\", LINEAGE_HEADER_SAFE]].copy()\n",
        "html_table = _display.to_html(index=False, escape=False, classes=f\"sortable {DOM_ID_PREFIX}dataframe\")\n",
        "\n",
        "# Tag table and first row with Gold 2 ids\n",
        "TABLE_ID = f\"{DOM_ID_PREFIX}table\"\n",
        "html_table = html_table.replace(\n",
        "    '<table border=\"1\" class=\"dataframe sortable',\n",
        "    f'<table border=\"1\" class=\"dataframe sortable {DOM_ID_PREFIX}dataframe',\n",
        "    1\n",
        ")\n",
        "html_table = html_table.replace(\n",
        "    f'<table border=\"1\" class=\"dataframe sortable {DOM_ID_PREFIX}dataframe\">',\n",
        "    f'<table border=\"1\" class=\"dataframe sortable {DOM_ID_PREFIX}dataframe\" id=\"{TABLE_ID}\">', 1\n",
        ")\n",
        "html_table = html_table.replace('<tbody>\\n<tr>', f'<tbody>\\n<tr id=\"{DOM_ID_PREFIX}first-row\">', 1)\n",
        "\n",
        "# widths via <colgroup>\n",
        "FIND_PX = 110\n",
        "colgroup_html = (\n",
        "    \"<colgroup>\\n\"\n",
        "    f\"  <col style=\\\"width:{FIND_PX}px;\\\" />\\n\"\n",
        "    f\"  <col style=\\\"width:{COL_A_PX}px;\\\" />\\n\"\n",
        "    \"  <col />\\n\"\n",
        "    \"</colgroup>\\n\"\n",
        ")\n",
        "html_table = html_table.replace(\n",
        "    f'<table border=\"1\" class=\"dataframe sortable {DOM_ID_PREFIX}dataframe\" id=\"{TABLE_ID}\">',\n",
        "    f'<table border=\"1\" class=\"dataframe sortable {DOM_ID_PREFIX}dataframe\" id=\"{TABLE_ID}\">\\n{colgroup_html}', 1\n",
        ")\n",
        "\n",
        "# add Select-all checkbox to header cell “Find”\n",
        "MASTER_CB_ID = f\"{DOM_ID_PREFIX}sel-all\"\n",
        "html_table = html_table.replace(\n",
        "    \"<th>Find</th>\",\n",
        "    f'<th>Find&nbsp;<input type=\"checkbox\" id=\"{MASTER_CB_ID}\" title=\"Select all visible\" /></th>',\n",
        "    1\n",
        ")\n",
        "\n",
        "html_table_scrolling = f'<div class=\"{DOM_ID_PREFIX}table-scroll\">\\n{html_table}\\n</div>'\n",
        "\n",
        "# ---------- CSS (Gold 2 namespace) ----------\n",
        "TABLE_CSS = (\n",
        "    \"<style type=\\\"text/css\\\">\\n\"\n",
        "    \"  html { scroll-behavior: smooth; }\\n\"\n",
        "    \"  body { font-family: Georgia, 'Times New Roman', serif; background:#ffffff; color:#222; margin:0; padding:0; line-height:1.5; }\\n\"\n",
        "    f\"  .{DOM_ID_PREFIX}wrap {{ max-width:{TABLE_WIDTH_PX}px; margin:0 auto; background:#ffffff; padding:20px; padding-bottom:48px; }}\\n\"\n",
        "    \"  a { color:#154b8b; text-decoration:none; } a:hover { text-decoration:underline; }\\n\"\n",
        "    \"  h1 { margin:0 0 6px 0; font-size:26px; line-height:1.2; text-align:center; }\\n\"\n",
        "    \"  .updated { font-size:12px; color:#555; text-align:center; margin:2px 0 10px 0; }\\n\"\n",
        "    f\"  .{DOM_ID_PREFIX}sortbar {{ margin:6px 0 10px 0; font-size:13px; background:#ffffff; padding:6px 8px; border-radius:6px;\\n\"\n",
        "    \"             display:flex; flex-wrap:wrap; gap:5px; align-items:center; border:1px solid #ddd; }}\\n\"\n",
        "    f\"  .{DOM_ID_PREFIX}btn {{ display:inline-block; border:1px solid #5b79b8; background:#5b79b8; color:#fff; padding:4px 9px;\\n\"\n",
        "    \"         text-decoration:none; cursor:pointer; border-radius:5px; line-height:1.2; transition:background 0.2s, transform 0.1s; user-select:none; }}\\n\"\n",
        "    f\"  .{DOM_ID_PREFIX}btn:hover {{ background:#4668aa; transform:translateY(-1px); }}\\n\"\n",
        "    f\"  input.{DOM_ID_PREFIX}search {{ background:#fff; color:#111; border:1px solid #bbb; padding:4px 9px; border-radius:5px; }}\\n\"\n",
        "    f\"  .{DOM_ID_PREFIX}btn-mini {{ font-size:12px; padding:2px 6px; line-height:1.1; margin-left:6px; }}\\n\"\n",
        "    f\"  .{DOM_ID_PREFIX}find-cell {{ white-space:nowrap; }}\\n\"\n",
        "    f\"  .{DOM_ID_PREFIX}selbox {{ margin-right:6px; vertical-align:middle; }}\\n\"\n",
        "    f\"  .{DOM_ID_PREFIX}table-scroll {{ max-height:70vh; overflow-y:auto; overflow-x:auto; border:1px solid #ddd; }}\\n\"\n",
        "    f\"  table.sortable {{ border-collapse:collapse; width:{TABLE_WIDTH_PX}px; table-layout:fixed; }}\\n\"\n",
        "    \"  table.sortable th, table.sortable td { border:1px solid #ddd; padding:6px 8px; vertical-align:top; }\\n\"\n",
        "    \"  table.sortable th { background:#e3eaf8; text-align:left; position:sticky; top:0; z-index:2; box-shadow:0 1px 0 #ccc; }\\n\"\n",
        "    \"  table.sortable td { word-wrap:break-word; overflow-wrap:break-word; }\\n\"\n",
        "    f\"  #{DOM_ID_PREFIX}first-row td {{ border-top:2px solid #999; }}\\n\"\n",
        "    f\"  #{DOM_ID_PREFIX}back-to-top {{ position:fixed; right:16px; bottom:16px; padding:6px 10px; border:1px solid #3e5a97; background:#5b79b8; color:#fff;\\n\"\n",
        "    \"                 cursor:pointer; border-radius:6px; font-size:12px; display:none; z-index:9999; }\\n\"\n",
        "    f\"  #{DOM_ID_PREFIX}back-to-top:hover {{ background:#4668aa; }}\\n\"\n",
        "    f\"  #{DOM_ID_PREFIX}dynamic {{ margin:10px 0 14px 0; }}\\n\"\n",
        "    \"  @media screen and (max-width: 820px) { \"\n",
        "    f\".{DOM_ID_PREFIX}wrap {{ padding:12px; }} h1 {{ font-size:22px; }} }}\\n\"\n",
        "    \"</style>\\n\"\n",
        ")\n",
        "\n",
        "# ---------- Toolbar (Gold 2 namespace + root-level partials) ----------\n",
        "BTN_EMAIL_SEL_ID = f\"{DOM_ID_PREFIX}email-selected\"\n",
        "BTN_CLEAR_SEL_ID = f\"{DOM_ID_PREFIX}clear-selected\"\n",
        "SEARCH_ID        = f\"{DOM_ID_PREFIX}search-box\"\n",
        "\n",
        "DYNAMIC_BLOCK = (\n",
        "    f\"<div class=\\\"{DOM_ID_PREFIX}sortbar\\\">\\n\"\n",
        "    \"  <a class=\\\"{btn}\\\" href=\\\"https://yates.one-name.net/gengen/dna_cousin_surname_study.htm\\\" target=\\\"_blank\\\">Study Details</a>\\n\"\n",
        "    \"  <a class=\\\"{btn}\\\" href=\\\"https://yates.one-name.net/gengen/dna_theory_of_the_case.htm\\\" target=\\\"_blank\\\">Theory in Action</a>\\n\"\n",
        "    \"  <span class=\\\"{btn}\\\" data-sort-col=\\\"1\\\" data-sort-dir=\\\"asc\\\">Sort Match &uarr;</span>\\n\"\n",
        "    \"  <span class=\\\"{btn}\\\" data-sort-col=\\\"1\\\" data-sort-dir=\\\"desc\\\">Sort Match &darr;</span>\\n\"\n",
        "    \"  <span class=\\\"{btn}\\\" data-sort-col=\\\"2\\\" data-sort-dir=\\\"asc\\\">Sort Lineage &uarr;</span>\\n\"\n",
        "    \"  <span class=\\\"{btn}\\\" data-sort-col=\\\"2\\\" data-sort-dir=\\\"desc\\\">Sort Lineage &darr;</span>\\n\"\n",
        "    \"  <a class=\\\"{btn}\\\" href=\\\"gengen/images/cousin-calculator.jpg\\\" target=\\\"_blank\\\">Cousin Connection</a>\\n\"\n",
        "    \"  <a class=\\\"{btn}\\\" href=\\\"gengen/images/Shared_cM_Project_v4.jpg\\\" target=\\\"_blank\\\">Cousin by DNA</a>\\n\"\n",
        "    # load-able partials into dynamic container (root-level preferred)\n",
        "    f\"  <a class=\\\"{{btn}}\\\" data-load-partial=\\\"match_count.htm\\\"   href=\\\"#\\\">Match Count</a>\\n\"\n",
        "    f\"  <a class=\\\"{{btn}}\\\" data-load-partial=\\\"lineage_count.htm\\\" href=\\\"#\\\">Lineage Count</a>\\n\"\n",
        "    f\"  <a class=\\\"{{btn}}\\\" href=\\\"/partials/cousin_list_print.htm\\\" target=\\\"_blank\\\">Cousin List</a>\\n\"\n",
        "    f\"  <span class=\\\"{{btn}}\\\" id=\\\"{BTN_EMAIL_SEL_ID}\\\">Email Selected</span>\\n\"\n",
        "    f\"  <span class=\\\"{{btn}}\\\" id=\\\"{BTN_CLEAR_SEL_ID}\\\">Clear</span>\\n\"\n",
        "    f\"  <input type=\\\"text\\\" id=\\\"{SEARCH_ID}\\\" class=\\\"{{search}}\\\" size=\\\"24\\\" value=\\\"\\\" placeholder=\\\"Search&hellip;\\\" \"\n",
        "    \"         autocomplete=\\\"off\\\" autocapitalize=\\\"off\\\" spellcheck=\\\"false\\\" inputmode=\\\"search\\\" enterkeyhint=\\\"search\\\" />\\n\"\n",
        "    \"</div>\\n\"\n",
        "    f\"<div id=\\\"{DOM_ID_PREFIX}dynamic\\\"></div>\\n\"\n",
        ").format(btn=f\"{DOM_ID_PREFIX}btn\", search=f\"{DOM_ID_PREFIX}search\")\n",
        "\n",
        "# ---------- Updated status line (top, dynamic) with Home link ----------\n",
        "JS_COUNT_URL = COUNT_PUBLIC_URL.replace(\"'\", \"%27\")\n",
        "UPDATED_BLOCK = (\n",
        "    \"<div class=\\\"updated\\\">\"\n",
        "    f\"<a href=\\\"{HOME_URL}\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">Home</a>\"\n",
        "    \" &nbsp;|&nbsp; Last updated: <span id=\\\"last-updated\\\"></span>\"\n",
        "    \" &nbsp;|&nbsp; Autosomal matches: <span id=\\\"auto-count\\\" class=\\\"js-count\\\"></span>\"\n",
        "    \"</div>\"\n",
        ")\n",
        "\n",
        "# ---------- Full HTML (string only) ----------\n",
        "BACK_TO_TOP_ID = f\"{DOM_ID_PREFIX}back-to-top\"\n",
        "\n",
        "TEMPLATE_HTML = \"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "<title>ONS Yates Study Autosomal DNA Register</title>\n",
        "{TABLE_CSS}\n",
        "</head>\n",
        "<body id=\"top\">\n",
        "<div class=\"{DOM_PREFIX}wrap\">\n",
        "  <h1>ONS Yates Study Autosomal DNA Register</h1>\n",
        "  {UPDATED_BLOCK}\n",
        "  {DYNAMIC_BLOCK}\n",
        "{HTML_TABLE_SCROLLING}\n",
        "</div>\n",
        "<button id=\"{BACK_TO_TOP_ID}\" class=\"{DOM_PREFIX}back-to-top\">&#9650; Top</button>\n",
        "<script type=\"text/javascript\">\n",
        "//<![CDATA[\n",
        "(function(){\n",
        "  var DOM_PREFIX = \"{DOM_PREFIX}\";\n",
        "  function textOf(cell){ return (cell && (cell.textContent || cell.innerText) || '').replace(/\\\\s+/g,' ').trim().toLowerCase(); }\n",
        "  function sortTable(tbl, colIndex, dir){\n",
        "    var tb=tbl && tbl.tBodies ? tbl.tBodies[0] : null; if(!tb) return;\n",
        "    var rows=[].slice.call(tb.rows||[]);\n",
        "    var asc=(dir==='asc');\n",
        "    rows.sort(function(a,b){\n",
        "      var A=textOf(a.cells[colIndex]), B=textOf(b.cells[colIndex]);\n",
        "      if(A<B) return asc?-1:1; if(A>B) return asc?1:-1; return 0;\n",
        "    });\n",
        "    var frag=document.createDocumentFragment();\n",
        "    for(var i=0;i<rows.length;i++) frag.appendChild(rows[i]);\n",
        "    tb.appendChild(frag);\n",
        "    updateSelAll(); // keep master checkbox in sync after sort\n",
        "  }\n",
        "  function bindSortButtons(){\n",
        "    var tbl=document.getElementById('{TABLE_ID}'); var bar=document.querySelector('.{DOM_PREFIX}sortbar'); if(!(tbl && bar)) return;\n",
        "    bar.addEventListener('click',function(e){\n",
        "      var t=e.target; if(!t) return;\n",
        "      var btn=t.closest? t.closest('.{DOM_PREFIX}btn') : null; if(!btn) return;\n",
        "      var colAttr=btn.getAttribute('data-sort-col'); if(colAttr==null) return; var col=parseInt(colAttr,10); if(isNaN(col)) return;\n",
        "      var dir=btn.getAttribute('data-sort-dir')||'asc'; sortTable(tbl,col,dir); e.preventDefault(); return false;\n",
        "    },false);\n",
        "  }\n",
        "  function bindHeaderSort(){\n",
        "    var tbl=document.getElementById('{TABLE_ID}'); if(!(tbl && tbl.tHead && tbl.tHead.rows.length)) return; var ths=tbl.tHead.rows[0].cells;\n",
        "    for(var i=0;i<ths.length;i++)(function(idx){\n",
        "      var dir='asc'; ths[idx].addEventListener('click',function(){ dir=(dir==='asc')?'desc':'asc'; sortTable(tbl,idx,dir); },false);\n",
        "    })(i);\n",
        "  }\n",
        "\n",
        "  // partials via multiple base locations (root/relative)\n",
        "  var PARTIAL_BASES=['/partials/','partials/','gengen/partials/','/gengen/partials/'];\n",
        "  function tryFetchSequential(urls,onOK,onFail){\n",
        "    if(!urls.length) return onFail('No valid locations'); var url=urls.shift();\n",
        "    fetch(url,{cache:'no-store'}).then(function(r){ if(!r.ok) throw new Error('HTTP '+r.status); return r.text();})\n",
        "      .then(onOK).catch(function(){ tryFetchSequential(urls,onOK,onFail);});\n",
        "  }\n",
        "  function bindPartials(){\n",
        "    var bar=document.querySelector('.{DOM_PREFIX}sortbar'); if(!bar) return;\n",
        "    bar.addEventListener('click',function(e){\n",
        "      var t=e.target; if(!t) return;\n",
        "      var btn=t.closest? t.closest('.{DOM_PREFIX}btn') : null; if(!btn) return;\n",
        "      var rel=btn.getAttribute('data-load-partial'); if(!rel) return;\n",
        "      var c=document.getElementById('{DOM_PREFIX}dynamic'); if(!c) return; c.innerHTML='<p><em>Loading latest data&hellip;</em></p>';\n",
        "      var bust=encodeURIComponent(document.lastModified||(new Date()).toUTCString());\n",
        "      var candidates=PARTIAL_BASES.map(function(b){return b+rel+'?v='+bust;});\n",
        "      tryFetchSequential(candidates.slice(), function(html){ c.innerHTML=html; }, function(){ c.innerHTML='<p style=\\\\\\\"color:#a00;\\\\\\\">Could not load content.</p>'; });\n",
        "    });\n",
        "  }\n",
        "\n",
        "  // updated stamp + count\n",
        "  function stampLastUpdated(){\n",
        "    var el=document.getElementById('last-updated'); if(!el) return;\n",
        "    var d=new Date(document.lastModified||new Date());\n",
        "    function z(n){return(n<10?'0':'')+n;}\n",
        "    el.innerHTML=d.getFullYear()+'-'+z(d.getMonth()+1)+'-'+z(d.getDate())+' '+z(d.getHours())+':'+z(d.getMinutes());\n",
        "  }\n",
        "  function formatWithCommas(n){\n",
        "    try{ var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return ''; return x.toLocaleString('en-US'); }catch(e){ return String(n||''); }\n",
        "  }\n",
        "  function loadAutoCount(){\n",
        "    var el=document.getElementById('auto-count'); if(!el) return;\n",
        "    var url='{COUNT_URL}';\n",
        "    try{\n",
        "      var xhr=new XMLHttpRequest(); xhr.open('GET', url+(url.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true);\n",
        "      xhr.onreadystatechange=function(){ if(xhr.readyState===4){ if(xhr.status>=200&&xhr.status<300){\n",
        "        var m=(xhr.responseText||'').match(/(\\\\d+)/); var num=m?m[1]:'';\n",
        "        el.textContent = formatWithCommas(num) || '(unavailable)';\n",
        "      } else { el.textContent='(unavailable)'; } } };\n",
        "      xhr.send(null);\n",
        "    }catch(e){ el.textContent='(unavailable)'; }\n",
        "  }\n",
        "\n",
        "  // ---- search (filters rows; select-all respects visibility) ----\n",
        "  function getParam(name){ var m=location.search.match(new RegExp('[?&]'+name+'=([^&]+)')); return m?decodeURIComponent(m[1].replace(/\\\\+/g,' ')):''; }\n",
        "  function bindSearch(){\n",
        "    var box=document.getElementById('{SEARCH_ID}'); var tbl=document.getElementById('{TABLE_ID}'); if(!(box && tbl && tbl.tBodies && tbl.tBodies[0])) return; var tb=tbl.tBodies[0];\n",
        "    function norm(s){ return String(s||'').replace(/\\\\s+/g,' ').toLowerCase(); }\n",
        "    function rowText(tr){ var t=''; for(var i=0;i<tr.cells.length;i++){ t+= ' ' + (tr.cells[i].textContent||tr.cells[i].innerText||''); } return norm(t); }\n",
        "    var cached=[]; (function seed(){ var rows=tb.rows; cached=[]; for(var i=0;i<rows.length;i++){ cached.push({el:rows[i], txt:rowText(rows[i])}); } })();\n",
        "    function apply(q){\n",
        "      q=norm(q);\n",
        "      for(var i=0;i<cached.length;i++){\n",
        "        var hit = !q || cached[i].txt.indexOf(q)>-1;\n",
        "        cached[i].el.style.display = hit? '' : 'none';\n",
        "      }\n",
        "      updateSelAll();\n",
        "    }\n",
        "    var to=null; function onInput(){ if(to) clearTimeout(to); to=setTimeout(function(){ apply(box.value); }, 60); }\n",
        "    box.addEventListener('input', onInput, false);\n",
        "    var q0=getParam('q');\n",
        "    if(q0){ box.value=q0; apply(q0); try{ history.replaceState(null, '', location.pathname); }catch(e){} }\n",
        "    else { box.value=''; apply(''); setTimeout(function(){ if(!getParam('q')){ box.value=''; apply(''); } }, 0); }\n",
        "  }\n",
        "\n",
        "  // ---- selection controls (Gold 2) ----\n",
        "  function visibleRowCheckboxes(){\n",
        "    var tbl=document.getElementById('{TABLE_ID}');\n",
        "    if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return [];\n",
        "    var tb=tbl.tBodies[0], out=[];\n",
        "    for(var i=0;i<tb.rows.length;i++){\n",
        "      var tr=tb.rows[i];\n",
        "      if(tr.style.display==='none') continue;\n",
        "      var cb = tr.cells[0] && tr.cells[0].querySelector('.{DOM_PREFIX}selbox');\n",
        "      if(cb) out.push(cb);\n",
        "    }\n",
        "    return out;\n",
        "  }\n",
        "  function updateSelAll(){\n",
        "    var master=document.getElementById('{MASTER_CB_ID}'); if(!master) return;\n",
        "    var cbs=visibleRowCheckboxes();\n",
        "    if(!cbs.length){ master.indeterminate=false; master.checked=false; return; }\n",
        "    var checked=cbs.filter(function(cb){ return cb.checked; }).length;\n",
        "    master.checked = (checked===cbs.length);\n",
        "    master.indeterminate = (checked>0 && checked<cbs.length);\n",
        "  }\n",
        "  function bindSelectAll(){\n",
        "    var master=document.getElementById('{MASTER_CB_ID}'); if(!master) return;\n",
        "    master.addEventListener('change', function(){\n",
        "      var want=master.checked;\n",
        "      var cbs=visibleRowCheckboxes();\n",
        "      for(var i=0;i<cbs.length;i++) cbs[i].checked = want;\n",
        "      updateSelAll();\n",
        "    });\n",
        "  }\n",
        "  function pageBase(){ try{ return location.origin + location.pathname; }catch(e){ return location.pathname; } }\n",
        "  function encodeQS(s){ return encodeURIComponent(String(s||'')); }\n",
        "  function buildRowEmail(tr){\n",
        "    var cells = tr.cells; if(!cells || cells.length < 3) return null;\n",
        "    var summary = (cells[1].textContent||'').trim();\n",
        "    var lineage = (cells[2].textContent||'').trim();\n",
        "    var subj = 'ONS Yates Register: ' + summary.substring(0, 90);\n",
        "    var qMatch = (function(){ try{ var em = cells[1].querySelector('strong'); return (em?em.textContent:'').trim(); }catch(e){ return ''; } })();\n",
        "    var link = pageBase() + (qMatch? ('?q='+encodeQS(qMatch)) : '');\n",
        "    var body = summary + '\\\\n\\\\nLineage:\\\\n' + lineage + '\\\\n\\\\nLink: ' + link;\n",
        "    return {subject: subj, body: body};\n",
        "  }\n",
        "  function openMailto(subject, body){\n",
        "    var href = 'mailto:?subject=' + encodeQS(subject) + '&body=' + encodeQS(body);\n",
        "    window.location.href = href;\n",
        "  }\n",
        "  function injectRowControls(){\n",
        "    var tbl = document.getElementById('{TABLE_ID}'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return; var tb = tbl.tBodies[0];\n",
        "    for(var i=0;i<tb.rows.length;i++){\n",
        "      (function(tr){\n",
        "        var cell = tr.cells[0]; if(!cell) return; if(cell.className.indexOf('{DOM_PREFIX}find-cell')===-1) cell.className += ' {DOM_PREFIX}find-cell';\n",
        "        var existingFind = cell.querySelector('a.find-btn'); // keep your “Find” link\n",
        "        var cb = document.createElement('input'); cb.type='checkbox'; cb.className='{DOM_PREFIX}selbox'; cb.title='Select row';\n",
        "        cb.addEventListener('change', updateSelAll);\n",
        "        cell.insertBefore(cb, existingFind || cell.firstChild);\n",
        "        // optional per-row Email button\n",
        "        var emailBtn = document.createElement('a'); emailBtn.href='#'; emailBtn.className='{DOM_PREFIX}btn {DOM_PREFIX}btn-mini'; emailBtn.textContent='Email'; emailBtn.title='Email this row'; emailBtn.style.marginLeft='6px';\n",
        "        emailBtn.addEventListener('click', function(ev){ ev.preventDefault(); var payload = buildRowEmail(tr); if(payload){ openMailto(payload.subject, payload.body); } });\n",
        "        if(existingFind){ existingFind.insertAdjacentElement('afterend', emailBtn); } else { cell.appendChild(emailBtn); }\n",
        "      })(tb.rows[i]);\n",
        "    }\n",
        "  }\n",
        "  function bindBulkEmail(){\n",
        "    var btn = document.getElementById('{BTN_EMAIL_SEL_ID}'); if(!btn) return;\n",
        "    btn.addEventListener('click', function(){\n",
        "      var tbl = document.getElementById('{TABLE_ID}'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return; var tb = tbl.tBodies[0];\n",
        "      var parts = []; var count = 0;\n",
        "      for(var i=0;i<tb.rows.length;i++){\n",
        "        var tr = tb.rows[i]; if(tr.style.display==='none') continue;\n",
        "        var cb = tr.cells[0] && tr.cells[0].querySelector('.{DOM_PREFIX}selbox');\n",
        "        if(cb && cb.checked){ var p = buildRowEmail(tr); if(p){ parts.push(p.body); count++; } }\n",
        "      }\n",
        "      if(!count){ alert('No rows selected. Tick the checkboxes in the Find column.'); return; }\n",
        "      var subject = 'ONS Yates Register: ' + count + ' selection' + (count>1?'s':'');\n",
        "      var body = parts.join('\\\\n\\\\n---\\\\n\\\\n');\n",
        "      openMailto(subject, body);\n",
        "    });\n",
        "    var clr = document.getElementById('{BTN_CLEAR_SEL_ID}'); if(clr){ clr.addEventListener('click', function(){\n",
        "      var tbl = document.getElementById('{TABLE_ID}'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return; var tb = tbl.tBodies[0];\n",
        "      for(var i=0;i<tb.rows.length;i++){ var cb = tb.rows[i].cells[0] && tb.rows[i].querySelector('.{DOM_PREFIX}selbox'); if(cb) cb.checked=false; }\n",
        "      updateSelAll();\n",
        "    }); }\n",
        "  }\n",
        "\n",
        "  // misc UI\n",
        "  function setupBackToTop(){\n",
        "    var btt=document.getElementById('{BACK_TO_TOP_ID}'); var cont=document.querySelector('.{DOM_PREFIX}table-scroll');\n",
        "    function onAny(){ var y=(window.scrollY||window.pageYOffset||0); var cy=cont?cont.scrollTop:0; btt.style.display=(y>200||cy>200)?'block':'none'; }\n",
        "    window.addEventListener('scroll',onAny,{passive:true}); if(cont) cont.addEventListener('scroll',onAny,{passive:true});\n",
        "    onAny(); if(btt){ btt.addEventListener('click',function(){ if(cont) cont.scrollTo({top:0,behavior:'smooth'}); window.scrollTo({top:0,behavior:'smooth'}); }); }\n",
        "  }\n",
        "\n",
        "  // init\n",
        "  function init(){\n",
        "    bindSortButtons(); bindHeaderSort(); bindPartials(); stampLastUpdated(); loadAutoCount();\n",
        "    setupBackToTop(); bindSearch();\n",
        "    injectRowControls(); bindSelectAll(); bindBulkEmail(); updateSelAll();\n",
        "  }\n",
        "  init();\n",
        "})();\n",
        "//]]>\n",
        "</script>\n",
        "</body></html>\n",
        "\"\"\"\n",
        "\n",
        "FULL_HTML = (TEMPLATE_HTML\n",
        "    .replace(\"{TABLE_CSS}\", TABLE_CSS)\n",
        "    .replace(\"{UPDATED_BLOCK}\", UPDATED_BLOCK)\n",
        "    .replace(\"{DYNAMIC_BLOCK}\", DYNAMIC_BLOCK)\n",
        "    .replace(\"{HTML_TABLE_SCROLLING}\", html_table_scrolling)\n",
        "    .replace(\"{COUNT_URL}\", JS_COUNT_URL)\n",
        "    .replace(\"{DOM_PREFIX}\", DOM_ID_PREFIX)\n",
        "    .replace(\"{TABLE_ID}\", TABLE_ID)\n",
        "    .replace(\"{MASTER_CB_ID}\", MASTER_CB_ID)\n",
        "    .replace(\"{SEARCH_ID}\", SEARCH_ID)\n",
        "    .replace(\"{BTN_EMAIL_SEL_ID}\", BTN_EMAIL_SEL_ID)\n",
        "    .replace(\"{BTN_CLEAR_SEL_ID}\", BTN_CLEAR_SEL_ID)\n",
        "    .replace(\"{BACK_TO_TOP_ID}\", BACK_TO_TOP_ID)\n",
        ")\n",
        "# ====== CUT STOP [5/6] REFACTOR-Gold 2 — HTML (table + CSS + JS, no uploads) =======================\n",
        "\n",
        "\n",
        "# ====== CUT START [6/6] REFACTOR-Gold 2 — Save + Upload + Reports + Partials + Printable ===========\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import os, re, posixpath\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "ENC          = \"iso-8859-15\"\n",
        "LOCAL_NAME   = globals().get(\"LOCAL_NAME\",  \"ons_yates_dna_register.htm\")\n",
        "REMOTE_NAME  = globals().get(\"REMOTE_NAME\", \"ons_yates_dna_register.htm\")\n",
        "HOME_URL     = \"https://yates.one-name.net/ons_yates_dna_register.htm\"\n",
        "\n",
        "# Safely embed the JS count URL (escape single quotes)\n",
        "JS_COUNT_URL = (globals().get(\"COUNT_PUBLIC_URL\",\"\") or \"\").replace(\"'\", \"%27\")\n",
        "\n",
        "# ---------- Bind subject_code_col (the resolver code column, i.e., “Match to”) ----------\n",
        "# Prefer an existing binding; otherwise fall back to match_to_col (from [3/6]); last resort a literal name.\n",
        "subject_code_col = globals().get(\"subject_code_col\") or globals().get(\"match_to_col\") or \"Match to\"\n",
        "# If the fallback literal isn’t present in df, and match_to_col exists, use that explicitly.\n",
        "try:\n",
        "    if 'df' in globals():\n",
        "        if subject_code_col not in list(df.columns) and 'match_to_col' in globals() and globals()['match_to_col'] in list(df.columns):\n",
        "            subject_code_col = globals()['match_to_col']\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# 1) Write main page HTML exactly as built upstream\n",
        "with open(LOCAL_NAME, \"w\", encoding=ENC, errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(FULL_HTML)\n",
        "print(f\"✅ Wrote HTML: {os.path.abspath(LOCAL_NAME)}\")\n",
        "\n",
        "# 2) Upload main page + optional assets\n",
        "with ftp_connect() as ftps:\n",
        "    try:\n",
        "        ftps.mkd(\"partials\")\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        ftps.delete(_remote_path(REMOTE_NAME))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    ftp_upload_overwrite(ftps, LOCAL_NAME, _remote_path(REMOTE_NAME))\n",
        "\n",
        "    if os.path.exists(globals().get(\"MATCH_COUSINS_CSV\",\"the_match_cousins.csv\")):\n",
        "        ftp_upload_overwrite(ftps, globals().get(\"MATCH_COUSINS_CSV\",\"the_match_cousins.csv\"),\n",
        "                             _remote_path(globals().get(\"MATCH_COUSINS_CSV\",\"the_match_cousins.csv\")))\n",
        "\n",
        "    if os.path.exists(globals().get(\"LOCAL_COUNT_FILE\",\"autosomal_count.txt\")):\n",
        "        ftp_upload_overwrite(ftps,\n",
        "                             globals().get(\"LOCAL_COUNT_FILE\",\"autosomal_count.txt\"),\n",
        "                             _remote_path(globals().get(\"REMOTE_COUNT_NAME\",\"autosomal_count.txt\")))\n",
        "        if globals().get(\"COUNT_PUBLIC_URL\"):\n",
        "            print(f\"✅ Published autosomal count: {globals().get('LOCAL_COUNT_FILE')} → {globals().get('COUNT_PUBLIC_URL')}\")\n",
        "    else:\n",
        "        print(f\"⚠️ Count file not found locally: {globals().get('LOCAL_COUNT_FILE','autosomal_count.txt')}\")\n",
        "\n",
        "    try:\n",
        "        ftps.quit()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# 3) Build filtered data for reports\n",
        "SUPPRESS_PREFIXES = [\"y-dna\", \"dar\", \"sar\"]\n",
        "def _suppress_by_match_summary(ms: str) -> bool:\n",
        "    s = (str(ms) or \"\").strip().lower()\n",
        "    return bool(s) and any(s.startswith(prefix + \" is\") for prefix in SUPPRESS_PREFIXES)\n",
        "\n",
        "display_df_all = display_df.copy()\n",
        "_suppress_mask = display_df_all[\"Match Summary\"].map(_suppress_by_match_summary)\n",
        "display_df_filtered = display_df_all[~_suppress_mask].reset_index(drop=True)\n",
        "filtered_df_for_reports = df.loc[display_df_all.index[~_suppress_mask]].copy()\n",
        "\n",
        "# ---------- Resolver usage / counts ----------\n",
        "used_series = filtered_df_for_reports[subject_code_col].astype(str).map(lambda x: str(x).strip().lower())\n",
        "counts = Counter([c for c in used_series if c and c != \"nan\"])\n",
        "\n",
        "rows = []\n",
        "all_keys = set(globals().get(\"MATCH_TO_UNMASKED\", {}).keys())\n",
        "for code in sorted(all_keys):\n",
        "    rows.append((code, globals()[\"MATCH_TO_UNMASKED\"].get(code, \"\"), counts.get(code, 0)))\n",
        "for code in sorted(set(counts.keys()) - all_keys):\n",
        "    rows.append((code, \"(unmapped)\", counts.get(code, 0)))\n",
        "\n",
        "usage_df = pd.DataFrame(rows, columns=[\"Match to (code)\", \"Unmasked\", \"Count\"]).sort_values(\n",
        "    [\"Match to (code)\"], ascending=[True]\n",
        ")\n",
        "usage_df_alpha = usage_df.reset_index(drop=True)\n",
        "\n",
        "RESOLVER_USAGE_CSV = \"resolver_usage_report.csv\"\n",
        "usage_df_alpha.to_csv(RESOLVER_USAGE_CSV, index=False, encoding=ENC)\n",
        "print(\"✅ Wrote resolver usage CSV:\", os.path.abspath(RESOLVER_USAGE_CSV))\n",
        "\n",
        "# ---------- Lineage Count ----------\n",
        "def _escape_html(s: str) -> str:\n",
        "    return (str(s).replace(\"&\", \"&amp;\").replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\"))\n",
        "\n",
        "def _norm_key_component(fullname: str) -> str:\n",
        "    nm = smart_titlecase(str(fullname)); parts = nm.split()\n",
        "    if not parts: return \"\"\n",
        "    last   = re.sub(r\"[^A-Za-z]\", \"\", parts[-1])\n",
        "    firsts = re.sub(r\"[^A-Za-z]\", \"\", \"\".join(parts[:-1]))[:7]\n",
        "    return f\"{last}{firsts}\"\n",
        "\n",
        "def oldest_pair_key(token_list):\n",
        "    if not token_list: return \"\"\n",
        "    first = token_list[0]\n",
        "    a, b = derive_common_from_first_token([first])\n",
        "    if not a and not b:\n",
        "        parts = re.split(r\"\\s*&\\s*\", first)\n",
        "        a = parts[0] if parts else \"\"\n",
        "        b = parts[1] if len(parts) > 1 else \"\"\n",
        "    ka = _norm_key_component(a) if a else \"\"\n",
        "    kb = _norm_key_component(b) if b else \"\"\n",
        "    return f\"{ka}&{kb}\" if ka or kb else \"\"\n",
        "\n",
        "lc_counter = Counter()\n",
        "for _, row in filtered_df_for_reports.iterrows():\n",
        "    toks = split_tokens(row[path_col])\n",
        "    key = oldest_pair_key(toks)\n",
        "    if key: lc_counter[key] += 1\n",
        "\n",
        "lc_rows = sorted(lc_counter.items(), key=lambda x: (-x[1], x[0]))\n",
        "lineage_count_df = pd.DataFrame(lc_rows, columns=[\"Oldest Distant Ancestor (normalized Last+First7) pair\", \"Count\"])\n",
        "\n",
        "LINEAGE_COUNT_CSV = \"lineage_count_report.csv\"\n",
        "lineage_count_df.to_csv(LINEAGE_COUNT_CSV, index=False, encoding=ENC)\n",
        "print(\"✅ Wrote lineage count CSV:\", os.path.abspath(LINEAGE_COUNT_CSV))\n",
        "\n",
        "# Upload report CSVs\n",
        "try:\n",
        "    with ftp_connect() as ftps:\n",
        "        ftp_upload_overwrite(ftps, RESOLVER_USAGE_CSV, _remote_path(RESOLVER_USAGE_CSV))\n",
        "        ftp_upload_overwrite(ftps, LINEAGE_COUNT_CSV, _remote_path(LINEAGE_COUNT_CSV))\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "    print(\"✅ Published report CSVs.\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Upload of report CSVs failed: {e}\")\n",
        "\n",
        "# ---------- Helpers for Match Count partial ----------\n",
        "def _build_person_details_html(code_lc: str) -> str:\n",
        "    mask = filtered_df_for_reports[subject_code_col].astype(str).str.strip().str.lower() == code_lc\n",
        "    if not mask.any(): return \"<em>No rows for this person.</em>\"\n",
        "    rows_idx = filtered_df_for_reports[mask].index\n",
        "    mini = display_df.loc[rows_idx, [\"Find\", \"Match Summary\", LINEAGE_HEADER_SAFE]].copy()\n",
        "    return mini.to_html(index=False, escape=False, classes=\"mini-table\", border=0)\n",
        "\n",
        "# ---------- Match Count partial (tight wrapper + working toolbar) ----------\n",
        "def _render_match_count_full_html(usage_alpha: pd.DataFrame) -> str:\n",
        "    try:\n",
        "        total_persons = int(usage_alpha.shape[0])\n",
        "        total_matches = int(pd.to_numeric(usage_alpha[\"Count\"], errors=\"coerce\").fillna(0).sum())\n",
        "    except Exception:\n",
        "        total_persons, total_matches = usage_alpha.shape[0], 0\n",
        "\n",
        "    rows_html = []\n",
        "    for _, r in usage_alpha.iterrows():\n",
        "        code    = str(r[\"Match to (code)\"])\n",
        "        code_lc = code.strip().lower()\n",
        "        unm     = _escape_html(r[\"Unmasked\"])\n",
        "        cnt     = int(pd.to_numeric(r[\"Count\"], errors=\"coerce\")) if str(r[\"Count\"]).strip() else 0\n",
        "        rows_html.append(\n",
        "            \"<tr class='top-row' data-code='{code_lc}'>\"\n",
        "            \"<td class='sel'><input type='checkbox' class='selbox' data-code='{code_lc}' title='Select' /></td>\"\n",
        "            \"<td class='code'>{code}</td>\"\n",
        "            \"<td class='unmasked'>{unm}</td>\"\n",
        "            \"<td class='count'><a href='#' class='count-toggle' data-code='{code_lc}' aria-expanded='false'>{cnt}</a></td>\"\n",
        "            \"</tr>\".format(code_lc=_escape_html(code_lc), code=_escape_html(code), unm=unm, cnt=f\"{cnt:,}\")\n",
        "        )\n",
        "        rows_html.append(\n",
        "            \"<tr class='details-row' id='details-{code_lc}' style='display:none;'>\"\n",
        "            \"<td colspan='4'><div class='details-outer'>{detail}</div></td>\"\n",
        "            \"</tr>\".format(code_lc=_escape_html(code_lc), detail=_build_person_details_html(code_lc))\n",
        "        )\n",
        "\n",
        "    style = (\n",
        "        \"<style>\"\n",
        "        \" body{font-family:Georgia,'Times New Roman',serif;background:#fff;color:#111;margin:0;padding:18px;line-height:1.6;font-size:15px}\"\n",
        "        \" .wrap{max-width:900px;margin:0 auto}\"\n",
        "        \" h2{font-size:20px;margin:0 0 10px 0;text-align:center;border-bottom:2px solid #5b79b8;padding-bottom:6px}\"\n",
        "        \" .updated{font-size:12px;color:#555;text-align:center;margin:2px 0 10px 0}\"\n",
        "        \" .stats{text-align:center;color:#444;font-size:13px;margin:6px 0 10px 0}\"\n",
        "        \" .toolbar{display:flex;flex-wrap:wrap;gap:8px;align-items:center;justify-content:flex-start;margin:8px 0 10px 0}\"\n",
        "        \" .btn{display:inline-block;border:1px solid #5b79b8;background:#5b79b8;color:#fff;padding:6px 12px;border-radius:6px;text-decoration:none;cursor:pointer}\"\n",
        "        \" .btn:hover{background:#4668aa}\"\n",
        "        \" .master{margin-left:auto;font-size:13px;color:#333}\"\n",
        "        \" table#mc-table{border-collapse:collapse;width:100%;table-layout:fixed}\"\n",
        "        \" #mc-table col.sel{width:72px} #mc-table col.code{width:26%} #mc-table col.unmasked{width:48%} #mc-table col.count{width:16%}\"\n",
        "        \" #mc-table th,#mc-table td{border:1px solid #ccc;padding:8px 10px;vertical-align:top;word-wrap:break-word;overflow-wrap:break-word}\"\n",
        "        \" #mc-table th{background:#e9eef9;position:sticky;top:0;z-index:1}\"\n",
        "        \" #mc-table td.count{text-align:right}\"\n",
        "        \" #mc-table a.count-toggle{display:inline-block;padding:2px 6px;background:#5b79b8;color:#fff;border-radius:4px;border:1px solid #3e5a97;text-decoration:none}\"\n",
        "        \" #mc-table a.count-toggle:hover{background:#4668aa}\"\n",
        "        \" .details-outer{background:#f9fbff;border:1px solid #d7e1fb;margin:8px 2px;padding:8px;border-radius:6px}\"\n",
        "        \" .mini-table{border-collapse:collapse;width:100%;table-layout:fixed}\"\n",
        "        \" .mini-table th,.mini-table td{border:1px solid #ddd;padding:6px 8px;vertical-align:top}\"\n",
        "        \" .mini-table th{background:#f2f6ff}\"\n",
        "        \" .mini-table col:nth-child(1){width:140px} \"\n",
        "        \" .mini-table col:nth-child(2){width:\" + str(globals().get('COL_A_PX',520)) + \"px} \"\n",
        "        \" .mini-table col:nth-child(3){width:auto}\"\n",
        "        \" @media screen and (max-width:900px){ body{padding:12px;font-size:14px} .toolbar{gap:6px} }\"\n",
        "        \"</style>\"\n",
        "    )\n",
        "\n",
        "    updated = (\n",
        "        \"<div class='updated'>\"\n",
        "        \"<a href='\" + HOME_URL + \"' target='_blank' rel='noopener'>Home</a>\"\n",
        "        \" &nbsp;|&nbsp; Last updated: <span id='last-updated'></span>\"\n",
        "        \" &nbsp;|&nbsp; Autosomal matches: <span id='auto-count' class='js-count'></span>\"\n",
        "        \"</div>\"\n",
        "    )\n",
        "\n",
        "    toolbar = (\n",
        "        \"<div class='toolbar'>\"\n",
        "        \" <button type='button' class='btn' id='btn-display'>Display Checked</button>\"\n",
        "        \" <button type='button' class='btn' id='btn-email'>Email Checked</button>\"\n",
        "        \" <button type='button' class='btn' id='btn-print'>Print Checked</button>\"\n",
        "        \" <label class='master'><input type='checkbox' id='sel-all' /> Select all</label>\"\n",
        "        \"</div>\"\n",
        "    )\n",
        "\n",
        "    html = (\n",
        "        \"<!DOCTYPE html><html lang='en'><head>\"\n",
        "        \"<meta charset='iso-8859-15' />\"\n",
        "        \"<meta name='viewport' content='width=device-width, initial-scale=1.0' />\"\n",
        "        \"<title>Match Count (by resolver code)</title>\"\n",
        "        + style +\n",
        "        \"</head><body>\"\n",
        "        \"<div class='wrap'>\"\n",
        "        \"<h2>Match Count (by resolver code, A&rightarrow;Z)</h2>\"\n",
        "        + updated +\n",
        "        \"<div class='stats'>Total distinct &ldquo;Match to&rdquo; persons: \" + f\"{total_persons:,}\" +\n",
        "        \" &nbsp;|&nbsp; Total matches counted: \" + f\"{total_matches:,}\" + \"</div>\"\n",
        "        + toolbar +\n",
        "        \"<table id='mc-table'>\"\n",
        "        \"<colgroup><col class='sel'><col class='code'><col class='unmasked'><col class='count'></colgroup>\"\n",
        "        \"<thead><tr><th>Select</th><th>Match to (code)</th><th>Unmasked</th><th>Count</th></tr></thead>\"\n",
        "        \"<tbody>\" + \"\".join(rows_html) + \"</tbody></table>\"\n",
        "        \"</div>\"\n",
        "        \"<script>(function(){\"\n",
        "        \" document.addEventListener('DOMContentLoaded', function(){\"\n",
        "        \"  function z(n){return(n<10?'0':'')+n;}\"\n",
        "        \"  function stamp(){var el=document.getElementById('last-updated'); if(!el) return; var d=new Date(document.lastModified||new Date());\"\n",
        "        \"   el.textContent=d.getFullYear()+'-'+z(d.getMonth()+1)+'-'+z(d.getDate())+' '+z(d.getHours())+':'+z(d.getMinutes());}\"\n",
        "        \"  function fmt(n){try{var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return ''; return x.toLocaleString('en-US');}catch(e){return String(n||'');}}\"\n",
        "        \"  function loadCnt(){var el=document.getElementById('auto-count'); if(!el) return; var url='\" + JS_COUNT_URL + \"';\"\n",
        "        \"   try{var xhr=new XMLHttpRequest(); xhr.open('GET', url+(url.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true);\"\n",
        "        \"    xhr.onreadystatechange=function(){ if(xhr.readyState===4){ if(xhr.status>=200&&xhr.status<300){ var m=(xhr.responseText||'').match(/(\\\\d+)/); el.textContent = fmt(m?m[1]:'') || '(unavailable)'; } else { el.textContent='(unavailable)'; } } };\"\n",
        "        \"    xhr.send(null);}catch(e){ el.textContent='(unavailable)'; }}\"\n",
        "        \"  stamp(); loadCnt();\"\n",
        "\n",
        "        \"  function toggleDetails(code, wantOpen){\"\n",
        "        \"    var row=document.getElementById('details-'+code); if(!row) return;\"\n",
        "        \"    row.style.display = wantOpen ? '' : 'none';\"\n",
        "        \"    var a=document.querySelector(\\\"a.count-toggle[data-code='\\\"+code+\\\"']\\\"); if(a){ a.setAttribute('aria-expanded', wantOpen?'true':'false'); }\"\n",
        "        \"  }\"\n",
        "        \"  function selectedCodes(){\"\n",
        "        \"    var out=[]; var cbs=document.querySelectorAll('#mc-table .selbox');\"\n",
        "        \"    for(var i=0;i<cbs.length;i++){ if(cbs[i].checked){ var c=cbs[i].getAttribute('data-code'); if(c) out.push(c); }}\"\n",
        "        \"    return out;\"\n",
        "        \"  }\"\n",
        "\n",
        "        \"  var master=document.getElementById('sel-all');\"\n",
        "        \"  if(master){ master.addEventListener('change', function(){\"\n",
        "        \"    var want=master.checked; var cbs=document.querySelectorAll('#mc-table .selbox');\"\n",
        "        \"    for(var i=0;i<cbs.length;i++){ cbs[i].checked = want; }\"\n",
        "        \"  }); }\"\n",
        "\n",
        "        \"  var btnDisp=document.getElementById('btn-display');\"\n",
        "        \"  if(btnDisp){ btnDisp.addEventListener('click', function(){\"\n",
        "        \"    var sel=selectedCodes();\"\n",
        "        \"    var all=document.querySelectorAll('tr.details-row'); for(var i=0;i<all.length;i++){ all[i].style.display='none'; }\"\n",
        "        \"    for(var j=0;j<sel.length;j++){ toggleDetails(sel[j], true); }\"\n",
        "        \"    if(sel.length){ try{ document.getElementById('details-'+sel[0]).scrollIntoView({behavior:'smooth',block:'start'});}catch(e){} }\"\n",
        "        \"  }); }\"\n",
        "\n",
        "        \"  function enc(s){ return encodeURIComponent(String(s||'')); }\"\n",
        "        \"  function textOf(el){ return (el && (el.textContent||el.innerText)||'').trim(); }\"\n",
        "\n",
        "        \"  var btnEmail=document.getElementById('btn-email');\"\n",
        "        \"  if(btnEmail){ btnEmail.addEventListener('click', function(){\"\n",
        "        \"    var sel=selectedCodes(); if(!sel.length){ alert('No persons selected.'); return; }\"\n",
        "        \"    function collectMatches(code){\"\n",
        "        \"      var out=[]; var host=document.getElementById('details-'+code); if(!host) return out;\"\n",
        "        \"      var rows=host.querySelectorAll('table.mini-table tbody tr');\"\n",
        "        \"      for(var i=0;i<rows.length;i++){\"\n",
        "        \"        var tds=rows[i].cells; if(!tds || tds.length<3) continue;\"\n",
        "        \"        var a=tds[0].querySelector('a'); var href=a ? a.href : '';\"\n",
        "        \"        var summary=textOf(tds[1]);\"\n",
        "        \"        out.push({summary:summary, href:href});\"\n",
        "        \"      }\"\n",
        "        \"      return out;\"\n",
        "        \"    }\"\n",
        "        \"    var lines=[], total=0;\"\n",
        "        \"    for(var k=0;k<sel.length;k++){\"\n",
        "        \"      var code=sel[k];\"\n",
        "        \"      var tr=document.querySelector(\\\"tr.top-row[data-code='\\\"+code+\\\"']\\\"); if(!tr) continue;\"\n",
        "        \"      var codeTxt=textOf(tr.querySelector('.code'));\"\n",
        "        \"      var unmTxt =textOf(tr.querySelector('.unmasked'));\"\n",
        "        \"      var cntTxt =textOf(tr.querySelector('.count a'));\"\n",
        "        \"      var header = codeTxt + (unmTxt? ' — '+unmTxt : '') + (cntTxt? ' ('+cntTxt+')' : '');\"\n",
        "        \"      lines.push('== ' + header + ' ==');\"\n",
        "        \"      var matches = collectMatches(code);\"\n",
        "        \"      if(!matches.length){\"\n",
        "        \"        lines.push('- (no inline rows available)');\"\n",
        "        \"      } else {\"\n",
        "        \"        total += matches.length;\"\n",
        "        \"        for(var m=0;m<matches.length;m++){\"\n",
        "        \"          var row = matches[m];\"\n",
        "        \"          lines.push('- ' + row.summary);\"\n",
        "        \"          if(row.href){ lines.push(row.href); }\"\n",
        "        \"        }\"\n",
        "        \"      }\"\n",
        "        \"      if(k < sel.length-1) lines.push('');\"\n",
        "        \"    }\"\n",
        "        \"    var subj='ONS Yates: ' + sel.length + ' person(s), ' + total + ' match row(s)';\"\n",
        "        \"    var body=lines.join('\\\\n');\"\n",
        "        \"    var href='mailto:?subject='+enc(subj)+'&body='+enc(body);\"\n",
        "        \"    window.location.href=href;\"\n",
        "        \"  }); }\"\n",
        "\n",
        "        \"  var btnPrint=document.getElementById('btn-print');\"\n",
        "        \"  if(btnPrint){ btnPrint.addEventListener('click', function(){\"\n",
        "        \"    var sel=selectedCodes(); if(!sel.length){ alert('No persons selected.'); return; }\"\n",
        "        \"    for(var i=0;i<sel.length;i++){ toggleDetails(sel[i], true); }\"\n",
        "        \"    setTimeout(function(){ window.print(); }, 100);\"\n",
        "        \"  }); }\"\n",
        "\n",
        "        \"  var tbl=document.getElementById('mc-table');\"\n",
        "        \"  if(tbl){ tbl.addEventListener('click',function(ev){\"\n",
        "        \"    var a=ev.target && ev.target.closest ? ev.target.closest('a.count-toggle') : null;\"\n",
        "        \"    if(!a) return; ev.preventDefault();\"\n",
        "        \"    var code=a.getAttribute('data-code'); if(!code) return;\"\n",
        "        \"    var row=document.getElementById('details-'+code); if(!row) return;\"\n",
        "        \"    var open=row.style.display!== 'none';\"\n",
        "        \"    row.style.display = open ? 'none' : '';\"\n",
        "        \"    a.setAttribute('aria-expanded', open?'false':'true');\"\n",
        "        \"    if(!open){ try{ row.scrollIntoView({behavior:'smooth',block:'start'});}catch(e){} }\"\n",
        "        \"  },false); }\"\n",
        "        \" });\"\n",
        "        \"})();</script>\"\n",
        "        \"</body></html>\"\n",
        "    )\n",
        "    return html\n",
        "\n",
        "match_partial_html = _render_match_count_full_html(usage_df_alpha)\n",
        "\n",
        "# ---------- Lineage Count partial ----------\n",
        "lineage_style = (\n",
        "    \"<style>\"\n",
        "    \" body{font-family:Georgia,'Times New Roman',serif;background:#fff;color:#111;margin:0;padding:18px;line-height:1.6;font-size:15px}\"\n",
        "    \" .wrap{max-width:1100px;margin:0 auto}\"\n",
        "    \" h2{font-size:20px;margin:0 0 10px 0;text-align:center;border-bottom:2px solid #5b79b8;padding-bottom:6px}\"\n",
        "    \" .updated{font-size:12px;color:#555;text-align:center;margin:2px 0 10px 0}\"\n",
        "    \" table.partial-table{border-collapse:collapse;width:100%;table-layout:auto}\"\n",
        "    \" table.partial-table th,table.partial-table td{border:1px solid #ccc;padding:8px 10px;vertical-align:top}\"\n",
        "    \" table.partial-table th{background:#e9eef9;position:sticky;top:0}\"\n",
        "    \" @media screen and (max-width:900px){ body{padding:12px;font-size:14px} }\"\n",
        "    \"</style>\"\n",
        ")\n",
        "lineage_updated = (\n",
        "    \"<div class='updated'>\"\n",
        "    \"<a href='\" + HOME_URL + \"' target='_blank' rel='noopener'>Home</a>\"\n",
        "    \" &nbsp;|&nbsp; Last updated: <span id='last-updated'></span>\"\n",
        "    \" &nbsp;|&nbsp; Autosomal matches: <span id='auto-count' class='js-count'></span>\"\n",
        "    \"</div>\"\n",
        ")\n",
        "lineage_js = (\n",
        "    \"<script>(function(){\"\n",
        "    \" document.addEventListener('DOMContentLoaded', function(){\"\n",
        "    \"  function z(n){return(n<10?'0':'')+n;}\"\n",
        "    \"  function stamp(){var el=document.getElementById('last-updated'); if(!el) return; var d=new Date(document.lastModified||new Date());\"\n",
        "    \"   el.textContent=d.getFullYear()+'-'+z(d.getMonth()+1)+'-'+z(d.getDate())+' '+z(d.getHours())+':'+z(d.getMinutes());}\"\n",
        "    \"  function fmt(n){try{var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return ''; return x.toLocaleString('en-US');}catch(e){return String(n||'');}}\"\n",
        "    \"  function loadCnt(){var el=document.getElementById('auto-count'); if(!el) return; var url='\" + JS_COUNT_URL + \"';\"\n",
        "    \"   try{var xhr=new XMLHttpRequest(); xhr.open('GET', url+(url.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true);\"\n",
        "    \"    xhr.onreadystatechange=function(){ if(xhr.readyState===4){ if(xhr.status>=200&&xhr.status<300){ var m=(xhr.responseText||'').match(/(\\\\d+)/); el.textContent = fmt(m?m[1]:'') || '(unavailable)'; } else { el.textContent='(unavailable)'; } } };\"\n",
        "    \"    xhr.send(null);}catch(e){ el.textContent='(unavailable)'; }}\"\n",
        "    \"  stamp(); loadCnt();\"\n",
        "    \" });\"\n",
        "    \"})();</script>\"\n",
        ")\n",
        "\n",
        "lineage_partial_html = (\n",
        "    \"<!DOCTYPE html><html lang='en'><head>\"\n",
        "    \"<meta charset='iso-8859-15' />\"\n",
        "    \"<meta name='viewport' content='width=device-width, initial-scale=1.0' />\"\n",
        "    \"<title>Lineage Count (by oldest distant ancestor pair)</title>\"\n",
        "    + lineage_style +\n",
        "    \"</head><body>\"\n",
        "    \"<div class='wrap'>\"\n",
        "    \"<h2>Lineage Count (by oldest distant ancestor pair)</h2>\"\n",
        "    + lineage_updated +\n",
        "    lineage_count_df.to_html(index=False, escape=False, classes='partial-table', border=0) +\n",
        "    \"</div>\"\n",
        "    + lineage_js +\n",
        "    \"</body></html>\"\n",
        ")\n",
        "\n",
        "# 4) Write & upload partials\n",
        "with open(\"match_count.htm\", \"w\", encoding=ENC, errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(match_partial_html)\n",
        "with open(\"lineage_count.htm\", \"w\", encoding=ENC, errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(lineage_partial_html)\n",
        "print(\"✅ Wrote partials locally: match_count.htm, lineage_count.htm\")\n",
        "\n",
        "try:\n",
        "    with ftp_connect() as ftps:\n",
        "        try:\n",
        "            ftps.mkd(\"partials\")\n",
        "        except Exception:\n",
        "            pass\n",
        "        ftp_upload_overwrite(ftps, \"match_count.htm\",   \"partials/match_count.htm\")\n",
        "        ftp_upload_overwrite(ftps, \"lineage_count.htm\", \"partials/lineage_count.htm\")\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "    print(\"✅ Published count partials to /partials/\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Upload of count partials failed: {e}\")\n",
        "\n",
        "# 5) Printable page (adds dynamic header)\n",
        "PRINT_PARTIAL_NAME  = \"cousin_list_print.htm\"\n",
        "PRINT_PARTIAL_LOCAL = PRINT_PARTIAL_NAME\n",
        "_print_table_html = (display_df_filtered if not display_df_filtered.empty else display_df_all).to_html(\n",
        "    index=False, escape=False, classes=\"print-table\", border=1\n",
        ")\n",
        "PRINT_PARTIAL_HTML = (\n",
        "    \"<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Transitional//EN\\\"\\n\"\n",
        "    \"  \\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\\\">\\n\"\n",
        "    \"<html xmlns=\\\"http://www.w3.org/1999/xhtml\\\" lang=\\\"en\\\">\\n\"\n",
        "    \"<head>\\n\"\n",
        "    \"<meta http-equiv=\\\"Content-Type\\\" content=\\\"text/html; charset=iso-8859-15\\\" />\\n\"\n",
        "    \"<meta name=\\\"viewport\\\" content=\\\"width=device-width, initial-scale=1.0\\\" />\\n\"\n",
        "    \"<title>ONS Yates Study &ndash; Cousin List (Printable)</title>\\n\"\n",
        "    \"<style type=\\\"text/css\\\">\\n\"\n",
        "    \"  body { font-family: Georgia, 'Times New Roman', serif; color:#000; background:#fff; margin:0; padding:16px; line-height:1.45; }\\n\"\n",
        "    \"  .wrap { max-width: 1100px; margin: 0 auto; }\\n\"\n",
        "    \"  h1 { font-size: 22px; margin: 0 0 8px 0; text-align:center; }\\n\"\n",
        "    \"  .updated { font-size:12px; color:#555; text-align:center; margin:2px 0 12px 0; }\\n\"\n",
        "    \"  .actions { text-align:center; margin: 10px 0 16px 0; }\\n\"\n",
        "    \"  .btn { display:inline-block; border:1px solid #444; background:#f4f4f4; color:#000; padding:6px 12px; text-decoration:none; }\\n\"\n",
        "    \"  table.print-table { border-collapse: collapse; width: 100%; table-layout: fixed; }\\n\"\n",
        "    \"  table.print-table th, table.print-table td { border:  1px solid #222; padding: 6px 8px; vertical-align: top; }\\n\"\n",
        "    \"  table.print-table th { background: #eee; }\\n\"\n",
        "    \"  @media print { .actions { display: none; } @page { margin: 0.6in; } }\\n\"\n",
        "    \"</style>\\n\"\n",
        "    \"</head>\\n\"\n",
        "    \"<body>\\n\"\n",
        "    \"  <div class=\\\"wrap\\\">\\n\"\n",
        "    \"    <h1>ONS Yates Study &ndash; Cousin List (Printable)</h1>\\n\"\n",
        "    \"    <div class=\\\"updated\\\"><a href=\\\"\" + HOME_URL + \"\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">Home</a>\"\n",
        "    \" &nbsp;|&nbsp; Last updated: <span id=\\\"last-updated\\\"></span>\"\n",
        "    \" &nbsp;|&nbsp; Autosomal matches: <span id=\\\"auto-count\\\" class=\\\"js-count\\\"></span></div>\\n\"\n",
        "    \"    <div class=\\\"actions\\\"><a class=\\\"btn\\\" href=\\\"#\\\" onclick=\\\"window.print();return false;\\\">Print this page</a></div>\\n\"\n",
        "    \"   \" + _print_table_html + \"\\n\"\n",
        "    \"    <div class=\\\"actions\\\" style=\\\"margin-top:16px;\\\"><a class=\\\"btn\\\" href=\\\"#\\\" onclick=\\\"window.print();return false;\\\">Print this page</a></div>\\n\"\n",
        "    \"  </div>\\n\"\n",
        "    \"<script>(function(){\"\n",
        "    \" document.addEventListener('DOMContentLoaded', function(){\"\n",
        "    \"  function z(n){return(n<10?'0':'')+n;}\"\n",
        "    \"  function stamp(){var el=document.getElementById('last-updated'); if(!el) return; var d=new Date(document.lastModified||new Date());\"\n",
        "    \"   el.textContent=d.getFullYear()+'-'+z(d.getMonth()+1)+'-'+z(d.getDate())+' '+z(d.getHours())+':'+z(d.getMinutes());}\"\n",
        "    \"  function fmt(n){try{var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return ''; return x.toLocaleString('en-US');}catch(e){return String(n||'');}}\"\n",
        "    \"  function loadCnt(){var el=document.getElementById('auto-count'); if(!el) return; var url='\" + JS_COUNT_URL + \"';\"\n",
        "    \"   try{var xhr=new XMLHttpRequest(); xhr.open('GET', url+(url.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true);\"\n",
        "    \"    xhr.onreadystatechange=function(){ if(xhr.readyState===4){ if(xhr.status>=200&&xhr.status<300){ var m=(xhr.responseText||'').match(/(\\\\d+)/); el.textContent = fmt(m?m[1]:'') || '(unavailable)'; } else { el.textContent='(unavailable)'; } } };\"\n",
        "    \"    xhr.send(null);}catch(e){ el.textContent='(unavailable)'; }}\"\n",
        "    \"  stamp(); loadCnt();\"\n",
        "    \" });\"\n",
        "    \"})();</script>\"\n",
        "    \"</body>\\n\"\n",
        "    \"</html>\\n\"\n",
        ")\n",
        "with open(PRINT_PARTIAL_LOCAL, \"w\", encoding=ENC, errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(PRINT_PARTIAL_HTML)\n",
        "\n",
        "try:\n",
        "    with ftp_connect() as ftps:\n",
        "        try:\n",
        "            ftps.mkd(\"partials\")\n",
        "        except Exception:\n",
        "            pass\n",
        "        ftp_upload_overwrite(ftps, PRINT_PARTIAL_LOCAL, \"partials/\" + PRINT_PARTIAL_NAME)\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "    print(f\"✅ Uploaded printable page: /partials/{PRINT_PARTIAL_NAME}\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Printable page upload failed: {e}\")\n",
        "\n",
        "print(f\"✅ HTML published at https://yates.one-name.net/{REMOTE_NAME}\")\n",
        "# ====== CUT STOP [6/6] REFACTOR-Gold 2 — Save + Upload + Reports + Partials + Printable ===========\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ipkws6LmIBAq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bde92034-5b62-47de-e7f4-0b89708ad1b2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded CSV — 1556 rows, 9 columns from /content/final_combined_df_with_value_labels.csv\n",
            "✅ Columns: {'ID (detected)': 'ID#', 'Match to': 'Match to', 'Name': 'Name', 'cM': 'cM', 'Lineage': 'Yates DNA Ancestral Line'}\n",
            "✅ Wrote local CSV (Column A): /content/the_match_cousins.csv\n",
            "✅ Wrote HTML: /content/ons_yates_dna_register.htm\n",
            "✅ Published autosomal count: autosomal_count.txt → \n",
            "✅ Wrote resolver usage CSV: /content/resolver_usage_report.csv\n",
            "✅ Wrote lineage count CSV: /content/lineage_count_report.csv\n",
            "✅ Published report CSVs.\n",
            "✅ Wrote partials locally: match_count.htm, lineage_count.htm\n",
            "✅ Published count partials to /partials/\n",
            "✅ Uploaded printable page: /partials/cousin_list_print.htm\n",
            "✅ HTML published at https://yates.one-name.net/ons_yates_dna_register.htm\n",
            "✅ Loaded CSV — 1556 rows, 9 columns from /content/final_combined_df_with_value_labels.csv\n",
            "✅ Columns: {'ID': 'id#', 'Match to': 'match to', 'Name': 'name', 'cM': 'cm', 'Lineage': 'yates dna ancestral line', 'SubjectCode': 'id#'}\n",
            "✅ Wrote local CSV (Column A): /content/the_match_cousins.csv\n",
            "✅ Built display_df with 1556 rows.\n",
            "✅ Wrote HTML: /content/ons_yates_dna_register.htm\n",
            "✅ Wrote resolver usage CSV: /content/resolver_usage_report.csv\n",
            "✅ Wrote lineage count CSV: /content/lineage_count_report.csv\n",
            "✅ Published report CSVs.\n",
            "✅ Wrote partials locally: match_count.htm, lineage_count.htm\n",
            "✅ Published count partials to /partials/\n",
            "✅ Uploaded printable page: /partials/cousin_list_print.htm\n",
            "✅ HTML published at https://yates.one-name.net/ons_yates_dna_register.htm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#EXPERIMENTAL 3\n",
        "# Gold 3 — create yates_ancestor_register.htm (mobile-friendly, sortable)\n",
        "\n",
        "# ====== CUT START [A] REFACTOR-Gold 3 — Config + FTP + Constants + Rules =========================\n",
        "import os\n",
        "import posixpath\n",
        "import socket\n",
        "from ftplib import FTP_TLS\n",
        "\n",
        "# ---------- Script identity ----------\n",
        "SCRIPT_NAME = \"REFACTOR-Gold 3\"\n",
        "SECTION_NAME = \"[A] Config + FTP + Constants + Rules\"\n",
        "DOM_ID_PREFIX = \"g3-\"  # all HTML ids/classes must begin with \"g3-\"\n",
        "NS_PREFIX = \"G3_\"      # Python-visible constant/function prefix\n",
        "\n",
        "# ---------- Encoding ----------\n",
        "ENC = \"iso-8859-15\"\n",
        "\n",
        "# ---------- Environment / FTP ----------\n",
        "FTP_HOST = os.getenv(\"FTP_HOST\", \"\")\n",
        "FTP_USER = os.getenv(\"FTP_USER\", \"\")\n",
        "FTP_PASS = os.getenv(\"FTP_PASS\", \"\")\n",
        "FTP_DIR  = os.getenv(\"FTP_DIR\", \"/gengen/\")\n",
        "FTP_TIMEOUT = int(os.getenv(\"FTP_TIMEOUT\", \"45\"))\n",
        "FTP_TLS_REQUIRED = True  # enforce FTPS\n",
        "\n",
        "# ---------- File naming (Gold 3: Lineages) ----------\n",
        "# Main page (this already exists live per Ron): yates_ancestor_register.htm\n",
        "LOCAL_NAME  = os.getenv(\"G3_LOCAL_NAME\",  \"yates_ancestor_register.htm\")\n",
        "REMOTE_NAME = os.getenv(\"G3_REMOTE_NAME\", \"yates_ancestor_register.htm\")\n",
        "\n",
        "# Partials unique to Gold 3 to avoid clashes with Gold 2\n",
        "PARTIAL_MATCH_COUNT   = os.getenv(\"G3_PARTIAL_MATCH_COUNT\",   \"partials/g3_match_count.htm\")\n",
        "PARTIAL_LINEAGE_COUNT = os.getenv(\"G3_PARTIAL_LINEAGE_COUNT\", \"partials/g3_lineage_count.htm\")\n",
        "PARTIAL_PRINTABLE     = os.getenv(\"G3_PARTIAL_PRINTABLE\",     \"partials/g3_print.htm\")\n",
        "\n",
        "# Optional counters/diagnostics (distinct from Gold 2)\n",
        "COUNT_PUBLIC_URL = os.getenv(\"G3_COUNT_PUBLIC_URL\", \"\")\n",
        "LOCAL_COUNT_FILE = os.getenv(\"G3_LOCAL_COUNT_FILE\", \"g3_autosomal_count.txt\")\n",
        "REMOTE_COUNT_NAME = os.getenv(\"G3_REMOTE_COUNT_NAME\", \"g3_autosomal_count.txt\")\n",
        "\n",
        "# ---------- Paths ----------\n",
        "def _remote_path(name: str) -> str:\n",
        "    \"\"\"Join FTP_DIR and name with posix semantics.\"\"\"\n",
        "    base = FTP_DIR.rstrip(\"/\")\n",
        "    return f\"{base}/{name.lstrip('/')}\"\n",
        "\n",
        "# ---------- FTP helpers (namespaced logic, no side effects on import) ----------\n",
        "def ftp_connect() -> FTP_TLS:\n",
        "    \"\"\"Return a logged-in FTPS handle with passive mode and timeout.\"\"\"\n",
        "    if not FTP_HOST or not FTP_USER or not FTP_PASS:\n",
        "        raise RuntimeError(\"FTP credentials are not set in environment variables.\")\n",
        "    ftps = FTP_TLS(timeout=FTP_TIMEOUT)\n",
        "    ftps.connect(host=FTP_HOST, port=21)\n",
        "    ftps.auth()  # upgrade to TLS\n",
        "    ftps.prot_p()  # secure data connection\n",
        "    ftps.login(user=FTP_USER, passwd=FTP_PASS)\n",
        "    ftps.set_pasv(True)\n",
        "    # Best-effort hostname note (for diagnostics)\n",
        "    try:\n",
        "        ftps.hostname = socket.gethostbyname(FTP_HOST)  # type: ignore[attr-defined]\n",
        "    except Exception:\n",
        "        pass\n",
        "    return ftps\n",
        "\n",
        "def ftp_upload_overwrite(ftps: FTP_TLS, local_path: str, remote_name: str) -> None:\n",
        "    \"\"\"Upload file to FTP_DIR/remote_name, overwriting if exists.\"\"\"\n",
        "    remote = _remote_path(remote_name)\n",
        "    # Ensure remote directory exists (best-effort, ignore failures on nested)\n",
        "    parts = remote.split(\"/\")\n",
        "    dir_parts, filename = parts[:-1], parts[-1]\n",
        "    cwd = \"/\"\n",
        "    try:\n",
        "        ftps.cwd(\"/\")\n",
        "    except Exception:\n",
        "        pass\n",
        "    for d in dir_parts:\n",
        "        if not d:\n",
        "            continue\n",
        "        cwd = posixpath.join(cwd, d)\n",
        "        try:\n",
        "            ftps.mkd(cwd)\n",
        "        except Exception:\n",
        "            pass\n",
        "    with open(local_path, \"rb\") as fh:\n",
        "        ftps.storbinary(f\"STOR {remote}\", fh)\n",
        "\n",
        "# ---------- Guardrails ----------\n",
        "# This script must not import or reference any G2_* symbols.\n",
        "# All DOM ids, classes, and JS functions created by this script must use the \"g3-\" prefix.\n",
        "# All files written by this script must use the Gold 3 filenames defined above.\n",
        "# ====== CUT STOP  [A] REFACTOR-Gold 3 — Add 5 returns for spacing ================\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "# ====== CUT START [B] REFACTOR-Gold 3 — Helpers / Resolver (root-level /partials support) ========\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import io\n",
        "import csv\n",
        "import posixpath\n",
        "from typing import Dict, Tuple\n",
        "\n",
        "try:\n",
        "    import pandas as pd\n",
        "except Exception:\n",
        "    pd = None\n",
        "\n",
        "# ---------- Absolute root-level /partials support (G3) ----------\n",
        "# Primary location: /partials/match_to_unmasked.csv (absolute from server root)\n",
        "# Fallback location: /gengen/partials/match_to_unmasked.csv (under FTP_DIR)\n",
        "G3_SERVER_PARTIALS_DIR = os.getenv(\"G3_SERVER_PARTIALS_DIR\", \"/partials\")\n",
        "G3_SERVER_MAPPING_BASENAME = os.getenv(\"G3_SERVER_MAPPING_BASENAME\", \"match_to_unmasked.csv\")\n",
        "G3_LOCAL_MAPPING_CACHE = os.getenv(\"G3_LOCAL_MAPPING_CACHE\", \"g3_match_to_unmasked.csv\")\n",
        "\n",
        "def g3_remote_abs(*parts: str) -> str:\n",
        "    \"\"\"Join into an absolute POSIX path that does NOT prepend FTP_DIR.\"\"\"\n",
        "    cleaned = [str(p).strip(\"/\") for p in parts if p is not None]\n",
        "    return \"/\" + \"/\".join([p for p in cleaned if p])\n",
        "\n",
        "def g3_remote_under_ftpdir(name: str) -> str:\n",
        "    \"\"\"Fallback to FTP_DIR-prefixed path (e.g., /gengen/partials/...).\"\"\"\n",
        "    base = str(globals().get(\"FTP_DIR\", \"/\")).rstrip(\"/\")\n",
        "    return f\"{base}/{name.lstrip('/')}\"\n",
        "\n",
        "def g3_ftps_fetch_to_local(ftps, remote_path: str, local_path: str) -> Tuple[bool, str]:\n",
        "    \"\"\"Try to RETR a remote file to local_path. Return (ok, error_text).\"\"\"\n",
        "    try:\n",
        "        # Ensure parent dir exists\n",
        "        parent = os.path.dirname(local_path)\n",
        "        if parent and not os.path.isdir(parent):\n",
        "            os.makedirs(parent, exist_ok=True)\n",
        "        with open(local_path, \"wb\") as fh:\n",
        "            ftps.retrbinary(f\"RETR {remote_path}\", fh.write)\n",
        "        return True, \"\"\n",
        "    except Exception as e:\n",
        "        return False, f\"{type(e).__name__}: {e}\"\n",
        "\n",
        "def g3_detect_cols(df) -> Tuple[str, str]:\n",
        "    \"\"\"Pick code and unmasked columns from a DataFrame by heuristics.\"\"\"\n",
        "    cols = [str(c) for c in df.columns]\n",
        "    code_candidates = [\"Match to\", \"match_to\", \"match to\", \"code\", \"Code\"]\n",
        "    name_candidates = [\"Unmasked\", \"unmasked\", \"name\", \"Name\", \"Unmask\", \"unmask\"]\n",
        "    code_col = None\n",
        "    name_col = None\n",
        "    lowered = {c.lower(): c for c in cols}\n",
        "    for c in code_candidates:\n",
        "        key = c.replace(\" \", \"\")\n",
        "        for col in cols:\n",
        "            if col == c or col.lower().replace(\" \", \"\") == key:\n",
        "                code_col = col\n",
        "                break\n",
        "        if code_col:\n",
        "            break\n",
        "    for c in name_candidates:\n",
        "        key = c.replace(\" \", \"\")\n",
        "        for col in cols:\n",
        "            if col == c or col.lower().replace(\" \", \"\") == key:\n",
        "                name_col = col\n",
        "                break\n",
        "        if name_col:\n",
        "            break\n",
        "    if code_col is None:\n",
        "        code_col = cols[0]\n",
        "    if name_col is None:\n",
        "        name_col = cols[1] if len(cols) > 1 else cols[0]\n",
        "    return code_col, name_col\n",
        "\n",
        "def g3_read_resolver_csv(local_path: str) -> Dict[str, str]:\n",
        "    \"\"\"Load resolver csv to {code: unmasked} with minimal normalization.\"\"\"\n",
        "    if pd is not None:\n",
        "        df = pd.read_csv(local_path, dtype=str, encoding=\"iso-8859-15\", keep_default_na=False)\n",
        "        code_col, name_col = g3_detect_cols(df)\n",
        "        mapping = {}\n",
        "        for _, row in df.iterrows():\n",
        "            k = str(row.get(code_col, \"\")).strip()\n",
        "            v = str(row.get(name_col, \"\")).strip()\n",
        "            if k:\n",
        "                mapping[k] = v\n",
        "        return mapping\n",
        "    # Fallback without pandas\n",
        "    mapping = {}\n",
        "    with open(local_path, \"r\", encoding=\"iso-8859-15\", errors=\"replace\", newline=\"\") as fh:\n",
        "        reader = csv.reader(fh)\n",
        "        rows = list(reader)\n",
        "    if not rows:\n",
        "        return mapping\n",
        "    header = rows[0]\n",
        "    if len(header) >= 2 and not header[0].strip().isdigit():\n",
        "        # Assume first row is header\n",
        "        data_rows = rows[1:]\n",
        "        code_idx = 0\n",
        "        name_idx = 1\n",
        "    else:\n",
        "        # No header\n",
        "        data_rows = rows\n",
        "        code_idx = 0\n",
        "        name_idx = 1 if len(rows[0]) > 1 else 0\n",
        "    for r in data_rows:\n",
        "        if not r:\n",
        "            continue\n",
        "        k = (r[code_idx] if len(r) > code_idx else \"\").strip()\n",
        "        v = (r[name_idx] if len(r) > name_idx else \"\").strip()\n",
        "        if k:\n",
        "            mapping[k] = v\n",
        "    return mapping\n",
        "\n",
        "def g3_load_resolver_from_server() -> Dict[str, str]:\n",
        "    \"\"\"Load resolver CSV from root-level /partials first, then fallback to /gengen/partials.\n",
        "    Writes a local cache copy and returns the mapping dict.\n",
        "    \"\"\"\n",
        "    if \"ftp_connect\" not in globals():\n",
        "        raise RuntimeError(\"ftp_connect() is not available; ensure Section [A] is loaded first.\")\n",
        "    ftps = ftp_connect()\n",
        "    try:\n",
        "        # Primary: absolute root /partials\n",
        "        primary = g3_remote_abs(G3_SERVER_PARTIALS_DIR, G3_SERVER_MAPPING_BASENAME)  # e.g., /partials/match_to_unmasked.csv\n",
        "        ok, err = g3_ftps_fetch_to_local(ftps, primary, G3_LOCAL_MAPPING_CACHE)\n",
        "        if not ok:\n",
        "            # Fallback: FTP_DIR/partials (e.g., /gengen/partials/...)\n",
        "            fallback = g3_remote_under_ftpdir(posixpath.join(\"partials\", G3_SERVER_MAPPING_BASENAME))\n",
        "            ok2, err2 = g3_ftps_fetch_to_local(ftps, fallback, G3_LOCAL_MAPPING_CACHE)\n",
        "            if not ok2:\n",
        "                raise RuntimeError(\n",
        "                    \"Resolver not found on server at either location:\\n\"\n",
        "                    f\"  1) {primary}\\n\"\n",
        "                    f\"  2) {fallback}\\n\"\n",
        "                    \"Action: Upload match_to_unmasked.csv to /partials/ (root) or to /gengen/partials/ and re-run.\\n\"\n",
        "                    f\"Details: primary error: {err}; fallback error: {err2}\"\n",
        "                )\n",
        "        mapping = g3_read_resolver_csv(G3_LOCAL_MAPPING_CACHE)\n",
        "        return mapping\n",
        "    finally:\n",
        "        try:\n",
        "            ftps.quit()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "# Global resolver dict for Gold 3\n",
        "G3_MATCH_TO_UNMASKED = g3_load_resolver_from_server()\n",
        "\n",
        "# ====== CUT STOP  [B] REFACTOR-Gold 3 — Add 5 returns for spacing ===============================\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "# ====== CUT START [C] REFACTOR-Gold 3 — CSV Load & Column Detection ==============================\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import re\n",
        "from typing import Dict, List, Optional\n",
        "\n",
        "try:\n",
        "    import pandas as pd\n",
        "except Exception:\n",
        "    pd = None\n",
        "\n",
        "# ---------- Purpose ----------\n",
        "# Load the canonical Gold 1 output (CSV) and detect core columns for lineages.\n",
        "# Exposes:\n",
        "#   - g3_df_core : the loaded DataFrame (no HTML transforms)\n",
        "#   - g3_cols    : dict of detected column names (id, name, match_to, subject_code, lineage-ish hints)\n",
        "#   - G3_COLUMNS : optional preferred display order for [E]/[F] (set only if obvious)\n",
        "\n",
        "# ---------- Source selection (Gold 1 output) ----------\n",
        "# You can point at either env var or default filename in current working dir.\n",
        "G3_SOURCE_CSV = os.getenv(\"G3_SOURCE_CSV\", os.getenv(\"G1_CSV_PATH\", \"final_combined_df_with_value_labels.csv\"))\n",
        "ENC = globals().get(\"ENC\", \"iso-8859-15\")\n",
        "\n",
        "# ---------- Local helpers (namespaced; independent of Gold 2) ----------\n",
        "def g3_normalize_colnames(df):\n",
        "    if df is None or getattr(df, \"columns\", None) is None:\n",
        "        return df\n",
        "    new = df.copy()\n",
        "    new.columns = [re.sub(r\"\\s+\", \" \", str(c)).strip() for c in df.columns]\n",
        "    return new\n",
        "\n",
        "def g3_find_col(df, regex_list: Optional[List[str]] = None, fallback_list: Optional[List[str]] = None) -> Optional[str]:\n",
        "    if df is None or getattr(df, \"columns\", None) is None:\n",
        "        return None\n",
        "    regex_list = regex_list or []\n",
        "    fallback_list = fallback_list or []\n",
        "    cols = list(df.columns)\n",
        "    # regex\n",
        "    for pattern in regex_list:\n",
        "        try:\n",
        "            rx = re.compile(pattern, flags=re.IGNORECASE)\n",
        "        except Exception:\n",
        "            continue\n",
        "        for c in cols:\n",
        "            if rx.search(str(c)):\n",
        "                return c\n",
        "    # exact fallback\n",
        "    for name in fallback_list:\n",
        "        t = str(name).strip().lower()\n",
        "        for c in cols:\n",
        "            if str(c).strip().lower() == t:\n",
        "                return c\n",
        "    return cols[0] if cols else None\n",
        "\n",
        "def g3_find_cols(df, patterns_or_names: List[str]) -> List[str]:\n",
        "    hits = []\n",
        "    if df is None or getattr(df, \"columns\", None) is None:\n",
        "        return hits\n",
        "    cols = list(df.columns)\n",
        "    for token in patterns_or_names:\n",
        "        is_regex = bool(re.search(r\"[\\\\^$.*+?()\\\\[\\\\]|]\", token))\n",
        "        if is_regex:\n",
        "            try:\n",
        "                rx = re.compile(token, flags=re.IGNORECASE)\n",
        "            except Exception:\n",
        "                continue\n",
        "            for c in cols:\n",
        "                if rx.search(str(c)):\n",
        "                    hits.append(c)\n",
        "        else:\n",
        "            low = token.strip().lower()\n",
        "            for c in cols:\n",
        "                if str(c).strip().lower() == low:\n",
        "                    hits.append(c)\n",
        "    # de-dupe\n",
        "    seen = set()\n",
        "    uniq = []\n",
        "    for c in hits:\n",
        "        if c not in seen:\n",
        "            uniq.append(c)\n",
        "            seen.add(c)\n",
        "    return uniq\n",
        "\n",
        "# ---------- Load CSV ----------\n",
        "if pd is None:\n",
        "    raise RuntimeError(\"pandas is required in Section [C]; install/enable pandas in Colab.\")\n",
        "\n",
        "if not os.path.isfile(G3_SOURCE_CSV):\n",
        "    raise RuntimeError(\n",
        "        \"Gold 3 cannot find the Gold 1 CSV.\\n\"\n",
        "        f\"Looked for: {G3_SOURCE_CSV}\\n\"\n",
        "        \"Set env G3_SOURCE_CSV or G1_CSV_PATH to the correct file, then re-run.\"\n",
        "    )\n",
        "\n",
        "g3_df_core = pd.read_csv(G3_SOURCE_CSV, dtype=str, encoding=ENC, keep_default_na=False)\n",
        "g3_df_core = g3_normalize_colnames(g3_df_core)\n",
        "\n",
        "# ---------- Column detection ----------\n",
        "g3_cols: Dict[str, Optional[str]] = {}\n",
        "\n",
        "g3_cols['id'] = g3_find_col(\n",
        "    g3_df_core,\n",
        "    [r'^(id#|personid|id)$', r'person\\s*id'],\n",
        "    [\"ID#\", \"PersonID\", \"personID\", \"id\"]\n",
        ")\n",
        "\n",
        "g3_cols['match_to'] = g3_find_col(\n",
        "    g3_df_core,\n",
        "    [r'^match\\s*to$', r'^matchto$'],\n",
        "    [\"Match to\", \"Match\"]\n",
        ")\n",
        "\n",
        "g3_cols['name'] = g3_find_col(\n",
        "    g3_df_core,\n",
        "    [r'^(name|full\\s*name)$'],\n",
        "    [\"Name\"]\n",
        ")\n",
        "\n",
        "# subject code / resolver code column (used widely in both tools)\n",
        "g3_cols['subject_code'] = g3_find_col(\n",
        "    g3_df_core,\n",
        "    [r'^(subject\\s*code|subjectcode|code)$'],\n",
        "    [\"Subject Code\", \"subject_code\", \"Code\"]\n",
        ")\n",
        "\n",
        "# lineage-ish hints (we won't enforce one here; [D] can decide which to use)\n",
        "# Try to gather potential columns used for grouping/lineage display.\n",
        "lineage_candidates = g3_find_cols(\n",
        "    g3_df_core,\n",
        "    [\n",
        "        r'lineage', r'branch', r'child', r'ancestor', r'pair', r'couple',\n",
        "        \"Named Pair\", \"named pair\", \"Pair\", \"pair\"\n",
        "    ]\n",
        ")\n",
        "g3_cols['lineage_candidates'] = lineage_candidates\n",
        "\n",
        "# Optional suggested order for [E], if we detect the common trio\n",
        "# You can override G3_COLUMNS in later sections if needed.\n",
        "if all([g3_cols.get('match_to'), g3_cols.get('name')]):\n",
        "    # We do not set 'Lineage' automatically here; [D] will craft a final column.\n",
        "    G3_COLUMNS = [\"Find\", \"Match Summary\", \"Lineage\"]\n",
        "\n",
        "# No disk writes in this section.\n",
        "# ====== CUT STOP  [C] REFACTOR-Gold 3 — Add 5 returns for spacing ===============================\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "# ====== CUT START [D] REFACTOR-Gold 3 — Transform (display_df) ================================\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import re\n",
        "from typing import Dict, List, Optional\n",
        "\n",
        "try:\n",
        "    import pandas as pd\n",
        "except Exception:\n",
        "    pd = None\n",
        "\n",
        "# ---------- Assumptions from prior sections ----------\n",
        "# - [B] may define: G3_MATCH_TO_UNMASKED (resolver dict) — optional\n",
        "# - [C] defines: g3_df_core (DataFrame), g3_cols (dict with keys: id, name, match_to, subject_code, lineage_candidates)\n",
        "# - This section produces: g3_display_df (3-column DataFrame: Find | Match Summary | Lineage)\n",
        "# - No uploads or disk writes here.\n",
        "\n",
        "ENC = globals().get(\"ENC\", \"iso-8859-15\")\n",
        "\n",
        "def g3_html_escape(s: str) -> str:\n",
        "    import html as _h\n",
        "    return _h.escape(\"\" if s is None else str(s), quote=True)\n",
        "\n",
        "def g3_slugify(s: str) -> str:\n",
        "    s = re.sub(r\"[^A-Za-z0-9]+\", \"-\", \"\" if s is None else str(s))\n",
        "    s = re.sub(r\"-{2,}\", \"-\", s).strip(\"-\")\n",
        "    return s.lower()\n",
        "\n",
        "def g3_coalesce(*vals) -> str:\n",
        "    for v in vals:\n",
        "        if v is None:\n",
        "            continue\n",
        "        s = str(v).strip()\n",
        "        if s and s.lower() != \"nan\":\n",
        "            return s\n",
        "    return \"\"\n",
        "\n",
        "def g3_build_lineage_html(row, lineage_cols: List[str]) -> str:\n",
        "    \"\"\"Join available lineage columns into a compact breadcrumb using &rarr;.\"\"\"\n",
        "    parts = []\n",
        "    for c in lineage_cols:\n",
        "        try:\n",
        "            val = row.get(c, \"\")\n",
        "        except Exception:\n",
        "            try:\n",
        "                val = row[c]\n",
        "            except Exception:\n",
        "                val = \"\"\n",
        "        txt = str(val).strip()\n",
        "        if not txt or txt.lower() == \"nan\":\n",
        "            continue\n",
        "        parts.append(g3_html_escape(txt))\n",
        "    if not parts:\n",
        "        return \"<span class=\\\"g3-lineage\\\">&hellip;</span>\"\n",
        "    return \"<span class=\\\"g3-lineage\\\">\" + \" &rarr; \".join(parts) + \"</span>\"\n",
        "\n",
        "def g3_resolve_name(code_value: str, fallback_name: str) -> str:\n",
        "    \"\"\"Use G3_MATCH_TO_UNMASKED when present; otherwise fallback to provided name.\"\"\"\n",
        "    mapping = globals().get(\"G3_MATCH_TO_UNMASKED\", None)\n",
        "    if mapping and isinstance(mapping, dict):\n",
        "        resolved = mapping.get(str(code_value).strip(), \"\")\n",
        "        if resolved:\n",
        "            return resolved\n",
        "    return fallback_name\n",
        "\n",
        "def g3_build_display_df(df_core, cols: Dict[str, Optional[str]]) -> \"pd.DataFrame\":\n",
        "    if pd is None:\n",
        "        raise RuntimeError(\"pandas is required in Section [D]; install/enable pandas in Colab.\")\n",
        "    if df_core is None or cols is None:\n",
        "        raise RuntimeError(\"g3_df_core / g3_cols are required to build g3_display_df.\")\n",
        "\n",
        "    id_c   = cols.get(\"id\")\n",
        "    name_c = cols.get(\"name\")\n",
        "    code_c = cols.get(\"match_to\")\n",
        "    subj_c = cols.get(\"subject_code\")\n",
        "    lineage_cands = cols.get(\"lineage_candidates\") or []\n",
        "\n",
        "    # Build rows\n",
        "    out_rows = []\n",
        "    for _, row in df_core.iterrows():\n",
        "        id_val   = g3_coalesce(row.get(id_c) if id_c else None)\n",
        "        name_val = g3_coalesce(row.get(name_c) if name_c else None)\n",
        "        code_val = g3_coalesce(row.get(code_c) if code_c else None)\n",
        "        subj_val = g3_coalesce(row.get(subj_c) if subj_c else None)\n",
        "\n",
        "        # Anchor id: prefer subject_code, then id, else slugified name or code\n",
        "        anchor_key = g3_coalesce(subj_val, id_val, name_val, code_val)\n",
        "        anchor = g3_slugify(anchor_key) if anchor_key else \"row\"\n",
        "\n",
        "        # Resolved name for match summary\n",
        "        resolved = g3_resolve_name(code_val, name_val or code_val)\n",
        "\n",
        "        # --- Find column ---\n",
        "        # Show display text = resolved name if available, else name/code/id.\n",
        "        disp_text = g3_coalesce(resolved, name_val, code_val, id_val)\n",
        "        find_html = f\"<a id=\\\"g3-{anchor}\\\" name=\\\"g3-{anchor}\\\">{g3_html_escape(disp_text)}</a>\"\n",
        "\n",
        "        # --- Match Summary column ---\n",
        "        # Show resolved name and (code) if distinct; append subject code in small text if present.\n",
        "        ms_bits = []\n",
        "        if resolved:\n",
        "            ms_bits.append(g3_html_escape(resolved))\n",
        "        if code_val and (resolved.strip().lower() != code_val.strip().lower()):\n",
        "            ms_bits.append(f\"(<span class=\\\"g3-code\\\">{g3_html_escape(code_val)}</span>)\")\n",
        "        if subj_val:\n",
        "            ms_bits.append(f\"<span class=\\\"g3-subject\\\">&nbsp;&middot;&nbsp;{g3_html_escape(subj_val)}</span>\")\n",
        "        ms_html = \" \".join(ms_bits) if ms_bits else g3_html_escape(disp_text)\n",
        "\n",
        "        # --- Lineage column (HTML) ---\n",
        "        lineage_html = g3_build_lineage_html(row, lineage_cands)\n",
        "\n",
        "        out_rows.append({\n",
        "            \"Find\": find_html,\n",
        "            \"Match Summary\": ms_html,\n",
        "            \"Lineage\": lineage_html,\n",
        "        })\n",
        "\n",
        "    display_df = pd.DataFrame(out_rows, columns=[\"Find\", \"Match Summary\", \"Lineage\"])\n",
        "    return display_df\n",
        "\n",
        "# ---------- Public artifact ----------\n",
        "g3_display_df = None\n",
        "try:\n",
        "    if 'g3_df_core' in globals() and 'g3_cols' in globals():\n",
        "        g3_display_df = g3_build_display_df(g3_df_core, g3_cols)\n",
        "except Exception as _e_g3:\n",
        "    # Leave as None; Section [E] or [F] can call g3_build_display_df(...) explicitly.\n",
        "    g3_display_df = None\n",
        "\n",
        "# No disk writes here.\n",
        "# ====== CUT STOP  [D] REFACTOR-Gold 3 — Add 5 returns for spacing =============================\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "# ====== CUT START [E] REFACTOR-Gold 3 — HTML (no uploads) =========================\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import html as _py_html\n",
        "import math\n",
        "\n",
        "# ---------- Assumptions from prior sections ----------\n",
        "# - A: ftp_connect(), ftp_upload_overwrite(), _remote_path(), LOCAL_NAME/REMOTE_NAME (G3)\n",
        "# - B/C/D prepare a DataFrame assigned to g3_display_df OR provide a function to retrieve it.\n",
        "# - The page built here must use only \"g3-\" DOM ids/classes and \"g3_\" JS functions.\n",
        "#\n",
        "# This section does NOT perform any FTP writes. Saving/uploading is handled in Section [F].\n",
        "\n",
        "# ---------- Config / safe defaults (do not collide with G2) ----------\n",
        "ENC = globals().get(\"ENC\", \"iso-8859-15\")\n",
        "G3_TITLE = globals().get(\"G3_TITLE\", \"Yates Ancestor Register &ndash; Lineages\")\n",
        "TABLE_WIDTH_PX = int(globals().get(\"G3_TABLE_WIDTH_PX\", 1150))\n",
        "COL_A_PX = int(globals().get(\"G3_COL_A_PX\", 320))   # first column width\n",
        "COL_B_PX = int(globals().get(\"G3_COL_B_PX\", 300))   # second column width\n",
        "COL_C_PX = int(globals().get(\"G3_COL_C_PX\", 530))   # third column width\n",
        "\n",
        "# The main output filename is set in Section [A] as LOCAL_NAME / REMOTE_NAME.\n",
        "LOCAL_NAME = globals().get(\"LOCAL_NAME\", \"yates_ancestor_register.htm\")\n",
        "\n",
        "# Column order expectation: allow prior sections to define, else fall back to df columns.\n",
        "G3_COLUMNS = globals().get(\"G3_COLUMNS\", None)  # e.g., [\"Find\", \"Match Summary\", \"Lineage\"]\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def g3_html_escape(s: str) -> str:\n",
        "    return _py_html.escape(\"\" if s is None else str(s), quote=True)\n",
        "\n",
        "def g3_format_int(n) -> str:\n",
        "    try:\n",
        "        i = int(n)\n",
        "        return f\"{i:,}\"\n",
        "    except Exception:\n",
        "        return g3_html_escape(n)\n",
        "\n",
        "def g3_build_table_html(df) -> str:\n",
        "    \"\"\"Render the main lineage table using only g3-* ids/classes.\n",
        "    We intentionally do NOT assume column names; we respect G3_COLUMNS if provided.\n",
        "    \"\"\"\n",
        "    if df is None:\n",
        "        return \"<!-- g3: no dataframe available -->\"\n",
        "    cols = list(G3_COLUMNS) if isinstance(G3_COLUMNS, (list, tuple)) and len(G3_COLUMNS) > 0 else list(df.columns)\n",
        "\n",
        "    # Column widths map (3-column expectation by default).\n",
        "    col_widths = [COL_A_PX, COL_B_PX, COL_C_PX]\n",
        "    # Ensure we have a width per visible column (pad with last width if needed).\n",
        "    if len(cols) > 3:\n",
        "        col_widths = col_widths + [col_widths[-1]] * (len(cols) - 3)\n",
        "\n",
        "    # Table header\n",
        "    ths = []\n",
        "    for i, c in enumerate(cols):\n",
        "        w = col_widths[i] if i < len(col_widths) else col_widths[-1]\n",
        "        ths.append(f'<th style=\"width:{int(w)}px\">{g3_html_escape(c)}</th>')\n",
        "    thead = \"<thead><tr>\" + \"\".join(ths) + \"</tr></thead>\"\n",
        "\n",
        "    # Table body\n",
        "    trs = []\n",
        "    for idx, row in df.iterrows():\n",
        "        tds = []\n",
        "        for i, c in enumerate(cols):\n",
        "            val = row.get(c, \"\")\n",
        "            # If this column presumably contains pre-built HTML from prior section (e.g., lineage cells),\n",
        "            # we allow minimal pass-through for strings that look like HTML; otherwise escape it.\n",
        "            if isinstance(val, str) and (\"<a \" in val or \"<span\" in val or \"<div\" in val or \"<br\" in val):\n",
        "                cell_html = val\n",
        "            else:\n",
        "                cell_html = g3_html_escape(val)\n",
        "            tds.append(f\"<td>{cell_html}</td>\")\n",
        "        trs.append(\"<tr>\" + \"\".join(tds) + \"</tr>\")\n",
        "    tbody = \"<tbody>\" + \"\".join(trs) + \"</tbody>\"\n",
        "\n",
        "    table = (\n",
        "        f'<table id=\"g3-table\" class=\"g3-table\" role=\"table\" aria-label=\"Lineage table\" '\n",
        "        f'style=\"width:{TABLE_WIDTH_PX}px\">'\n",
        "        f\"{thead}{tbody}</table>\"\n",
        "    )\n",
        "    return table\n",
        "\n",
        "def g3_build_css() -> str:\n",
        "    return (\n",
        "        \"<style type=\\\"text/css\\\">\\n\"\n",
        "        \"  html { scroll-behavior: smooth; }\\n\"\n",
        "        \"  body { font-family: Georgia, \\\"Times New Roman\\\", serif; background:#ffffff; color:#222; margin:0; padding:0; line-height:1.5; }\\n\"\n",
        "        f\"  .g3-wrap {{ max-width:{TABLE_WIDTH_PX}px; margin:0 auto; background:#ffffff; padding:20px; padding-bottom:48px; }}\\n\"\n",
        "        \"  a { color:#154b8b; text-decoration:none; } a:hover { text-decoration:underline; }\\n\"\n",
        "        \"  h1 { margin:0 0 6px 0; font-size:26px; line-height:1.2; text-align:center; }\\n\"\n",
        "        \"  .g3-updated { font-size:12px; color:#555; text-align:center; margin:2px 0 10px 0; }\\n\"\n",
        "        \"  .g3-menu { display:flex; gap:8px; flex-wrap:wrap; align-items:center; margin:8px 0 12px 0; }\\n\"\n",
        "        \"  .g3-menu .g3-pill { display:inline-block; border:1px solid #ccc; padding:6px 10px; border-radius:18px; font-size:13px; }\\n\"\n",
        "        \"  table.g3-table { border-collapse:collapse; width:100%; table-layout:fixed; }\\n\"\n",
        "        \"  table.g3-table th, table.g3-table td { border:1px solid #ddd; padding:8px; vertical-align:top; }\\n\"\n",
        "        \"  table.g3-table th { background:#ffffcc; text-align:left; font-weight:bold; position:sticky; top:0; z-index:2; }\\n\"\n",
        "        \"  .g3-foot { margin-top:28px; font-size:12px; color:#666; text-align:center; }\\n\"\n",
        "        \"  /* Print tweaks */\\n\"\n",
        "        \"  @media print {\\n\"\n",
        "        \"    .g3-menu { display:none !important; }\\n\"\n",
        "        \"    .g3-wrap { padding:0; }\\n\"\n",
        "        \"  }\\n\"\n",
        "        \"</style>\\n\"\n",
        "    )\n",
        "\n",
        "def g3_last_updated_snippet() -> str:\n",
        "    \"\"\"XHTML-safe last updated stamp, 24h YYYY-MM-DD HH:MM, using document.lastModified.\"\"\"\n",
        "    return (\n",
        "        \"<script type=\\\"text/javascript\\\">\\n\"\n",
        "        \"//<![CDATA[\\n\"\n",
        "        \"(function(){\\n\"\n",
        "        \"  var el = document.getElementById('last-updated');\\n\"\n",
        "        \"  if(!el) return;\\n\"\n",
        "        \"  var d = new Date(document.lastModified || new Date());\\n\"\n",
        "        \"  function z(n){ return (n < 10 ? '0' : '') + n; }\\n\"\n",
        "        \"  var formatted = d.getFullYear() + '-' + z(d.getMonth()+1) + '-' + z(d.getDate()) + ' ' + z(d.getHours()) + ':' + z(d.getMinutes());\\n\"\n",
        "        \"  el.innerHTML = 'Last updated: ' + formatted;\\n\"\n",
        "        \"})();\\n\"\n",
        "        \"//]]>\\n\"\n",
        "        \"</script>\\n\"\n",
        "    )\n",
        "\n",
        "def g3_build_header() -> str:\n",
        "    return (\\\n",
        "        \"<h1>Yates Ancestor Register &ndash; Lineages</h1>\\n\"\n",
        "        \"<div id=\\\"last-updated\\\" class=\\\"g3-updated\\\">Last updated: &hellip;</div>\\n\"\n",
        "    )\n",
        "\n",
        "def g3_build_menu() -> str:\n",
        "    # Minimal, non-colliding toolbox; expand in later sections if needed.\n",
        "    return (\\\n",
        "        \"<div class=\\\"g3-menu\\\" id=\\\"g3-menu\\\">\\n\"\n",
        "        \"  <span class=\\\"g3-pill\\\">Lineages</span>\\n\"\n",
        "        \"  <span class=\\\"g3-pill\\\">Sortable</span>\\n\"\n",
        "        \"</div>\\n\"\n",
        "    )\n",
        "\n",
        "def g3_build_init_js() -> str:\n",
        "    \"\"\"Minimal init; placeholder for future search/sort hooks under g3_ namespace only.\"\"\"\n",
        "    return (\\\n",
        "        \"<script type=\\\"text/javascript\\\">\\n\"\n",
        "        \"//<![CDATA[\\n\"\n",
        "        \"function g3_init(){\\n\"\n",
        "        \"  // Placeholder for future g3-specific behaviors (search, sort, etc.).\\n\"\n",
        "        \"}\\n\"\n",
        "        \"if (document.readyState === 'loading') { document.addEventListener('DOMContentLoaded', g3_init); } else { g3_init(); }\\n\"\n",
        "        \"//]]>\\n\"\n",
        "        \"</script>\\n\"\n",
        "    )\n",
        "\n",
        "def g3_build_full_html(df) -> str:\n",
        "    css = g3_build_css()\n",
        "    header = g3_build_header()\n",
        "    menu = g3_build_menu()\n",
        "    table_html = g3_build_table_html(df)\n",
        "    init_js = g3_build_init_js()\n",
        "    updated_js = g3_last_updated_snippet()\n",
        "    # XHTML 1.0 Transitional\n",
        "    doc = (\\\n",
        "        \"<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Transitional//EN\\\" \\n\"\n",
        "        \"  \\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\\\">\\n\"\n",
        "        \"<html xmlns=\\\"http://www.w3.org/1999/xhtml\\\" lang=\\\"en\\\" xml:lang=\\\"en\\\">\\n\"\n",
        "        \"<head>\\n\"\n",
        "        \"  <meta http-equiv=\\\"Content-Type\\\" content=\\\"text/html; charset=iso-8859-15\\\" />\\n\"\n",
        "        f\"  <title>{G3_TITLE}</title>\\n\"\n",
        "        f\"{css}\"\n",
        "        \"</head>\\n\"\n",
        "        \"<body>\\n\"\n",
        "        f\"  <div class=\\\"g3-wrap\\\" id=\\\"g3-app\\\">\\n\"\n",
        "        f\"    {header}\\n\"\n",
        "        f\"    {menu}\\n\"\n",
        "        f\"    {table_html}\\n\"\n",
        "        \"    <div class=\\\"g3-foot\\\">&copy; Yates One-Name Study</div>\\n\"\n",
        "        \"  </div>\\n\"\n",
        "        f\"{updated_js}\"\n",
        "        f\"{init_js}\"\n",
        "        \"</body>\\n\"\n",
        "        \"</html>\\n\"\n",
        "    )\n",
        "    return doc\n",
        "\n",
        "# ---------- Public artifact ----------\n",
        "# If prior sections have prepared g3_display_df, build FULL_HTML now; else expose the function.\n",
        "FULL_HTML = None\n",
        "try:\n",
        "    if 'g3_display_df' in globals() and g3_display_df is not None:\n",
        "        FULL_HTML = g3_build_full_html(g3_display_df)\n",
        "except Exception as _g3_e:\n",
        "    # Leave FULL_HTML as None; Section [F] can call g3_build_full_html(...) explicitly.\n",
        "    FULL_HTML = None\n",
        "\n",
        "# This section must not perform any disk writes or FTP operations.\n",
        "# ====== CUT STOP  [E] REFACTOR-Gold 3 — Add 5 returns for spacing ================\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "# ====== CUT START [F] REFACTOR-Gold 3 — Save + Upload + Partials + Printable =====================\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import io\n",
        "import posixpath\n",
        "from typing import Dict, Any\n",
        "\n",
        "try:\n",
        "    import pandas as pd  # used for CSV/printing helpers if available\n",
        "except Exception:\n",
        "    pd = None  # allow running without pandas in edge cases\n",
        "\n",
        "# ---------- Assumptions from prior sections ----------\n",
        "# - [A] defines: ftp_connect(), ftp_upload_overwrite(), _remote_path(),\n",
        "#                LOCAL_NAME, REMOTE_NAME, PARTIAL_MATCH_COUNT, PARTIAL_LINEAGE_COUNT, PARTIAL_PRINTABLE\n",
        "# - [E] defines: g3_build_full_html(df), FULL_HTML (optional), ENC, TABLE_WIDTH_PX\n",
        "# - Prior section(s) produce: g3_display_df (DataFrame) with columns expected by [E]\n",
        "\n",
        "# ---------- Local config ----------\n",
        "ENC = globals().get(\"ENC\", \"iso-8859-15\")\n",
        "\n",
        "LOCAL_NAME  = globals().get(\"LOCAL_NAME\",  \"yates_ancestor_register.htm\")\n",
        "REMOTE_NAME = globals().get(\"REMOTE_NAME\", \"yates_ancestor_register.htm\")\n",
        "\n",
        "PARTIAL_MATCH_COUNT   = globals().get(\"PARTIAL_MATCH_COUNT\",   \"partials/g3_match_count.htm\")\n",
        "PARTIAL_LINEAGE_COUNT = globals().get(\"PARTIAL_LINEAGE_COUNT\", \"partials/g3_lineage_count.htm\")\n",
        "PARTIAL_PRINTABLE     = globals().get(\"PARTIAL_PRINTABLE\",     \"partials/g3_print.htm\")\n",
        "\n",
        "# Ensure local partial directories exist when saving to disk\n",
        "def _ensure_parent_dir(path: str) -> None:\n",
        "    try:\n",
        "        parent = os.path.dirname(path)\n",
        "        if parent and not os.path.isdir(parent):\n",
        "            os.makedirs(parent, exist_ok=True)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# ---------- Builders for partials ----------\n",
        "def g3_build_match_count_html(df) -> str:\n",
        "    \"\"\"Return minimal HTML showing autosomal (row) count with comma formatting.\"\"\"\n",
        "    try:\n",
        "        n = int(len(df)) if df is not None else 0\n",
        "    except Exception:\n",
        "        n = 0\n",
        "    count_str = f\"{n:,}\"\n",
        "    return (\n",
        "        \"<!DOCTYPE html>\\n\"\n",
        "        \"<html><head><meta http-equiv=\\\"Content-Type\\\" content=\\\"text/html; charset=iso-8859-15\\\" /></head>\\n\"\n",
        "        \"<body>\\n\"\n",
        "        f\"<div id=\\\"g3-match-count\\\" class=\\\"g3-pill\\\">Autosomal matches: {count_str}</div>\\n\"\n",
        "        \"</body></html>\\n\"\n",
        "    )\n",
        "\n",
        "def g3_build_lineage_count_html(df) -> str:\n",
        "    \"\"\"Return minimal HTML with a distinct lineage count if a 'Lineage' (or similar) column exists.\n",
        "    Fallback: unique values of the last column if heuristics fail.\n",
        "    \"\"\"\n",
        "    if df is None:\n",
        "        uniq = 0\n",
        "    else:\n",
        "        cols = list(df.columns)\n",
        "        target_col = None\n",
        "        # Heuristics for likely lineage column names\n",
        "        candidates = [\"Lineage\", \"lineage\", \"Lineages\", \"lineages\", \"Lineage HTML\", \"lineage HTML\"]\n",
        "        for c in cols:\n",
        "            if c in candidates or c.lower() in [\"lineage\", \"lineages\"]:\n",
        "                target_col = c\n",
        "                break\n",
        "        if target_col is None:\n",
        "            # fallback to last column\n",
        "            target_col = cols[-1]\n",
        "        try:\n",
        "            uniq = len(set([str(x).strip() for x in df[target_col].tolist()]))\n",
        "        except Exception:\n",
        "            uniq = 0\n",
        "    count_str = f\"{uniq:,}\"\n",
        "    return (\n",
        "        \"<!DOCTYPE html>\\n\"\n",
        "        \"<html><head><meta http-equiv=\\\"Content-Type\\\" content=\\\"text/html; charset=iso-8859-15\\\" /></head>\\n\"\n",
        "        \"<body>\\n\"\n",
        "        f\"<div id=\\\"g3-lineage-count\\\" class=\\\"g3-pill\\\">Lineages: {count_str}</div>\\n\"\n",
        "        \"</body></html>\\n\"\n",
        "    )\n",
        "\n",
        "def g3_build_printable_html(df) -> str:\n",
        "    \"\"\"Simple printable view of the table (no toolbox).\"\"\"\n",
        "    if df is None:\n",
        "        table_rows = \"\"\n",
        "        cols = []\n",
        "    else:\n",
        "        cols = list(df.columns)\n",
        "        # Build rows with HTML-escape except for obvious inline HTML in cells\n",
        "        def esc(v):\n",
        "            s = \"\" if v is None else str(v)\n",
        "            if (\"<a \" in s) or (\"<span\" in s) or (\"<div\" in s) or (\"<br\" in s):\n",
        "                return s\n",
        "            import html as _h\n",
        "            return _h.escape(s, quote=True)\n",
        "        trs = []\n",
        "        for _, row in df.iterrows():\n",
        "            tds = \"\".join([f\"<td>{esc(row.get(c, ''))}</td>\" for c in cols])\n",
        "            trs.append(f\"<tr>{tds}</tr>\")\n",
        "        table_rows = \"\\n\".join(trs)\n",
        "    thead = \"\".join([f\"<th>{c}</th>\" for c in cols])\n",
        "    return (\\\n",
        "        \"<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Transitional//EN\\\" \\n\"\n",
        "        \"  \\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\\\">\\n\"\n",
        "        \"<html xmlns=\\\"http://www.w3.org/1999/xhtml\\\" lang=\\\"en\\\" xml:lang=\\\"en\\\">\\n\"\n",
        "        \"<head>\\n\"\n",
        "        \"  <meta http-equiv=\\\"Content-Type\\\" content=\\\"text/html; charset=iso-8859-15\\\" />\\n\"\n",
        "        \"  <title>Yates Ancestor Register &ndash; Printable</title>\\n\"\n",
        "        \"  <style type=\\\"text/css\\\">\\n\"\n",
        "        \"    body { font-family: Georgia, \\\"Times New Roman\\\", serif; background:#fff; color:#000; }\\n\"\n",
        "        \"    table { border-collapse: collapse; width: 100%; }\\n\"\n",
        "        \"    th, td { border: 1px solid #ccc; padding: 6px; vertical-align: top; }\\n\"\n",
        "        \"    th { background: #ffffcc; }\\n\"\n",
        "        \"    @media print { a { color:#000 !important; text-decoration:none; } }\\n\"\n",
        "        \"  </style>\\n\"\n",
        "        \"</head>\\n\"\n",
        "        \"<body>\\n\"\n",
        "        \"  <h1>Yates Ancestor Register &ndash; Printable</h1>\\n\"\n",
        "        f\"  <table id=\\\"g3-print-table\\\"><thead><tr>{thead}</tr></thead><tbody>\\n\"\n",
        "        f\"{table_rows}\\n\"\n",
        "        \"  </tbody></table>\\n\"\n",
        "        \"</body>\\n\"\n",
        "        \"</html>\\n\"\n",
        "    )\n",
        "\n",
        "# ---------- Save helpers ----------\n",
        "def g3_write_text(local_path: str, text: str) -> None:\n",
        "    _ensure_parent_dir(local_path)\n",
        "    with open(local_path, \"w\", encoding=ENC, errors=\"replace\") as fh:\n",
        "        fh.write(text)\n",
        "\n",
        "def g3_save_local(df) -> Dict[str, str]:\n",
        "    \"\"\"Write main HTML and partials to local disk. Returns dict of paths.\"\"\"\n",
        "    outputs = {}\n",
        "    # Main\n",
        "    if 'FULL_HTML' in globals() and isinstance(globals()['FULL_HTML'], str) and globals()['FULL_HTML']:\n",
        "        html = globals()['FULL_HTML']\n",
        "    else:\n",
        "        if 'g3_build_full_html' not in globals():\n",
        "            raise RuntimeError(\"g3_build_full_html is not available in scope.\")\n",
        "        if 'g3_display_df' not in globals():\n",
        "            raise RuntimeError(\"g3_display_df is not available in scope.\")\n",
        "        html = g3_build_full_html(df)\n",
        "    g3_write_text(LOCAL_NAME, html)\n",
        "    outputs['main'] = os.path.abspath(LOCAL_NAME)\n",
        "\n",
        "    # Partials\n",
        "    g3_write_text(PARTIAL_MATCH_COUNT, g3_build_match_count_html(df))\n",
        "    outputs['match_count'] = os.path.abspath(PARTIAL_MATCH_COUNT)\n",
        "\n",
        "    g3_write_text(PARTIAL_LINEAGE_COUNT, g3_build_lineage_count_html(df))\n",
        "    outputs['lineage_count'] = os.path.abspath(PARTIAL_LINEAGE_COUNT)\n",
        "\n",
        "    g3_write_text(PARTIAL_PRINTABLE, g3_build_printable_html(df))\n",
        "    outputs['printable'] = os.path.abspath(PARTIAL_PRINTABLE)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "def g3_upload_all(ftps, local_map: Dict[str, str]) -> None:\n",
        "    \"\"\"Upload main and partials via already-authenticated FTPS connection.\"\"\"\n",
        "    if ftps is None:\n",
        "        raise RuntimeError(\"FTPS handle is None.\")\n",
        "    # main\n",
        "    ftp_upload_overwrite(ftps, local_map['main'], REMOTE_NAME)\n",
        "    # partials: use same basename on server as local for clarity\n",
        "    ftp_upload_overwrite(ftps, local_map['match_count'], PARTIAL_MATCH_COUNT)\n",
        "    ftp_upload_overwrite(ftps, local_map['lineage_count'], PARTIAL_LINEAGE_COUNT)\n",
        "    ftp_upload_overwrite(ftps, local_map['printable'], PARTIAL_PRINTABLE)\n",
        "\n",
        "# ---------- Orchestrator ----------\n",
        "def g3_run_save_and_upload(do_upload: bool = True) -> Dict[str, Any]:\n",
        "    \"\"\"Save all artifacts locally, and optionally upload over FTPS.\n",
        "    Returns a summary dict with local paths and flags.\n",
        "    \"\"\"\n",
        "    if 'g3_display_df' not in globals():\n",
        "        raise RuntimeError(\"g3_display_df is not in scope; cannot render HTML/partials.\")\n",
        "    df = globals()['g3_display_df']\n",
        "    out = {'saved': False, 'uploaded': False, 'paths': {}}\n",
        "\n",
        "    paths = g3_save_local(df)\n",
        "    out['paths'] = paths\n",
        "    out['saved'] = True\n",
        "\n",
        "    if do_upload:\n",
        "        ftps = ftp_connect()\n",
        "        try:\n",
        "            g3_upload_all(ftps, paths)\n",
        "            out['uploaded'] = True\n",
        "        finally:\n",
        "            try:\n",
        "                ftps.quit()\n",
        "            except Exception:\n",
        "                pass\n",
        "    return out\n",
        "\n",
        "# ====== CUT STOP  [F] REFACTOR-Gold 3 — Add 5 returns for spacing =================\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fJJFoWhq4pgv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gold 3 — create yates_ancestor_register.htm (mobile-friendly, sortable)\n",
        "\n",
        "# ====== CUT START [A] REFACTOR-Gold 3 — Config + FTP + Constants + Rules =========================\n",
        "import os, re, json, time, io, posixpath, socket\n",
        "import pandas as pd\n",
        "from ftplib import FTP_TLS\n",
        "\n",
        "# ---------- Ron Rules ----------\n",
        "# - All edits are full-section replacements using explicit CUT START/STOP lines.\n",
        "# - Script is split into easily replaceable sections; provide code in python\n",
        "\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "# Column name defaults used across sections\n",
        "subject_code_col = \"Match to\"\n",
        "path_col = \"Yates DNA Ancestral Line\"\n",
        "LINEAGE_HEADER = \"Lineage (Starting with oldest ancestor, the line is:)\"  # used in table headings\n",
        "ARROW_ENTITY = \"&rarr;\"\n",
        "REMOVE_PERIOD_AT_END = True\n",
        "\n",
        "# Layout\n",
        "TABLE_WIDTH_PX = 3150\n",
        "COL_A_PX = 50  # width for \"Match Name\" column in HTML\n",
        "\n",
        "# Data / Output\n",
        "CSV_PATH = \"final_combined_df_with_value_labels.csv\"     # default input\n",
        "LOCAL_NAME = \"yates_ancestor_register.htm\"               # main page filename (local)\n",
        "REMOTE_NAME = \"yates_ancestor_register.htm\"              # remote filename (same name)\n",
        "\n",
        "# Local exports\n",
        "MATCH_COUSINS_CSV = \"the_match_cousins.csv\"  # Column A (what’s shown)\n",
        "\n",
        "# Remote I/O toggles (same creds/dir as HTML upload)\n",
        "REMOTE_READ = True      # Pull resolver CSV from server before processing\n",
        "UPLOAD_COLUMN_A = True  # Push the_match_cousins.csv to server after build\n",
        "\n",
        "# TNG link pieces for matchee hotlink (still used in some partials)\n",
        "TNG_BASE = \"https://yates.one-name.net/tng\"\n",
        "TNG_TREE = \"tree1\"\n",
        "\n",
        "# FTP settings (hard timeouts)\n",
        "FTP_DIR = os.environ.get(\"FTP_DIR\", \"\").strip()  # e.g., \"gengen\" or \"\"\n",
        "FTP_TIMEOUT = int(os.environ.get(\"FTP_TIMEOUT\", \"30\"))  # connect + socket timeout\n",
        "FTP_PASSIVE = True  # passive safest behind NAT\n",
        "\n",
        "# ---------- Autosomal Count (Colab → Website) ----------\n",
        "LOCAL_COUNT_FILE = \"/content/autosomal_count.txt\"  # produced in Colab\n",
        "REMOTE_COUNT_NAME = \"autosomal_count.txt\"          # destination on host\n",
        "COUNT_PUBLIC_URL = f\"/{FTP_DIR}/{REMOTE_COUNT_NAME}\" if FTP_DIR else f\"/{REMOTE_COUNT_NAME}\"\n",
        "\n",
        "# ---------- Resolver (single source: website) ----------\n",
        "SERVER_PARTIALS_DIR = \"partials\"\n",
        "SERVER_MAPPING_BASENAME = \"match_to_unmasked.csv\"\n",
        "SERVER_MAPPING_REMOTE = posixpath.join(SERVER_PARTIALS_DIR, SERVER_MAPPING_BASENAME)\n",
        "SERVER_MAPPING_LOCAL_CACHE = \"match_to_unmasked.server.csv\"  # temp file we download to\n",
        "\n",
        "# ---------- FTP helpers (with timeouts & cleanup) ----------\n",
        "def ftp_connect():\n",
        "    ftps = FTP_TLS(timeout=FTP_TIMEOUT)\n",
        "    socket.setdefaulttimeout(FTP_TIMEOUT)\n",
        "    ftps.connect(os.environ['FTP_HOST'], int(os.environ.get('FTP_PORT', 21)))\n",
        "    ftps.login(os.environ['FTP_USER'], os.environ['FTP_PASS'])\n",
        "    try:\n",
        "        ftps.prot_p()  # secure data channel if supported\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        ftps.set_pasv(FTP_PASSIVE)\n",
        "    except Exception:\n",
        "        pass\n",
        "    if FTP_DIR:\n",
        "        try:\n",
        "            ftps.cwd(FTP_DIR)\n",
        "        except Exception:\n",
        "            parts = [p for p in FTP_DIR.split(\"/\") if p]\n",
        "            for p in parts:\n",
        "                try:\n",
        "                    ftps.mkd(p)\n",
        "                except Exception:\n",
        "                    pass\n",
        "                ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "def _remote_path(name: str) -> str:\n",
        "    return posixpath.join(FTP_DIR, name) if FTP_DIR else name\n",
        "\n",
        "def ftp_download_if_exists(ftps: FTP_TLS, remote_name: str, local_name: str) -> bool:\n",
        "    try:\n",
        "        with open(local_name, \"wb\") as f:\n",
        "            ftps.retrbinary(f\"RETR \" + remote_name, f.write)\n",
        "        print(f\"⬇️ Pulled remote file: {remote_name} → {os.path.abspath(local_name)}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"ℹ️ Remote not found or unreadable: {remote_name} ({e})\")\n",
        "        try:\n",
        "            if os.path.exists(local_name):\n",
        "                os.remove(local_name)\n",
        "        except Exception:\n",
        "            pass\n",
        "        return False\n",
        "\n",
        "def ftp_upload_overwrite(ftps: FTP_TLS, local_path: str, remote_name: str):\n",
        "    try:\n",
        "        with open(local_path, \"rb\") as fh:\n",
        "            ftps.storbinary(f\"STOR {remote_name}\", fh)\n",
        "        print(f\"⬆️ Uploaded: {local_path} → {remote_name}\")\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Upload failed for {local_path} → {remote_name}: {e}\")\n",
        "# ====== CUT STOP [A] REFACTOR-Gold 3 — Config + FTP + Constants + Rules =========================\n",
        "\n",
        "\n",
        "# ====== CUT START [B] REFACTOR-Gold 3 — Resolver (server-only) + Name Helpers ===================\n",
        "import os, re, pandas as pd\n",
        "\n",
        "# ---------- Load resolver from WEBSITE only ----------\n",
        "def _read_mapping_csv(path: str) -> pd.DataFrame:\n",
        "    encs = (\"iso-8859-15\", \"utf-8-sig\", \"utf-8\", \"cp1252\", \"latin1\")\n",
        "    last = None\n",
        "    for enc in encs:\n",
        "        try:\n",
        "            df = pd.read_csv(path, encoding=enc, dtype=str, keep_default_na=False)\n",
        "            break\n",
        "        except Exception as e:\n",
        "            last = e\n",
        "            df = None\n",
        "    if df is None:\n",
        "        raise RuntimeError(f\"Unable to read mapping CSV {path}: {last}\")\n",
        "    if df.shape[1] < 2:\n",
        "        raise RuntimeError(\"Mapping CSV must have at least two columns: code, unmasked\")\n",
        "\n",
        "    df = df.iloc[:, :2].copy()\n",
        "    df.columns = [\"code\", \"unmasked\"]\n",
        "    df[\"code\"] = df[\"code\"].astype(str).str.strip().str.lower()\n",
        "    df[\"unmasked\"] = df[\"unmasked\"].astype(str).str.strip()\n",
        "    df = df[df[\"code\"] != \"\"].drop_duplicates(subset=[\"code\"], keep=\"first\")\n",
        "    if df.empty:\n",
        "        raise RuntimeError(\"Mapping CSV is empty after normalization.\")\n",
        "    return df\n",
        "\n",
        "def load_resolver_from_server() -> dict:\n",
        "    \"\"\"\n",
        "    Download /partials/match_to_unmasked.csv → local temp; fail if missing.\n",
        "    Relies on ftp_connect(), _remote_path(), and SERVER_* constants from [1/6].\n",
        "    \"\"\"\n",
        "    with ftp_connect() as ftps:\n",
        "        ok = ftp_download_if_exists(\n",
        "            ftps,\n",
        "            _remote_path(SERVER_MAPPING_REMOTE),\n",
        "            SERVER_MAPPING_LOCAL_CACHE\n",
        "        )\n",
        "        try:\n",
        "            ftps.quit()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    if not ok:\n",
        "        raise RuntimeError(\n",
        "            f\"Resolver not found on server: /{_remote_path(SERVER_MAPPING_REMOTE)}. \"\n",
        "            f\"Upload {SERVER_MAPPING_BASENAME} to /{SERVER_PARTIALS_DIR}/ and re-run.\"\n",
        "        )\n",
        "\n",
        "    df_map = _read_mapping_csv(SERVER_MAPPING_LOCAL_CACHE)\n",
        "    print(f\"✅ Loaded resolver from server: {len(df_map)} codes\")\n",
        "    return dict(zip(df_map[\"code\"], df_map[\"unmasked\"]))  # single source of truth\n",
        "\n",
        "# Global resolver dict\n",
        "MATCH_TO_UNMASKED = load_resolver_from_server()\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def find_col(df, patterns, prefer_exact=None):\n",
        "    \"\"\"Find a column by regex patterns, preferring exact names if present.\"\"\"\n",
        "    cols = list(df.columns)\n",
        "    lowmap = {c.lower(): c for c in cols}\n",
        "    if prefer_exact:\n",
        "        for name in prefer_exact:\n",
        "            if name in df.columns:\n",
        "                return name\n",
        "            if name and name.lower() in lowmap:\n",
        "                return lowmap[name.lower()]\n",
        "    for pat in patterns:\n",
        "        rx = re.compile(pat, re.I)\n",
        "        for c in cols:\n",
        "            if rx.search(c):\n",
        "                return c\n",
        "    return None\n",
        "\n",
        "# Split tokens for lineage path (handles →, &rarr;, arrows, commas, pipes, etc.)\n",
        "SEP_RE = re.compile(r\"\\s*(?:→|&rarr;|\\u2192|;|>|,|~{2,}|/{2,}|\\|{2,})\\s*\")\n",
        "def split_tokens(s):\n",
        "    if pd.isna(s): return []\n",
        "    if not isinstance(s, str): s = str(s)\n",
        "    return [p.strip() for p in SEP_RE.split(s) if str(p).strip()]\n",
        "\n",
        "def _clean_piece(text: str) -> str:\n",
        "    t = re.sub(r'~+', ' ', str(text))\n",
        "    t = re.sub(r'\\s+', ' ', t)\n",
        "    return t.strip()\n",
        "\n",
        "_PARTICLES = {\"de\",\"del\",\"della\",\"der\",\"van\",\"von\",\"da\",\"dos\",\"das\",\"di\",\"la\",\"le\",\"du\",\"of\"}\n",
        "\n",
        "def _smart_title(token: str) -> str:\n",
        "    if not token:\n",
        "        return token\n",
        "    token = re.sub(\n",
        "        r\"(^|\\b)([a-z])(['’])([a-z])\",\n",
        "        lambda m: m.group(1)+m.group(2).upper()+m.group(3)+m.group(4).upper(),\n",
        "        token.lower()\n",
        "    )\n",
        "    token = \"-\".join([w.capitalize() for w in token.split(\"-\")])\n",
        "    token = re.sub(r\"\\bmc([a-z])\",  lambda m: \"Mc\"+m.group(1).upper(),  token)\n",
        "    token = re.sub(r\"\\bmac([a-z])\", lambda m: \"Mac\"+m.group(1).upper(), token)\n",
        "    return token\n",
        "\n",
        "def smart_titlecase(name: str) -> str:\n",
        "    name = _clean_piece(name)\n",
        "    if not name:\n",
        "        return name\n",
        "    if \",\" in name:\n",
        "        last, first = [p.strip() for p in name.split(\",\", 1)]\n",
        "        pieces = (first + \" \" + last).split()\n",
        "    else:\n",
        "        pieces = name.split()\n",
        "    out = []\n",
        "    for i, w in enumerate(pieces):\n",
        "        out.append(w.lower() if (i>0 and w.lower() in _PARTICLES) else _smart_title(w))\n",
        "    return \" \".join(out)\n",
        "\n",
        "def surname_given_from_token(token):\n",
        "    token = token.strip()\n",
        "    if not token:\n",
        "        return (token,)\n",
        "    idx = None\n",
        "    for i in range(1, len(token)):\n",
        "        if token[i-1].islower() and token[i].isupper():\n",
        "            idx = i; break\n",
        "    if idx is None:\n",
        "        for i in range(1, len(token)):\n",
        "            if token[i].isupper():\n",
        "                idx = i; break\n",
        "    if idx is None:\n",
        "        return (token,)\n",
        "    surname = token[:idx]; given = token[idx:]\n",
        "    given_spaced = re.sub(r'(?<!^)([A-Z])', r' \\1', given)\n",
        "    return (f\"{given_spaced.strip()} {surname.strip()}\",)\n",
        "\n",
        "def normalize_person_name(s: str) -> str:\n",
        "    if pd.isna(s): return \"\"\n",
        "    s = _clean_piece(str(s))\n",
        "    if \",\" in s:\n",
        "        last, first = [p.strip() for p in s.split(\",\", 1)]\n",
        "        s = f\"{first} {last}\"\n",
        "    if \" \" not in s and s.isalpha():\n",
        "        return smart_titlecase(surname_given_from_token(s)[0])\n",
        "    return smart_titlecase(s)\n",
        "\n",
        "def truncate_first(name: str, n: int = 4) -> str:\n",
        "    name = name.strip()\n",
        "    if not name: return name\n",
        "    parts = name.split()\n",
        "    return parts[0][:n] if len(parts) == 1 else f\"{parts[0][:n]} {parts[-1]}\"\n",
        "\n",
        "def derive_common_from_first_token(tokens):\n",
        "    if not tokens:\n",
        "        return (\"\", \"\")\n",
        "    first = _clean_piece(tokens[0])\n",
        "    parts = re.split(r\"\\s*(?:&| and )\\s*\", first, maxsplit=1, flags=re.I)\n",
        "    if len(parts) != 2:\n",
        "        return (\"\", \"\")\n",
        "    def _norm(s):\n",
        "        return smart_titlecase(s) if \" \" in s else smart_titlecase(surname_given_from_token(s)[0])\n",
        "    return (_norm(parts[0]), _norm(parts[1]))\n",
        "\n",
        "def degree_label_from_generations(g):\n",
        "    if g <= 1:\n",
        "        return \"parents\" if g == 1 else \"self\"\n",
        "    if g == 2:\n",
        "        return \"grandparents\"\n",
        "    greats = g - 2\n",
        "    if greats == 1:\n",
        "        return \"great-grandparents\"\n",
        "    return f\"{greats}\\u00d7-great-grandparents\"\n",
        "\n",
        "def resolve_match_to(code: str) -> str:\n",
        "    if not isinstance(code, str): return \"\"\n",
        "    return MATCH_TO_UNMASKED.get(str(code).strip().lower(), str(code))\n",
        "\n",
        "# For converting single-token like RosenbalmJessica → \"Jessica Rosenbalm\"\n",
        "_CAMEL_WORDS = re.compile(r\"[A-Z][a-z]*|[A-Z]+(?![a-z])|[a-z]+\")\n",
        "def _truncate_alpha(s: str, n: int) -> str:\n",
        "    return re.sub(r\"[^A-Za-z]\", \"\", s)[:n]\n",
        "\n",
        "def norm_matchee_name(raw: str) -> str:\n",
        "    raw = str(raw or \"\").strip()\n",
        "    if not raw:\n",
        "        return \"\"\n",
        "    if \" \" in raw or \",\" in raw:\n",
        "        nm = smart_titlecase(raw)\n",
        "        parts = nm.split()\n",
        "        if len(parts) == 1:\n",
        "            return nm\n",
        "        given = parts[0]\n",
        "        surname = parts[-1]\n",
        "        return f\"{_truncate_alpha(given, 7)} {surname}\".strip()\n",
        "    words = _CAMEL_WORDS.findall(raw)\n",
        "    while words and len(words[0]) == 1:\n",
        "        words.pop(0)\n",
        "    if not words:\n",
        "        nm = smart_titlecase(surname_given_from_token(raw)[0])\n",
        "        ps = nm.split()\n",
        "        if len(ps) == 1:\n",
        "            return nm\n",
        "        return f\"{_truncate_alpha(ps[0], 7)} {ps[-1]}\".strip()\n",
        "    surname = smart_titlecase(words[0])\n",
        "    given_candidates = [w for w in words[1:] if w.lower() != surname.lower()]\n",
        "    if not given_candidates:\n",
        "        return surname\n",
        "    given = smart_titlecase(given_candidates[0])\n",
        "    return f\"{_truncate_alpha(given, 7)} {surname}\".strip()\n",
        "\n",
        "def extract_person_id(s: str) -> str:\n",
        "    m = re.search(r\"\\bI\\d+\\b\", str(s or \"\"), re.I)\n",
        "    return m.group(0).upper() if m else \"\"\n",
        "# ====== CUT STOP [B] REFACTOR-Gold 3 — Resolver (server-only) + Name Helpers ===================\n",
        "\n",
        "\n",
        "# ====== CUT START [C] REFACTOR-Gold 3 — CSV Load + Column Detection + Row Helpers ================\n",
        "import os, re, pandas as pd, urllib.parse as _u\n",
        "\n",
        "# Use the path defined in [1/6]; default to the expected file\n",
        "CSV_IN = os.environ.get(\"CSV_IN\", CSV_PATH if 'CSV_PATH' in globals() else \"/content/final_combined_df_with_value_labels.csv\")\n",
        "\n",
        "# ---- Load CSV (robust encodings) ----\n",
        "_encs = (\"utf-8-sig\", \"utf-8\", \"cp1252\", \"iso-8859-15\", \"latin1\")\n",
        "_last_err = None\n",
        "df = None\n",
        "for _e in _encs:\n",
        "    try:\n",
        "        df = pd.read_csv(CSV_IN, encoding=_e, dtype=str, keep_default_na=False)\n",
        "        break\n",
        "    except Exception as _ex:\n",
        "        _last_err = _ex\n",
        "        df = None\n",
        "if df is None:\n",
        "    raise RuntimeError(f\"Unable to read CSV: {CSV_IN} ({_last_err})\")\n",
        "print(f\"✅ Loaded CSV — {len(df)} rows, {len(df.columns)} columns from {os.path.abspath(CSV_IN)}\")\n",
        "\n",
        "# ---- Locate columns (names vary slightly across exports) ----\n",
        "# relies on find_col() from [2/6]\n",
        "id_col        = find_col(df, [r'^(id#|personid)$'], [\"ID#\", \"ID\", \"PersonID\", \"personID\"])\n",
        "match_to_col  = find_col(df, [r'^match\\s*to$'], [\"Match to\",\"Match\"])\n",
        "name_col      = find_col(df, [r'^name$'], [\"Name\"])\n",
        "cm_col        = find_col(df, [r'^(c\\s*:?m|cm)$', r'centi.?morgan'], [\"cM\",\"cm\"])\n",
        "path_col      = find_col(df, [r'(yates\\s*dna\\s*ancestral\\s*line|ancestral\\s*line|lineage)'],\n",
        "                         [\"Yates DNA Ancestral Line\",\"Ancestral Line\",\"Lineage\"])\n",
        "\n",
        "if not id_col:       raise ValueError(\"CSV missing an ID#/PersonID column.\")\n",
        "if not match_to_col: raise ValueError(\"CSV missing 'Match to' column.\")\n",
        "if not name_col:     raise ValueError(\"CSV missing 'Name' column.\")\n",
        "if not cm_col:       raise ValueError(\"CSV missing 'cM' column.\")\n",
        "if not path_col:     raise ValueError(\"CSV missing lineage/path column.\")\n",
        "\n",
        "print(\"✅ Columns:\", {\"ID\": id_col, \"Match to\": match_to_col, \"Name\": name_col, \"cM\": cm_col, \"Lineage\": path_col})\n",
        "# ====== CUT STOP [C] REFACTOR-Gold 3 — CSV Load + Column Detection + Row Helpers ================\n",
        "\n",
        "\n",
        "# ====== CUT START [D] REFACTOR-Gold 3 — Transform & Column A (build display_df) ==================\n",
        "import urllib.parse as _u\n",
        "\n",
        "# ---------- Build the three display columns ----------\n",
        "match_names = []\n",
        "lineages    = []\n",
        "findcol     = []\n",
        "\n",
        "# Allow absolute link to this page: /{REMOTE_NAME}?q=...\n",
        "REMOTE_NAME_ABS = \"/\" + (REMOTE_NAME if 'REMOTE_NAME' in globals() else \"yates_ancestor_register.htm\")\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    # Subject: resolver code in \"Match to\" → unmasked subject name (used for Find link)\n",
        "    subject_raw  = row.get(match_to_col, \"\")\n",
        "    subject_name = normalize_person_name(resolve_match_to(subject_raw))\n",
        "\n",
        "    # Matchee: normalized name ONLY (no sentence)\n",
        "    pid = extract_person_id(row.get(id_col, \"\"))\n",
        "    matchee_name = norm_matchee_name(row.get(name_col, \"\")) or subject_name\n",
        "\n",
        "    # Lineage path (tokens oldest→youngest); first token is common couple\n",
        "    tokens      = split_tokens(row.get(path_col, \"\"))\n",
        "    tokens_disp = tokens[:7]  # show first 7 pairs\n",
        "    if tokens_disp:\n",
        "        tokens_disp[0] = f\"<strong>{tokens_disp[0]}</strong>\"\n",
        "    sep = f\" {ARROW_ENTITY} \"\n",
        "    lineage_text = sep.join(tokens_disp) if tokens_disp else \"\"\n",
        "\n",
        "    # Per-row quick-open search button (?q=Subject Name)\n",
        "    q = _u.quote(subject_name)\n",
        "    quick = (f'<a class=\"find-btn\" href=\"{REMOTE_NAME_ABS}?q={q}\" target=\"_blank\" rel=\"noopener\" '\n",
        "             f'title=\"Open a filtered view for {subject_name}\">Find</a>')\n",
        "\n",
        "    match_names.append(matchee_name)\n",
        "    lineages.append(lineage_text)\n",
        "    findcol.append(quick)\n",
        "\n",
        "# Column names\n",
        "MATCH_NAME_COL = \"Match Name\"\n",
        "LINEAGE_HEADER_SAFE = LINEAGE_HEADER if 'LINEAGE_HEADER' in globals() else \"Lineage (Starting with oldest ancestor, the line is:)\"\n",
        "\n",
        "# Assemble the display dataframe (GUARDED so “Find” always exists)\n",
        "df[MATCH_NAME_COL]              = match_names\n",
        "df[LINEAGE_HEADER_SAFE]         = lineages\n",
        "df[\"Find\"]                      = findcol  # guarantees presence for [5/6]\n",
        "display_df = df[[\"Find\", MATCH_NAME_COL, LINEAGE_HEADER_SAFE]]\n",
        "\n",
        "# Column A CSV for side-uses (now just the match names)\n",
        "display_df[[MATCH_NAME_COL]].to_csv(MATCH_COUSINS_CSV, index=False, encoding=\"iso-8859-15\")\n",
        "print(\"✅ Wrote local CSV (Column A):\", os.path.abspath(MATCH_COUSINS_CSV))\n",
        "# ====== CUT STOP [D] REFACTOR-Gold 3 — Transform & Column A (build display_df) ==================\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "# ====== CUT START [E] REFACTOR-Gold 3 — HTML (table + CSS + JS, no uploads) ======================\n",
        "import html as _html\n",
        "\n",
        "# Use this as the Home link everywhere\n",
        "HOME_URL = \"https://yates.one-name.net/yates_ancestor_register.htm\"\n",
        "\n",
        "# Make the “Match To Name” column narrower (tweak as needed)\n",
        "COL_A_PX = 160\n",
        "\n",
        "# ---------- Build/attach the “Match To Name” column (resolver-based) ----------\n",
        "# Assumes df, display_df, match_to_col, resolve_match_to(), normalize_person_name() exist from prior sections.\n",
        "_match_to_names = []\n",
        "for _, _row in df.iterrows():\n",
        "    _raw = _row.get(match_to_col, \"\")\n",
        "    _nm  = normalize_person_name(resolve_match_to(_raw))\n",
        "    _match_to_names.append(_nm)\n",
        "\n",
        "# Important: persist the new column on display_df so later sections (partials/print) can use it.\n",
        "display_df = display_df.copy()\n",
        "display_df[\"Match To Name\"] = _match_to_names\n",
        "\n",
        "# ---------- Build HTML table ----------\n",
        "LINEAGE_HEADER_SAFE = LINEAGE_HEADER if 'LINEAGE_HEADER' in globals() else \"Lineage (Starting with oldest ancestor, the line is:)\"\n",
        "display_for_html = display_df\n",
        "\n",
        "html_table = display_for_html[[\"Find\", \"Match To Name\", LINEAGE_HEADER_SAFE]].to_html(\n",
        "    index=False, escape=False, classes=\"sortable\"\n",
        ")\n",
        "\n",
        "# tag table + first row\n",
        "html_table = html_table.replace(\n",
        "    '<table border=\"1\" class=\"dataframe sortable\">',\n",
        "    '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">', 1\n",
        ")\n",
        "html_table = html_table.replace('<tbody>\\n<tr>', '<tbody>\\n<tr id=\"first-row\">', 1)\n",
        "\n",
        "# widths via <colgroup>\n",
        "FIND_PX = 110  # width of Find column (checkbox + Email + Find)\n",
        "colgroup_html = (\n",
        "    \"<colgroup>\\n\"\n",
        "    f\"  <col style=\\\"width:{FIND_PX}px;\\\" />\\n\"\n",
        "    f\"  <col style=\\\"width:{COL_A_PX}px;\\\" />\\n\"\n",
        "    \"  <col />\\n\"\n",
        "    \"</colgroup>\\n\"\n",
        ")\n",
        "html_table = html_table.replace(\n",
        "    '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">',\n",
        "    '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">\\n' + colgroup_html, 1\n",
        ")\n",
        "\n",
        "# add Select-all checkbox to header cell “Find”\n",
        "html_table = html_table.replace(\n",
        "    \"<th>Find</th>\",\n",
        "    \"<th>Find&nbsp;<input type=\\\"checkbox\\\" id=\\\"sel-all\\\" title=\\\"Select all visible\\\" /></th>\",\n",
        "    1\n",
        ")\n",
        "\n",
        "html_table_scrolling = '<div class=\"table-scroll\">\\n' + html_table + '\\n</div>'\n",
        "\n",
        "# ---------- CSS ----------\n",
        "TABLE_CSS = (\n",
        "    \"<style type=\\\"text/css\\\">\\n\"\n",
        "    \"  html { scroll-behavior: smooth; }\\n\"\n",
        "    \"  body { font-family: Georgia, 'Times New Roman', serif; background:#ffffff; color:#222; margin:0; padding:0; line-height:1.5; }\\n\"\n",
        "    f\"  .wrap {{ max-width:{TABLE_WIDTH_PX}px; margin:0 auto; background:#ffffff; padding:20px; padding-bottom:48px; }}\\n\"\n",
        "    \"  a { color:#154b8b; text-decoration:none; } a:hover { text-decoration:underline; }\\n\"\n",
        "    \"  h1 { margin:0 0 6px 0; font-size:26px; line-height:1.2; text-align:center; }\\n\"\n",
        "    \"  .updated { font-size:12px; color:#555; text-align:center; margin:2px 0 10px 0; }\\n\"\n",
        "    \"  .sortbar { margin:6px 0 10px 0; font-size:13px; background:#ffffff; padding:6px 8px; border-radius:6px;\\n\"\n",
        "    \"             display:flex; flex-wrap:wrap; gap:5px; align-items:center; border:1px solid #ddd; }\\n\"\n",
        "    \"  .btn { display:inline-block; border:1px solid #5b79b8; background:#5b79b8; color:#fff; padding:4px 9px;\\n\"\n",
        "    \"         text-decoration:none; cursor:pointer; border-radius:5px; line-height:1.2; transition:background 0.2s, transform 0.1s; user-select:none; }\\n\"\n",
        "    \"  .btn:hover { background:#4668aa; transform:translateY(-1px); }\\n\"\n",
        "    \"  input.btn.search { background:#fff; color:#111; border-color:#bbb; }\\n\"\n",
        "    \"  .btn-mini { font-size:12px; padding:2px 6px; line-height:1.1; margin-left:6px; }\\n\"\n",
        "    \"  .find-cell { white-space:nowrap; }\\n\"\n",
        "    \"  .selbox { margin-right:6px; vertical-align:middle; }\\n\"\n",
        "    \"  .table-scroll { max-height:70vh; overflow-y:auto; overflow-x:auto; border:1px solid #ddd; }\\n\"\n",
        "    f\"  table.sortable {{ border-collapse:collapse; width:{TABLE_WIDTH_PX}px; table-layout:fixed; }}\\n\"\n",
        "    \"  table.sortable th, table.sortable td { border:1px solid #ddd; padding:6px 8px; vertical-align:top; }\\n\"\n",
        "    \"  table.sortable th { background:#e3eaf8; text-align:left; position:sticky; top:0; z-index:2; box-shadow:0 1px 0 #ccc; }\\n\"\n",
        "    \"  table.sortable td { word-wrap:break-word; overflow-wrap:break-word; }\\n\"\n",
        "    \"  #first-row td { border-top:2px solid #999; }\\n\"\n",
        "    \"  .back-to-top { position:fixed; right:16px; bottom:16px; padding:6px 10px; border:1px solid #3e5a97; background:#5b79b8; color:#fff;\\n\"\n",
        "    \"                 cursor:pointer; border-radius:6px; font-size:12px; display:none; z-index:9999; }\\n\"\n",
        "    \"  .back-to-top:hover { background:#4668aa; }\\n\"\n",
        "    \"  #dynamicContent { margin:10px 0 14px 0; }\\n\"\n",
        "    \"  @media screen and (max-width: 820px) { .wrap { padding:12px; } h1 { font-size:22px; } }\\n\"\n",
        "    \"</style>\\n\"\n",
        ")\n",
        "\n",
        "# ---------- Toolbar ----------\n",
        "DYNAMIC_BLOCK = (\n",
        "    \"<div class=\\\"sortbar\\\">\\n\"\n",
        "    \"  <a class=\\\"btn\\\" href=\\\"https://yates.one-name.net/gengen/dna_cousin_surname_study.htm\\\" target=\\\"_blank\\\">Study Details</a>\\n\"\n",
        "    \"  <a class=\\\"btn\\\" href=\\\"https://yates.one-name.net/gengen/dna_theory_of_the_case.htm\\\" target=\\\"_blank\\\">Theory in Action</a>\\n\"\n",
        "    \"  <span class=\\\"btn\\\" data-sort-col=\\\"1\\\" data-sort-dir=\\\"asc\\\">Sort Match &uarr;</span>\\n\"\n",
        "    \"  <span class=\\\"btn\\\" data-sort-col=\\\"1\\\" data-sort-dir=\\\"desc\\\">Sort Match &darr;</span>\\n\"\n",
        "    \"  <span class=\\\"btn\\\" data-sort-col=\\\"2\\\" data-sort-dir=\\\"asc\\\">Sort Lineage &uarr;</span>\\n\"\n",
        "    \"  <span class=\\\"btn\\\" data-sort-col=\\\"2\\\" data-sort-dir=\\\"desc\\\">Sort Lineage &darr;</span>\\n\"\n",
        "    \"  <a class=\\\"btn\\\" href=\\\"gengen/images/cousin-calculator.jpg\\\" target=\\\"_blank\\\">Cousin Connection</a>\\n\"\n",
        "    \"  <a class=\\\"btn\\\" href=\\\"gengen/images/Shared_cM_Project_v4.jpg\\\" target=\\\"_blank\\\">Cousin by DNA</a>\\n\"\n",
        "    \"  <a class=\\\"btn\\\" href=\\\"partials/match_count.htm\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">Match Count</a>\\n\"\n",
        "    \"  <a class=\\\"btn\\\" href=\\\"partials/lineage_count.htm\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">Lineage Count</a>\\n\"\n",
        "    \"  <a class=\\\"btn\\\" href=\\\"/partials/cousin_list_print.htm\\\" target=\\\"_blank\\\">Cousin List</a>\\n\"\n",
        "    \"  <span class=\\\"btn\\\" id=\\\"email-selected\\\">Email Selected</span>\\n\"\n",
        "    \"  <span class=\\\"btn\\\" id=\\\"clear-selected\\\">Clear</span>\\n\"\n",
        "    \"  <input type=\\\"text\\\" id=\\\"search-box\\\" class=\\\"btn search\\\" size=\\\"24\\\" value=\\\"\\\" placeholder=\\\"Search&hellip;\\\" \"\n",
        "    \"         autocomplete=\\\"off\\\" autocapitalize=\\\"off\\\" spellcheck=\\\"false\\\" inputmode=\\\"search\\\" enterkeyhint=\\\"search\\\" />\\n\"\n",
        "    \"</div>\\n\"\n",
        "    \"<div id=\\\"dynamicContent\\\"></div>\\n\"\n",
        ")\n",
        "\n",
        "# ---------- Full HTML (string only) ----------\n",
        "JS_COUNT_URL = COUNT_PUBLIC_URL.replace(\"'\", \"%27\")\n",
        "\n",
        "UPDATED_BLOCK = (\n",
        "    \"<div class=\\\"updated\\\">\"\n",
        "    f\"<a href=\\\"{HOME_URL}\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">Home</a>\"\n",
        "    \" &nbsp;|&nbsp; Last updated: <span id=\\\"last-updated\\\"></span>\"\n",
        "    \" &nbsp;|&nbsp; Autosomal matches: <span id=\\\"auto-count\\\" class=\\\"js-count\\\"></span>\"\n",
        "    \"</div>\"\n",
        ")\n",
        "\n",
        "TEMPLATE_HTML = \"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "<title>ONS Yates Study Ancestor Register</title>\n",
        "{TABLE_CSS}\n",
        "</head>\n",
        "<body id=\"top\">\n",
        "<div class=\"wrap\">\n",
        "  <h1>ONS Yates Study Ancestor Register</h1>\n",
        "  {UPDATED_BLOCK}\n",
        "  {DYNAMIC_BLOCK}\n",
        "{HTML_TABLE_SCROLLING}\n",
        "</div>\n",
        "<button id=\"back-to-top\" class=\"back-to-top\">&#9650; Top</button>\n",
        "<script type=\"text/javascript\">\n",
        "//<![CDATA[\n",
        "(function(){\n",
        "  function textOf(cell){ return (cell && (cell.textContent || cell.innerText) || '').replace(/\\\\s+/g,' ').trim().toLowerCase(); }\n",
        "  function sortTable(tbl, colIndex, dir){\n",
        "    var tb=tbl && tbl.tBodies ? tbl.tBodies[0] : null; if(!tb) return;\n",
        "    var rows=[].slice.call(tb.rows||[]);\n",
        "    var asc=(dir==='asc');\n",
        "    rows.sort(function(a,b){\n",
        "      var A=textOf(a.cells[colIndex]), B=textOf(b.cells[colIndex]);\n",
        "      if(A<B) return asc?-1:1; if(A>B) return asc?1:-1; return 0;\n",
        "    });\n",
        "    var frag=document.createDocumentFragment();\n",
        "    for(var i=0;i<rows.length;i++) frag.appendChild(rows[i]);\n",
        "    tb.appendChild(frag);\n",
        "    updateSelAll(); // keep master checkbox in sync after sort\n",
        "  }\n",
        "  function bindSortButtons(){\n",
        "    var tbl=document.getElementById('refactor-table'); var bar=document.querySelector('.sortbar'); if(!(tbl && bar)) return;\n",
        "    bar.addEventListener('click',function(e){\n",
        "      var btn=e.target && e.target.closest ? e.target.closest('.btn') : null; if(!btn) return;\n",
        "      var colAttr=btn.getAttribute('data-sort-col'); if(colAttr==null) return; var col=parseInt(colAttr,10); if(isNaN(col)) return;\n",
        "      var dir=btn.getAttribute('data-sort-dir')||'asc'; sortTable(tbl,col,dir); e.preventDefault(); return false;\n",
        "    },false);\n",
        "  }\n",
        "  function bindHeaderSort(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tHead && tbl.tHead.rows.length)) return; var ths=tbl.tHead.rows[0].cells;\n",
        "    for(var i=0;i<ths.length;i++)(function(idx){\n",
        "      var dir='asc'; ths[idx].addEventListener('click',function(){ dir=(dir==='asc')?'desc':'asc'; sortTable(tbl,idx,dir); },false);\n",
        "    })(i);\n",
        "  }\n",
        "\n",
        "  // partials\n",
        "  var PARTIAL_BASES=['/partials/','partials/','gengen/partials/','/gengen/partials/'];\n",
        "  function tryFetchSequential(urls,onOK,onFail){\n",
        "    if(!urls.length) return onFail('No valid locations'); var url=urls.shift();\n",
        "    fetch(url,{cache:'no-store'}).then(function(r){ if(!r.ok) throw new Error('HTTP '+r.status); return r.text();})\n",
        "      .then(onOK).catch(function(){ tryFetchSequential(urls,onOK,onFail);});\n",
        "  }\n",
        "  function bindPartials(){\n",
        "    var bar=document.querySelector('.sortbar'); if(!bar) return;\n",
        "    bar.addEventListener('click',function(e){\n",
        "      var btn=e.target && e.target.closest ? e.target.closest('.btn') : null; if(!btn) return;\n",
        "      var rel=btn.getAttribute('data-load-partial'); if(!rel) return;\n",
        "      var c=document.getElementById('dynamicContent'); if(!c) return; c.innerHTML='<p><em>Loading latest data&hellip;</em></p>';\n",
        "      var bust=encodeURIComponent(document.lastModified||(new Date()).toUTCString());\n",
        "      var bases=PARTIAL_BASES.slice(); var candidates=bases.map(function(b){return b+rel+'?v='+bust;});\n",
        "      tryFetchSequential(candidates.slice(), function(html){ c.innerHTML=html; }, function(){ c.innerHTML='<p style=\\\\\\\"color:#a00;\\\\\\\">Could not load content.</p>'; });\n",
        "    });\n",
        "  }\n",
        "\n",
        "  // updated stamp + count\n",
        "  function stampLastUpdated(){\n",
        "    var el=document.getElementById('last-updated'); if(!el) return;\n",
        "    var d=new Date(document.lastModified||new Date());\n",
        "    function z(n){return(n<10?'0':'')+n;}\n",
        "    el.innerHTML=d.getFullYear()+'-'+z(d.getMonth()+1)+'-'+z(d.getDate())+' '+z(d.getHours())+':'+z(d.getMinutes());\n",
        "  }\n",
        "  function formatWithCommas(n){\n",
        "    try{ var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return ''; return x.toLocaleString('en-US'); }catch(e){ return String(n||''); }\n",
        "  }\n",
        "  function loadAutoCount(){\n",
        "    var el=document.getElementById('auto-count'); if(!el) return;\n",
        "    var url='{COUNT_URL}';\n",
        "    try{\n",
        "      var xhr=new XMLHttpRequest(); xhr.open('GET', url+(url.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true);\n",
        "      xhr.onreadystatechange=function(){ if(xhr.readyState===4){ if(xhr.status>=200&&xhr.status<300){\n",
        "        var m=(xhr.responseText||'').match(/(\\\\d+)/); var num=m?m[1]:'';\n",
        "        el.textContent = formatWithCommas(num) || '(unavailable)';\n",
        "      } else { el.textContent='(unavailable)'; } } };\n",
        "      xhr.send(null);\n",
        "    }catch(e){ el.textContent='(unavailable)'; }\n",
        "  }\n",
        "\n",
        "  // search (filters rows; select-all respects visibility)\n",
        "  function getParam(name){ var m=location.search.match(new RegExp('[?&]'+name+'=([^&]+)')); return m?decodeURIComponent(m[1].replace(/\\\\+/g,' ')):''; }\n",
        "  function bindSearch(){\n",
        "    var box=document.getElementById('search-box'); var tbl=document.getElementById('refactor-table'); if(!(box && tbl && tbl.tBodies && tbl.tBodies[0])) return; var tb=tbl.tBodies[0];\n",
        "    function norm(s){ return String(s||'').replace(/\\\\s+/g,' ').toLowerCase(); }\n",
        "    function rowText(tr){ var t=''; for(var i=0;i<tr.cells.length;i++){ t+= ' ' + (tr.cells[i].textContent||tr.cells[i].innerText||''); } return norm(t); }\n",
        "    var cached=[]; (function seed(){ var rows=tb.rows; cached=[]; for(var i=0;i<rows.length;i++){ cached.push({el:rows[i], txt:rowText(rows[i])}); } })();\n",
        "    function apply(q){\n",
        "      q=norm(q);\n",
        "      for(var i=0;i<cached.length;i++){\n",
        "        var hit = !q || cached[i].txt.indexOf(q)>-1;\n",
        "        cached[i].el.style.display = hit? '' : 'none';\n",
        "      }\n",
        "      updateSelAll();\n",
        "    }\n",
        "    var to=null; function onInput(){ if(to) clearTimeout(to); to=setTimeout(function(){ apply(box.value); }, 60); }\n",
        "    box.addEventListener('input', onInput, false);\n",
        "    var q0=getParam('q');\n",
        "    if(q0){ box.value=q0; apply(q0); try{ history.replaceState(null, '', location.pathname); }catch(e){} }\n",
        "    else { box.value=''; apply(''); setTimeout(function(){ if(!getParam('q')){ box.value=''; apply(''); } }, 0); }\n",
        "  }\n",
        "\n",
        "  // --- selection controls ---\n",
        "  function visibleRowCheckboxes(){\n",
        "    var tbl=document.getElementById('refactor-table');\n",
        "    if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return [];\n",
        "    var tb=tbl.tBodies[0], out=[];\n",
        "    for(var i=0;i<tb.rows.length;i++){\n",
        "      var tr=tb.rows[i];\n",
        "      if(tr.style.display==='none') continue;\n",
        "      var cb = tr.cells[0] && tr.cells[0].querySelector('.selbox');\n",
        "      if(cb) out.push(cb);\n",
        "    }\n",
        "    return out;\n",
        "  }\n",
        "  function updateSelAll(){\n",
        "    var master=document.getElementById('sel-all'); if(!master) return;\n",
        "    var cbs=visibleRowCheckboxes();\n",
        "    if(!cbs.length){ master.indeterminate=false; master.checked=false; return; }\n",
        "    var checked=cbs.filter(function(cb){ return cb.checked; }).length;\n",
        "    master.checked = (checked===cbs.length);\n",
        "    master.indeterminate = (checked>0 && checked<cbs.length);\n",
        "  }\n",
        "  function bindSelectAll(){\n",
        "    var master=document.getElementById('sel-all'); if(!master) return;\n",
        "    master.addEventListener('change', function(){\n",
        "      var want=master.checked;\n",
        "      var cbs=visibleRowCheckboxes();\n",
        "      for(var i=0;i<cbs.length;i++) cbs[i].checked = want;\n",
        "      updateSelAll();\n",
        "    });\n",
        "  }\n",
        "  function pageBase(){ try{ return location.origin + location.pathname; }catch(e){ return location.pathname; } }\n",
        "  function encodeQS(s){ return encodeURIComponent(String(s||'')); }\n",
        "  function buildRowEmail(tr){\n",
        "    var cells = tr.cells; if(!cells || cells.length < 3) return null;\n",
        "    var summary = (cells[1].textContent||'').trim();\n",
        "    var lineage = (cells[2].textContent||'').trim();\n",
        "    var subj = 'ONS Yates Register: ' + summary.substring(0, 90);\n",
        "    var qMatch = (function(){ try{ var em = cells[1].querySelector('strong'); return (em?em.textContent:'').trim(); }catch(e){ return ''; } })();\n",
        "    var link = pageBase() + (qMatch? ('?q='+encodeQS(qMatch)) : '');\n",
        "    var body = summary + '\\\\n\\\\nLineage:\\\\n' + lineage + '\\\\n\\\\nLink: ' + link;\n",
        "    return {subject: subj, body: body};\n",
        "  }\n",
        "  function openMailto(subject, body){\n",
        "    var href = 'mailto:?subject=' + encodeQS(subject) + '&body=' + encodeQS(body);\n",
        "    window.location.href = href;\n",
        "  }\n",
        "  function injectRowControls(){\n",
        "    var tbl = document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return; var tb = tbl.tBodies[0];\n",
        "    for(var i=0;i<tb.rows.length;i++){\n",
        "      (function(tr){\n",
        "        var cell = tr.cells[0]; if(!cell) return; if(cell.className.indexOf('find-cell')===-1) cell.className += ' find-cell';\n",
        "        var existingFind = cell.querySelector('a.find-btn'); // preserve your “Find” link\n",
        "        var cb = document.createElement('input'); cb.type='checkbox'; cb.className='selbox'; cb.title='Select row';\n",
        "        cb.addEventListener('change', updateSelAll);\n",
        "        cell.insertBefore(cb, existingFind || cell.firstChild);\n",
        "        // optional per-row Email button\n",
        "        var emailBtn = document.createElement('a'); emailBtn.href='#'; emailBtn.className='btn btn-mini'; emailBtn.textContent='Email'; emailBtn.title='Email this row'; emailBtn.style.marginLeft='6px';\n",
        "        emailBtn.addEventListener('click', function(ev){ ev.preventDefault(); var payload = buildRowEmail(tr); if(payload){ openMailto(payload.subject, payload.body); } });\n",
        "        if(existingFind){ existingFind.insertAdjacentElement('afterend', emailBtn); } else { cell.appendChild(emailBtn); }\n",
        "      })(tb.rows[i]);\n",
        "    }\n",
        "  }\n",
        "  function bindBulkEmail(){\n",
        "    var btn = document.getElementById('email-selected'); if(!btn) return;\n",
        "    btn.addEventListener('click', function(){\n",
        "      var tbl = document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return; var tb = tbl.tBodies[0];\n",
        "      var parts = []; var count = 0;\n",
        "      for(var i=0;i<tb.rows.length;i++){\n",
        "        var tr = tb.rows[i]; if(tr.style.display==='none') continue;\n",
        "        var cb = tr.cells[0] && tr.cells[0].querySelector('.selbox');\n",
        "        if(cb && cb.checked){ var p = buildRowEmail(tr); if(p){ parts.push(p.body); count++; } }\n",
        "      }\n",
        "      if(!count){ alert('No rows selected. Tick the checkboxes in the Find column.'); return; }\n",
        "      var subject = 'ONS Yates Register: ' + count + ' selection' + (count>1?'s':'');\n",
        "      var body = parts.join('\\\\n\\\\n---\\\\n\\\\n');\n",
        "      openMailto(subject, body);\n",
        "    });\n",
        "    var clr = document.getElementById('clear-selected'); if(clr){ clr.addEventListener('click', function(){\n",
        "      var tbl = document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return; var tb = tbl.tBodies[0];\n",
        "      for(var i=0;i<tb.rows.length;i++){ var cb = tb.rows[i].cells[0] && tb.rows[i].querySelector('.selbox'); if(cb) cb.checked=false; }\n",
        "      updateSelAll();\n",
        "    }); }\n",
        "  }\n",
        "\n",
        "  // misc UI\n",
        "  function setupBackToTop(){\n",
        "    var btt=document.getElementById('back-to-top'); var cont=document.querySelector('.table-scroll');\n",
        "    function onAny(){ var y=(window.scrollY||window.pageYOffset||0); var cy=cont?cont.scrollTop:0; btt.style.display=(y>200||cy>200)?'block':'none'; }\n",
        "    window.addEventListener('scroll',onAny,{passive:true}); if(cont) cont.addEventListener('scroll',onAny,{passive:true});\n",
        "    onAny(); if(btt){ btt.addEventListener('click',function(){ if(cont) cont.scrollTo({top:0,behavior:'smooth'}); window.scrollTo({top:0,behavior:'smooth'}); }); }\n",
        "  }\n",
        "\n",
        "  // init\n",
        "  function init(){\n",
        "    bindSortButtons(); bindHeaderSort(); bindPartials(); stampLastUpdated(); loadAutoCount();\n",
        "    setupBackToTop(); bindSearch();\n",
        "    injectRowControls(); bindSelectAll(); bindBulkEmail(); updateSelAll();\n",
        "  }\n",
        "  init();\n",
        "})();\n",
        "//]]>\n",
        "</script>\n",
        "</body></html>\n",
        "\"\"\"\n",
        "\n",
        "FULL_HTML = (TEMPLATE_HTML\n",
        "    .replace(\"{TABLE_CSS}\", TABLE_CSS)\n",
        "    .replace(\"{UPDATED_BLOCK}\", UPDATED_BLOCK)\n",
        "    .replace(\"{DYNAMIC_BLOCK}\", DYNAMIC_BLOCK)\n",
        "    .replace(\"{HTML_TABLE_SCROLLING}\", html_table_scrolling)\n",
        "    .replace(\"{COUNT_URL}\", JS_COUNT_URL)\n",
        ")\n",
        "# ====== CUT STOP [E] REFACTOR-Gold 3 — HTML (table + CSS + JS, no uploads) ======================\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "# ====== CUT START [F] REFACTOR-Gold 3 — Save + Upload + Reports + Partials + Printable ===========\n",
        "import os, re, posixpath\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "ENC          = \"iso-8859-15\"\n",
        "LOCAL_NAME   = globals().get(\"LOCAL_NAME\",  \"yates_ancestor_register.htm\")\n",
        "REMOTE_NAME  = globals().get(\"REMOTE_NAME\", \"yates_ancestor_register.htm\")\n",
        "HOME_URL     = \"https://yates.one-name.net/yates_ancestor_register.htm\"\n",
        "\n",
        "# Safely embed the JS count URL (escape single quotes)\n",
        "JS_COUNT_URL = COUNT_PUBLIC_URL.replace(\"'\", \"%27\")\n",
        "\n",
        "# 1) Write main page HTML exactly as built upstream\n",
        "with open(LOCAL_NAME, \"w\", encoding=ENC, errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(FULL_HTML)\n",
        "print(f\"✅ Wrote HTML: {os.path.abspath(LOCAL_NAME)}\")\n",
        "\n",
        "# 2) Upload main page + optional assets\n",
        "with ftp_connect() as ftps:\n",
        "    try:\n",
        "        ftps.mkd(\"partials\")\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        ftps.delete(_remote_path(REMOTE_NAME))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    ftp_upload_overwrite(ftps, LOCAL_NAME, _remote_path(REMOTE_NAME))\n",
        "\n",
        "    if os.path.exists(MATCH_COUSINS_CSV):\n",
        "        ftp_upload_overwrite(ftps, MATCH_COUSINS_CSV, _remote_path(MATCH_COUSINS_CSV))\n",
        "\n",
        "    if os.path.exists(LOCAL_COUNT_FILE):\n",
        "        ftp_upload_overwrite(ftps, LOCAL_COUNT_FILE, _remote_path(REMOTE_COUNT_NAME))\n",
        "        print(f\"✅ Published autosomal count: {LOCAL_COUNT_FILE} → {COUNT_PUBLIC_URL}\")\n",
        "    else:\n",
        "        print(f\"⚠️ Count file not found locally: {LOCAL_COUNT_FILE}\")\n",
        "\n",
        "    try:\n",
        "        ftps.quit()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# 3) Build data for reports/partials\n",
        "display_df_all = display_df.copy()\n",
        "display_df_filtered = display_df_all.reset_index(drop=True)\n",
        "filtered_df_for_reports = df.loc[display_df_all.index].copy()\n",
        "\n",
        "# ---------- Resolver usage report ----------\n",
        "used_series = filtered_df_for_reports[subject_code_col].astype(str).map(lambda x: str(x).strip().lower())\n",
        "counts = Counter([c for c in used_series if c and c != \"nan\"])\n",
        "\n",
        "rows = []\n",
        "all_keys = set(globals().get(\"MATCH_TO_UNMASKED\", {}).keys())\n",
        "for code in sorted(all_keys):\n",
        "    rows.append((code, globals()[\"MATCH_TO_UNMASKED\"].get(code, \"\"), counts.get(code, 0)))\n",
        "for code in sorted(set(counts.keys()) - all_keys):\n",
        "    rows.append((code, \"(unmapped)\", counts.get(code, 0)))\n",
        "\n",
        "usage_df = pd.DataFrame(rows, columns=[\"Match to (code)\", \"Unmasked\", \"Count\"]).sort_values(\n",
        "    [\"Match to (code)\"], ascending=[True]\n",
        ")\n",
        "usage_df_alpha = usage_df.reset_index(drop=True)\n",
        "\n",
        "RESOLVER_USAGE_CSV = \"resolver_usage_report.csv\"\n",
        "usage_df_alpha.to_csv(RESOLVER_USAGE_CSV, index=False, encoding=ENC)\n",
        "print(\"✅ Wrote resolver usage CSV:\", os.path.abspath(RESOLVER_USAGE_CSV))\n",
        "\n",
        "# ---------- Lineage Count (by oldest common pair, normalized) ----------\n",
        "def _escape_html(s: str) -> str:\n",
        "    return (str(s).replace(\"&\", \"&amp;\").replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\"))\n",
        "\n",
        "def _norm_key_component(fullname: str) -> str:\n",
        "    nm = smart_titlecase(str(fullname)); parts = nm.split()\n",
        "    if not parts: return \"\"\n",
        "    last   = re.sub(r\"[^A-Za-z]\", \"\", parts[-1])\n",
        "    firsts = re.sub(r\"[^A-Za-z]\", \"\", \"\".join(parts[:-1]))[:7]\n",
        "    return f\"{last}{firsts}\"\n",
        "\n",
        "def oldest_pair_key(token_list):\n",
        "    if not token_list: return \"\"\n",
        "    first = token_list[0]\n",
        "    a, b = derive_common_from_first_token([first])\n",
        "    if not a and not b:\n",
        "        parts = re.split(r\"\\s*&\\s*\", first)\n",
        "        a = parts[0] if parts else \"\"\n",
        "        b = parts[1] if len(parts) > 1 else \"\"\n",
        "    ka = _norm_key_component(a) if a else \"\"\n",
        "    kb = _norm_key_component(b) if b else \"\"\n",
        "    return f\"{ka}&{kb}\" if ka or kb else \"\"\n",
        "\n",
        "lc_counter = Counter()\n",
        "for _, row in filtered_df_for_reports.iterrows():\n",
        "    toks = split_tokens(row[path_col])\n",
        "    key = oldest_pair_key(toks)\n",
        "    if key: lc_counter[key] += 1\n",
        "\n",
        "lc_rows = sorted(lc_counter.items(), key=lambda x: (-x[1], x[0]))\n",
        "lineage_count_df = pd.DataFrame(lc_rows, columns=[\"Oldest Distant Ancestor (normalized Last+First7) pair\", \"Count\"])\n",
        "\n",
        "LINEAGE_COUNT_CSV = \"lineage_count_report.csv\"\n",
        "lineage_count_df.to_csv(LINEAGE_COUNT_CSV, index=False, encoding=ENC)\n",
        "print(\"✅ Wrote lineage count CSV:\", os.path.abspath(LINEAGE_COUNT_CSV))\n",
        "\n",
        "# Upload report CSVs\n",
        "try:\n",
        "    with ftp_connect() as ftps:\n",
        "        ftp_upload_overwrite(ftps, RESOLVER_USAGE_CSV, _remote_path(RESOLVER_USAGE_CSV))\n",
        "        ftp_upload_overwrite(ftps, LINEAGE_COUNT_CSV, _remote_path(LINEAGE_COUNT_CSV))\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "    print(\"✅ Published report CSVs.\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Upload of report CSVs failed: {e}\")\n",
        "\n",
        "# ---------- Helpers for Match Count partial ----------\n",
        "def _build_person_details_html(code_lc: str) -> str:\n",
        "    mask = filtered_df_for_reports[subject_code_col].astype(str).str.strip().str.lower() == code_lc\n",
        "    if not mask.any(): return \"<em>No rows for this person.</em>\"\n",
        "    rows_idx = filtered_df_for_reports[mask].index\n",
        "    mini = display_df.loc[rows_idx, [\"Find\", \"Match To Name\", LINEAGE_HEADER_SAFE]].copy()\n",
        "    return mini.to_html(index=False, escape=False, classes=\"mini-table\", border=0)\n",
        "\n",
        "# ---------- Match Count partial ----------\n",
        "def _render_match_count_full_html(usage_alpha: pd.DataFrame) -> str:\n",
        "    try:\n",
        "        total_persons = int(usage_alpha.shape[0])\n",
        "        total_matches = int(pd.to_numeric(usage_alpha[\"Count\"], errors=\"coerce\").fillna(0).sum())\n",
        "    except Exception:\n",
        "        total_persons, total_matches = usage_alpha.shape[0], 0\n",
        "\n",
        "    rows_html = []\n",
        "    for _, r in usage_alpha.iterrows():\n",
        "        code    = str(r[\"Match to (code)\"])\n",
        "        code_lc = code.strip().lower()\n",
        "        unm     = _escape_html(r[\"Unmasked\"])\n",
        "        cnt     = int(pd.to_numeric(r[\"Count\"], errors=\"coerce\")) if str(r[\"Count\"]).strip() else 0\n",
        "        rows_html.append(\n",
        "            \"<tr class='top-row' data-code='{code_lc}'>\"\n",
        "            \"<td class='sel'><input type='checkbox' class='selbox' data-code='{code_lc}' title='Select' /></td>\"\n",
        "            \"<td class='code'>{code}</td>\"\n",
        "            \"<td class='unmasked'>{unm}</td>\"\n",
        "            \"<td class='count'><a href='#' class='count-toggle' data-code='{code_lc}' aria-expanded='false'>{cnt}</a></td>\"\n",
        "            \"</tr>\".format(code_lc=_escape_html(code_lc), code=_escape_html(code), unm=unm, cnt=f\"{cnt:,}\")\n",
        "        )\n",
        "        rows_html.append(\n",
        "            \"<tr class='details-row' id='details-{code_lc}' style='display:none;'>\"\n",
        "            \"<td colspan='4'><div class='details-outer'>{detail}</div></td>\"\n",
        "            \"</tr>\".format(code_lc=_escape_html(code_lc), detail=_build_person_details_html(code_lc))\n",
        "        )\n",
        "\n",
        "    style = (\n",
        "        \"<style>\"\n",
        "        \" body{font-family:Georgia,'Times New Roman',serif;background:#fff;color:#111;margin:0;padding:18px;line-height:1.6;font-size:15px}\"\n",
        "        \" .wrap{max-width:900px;margin:0 auto}\"\n",
        "        \" h2{font-size:20px;margin:0 0 10px 0;text-align:center;border-bottom:2px solid #5b79b8;padding-bottom:6px}\"\n",
        "        \" .updated{font-size:12px;color:#555;text-align:center;margin:2px 0 10px 0}\"\n",
        "        \" .stats{text-align:center;color:#444;font-size:13px;margin:6px 0 10px 0}\"\n",
        "        \" .toolbar{display:flex;flex-wrap:wrap;gap:8px;align-items:center;justify-content:flex-start;margin:8px 0 10px 0}\"\n",
        "        \" .btn{display:inline-block;border:1px solid #5b79b8;background:#5b79b8;color:#fff;padding:6px 12px;border-radius:6px;text-decoration:none;cursor:pointer}\"\n",
        "        \" .btn:hover{background:#4668aa}\"\n",
        "        \" .master{margin-left:auto;font-size:13px;color:#333}\"\n",
        "        \" table#mc-table{border-collapse:collapse;width:100%;table-layout:fixed}\"\n",
        "        \" #mc-table col.sel{width:72px} #mc-table col.code{width:26%} #mc-table col.unmasked{width:48%} #mc-table col.count{width:16%}\"\n",
        "        \" #mc-table th,#mc-table td{border:1px solid #ccc;padding:8px 10px;vertical-align:top;word-wrap:break-word;overflow-wrap:break-word}\"\n",
        "        \" #mc-table th{background:#e9eef9;position:sticky;top:0;z-index:1}\"\n",
        "        \" #mc-table td.count{text-align:right}\"\n",
        "        \" #mc-table a.count-toggle{display:inline-block;padding:2px 6px;background:#5b79b8;color:#fff;border-radius:4px;border:1px solid #3e5a97;text-decoration:none}\"\n",
        "        \" #mc-table a.count-toggle:hover{background:#4668aa}\"\n",
        "        \" .details-outer{background:#f9fbff;border:1px solid #d7e1fb;margin:8px 2px;padding:8px;border-radius:6px}\"\n",
        "        \" .mini-table{border-collapse:collapse;width:100%;table-layout:fixed}\"\n",
        "        \" .mini-table th,.mini-table td{border:1px solid #ddd;padding:6px 8px;vertical-align:top}\"\n",
        "        \" .mini-table th{background:#f2f6ff}\"\n",
        "        \" .mini-table col:nth-child(1){width:140px} \"\n",
        "        f\" .mini-table col:nth-child(2){{width:{COL_A_PX}px}} \"\n",
        "        \" .mini-table col:nth-child(3){width:auto}\"\n",
        "        \" @media screen and (max-width:900px){ body{padding:12px;font-size:14px} .toolbar{gap:6px} }\"\n",
        "        \"</style>\"\n",
        "    )\n",
        "\n",
        "    updated = (\n",
        "        \"<div class='updated'>\"\n",
        "        \"<a href='\" + HOME_URL + \"' target='_blank' rel='noopener'>Home</a>\"\n",
        "        \" &nbsp;|&nbsp; Last updated: <span id='last-updated'></span>\"\n",
        "        \" &nbsp;|&nbsp; Autosomal matches: <span id='auto-count' class='js-count'></span>\"\n",
        "        \"</div>\"\n",
        "    )\n",
        "\n",
        "    toolbar = (\n",
        "        \"<div class='toolbar'>\"\n",
        "        \" <button type='button' class='btn' id='btn-display'>Display Checked</button>\"\n",
        "        \" <button type='button' class='btn' id='btn-email'>Email Checked</button>\"\n",
        "        \" <button type='button' class='btn' id='btn-print'>Print Checked</button>\"\n",
        "        \" <label class='master'><input type='checkbox' id='sel-all' /> Select all</label>\"\n",
        "        \"</div>\"\n",
        "    )\n",
        "\n",
        "    html = (\n",
        "        \"<!DOCTYPE html><html lang='en'><head>\"\n",
        "        \"<meta charset='iso-8859-15' />\"\n",
        "        \"<meta name='viewport' content='width=device-width, initial-scale=1.0' />\"\n",
        "        \"<title>Match Count (by resolver code)</title>\"\n",
        "        + style +\n",
        "        \"</head><body>\"\n",
        "        \"<div class='wrap'>\"\n",
        "        \"<h2>Match Count (by resolver code, A&rightarrow;Z)</h2>\"\n",
        "        + updated +\n",
        "        \"<div class='stats'>Total distinct &ldquo;Match to&rdquo; persons: \" + f\"{total_persons:,}\" +\n",
        "        \" &nbsp;|&nbsp; Total matches counted: \" + f\"{total_matches:,}\" + \"</div>\"\n",
        "        + toolbar +\n",
        "        \"<table id='mc-table'>\"\n",
        "        \"<colgroup><col class='sel'><col class='code'><col class='unmasked'><col class='count'></colgroup>\"\n",
        "        \"<thead><tr><th>Select</th><th>Match to (code)</th><th>Unmasked</th><th>Count</th></tr></thead>\"\n",
        "        \"<tbody>\" + \"\".join(rows_html) + \"</tbody></table>\"\n",
        "        \"</div>\"\n",
        "        \"<script>(function(){\"\n",
        "        \" document.addEventListener('DOMContentLoaded', function(){\"\n",
        "        \"  function z(n){return(n<10?'0':'')+n;}\"\n",
        "        \"  function stamp(){var el=document.getElementById('last-updated'); if(!el) return; var d=new Date(document.lastModified||new Date());\"\n",
        "        \"   el.textContent=d.getFullYear()+'-'+z(d.getMonth()+1)+'-'+z(d.getDate())+' '+z(d.getHours())+':'+z(d.getMinutes());}\"\n",
        "        \"  function fmt(n){try{var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return ''; return x.toLocaleString('en-US');}catch(e){return String(n||'');}}\"\n",
        "        \"  function loadCnt(){var el=document.getElementById('auto-count'); if(!el) return; var url='\" + JS_COUNT_URL + \"';\"\n",
        "        \"   try{var xhr=new XMLHttpRequest(); xhr.open('GET', url+(url.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true);\"\n",
        "        \"    xhr.onreadystatechange=function(){ if(xhr.readyState===4){ if(xhr.status>=200&&xhr.status<300){ var m=(xhr.responseText||'').match(/(\\\\d+)/); el.textContent = fmt(m?m[1]:'') || '(unavailable)'; } else { el.textContent='(unavailable)'; } } };\"\n",
        "        \"    xhr.send(null);}catch(e){ el.textContent='(unavailable)'; }}\"\n",
        "        \"  stamp(); loadCnt();\"\n",
        "\n",
        "        \"  function toggleDetails(code, wantOpen){\"\n",
        "        \"    var row=document.getElementById('details-'+code); if(!row) return;\"\n",
        "        \"    row.style.display = wantOpen ? '' : 'none';\"\n",
        "        \"    var a=document.querySelector(\\\"a.count-toggle[data-code='\\\"+code+\\\"']\\\"); if(a){ a.setAttribute('aria-expanded', wantOpen?'true':'false'); }\"\n",
        "        \"  }\"\n",
        "        \"  function selectedCodes(){\"\n",
        "        \"    var out=[]; var cbs=document.querySelectorAll('#mc-table .selbox');\"\n",
        "        \"    for(var i=0;i<cbs.length;i++){ if(cbs[i].checked){ var c=cbs[i].getAttribute('data-code'); if(c) out.push(c); }}\"\n",
        "        \"    return out;\"\n",
        "        \"  }\"\n",
        "\n",
        "        \"  var master=document.getElementById('sel-all');\"\n",
        "        \"  if(master){ master.addEventListener('change', function(){\"\n",
        "        \"    var want=master.checked; var cbs=document.querySelectorAll('#mc-table .selbox');\"\n",
        "        \"    for(var i=0;i<cbs.length;i++){ cbs[i].checked = want; }\"\n",
        "        \"  }); }\"\n",
        "\n",
        "        \"  var btnDisp=document.getElementById('btn-display');\"\n",
        "        \"  if(btnDisp){ btnDisp.addEventListener('click', function(){\"\n",
        "        \"    var sel=selectedCodes();\"\n",
        "        \"    var all=document.querySelectorAll('tr.details-row'); for(var i=0;i<all.length;i++){ all[i].style.display='none'; }\"\n",
        "        \"    for(var j=0;j<sel.length;j++){ toggleDetails(sel[j], true); }\"\n",
        "        \"    if(sel.length){ try{ document.getElementById('details-'+sel[0]).scrollIntoView({behavior:'smooth',block:'start'});}catch(e){} }\"\n",
        "        \"  }); }\"\n",
        "\n",
        "        \"  function enc(s){ return encodeURIComponent(String(s||'')); }\"\n",
        "        \"  function textOf(el){ return (el && (el.textContent||el.innerText)||'').trim(); }\"\n",
        "\n",
        "        \"  var btnEmail=document.getElementById('btn-email');\"\n",
        "        \"  if(btnEmail){ btnEmail.addEventListener('click', function(){\"\n",
        "        \"    var sel=selectedCodes(); if(!sel.length){ alert('No persons selected.'); return; }\"\n",
        "        \"    function collectMatches(code){\"\n",
        "        \"      var out=[]; var host=document.getElementById('details-'+code); if(!host) return out;\"\n",
        "        \"      var rows=host.querySelectorAll('table.mini-table tbody tr');\"\n",
        "        \"      for(var i=0;i<rows.length;i++){\"\n",
        "        \"        var tds=rows[i].cells; if(!tds || tds.length<3) continue;\"\n",
        "        \"        var a=tds[0].querySelector('a'); var href=a ? a.href : '';\"\n",
        "        \"        var summary=textOf(tds[1]);\"\n",
        "        \"        out.push({summary:summary, href:href});\"\n",
        "        \"      }\"\n",
        "        \"      return out;\"\n",
        "        \"    }\"\n",
        "        \"    var lines=[], total=0;\"\n",
        "        \"    for(var k=0;k<sel.length;k++){\"\n",
        "        \"      var code=sel[k];\"\n",
        "        \"      var tr=document.querySelector(\\\"tr.top-row[data-code='\\\"+code+\\\"']\\\"); if(!tr) continue;\"\n",
        "        \"      var codeTxt=textOf(tr.querySelector('.code'));\"\n",
        "        \"      var unmTxt =textOf(tr.querySelector('.unmasked'));\"\n",
        "        \"      var cntTxt =textOf(tr.querySelector('.count a'));\"\n",
        "        \"      var header = codeTxt + (unmTxt? ' — '+unmTxt : '') + (cntTxt? ' ('+cntTxt+')' : '');\"\n",
        "        \"      lines.push('== ' + header + ' ==');\"\n",
        "        \"      var matches = collectMatches(code);\"\n",
        "        \"      if(!matches.length){\"\n",
        "        \"        lines.push('- (no inline rows available)');\"\n",
        "        \"      } else {\"\n",
        "        \"        total += matches.length;\"\n",
        "        \"        for(var m=0;m<matches.length;m++){\"\n",
        "        \"          var row = matches[m];\"\n",
        "        \"          lines.push('- ' + row.summary);\"\n",
        "        \"          if(row.href){ lines.push(row.href); }\"\n",
        "        \"        }\"\n",
        "        \"      }\"\n",
        "        \"      if(k < sel.length-1) lines.push('');\"\n",
        "        \"    }\"\n",
        "        \"    var subj='ONS Yates: ' + sel.length + ' person(s), ' + total + ' match row(s)';\"\n",
        "        \"    var body=lines.join('\\\\n');\"\n",
        "        \"    var href='mailto:?subject='+enc(subj)+'&body='+enc(body);\"\n",
        "        \"    window.location.href=href;\"\n",
        "        \"  }); }\"\n",
        "\n",
        "        \"  var btnPrint=document.getElementById('btn-print');\"\n",
        "        \"  if(btnPrint){ btnPrint.addEventListener('click', function(){\"\n",
        "        \"    var sel=selectedCodes(); if(!sel.length){ alert('No persons selected.'); return; }\"\n",
        "        \"    for(var i=0;i<sel.length;i++){ toggleDetails(sel[i], true); }\"\n",
        "        \"    setTimeout(function(){ window.print(); }, 100);\"\n",
        "        \"  }); }\"\n",
        "\n",
        "        \"  var tbl=document.getElementById('mc-table');\"\n",
        "        \"  if(tbl){ tbl.addEventListener('click',function(ev){\"\n",
        "        \"    var a=ev.target && ev.target.closest ? ev.target.closest('a.count-toggle') : null;\"\n",
        "        \"    if(!a) return; ev.preventDefault();\"\n",
        "        \"    var code=a.getAttribute('data-code'); if(!code) return;\"\n",
        "        \"    var row=document.getElementById('details-'+code); if(!row) return;\"\n",
        "        \"    var open=row.style.display!== 'none';\"\n",
        "        \"    row.style.display = open ? 'none' : '';\"\n",
        "        \"    a.setAttribute('aria-expanded', open?'false':'true');\"\n",
        "        \"    if(!open){ try{ row.scrollIntoView({behavior:'smooth',block:'start'});}catch(e){} }\"\n",
        "        \"  },false); }\"\n",
        "        \" });\"\n",
        "        \"})();</script>\"\n",
        "        \"</body></html>\"\n",
        "    )\n",
        "    return html\n",
        "\n",
        "match_partial_html = _render_match_count_full_html(usage_df_alpha)\n",
        "\n",
        "# ---------- Lineage Count partial ----------\n",
        "lineage_style = (\n",
        "    \"<style>\"\n",
        "    \" body{font-family:Georgia,'Times New Roman',serif;background:#fff;color:#111;margin:0;padding:18px;line-height:1.6;font-size:15px}\"\n",
        "    \" .wrap{max-width:1100px;margin:0 auto}\"\n",
        "    \" h2{font-size:20px;margin:0 0 10px 0;text-align:center;border-bottom:2px solid #5b79b8;padding-bottom:6px}\"\n",
        "    \" .updated{font-size:12px;color:#555;text-align:center;margin:2px 0 10px 0}\"\n",
        "    \" table.partial-table{border-collapse:collapse;width:100%;table-layout:auto}\"\n",
        "    \" table.partial-table th,table.partial-table td{border:1px solid #ccc;padding:8px 10px;vertical-align:top}\"\n",
        "    \" table.partial-table th{background:#e9eef9;position:sticky;top:0}\"\n",
        "    \" @media screen and (max-width:900px){ body{padding:12px;font-size:14px} }\"\n",
        "    \"</style>\"\n",
        ")\n",
        "lineage_updated = (\n",
        "    \"<div class='updated'>\"\n",
        "    \"<a href='\" + HOME_URL + \"' target='_blank' rel='noopener'>Home</a>\"\n",
        "    \" &nbsp;|&nbsp; Last updated: <span id='last-updated'></span>\"\n",
        "    \" &nbsp;|&nbsp; Autosomal matches: <span id='auto-count' class='js-count'></span>\"\n",
        "    \"</div>\"\n",
        ")\n",
        "lineage_js = (\n",
        "    \"<script>(function(){\"\n",
        "    \" document.addEventListener('DOMContentLoaded', function(){\"\n",
        "    \"  function z(n){return(n<10?'0':'')+n;}\"\n",
        "    \"  function stamp(){var el=document.getElementById('last-updated'); if(!el) return; var d=new Date(document.lastModified||new Date());\"\n",
        "    \"   el.textContent=d.getFullYear()+'-'+z(d.getMonth()+1)+'-'+z(d.getDate())+' '+z(d.getHours())+':'+z(d.getMinutes());}\"\n",
        "    \"  function fmt(n){try{var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return ''; return x.toLocaleString('en-US');}catch(e){return String(n||'');}}\"\n",
        "    \"  function loadCnt(){var el=document.getElementById('auto-count'); if(!el) return; var url='\" + JS_COUNT_URL + \"';\"\n",
        "    \"   try{var xhr=new XMLHttpRequest(); xhr.open('GET', url+(url.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true);\"\n",
        "    \"    xhr.onreadystatechange=function(){ if(xhr.readyState===4){ if(xhr.status>=200&&xhr.status<300){ var m=(xhr.responseText||'').match(/(\\\\d+)/); el.textContent = fmt(m?m[1]:'') || '(unavailable)'; } else { el.textContent='(unavailable)'; } } };\"\n",
        "    \"    xhr.send(null);}catch(e){ el.textContent='(unavailable)'; }}\"\n",
        "    \"  stamp(); loadCnt();\"\n",
        "    \" });\"\n",
        "    \"})();</script>\"\n",
        ")\n",
        "\n",
        "lineage_partial_html = (\n",
        "    \"<!DOCTYPE html><html lang='en'><head>\"\n",
        "    \"<meta charset='iso-8859-15' />\"\n",
        "    \"<meta name='viewport' content='width=device-width, initial-scale=1.0' />\"\n",
        "    \"<title>Lineage Count (by oldest distant ancestor pair)</title>\"\n",
        "    + lineage_style +\n",
        "    \"</head><body>\"\n",
        "    \"<div class='wrap'>\"\n",
        "    \"<h2>Lineage Count (by oldest distant ancestor pair)</h2>\"\n",
        "    + lineage_updated +\n",
        "    lineage_count_df.to_html(index=False, escape=False, classes='partial-table', border=0) +\n",
        "    \"</div>\"\n",
        "    + lineage_js +\n",
        "    \"</body></html>\"\n",
        ")\n",
        "\n",
        "# 4) Write & upload partials\n",
        "with open(\"match_count.htm\", \"w\", encoding=ENC, errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(match_partial_html)\n",
        "with open(\"lineage_count.htm\", \"w\", encoding=ENC, errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(lineage_partial_html)\n",
        "print(\"✅ Wrote partials locally: match_count.htm, lineage_count.htm\")\n",
        "\n",
        "try:\n",
        "    with ftp_connect() as ftps:\n",
        "        try: ftps.mkd(\"partials\")\n",
        "        except Exception: pass\n",
        "        ftp_upload_overwrite(ftps, \"match_count.htm\",   \"partials/match_count.htm\")\n",
        "        ftp_upload_overwrite(ftps, \"lineage_count.htm\", \"partials/lineage_count.htm\")\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "    print(\"✅ Published count partials to /partials/\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Upload of count partials failed: {e}\")\n",
        "\n",
        "# 5) Printable page (adds dynamic header)\n",
        "PRINT_PARTIAL_NAME  = \"cousin_list_print.htm\"\n",
        "PRINT_PARTIAL_LOCAL = PRINT_PARTIAL_NAME\n",
        "_print_table_html_df = (display_df_filtered if not display_df_filtered.empty else display_df_all).copy()\n",
        "_print_table_html = _print_table_html_df[[\"Find\", \"Match To Name\", LINEAGE_HEADER_SAFE]].to_html(\n",
        "    index=False, escape=False, classes=\"print-table\", border=1\n",
        ")\n",
        "PRINT_PARTIAL_HTML = (\n",
        "    \"<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Transitional//EN\\\"\\n\"\n",
        "    \"  \\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\\\">\\n\"\n",
        "    \"<html xmlns=\\\"http://www.w3.org/1999/xhtml\\\" lang=\\\"en\\\">\\n\"\n",
        "    \"<head>\\n\"\n",
        "    \"<meta http-equiv=\\\"Content-Type\\\" content=\\\"text/html; charset=iso-8859-15\\\" />\\n\"\n",
        "    \"<meta name=\\\"viewport\\\" content=\\\"width=device-width, initial-scale=1.0\\\" />\\n\"\n",
        "    \"<title>ONS Yates Study &ndash; Cousin List (Printable)</title>\\n\"\n",
        "    \"<style type=\\\"text/css\\\">\\n\"\n",
        "    \"  body { font-family: Georgia, 'Times New Roman', serif; color:#000; background:#fff; margin:0; padding:16px; line-height:1.45; }\\n\"\n",
        "    \"  .wrap { max-width: 1100px; margin: 0 auto; }\\n\"\n",
        "    \"  h1 { font-size: 22px; margin: 0 0 8px 0; text-align:center; }\\n\"\n",
        "    \"  .updated { font-size:12px; color:#555; text-align:center; margin:2px 0 12px 0; }\\n\"\n",
        "    \"  .actions { text-align:center; margin: 10px 0 16px 0; }\\n\"\n",
        "    \"  .btn { display:inline-block; border:1px solid #444; background:#f4f4f4; color:#000; padding:6px 12px; text-decoration:none; }\\n\"\n",
        "    \"  table.print-table { border-collapse: collapse; width: 100%; table-layout: fixed; }\\n\"\n",
        "    \"  table.print-table th, table.print-table td { border:  1px solid #222; padding: 6px 8px; vertical-align: top; }\\n\"\n",
        "    \"  table.print-table th { background: #eee; }\\n\"\n",
        "    \"  @media print { .actions { display: none; } @page { margin: 0.6in; } }\\n\"\n",
        "    \"</style>\\n\"\n",
        "    \"</head>\\n\"\n",
        "    \"<body>\\n\"\n",
        "    \"  <div class=\\\"wrap\\\">\\n\"\n",
        "    \"    <h1>ONS Yates Study &ndash; Cousin List (Printable)</h1>\\n\"\n",
        "    \"    <div class=\\\"updated\\\"><a href=\\\"\" + HOME_URL + \"\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">Home</a>\"\n",
        "    \" &nbsp;|&nbsp; Last updated: <span id=\\\"last-updated\\\"></span>\"\n",
        "    \" &nbsp;|&nbsp; Autosomal matches: <span id=\\\"auto-count\\\" class=\\\"js-count\\\"></span></div>\\n\"\n",
        "    \"    <div class=\\\"actions\\\"><a class=\\\"btn\\\" href=\\\"#\\\" onclick=\\\"window.print();return false;\\\">Print this page</a></div>\\n\"\n",
        "    \"   \" + _print_table_html + \"\\n\"\n",
        "    \"    <div class=\\\"actions\\\" style=\\\"margin-top:16px;\\\"><a class=\\\"btn\\\" href=\\\"#\\\" onclick=\\\"window.print();return false;\\\">Print this page</a></div>\\n\"\n",
        "    \"  </div>\\n\"\n",
        "    \"<script>(function(){\"\n",
        "    \" document.addEventListener('DOMContentLoaded', function(){\"\n",
        "    \"  function z(n){return(n<10?'0':'')+n;}\"\n",
        "    \"  function stamp(){var el=document.getElementById('last-updated'); if(!el) return; var d=new Date(document.lastModified||new Date());\"\n",
        "    \"   el.textContent=d.getFullYear()+'-'+z(d.getMonth()+1)+'-'+z(d.getDate())+' '+z(d.getHours())+':'+z(d.getMinutes());}\"\n",
        "    \"  function fmt(n){try{var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return ''; return x.toLocaleString('en-US');}catch(e){return String(n||'');}}\"\n",
        "    \"  function loadCnt(){var el=document.getElementById('auto-count'); if(!el) return; var url='\" + JS_COUNT_URL + \"';\"\n",
        "    \"   try{var xhr=new XMLHttpRequest(); xhr.open('GET', url+(url.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true);\"\n",
        "    \"    xhr.onreadystatechange=function(){ if(xhr.readyState===4){ if(xhr.status>=200&&xhr.status<300){ var m=(xhr.responseText||'').match(/(\\\\d+)/); el.textContent = fmt(m?m[1]:'') || '(unavailable)'; } else { el.textContent='(unavailable)'; } } };\"\n",
        "    \"    xhr.send(null);}catch(e){ el.textContent='(unavailable)'; }}\"\n",
        "    \"  stamp(); loadCnt();\"\n",
        "    \" });\"\n",
        "    \"})();</script>\"\n",
        "    \"</body>\\n\"\n",
        "    \"</html>\\n\"\n",
        ")\n",
        "with open(PRINT_PARTIAL_LOCAL, \"w\", encoding=ENC, errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(PRINT_PARTIAL_HTML)\n",
        "\n",
        "try:\n",
        "    with ftp_connect() as ftps:\n",
        "        try: ftps.mkd(\"partials\")\n",
        "        except Exception: pass\n",
        "        ftp_upload_overwrite(ftps, PRINT_PARTIAL_LOCAL, \"partials/\" + PRINT_PARTIAL_NAME)\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "    print(f\"✅ Uploaded printable page: /partials/{PRINT_PARTIAL_NAME}\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Printable page upload failed: {e}\")\n",
        "\n",
        "print(f\"✅ HTML published at https://yates.one-name.net/{REMOTE_NAME}\")\n",
        "# ====== CUT STOP [F] REFACTOR-Gold 3 — Save + Upload + Reports + Partials + Printable ===========\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egVaCZBRh9Vo",
        "outputId": "540a9117-4792-4fe7-aefe-54bb2de398ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⬇️ Pulled remote file: partials/match_to_unmasked.csv → /content/match_to_unmasked.server.csv\n",
            "✅ Loaded resolver from server: 79 codes\n",
            "✅ Loaded CSV — 7 rows, 9 columns from /content/final_combined_df_with_value_labels.csv\n",
            "✅ Columns: {'ID': 'ID#', 'Match to': 'Match to', 'Name': 'Name', 'cM': 'cM', 'Lineage': 'Yates DNA Ancestral Line'}\n",
            "✅ Wrote local CSV (Column A): /content/the_match_cousins.csv\n",
            "✅ Wrote HTML: /content/yates_ancestor_register.htm\n",
            "⬆️ Uploaded: yates_ancestor_register.htm → yates_ancestor_register.htm\n",
            "⬆️ Uploaded: the_match_cousins.csv → the_match_cousins.csv\n",
            "⬆️ Uploaded: /content/autosomal_count.txt → autosomal_count.txt\n",
            "✅ Published autosomal count: /content/autosomal_count.txt → /autosomal_count.txt\n",
            "✅ Wrote resolver usage CSV: /content/resolver_usage_report.csv\n",
            "✅ Wrote lineage count CSV: /content/lineage_count_report.csv\n",
            "⬆️ Uploaded: resolver_usage_report.csv → resolver_usage_report.csv\n",
            "⬆️ Uploaded: lineage_count_report.csv → lineage_count_report.csv\n",
            "✅ Published report CSVs.\n",
            "✅ Wrote partials locally: match_count.htm, lineage_count.htm\n",
            "⬆️ Uploaded: match_count.htm → partials/match_count.htm\n",
            "⬆️ Uploaded: lineage_count.htm → partials/lineage_count.htm\n",
            "✅ Published count partials to /partials/\n",
            "⬆️ Uploaded: cousin_list_print.htm → partials/cousin_list_print.htm\n",
            "✅ Uploaded printable page: /partials/cousin_list_print.htm\n",
            "✅ HTML published at https://yates.one-name.net/yates_ancestor_register.htm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Gold #4 for Y-DNA Grid with Auto-Adjusting Column Widths\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from zoneinfo import ZoneInfo\n",
        "from ftplib import FTP_TLS\n",
        "\n",
        "# ── PATHS ─────────────────────────────────────────────────────────────────\n",
        "combo_csv  = \"/content/y_dna_user_detail_combo.csv\"\n",
        "output_csv = \"/content/y_dna_grid.csv\"\n",
        "output_htm = \"/content/y_dna_grid.htm\"\n",
        "\n",
        "# ── 1) Load vertical data ─────────────────────────────────────────────────\n",
        "df = pd.read_csv(combo_csv)\n",
        "\n",
        "# Rename “Date” → “Era”\n",
        "if \"Date\" in df.columns:\n",
        "    df.rename(columns={\"Date\": \"Era\"}, inplace=True)\n",
        "\n",
        "# ── 2) Insert Action *after* Era ──────────────────────────────────────────\n",
        "# Era is at index 1, so Action goes at index 2\n",
        "df.insert(2, \"Action\", [\"→\"] * len(df))\n",
        "\n",
        "# ── 3) Save vertical CSV ─────────────────────────────────────────────────\n",
        "df.to_csv(output_csv, index=False)\n",
        "print(f\"✅ Saved vertical grid CSV to {output_csv}\")\n",
        "\n",
        "# ── 4) Build HTML ─────────────────────────────────────────────────────────\n",
        "now = datetime.now(ZoneInfo(\"America/New_York\"))\n",
        "ts  = now.strftime(\"%-m/%-d/%y, %-I:%M %p EDT\")\n",
        "cols = df.columns.tolist()\n",
        "\n",
        "html = f\"\"\"<!DOCTYPE html>\n",
        "<html>\n",
        "<head><meta charset=\"UTF-8\"><title>Yates Y-DNA Grid</title>\n",
        "<style>\n",
        "body {{\n",
        "  background: #faf9d3;\n",
        "  font-family: Arial, sans-serif;\n",
        "  font-size: 14px;\n",
        "  margin: 0;\n",
        "  padding: 0;\n",
        "}}\n",
        ".container {{\n",
        "  padding: 10px;\n",
        "}}\n",
        ".table-container {{\n",
        "  overflow-x: auto;\n",
        "  max-height: 80vh;\n",
        "}}\n",
        "table {{\n",
        "  border: 2px solid #333;\n",
        "  border-collapse: collapse;\n",
        "  margin: 0 auto;\n",
        "}}\n",
        "table.mainsection {{\n",
        "  /* allows CSS targeting of blank under “Year” */\n",
        "}}\n",
        "thead {{\n",
        "  display: table-header-group;\n",
        "}}\n",
        "thead th {{\n",
        "  position: sticky;\n",
        "  top: 0;\n",
        "  background: #333;\n",
        "  color: #fff;\n",
        "  padding: 6px;\n",
        "  border: 1px solid #999;\n",
        "  z-index: 3;\n",
        "}}\n",
        "a {{\n",
        "  color: #fff;\n",
        "  text-decoration: underline;\n",
        "}}\n",
        ".era {{\n",
        "  background: #666;\n",
        "  color: #eee;\n",
        "  padding: 6px;\n",
        "  border: 1px solid #999;\n",
        "  font-size: 0.9em;\n",
        "}}\n",
        ".action {{\n",
        "  background: #fff;\n",
        "  padding: 6px;\n",
        "  border: 1px solid #999;\n",
        "  text-align: center;\n",
        "}}\n",
        "td {{\n",
        "  padding: 6px;\n",
        "  border: 1px solid #999;\n",
        "  text-align: center;\n",
        "}}\n",
        "th:nth-child(n+4),\n",
        "td:nth-child(n+4) {{\n",
        "  border: 1px solid #333;\n",
        "}}\n",
        ".match {{\n",
        "  background: #fff;\n",
        "}}\n",
        ".blank {{\n",
        "  background: #ccc;\n",
        "  color: #ccc;\n",
        "}}\n",
        "/* make the blank under the “Year” header match the era-cell background */\n",
        "table.mainsection td.blank:nth-child(2) {{\n",
        "  background-color: #fdfcd0;\n",
        "}}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "  <div class=\"container\">\n",
        "    <h1 style=\"text-align:center\">Yates Y-DNA Grid</h1>\n",
        "    <p style=\"text-align:center;font-size:0.9em\">Updated: {ts}</p>\n",
        "    <p style=\"text-align:center;margin-bottom:12px\">\n",
        "      <a href=\"https://yates.one-name.net/gengen/dna_cousin_surname_study.htm\">\n",
        "        Return to DNA Cousin Surname Study\n",
        "      </a>\n",
        "    </p>\n",
        "    <div class=\"table-container\">\n",
        "      <table class=\"mainsection\">\n",
        "        <thead>\n",
        "          <tr>\"\"\"\n",
        "\n",
        "# Header row\n",
        "for i, c in enumerate(cols):\n",
        "    if i == 0:\n",
        "        html += \"<th>SNP</th>\"\n",
        "    elif i == 1:\n",
        "        html += \"<th>Year</th>\"\n",
        "    elif i == 2:\n",
        "        html += \"<th>Action</th>\"\n",
        "    else:\n",
        "        pid = c.split(\"-\")[0].upper()\n",
        "        html += (\n",
        "          '<th>'\n",
        "          f'<a href=\"https://yates.one-name.net/tng/verticalchart.php?'\n",
        "          f'personID={pid}&tree=tree1&parentset=0&display=vertical&generations=15\">{c}</a>'\n",
        "          '</th>'\n",
        "        )\n",
        "\n",
        "html += \"\"\"\n",
        "          </tr>\n",
        "        </thead>\n",
        "        <tbody>\"\"\"\n",
        "\n",
        "# Data rows\n",
        "for _, row in df.iterrows():\n",
        "    html += \"<tr>\"\n",
        "    for i, c in enumerate(cols):\n",
        "        v = row[c]\n",
        "        if i == 0:\n",
        "            html += f\"<td>{v}</td>\"\n",
        "        elif i == 1:\n",
        "            html += '<td class=\"blank\">–</td>' if pd.isna(v) or not str(v).strip() else f'<td class=\"era\">{v}</td>'\n",
        "        elif i == 2:\n",
        "            html += '<td class=\"blank\">–</td>' if pd.isna(v) or not str(v).strip() else f'<td class=\"action\">{v}</td>'\n",
        "        else:\n",
        "            html += '<td class=\"blank\">–</td>' if pd.isna(v) or not str(v).strip() else f'<td class=\"match\">{v}</td>'\n",
        "    html += \"</tr>\"\n",
        "\n",
        "html += \"\"\"\n",
        "        </tbody>\n",
        "      </table>\n",
        "    </div>\n",
        "  </div>\n",
        "</body>\n",
        "</html>\"\"\"\n",
        "\n",
        "with open(output_htm, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(html)\n",
        "print(f\"✅ Saved vertical XHTML to {output_htm}\")\n",
        "\n",
        "# ── 5) FTP upload ────────────────────────────────────────────────────────\n",
        "ftp = FTP_TLS()\n",
        "ftp.connect(os.environ[\"FTP_HOST\"], int(os.environ[\"FTP_PORT\"]))\n",
        "ftp.login(os.environ[\"FTP_USER\"], os.environ[\"FTP_PASS\"])\n",
        "ftp.prot_p()\n",
        "for path in (output_csv, output_htm):\n",
        "    fn = os.path.basename(path)\n",
        "    try:\n",
        "        ftp.delete(fn)\n",
        "    except:\n",
        "        pass\n",
        "    with open(path, \"rb\") as fp:\n",
        "        ftp.storbinary(f\"STOR {fn}\", fp)\n",
        "ftp.quit()\n",
        "print(\"✅ Uploaded CSV & HTML to server\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "xecfLjgt4h-y",
        "outputId": "796cf8d6-d41e-46f7-bbad-32c1d9d29fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/y_dna_user_detail_combo.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2430857946.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# ── 1) Load vertical data ─────────────────────────────────────────────────\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombo_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Rename “Date” → “Era”\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/y_dna_user_detail_combo.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## EXP\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from zoneinfo import ZoneInfo\n",
        "from ftplib import FTP_TLS\n",
        "\n",
        "# ── CONFIG ───────────────────────────────────────────────────────────────\n",
        "info_csv   = \"/content/haplogroup_info.csv\"\n",
        "user_csv   = \"/content/y_dna_user_detail.csv\"\n",
        "output_csv = \"/content/y_dna_grid.csv\"\n",
        "output_htm = \"/content/y_dna_grid.htm\"\n",
        "\n",
        "# ── 1) Load & prepare haplogroup info ───────────────────────────────────\n",
        "df_info = pd.read_csv(info_csv)\n",
        "if \"Date\" in df_info.columns:\n",
        "    df_info.rename(columns={\"Date\": \"Era\"}, inplace=True)\n",
        "df_info = df_info.loc[df_info[\"Haplogroup\"].drop_duplicates().index]\n",
        "hap_order = df_info[\"Haplogroup\"].tolist()\n",
        "era_map   = dict(zip(df_info[\"Haplogroup\"], df_info.get(\"Era\", [\"\"] * len(df_info))))\n",
        "\n",
        "# ── 2) Load user detail table ───────────────────────────────────────────\n",
        "df_users = pd.read_csv(user_csv)\n",
        "if \"User_ID\" not in df_users.columns:\n",
        "    df_users.rename(columns={df_users.columns[0]: \"User_ID\"}, inplace=True)\n",
        "user_chains = [\n",
        "    [str(v) for v in row.drop(labels=[\"User_ID\"]).tolist() if pd.notna(v) and str(v).strip()]\n",
        "    for _, row in df_users.iterrows()\n",
        "]\n",
        "\n",
        "# ── 3) Insert new SNPs after parent ──────────────────────────────────────\n",
        "for chain in user_chains:\n",
        "    prev = None\n",
        "    for h in chain:\n",
        "        if prev and h not in hap_order:\n",
        "            idx = hap_order.index(prev)\n",
        "            hap_order.insert(idx + 1, h)\n",
        "        prev = h\n",
        "# Build final eras list\n",
        "eras = [era_map.get(h, \"\") for h in hap_order]\n",
        "\n",
        "# ── 4) Build horizontal grid DataFrame ───────────────────────────────────\n",
        "for h in hap_order:\n",
        "    if h not in df_users.columns:\n",
        "        df_users[h] = \"\"\n",
        "df_grid_h = df_users[[\"User_ID\"] + hap_order]\n",
        "\n",
        "# ── 5) Transform to vertical layout ─────────────────────────────────────\n",
        "df_vert = df_grid_h.set_index(\"User_ID\").T\n",
        "# Insert Era as first column\n",
        "df_vert.insert(0, 'Era', eras)\n",
        "df_vert.index.name = 'SNP'\n",
        "df_grid = df_vert.reset_index()\n",
        "\n",
        "# ── 6) Save vertical CSV ─────────────────────────────────────────────────\n",
        "df_grid.to_csv(output_csv, index=False)\n",
        "print(f\"✅ Vertical grid CSV saved to {output_csv}\")\n",
        "\n",
        "# ── 7) Generate XHTML (vertical) ────────────────────────────────────────\n",
        "now = datetime.now(ZoneInfo(\"America/New_York\"))\n",
        "ts  = now.strftime(\"%-m/%-d/%y, %-I:%M %p EDT\")\n",
        "\n",
        "template = '''<!DOCTYPE html>\n",
        "<html><head><meta charset=\"UTF-8\"><title>Yates Y-DNA Grid</title>\n",
        "<style>\n",
        "  body { background:#faf9d3; font-family:Arial,Helvetica,sans-serif; font-size:14px; }\n",
        "  table { width:100%; border:1px solid #333; border-collapse:collapse; table-layout:auto; }\n",
        "  th { background:#333; color:#fff; padding:6px; border:1px solid #999; }\n",
        "  .era { background:#666; color:#eee; padding:6px; border:1px solid #999; font-size:0.9em; }\n",
        "  td { padding:6px; border:1px solid #999; text-align:center; white-space:nowrap; }\n",
        "  .match { background:#fff; }\n",
        "  .blank { background:#ccc; color:#ccc; }\n",
        "</style>\n",
        "</head><body>\n",
        "  <h1 style=\"text-align:center;\">Yates Y-DNA Grid</h1>\n",
        "  <table>\n",
        "'''  # end template\n",
        "\n",
        "# Build header row\n",
        "cols = df_grid.columns.tolist()\n",
        "header_html = '<tr><th>SNP</th><th>Era</th>' + ''.join(f'<th>{u}</th>' for u in cols[2:]) + '</tr>'\n",
        "\n",
        "# Build data rows\n",
        "rows_html = []\n",
        "for _, row in df_grid.iterrows():\n",
        "    cells = []\n",
        "    for u in cols[2:]:\n",
        "        v = row[u]\n",
        "        if pd.isna(v) or not str(v).strip():\n",
        "            cells.append('<td class=\"blank\">–</td>')\n",
        "        else:\n",
        "            cells.append(f'<td class=\"match\">{v}</td>')\n",
        "    rows_html.append(f'<tr><td>{row[\"SNP\"]}</td><td class=\"era\">{row[\"Era\"]}</td>' + ''.join(cells) + '</tr>')\n",
        "\n",
        "# Combine and save HTML\n",
        "html = template + header_html + '\\n' + '\\n'.join(rows_html) + f'''\n",
        "  </table>\n",
        "  <p style=\"text-align:right;font-size:0.9em;\">Updated: {ts}</p>\n",
        "</body>\n",
        "</html>'''\n",
        "with open(output_htm, 'w', encoding='utf-8') as f:\n",
        "    f.write(html)\n",
        "print(f\"✅ Vertical XHTML Grid saved to {output_htm}\")\n",
        "\n",
        "# ── 8) FTP Upload ───────────────────────────────────────────────────────\n",
        "ftp = FTP_TLS()\n",
        "ftp.connect(os.environ['FTP_HOST'], int(os.environ.get('FTP_PORT',21)))\n",
        "ftp.login(os.environ['FTP_USER'], os.environ['FTP_PASS'])\n",
        "ftp.prot_p()\n",
        "for path in [output_csv, output_htm]:\n",
        "    name = os.path.basename(path)\n",
        "    try: ftp.delete(name)\n",
        "    except: pass\n",
        "    with open(path,'rb') as fp:\n",
        "        ftp.storbinary(f\"STOR {name}\", fp)\n",
        "ftp.quit()\n",
        "print(\"✅ Uploaded to server.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFqM0kUliAqX",
        "outputId": "d6d54e4c-5b1c-497b-f896-757477e43e2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Vertical grid CSV saved to /content/y_dna_grid.csv\n",
            "✅ Vertical XHTML Grid saved to /content/y_dna_grid.htm\n",
            "✅ Uploaded to server.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Y-DNA cell 1\n",
        "\n",
        "# === Cell 1: New user settings ===\n",
        "USER_ID       = 'I56217'  # the new column header\n",
        "PATH_STRING   = (      # the SNP chain for this user\n",
        "    \"R-M207 > R-M173 > R-M343 > R-M269 > R-FT266064 > R-FT266579 > R-FTF17042\"\n",
        ")\n",
        "INSERT_MISSING = True       # if True, adds any SNPs from PATH_STRING that aren't yet rows\n",
        "MASTER_CSV     = '/content/y_dna_user_detail_combo.csv'\n",
        "UPDATED_CSV    = '/content/y_dna_user_detail_combo_updated.csv'\n"
      ],
      "metadata": {
        "id": "0bO8B-Gnls49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Load → Append User → Save\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# 1) Load the existing master CSV\n",
        "df = pd.read_csv(MASTER_CSV)\n",
        "\n",
        "# 2) Normalize the first column name to 'SNP' for easy matching\n",
        "first_col = df.columns[0]\n",
        "if first_col != 'SNP':\n",
        "    df.rename(columns={first_col: 'SNP'}, inplace=True)\n",
        "\n",
        "# 3) Parse the new user's SNP chain\n",
        "chain = PATH_STRING.split('>')\n",
        "\n",
        "# 4) Optionally insert any SNPs not yet present (appends at bottom)\n",
        "if INSERT_MISSING:\n",
        "    missing = [s for s in chain if s not in df['SNP'].values]\n",
        "    if missing:\n",
        "        df = pd.concat([df, pd.DataFrame([{'SNP': s} for s in missing])],\n",
        "                       ignore_index=True)\n",
        "\n",
        "# 5) Create the new user column in the next free position\n",
        "df[USER_ID] = ''\n",
        "\n",
        "# 6) Populate: copy the SNP value into that column where it matches the chain\n",
        "df.loc[df['SNP'].isin(chain), USER_ID] = df['SNP']\n",
        "\n",
        "# 7) Save the updated CSV back to /content\n",
        "df.to_csv(UPDATED_CSV, index=False)\n",
        "print(f\"✅ Updated CSV saved to {UPDATED_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tjd2-uEdmJKR",
        "outputId": "b6746fb3-cc40-4e7e-d787-d1a5ec09ad00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Updated CSV saved to /content/y_dna_user_detail_combo_updated.csv\n"
          ]
        }
      ]
    }
  ]
}