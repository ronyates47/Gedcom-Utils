{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXR4r2XWLhDUesOVKnp4eh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronyates47/Gedcom-Utils/blob/main/Copy_of_A_v_31_00_Done_stable_Primary_2023_gedcom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsVWCghMxefi",
        "outputId": "a0de0b35-0f5c-4e3c-81ac-73e48f3d2fc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically selecting the first GEDCOM file.\n",
            "GEDCOM contained 51159 total records\n",
            "Records tagged and filtered by NPFX: 420\n",
            "filtered_ids.xlsx not found. Skipping second-level manual filter.\n",
            "        ID#       Match to               Name    cM  \\\n",
            "407  I51018   yatesjohnrob      YatesTerriAnn   361   \n",
            "15   I18236   yatesjohnrob      YatesNelsonFr  3457   \n",
            "409  I51045   yatesjohnrob         RoweRhonda    19   \n",
            "408  I51034   yatesjohnrob     MillerCynthiaL    20   \n",
            "176  I47365  yatesjamesrob  AndersonSaralinda    13   \n",
            "..      ...            ...                ...   ...   \n",
            "411  I51055     adamssarah      AdamsNancyAnn  2393   \n",
            "412  I51064     adamssarah       GaleNorrisEd   240   \n",
            "410  I51054     adamssarah         Ellisetj62    60   \n",
            "415  I51098     adamssarah     CherryPaulaJea    11   \n",
            "414  I51090     adamssarah  SiemeringWilliamR    15   \n",
            "\n",
            "                                                  LUN#  \\\n",
            "407  <a href=\"https://yates.one-name.net/tng/vertic...   \n",
            "15   <a href=\"https://yates.one-name.net/tng/vertic...   \n",
            "409  <a href=\"https://yates.one-name.net/tng/vertic...   \n",
            "408  <a href=\"https://yates.one-name.net/tng/vertic...   \n",
            "176  <a href=\"https://yates.one-name.net/tng/vertic...   \n",
            "..                                                 ...   \n",
            "411  <a href=\"https://yates.one-name.net/tng/vertic...   \n",
            "412  <a href=\"https://yates.one-name.net/tng/vertic...   \n",
            "410  <a href=\"https://yates.one-name.net/tng/vertic...   \n",
            "415  <a href=\"https://yates.one-name.net/tng/vertic...   \n",
            "414  <a href=\"https://yates.one-name.net/tng/vertic...   \n",
            "\n",
            "                              Yates DNA Ancestral Line  \n",
            "407  YatesFrancis&TichborneJane~~YatesThomas&Stephe...  \n",
            "15   YatesFrancis&TichborneJane~~YatesThomas&Stephe...  \n",
            "409  YatesFrancis&TichborneJane~~YatesThomas&Stephe...  \n",
            "408  YatesFrancis&TichborneJane~~YatesThomas&Stephe...  \n",
            "176  YatesFrancis&TichborneJane~~YatesThomas&Stephe...  \n",
            "..                                                 ...  \n",
            "411  YatesFrancis&TichborneJane~~YatesThomas&Stephe...  \n",
            "412  YatesFrancis&TichborneJane~~YatesThomas&Stephe...  \n",
            "410  YatesFrancis&TichborneJane~~YatesThomas&Stephe...  \n",
            "415  YatesFrancis&TichborneJane~~YatesThomas&Stephe...  \n",
            "414  YatesFrancis&TichborneJane~~YatesThomas&Stephe...  \n",
            "\n",
            "[420 rows x 6 columns]\n",
            "=== Top 30 Parent Pairs (Frequency Count >= 3) ===\n",
            "                           Parent Pair  Frequency  Column #  Percentage\n",
            "0           YatesFrancis&TichborneJane        289         1          68\n",
            "1          YatesThomas&StephensDorothy        288         2          68\n",
            "2         YatesJohn&TettershalMaryEliz        232         3          55\n",
            "3                YatesGeorge&WellsMary        216         4          51\n",
            "4          YatesGeorge&WarfieldRachael        155         5          36\n",
            "5               YatesGeorge&GuineyAnne        129         6          30\n",
            "34             YatesJames&WebsterAgnes         56         3          13\n",
            "24           YatesJohn&TuckerElizabeth         53         5          12\n",
            "25          YatesJohn&KilgoreElizabeth         48         6          11\n",
            "251              YatesWilliam&TappMary         47         7          11\n",
            "173   YatesJohnThom&HatfieldeElizabeth         41         1           9\n",
            "52          YatesJosephWe&RiggMargaret         39         4           9\n",
            "6            YatesGeorge&LewisFrancesF         39         7           9\n",
            "53         YatesWilliam&GibsonNancyAnn         37         5           8\n",
            "174           YatesJohn&JobeGaithJoane         28         2           6\n",
            "15           YatesSamuel&GouldJohannah         25         6           5\n",
            "139                YatesJohn&SwiftMary         19         7           4\n",
            "54          YatesJamesHen&SanfordSarah         17         6           4\n",
            "140       YatesJohnE&RobersonElizabeth         17         8           4\n",
            "252        YatesBenjamin&ShockleySarah         17         8           4\n",
            "1326     YatesWilliam&WimberlyMaryPoll         16         8           3\n",
            "141          YatesJamesWil&OttMaryElle         15         9           3\n",
            "285          YatesStephen&ParsonsLydia         14         7           3\n",
            "112          YatesJohn&GainesElizabeth         13         8           3\n",
            "335            YatesRobertJo&DysonMary         12         2           2\n",
            "336    YatesJosephCh&MarcelisHuybertje         12         3           2\n",
            "156              YatesJohn&RoperJemima         11         7           2\n",
            "164        YatesJohn&BarfieldElizabeth         10         1           2\n",
            "175      SheltonWilliamJ&YatesHannahEv         10         3           2\n",
            "818          YatesJohn&ParkerElizabeth         10         4           2\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import glob\n",
        "from gedcom.element.individual import IndividualElement\n",
        "from gedcom.parser import Parser\n",
        "import pandas as pd\n",
        "\n",
        "anchor_gen1 = None\n",
        "\n",
        "class GedcomDataset:\n",
        "    def __init__(self, gen_person):\n",
        "        self.gen_person = gen_person\n",
        "        self.extractable_detail = {}\n",
        "        self.anchor_gen1 = None  # Initialize anchor_gen1 here\n",
        "\n",
        "    def add_extractable_detail(self, key, value):\n",
        "        self.extractable_detail[key] = value\n",
        "\n",
        "    def get_gen_person(self):\n",
        "        name = self.extractable_detail.get('NAME', '')\n",
        "        parts = name.split('/', 1)\n",
        "        first_name = parts[0].split(' ')[0]\n",
        "        last_name = parts[1].rstrip('/') if len(parts) > 1 else \"\"\n",
        "        self.anchor_gen1 = last_name.replace(\" \", \"\") + first_name.replace(\" \", \"\")\n",
        "        global anchor_gen1  # Declare that we're using the global variable\n",
        "        anchor_gen1 = self.anchor_gen1  # Update the global variable\n",
        "        return self.gen_person.strip('@')\n",
        "\n",
        "    def get_anchor_gen1(self):\n",
        "        return self.anchor_gen1\n",
        "\n",
        "    def get_extractable_NPFX(self):\n",
        "        return self.extractable_detail.get('NPFX', '')\n",
        "\n",
        "    def get_extractable_cm(self):\n",
        "        npfx_value = self.extractable_detail.get('NPFX', '')\n",
        "        if '&' in npfx_value:\n",
        "            cm_value = npfx_value.split('&')[0].strip()\n",
        "        else:\n",
        "            cm_value = npfx_value.strip()\n",
        "        try:\n",
        "            int(cm_value)\n",
        "            return cm_value\n",
        "        except ValueError:\n",
        "            return 'error'\n",
        "\n",
        "    def get_extractable_sort(self):\n",
        "        npfx_value = self.extractable_detail.get('NPFX', '')\n",
        "        if '&' in npfx_value:\n",
        "            sort_value = npfx_value.split('&')[1].strip()\n",
        "            return sort_value\n",
        "        else:\n",
        "            return ''\n",
        "\n",
        "    def get_extractable_FAMC(self):\n",
        "        return self.extractable_detail.get('FAMC', '').strip('@')\n",
        "\n",
        "# Function definitions\n",
        "def extract_id(record):\n",
        "    id_start = record.find('@') + 1\n",
        "    id_end = record.find('@', id_start)\n",
        "    return record[id_start:id_end]\n",
        "\n",
        "def extract_name(record):\n",
        "    name_start = record.find('1 NAME ') + 6\n",
        "    name_end = record.find('\\n', name_start)\n",
        "    name = record[name_start:name_end]\n",
        "    first_name, last_name = name.split('/', 1)\n",
        "    first_name = first_name[:10] # Use slicing syntax to extract the first 10 characters of the first_name variable\n",
        "    last_name = last_name[:10].rstrip('/') # Use slicing syntax to extract the first 10 characters of the last_name variable\n",
        "    return last_name.replace(\" \", \"\") + first_name.replace(\" \", \"\")\n",
        "\n",
        "name_to_id = {}   # Global dictionary to hold name to ID mapping\n",
        "\n",
        "class Gedcom:\n",
        "    def __init__(self, file_name):\n",
        "        self.file_name = file_name\n",
        "        self.gedcom_datasets = []\n",
        "        self.filter_pool = []\n",
        "\n",
        "    @staticmethod\n",
        "    def get_standard_name(file_path):\n",
        "        file_name = file_path.split('/')[-1]\n",
        "        if '.' in file_name:\n",
        "            file_name = file_name.rsplit('.', 1)[0]\n",
        "        standard_name = file_name.replace(' ', '_').lower()\n",
        "        return standard_name\n",
        "\n",
        "class Gedcom:\n",
        "    def __init__(self, file_name):\n",
        "        self.file_name = file_name\n",
        "        self.gedcom_datasets = []\n",
        "        self.filter_pool = []\n",
        "\n",
        "    def parse_gedcom(self):\n",
        "        global name_to_id  # Declare name_to_id as global to modify it\n",
        "        with open(self.file_name, 'r', encoding='utf-8-sig') as f:\n",
        "            gedcom_lines = f.readlines()\n",
        "        current_dataset = None\n",
        "        npfx_count = 0\n",
        "        total_count = 0\n",
        "\n",
        "        for line in gedcom_lines:\n",
        "            parts = line.strip().split(' ', 2)\n",
        "            level = int(parts[0])\n",
        "            tag = parts[1]\n",
        "            value = parts[2] if len(parts) > 2 else None\n",
        "\n",
        "            if level == 0 and tag.startswith('@') and tag.endswith('@') and value == 'INDI':\n",
        "                total_count += 1\n",
        "                current_dataset = GedcomDataset(tag)\n",
        "                self.gedcom_datasets.append(current_dataset)\n",
        "\n",
        "                # Populate name_to_id\n",
        "                individual_name = current_dataset.get_anchor_gen1()\n",
        "                individual_id = current_dataset.get_gen_person()\n",
        "                name_to_id[individual_name] = individual_id\n",
        "\n",
        "            elif current_dataset is not None:\n",
        "                if level == 1 and tag in ['NAME', 'FAMC']:\n",
        "                    current_key = tag\n",
        "                    current_dataset.add_extractable_detail(current_key, value)\n",
        "\n",
        "                elif level == 2 and tag == 'NPFX':\n",
        "                    npfx_count += 1\n",
        "                    current_dataset.add_extractable_detail(tag, value)\n",
        "\n",
        "        print(f'GEDCOM contained {total_count} total records')\n",
        "        print(f'Records tagged and filtered by NPFX: {npfx_count}')\n",
        "\n",
        "        # First level of filtering: Filter those with NPFX\n",
        "        for dataset in self.gedcom_datasets:\n",
        "            if dataset.get_extractable_NPFX():\n",
        "                self.filter_pool.append(dataset)\n",
        "\n",
        "        # Check if manual filtering should be applied\n",
        "        manual_filter_activated = True  # or False depending on your situation\n",
        "\n",
        "        # Second level of filtering: Apply manual filter from Excel sheet\n",
        "        if manual_filter_activated:\n",
        "            import pandas as pd  # Assuming you haven't imported it yet\n",
        "            try:\n",
        "                df = pd.read_excel('filtered_ids.xlsx')\n",
        "            except FileNotFoundError:\n",
        "                print(\"filtered_ids.xlsx not found. Skipping second-level manual filter.\")\n",
        "            else:\n",
        "                manual_filtered_ids = set(df['ID'])\n",
        "                print(f\"Manual filter IDs loaded: {len(manual_filtered_ids) - 1}\")\n",
        "\n",
        "                self.filter_pool = [dataset for dataset in self.filter_pool if dataset.get_gen_person() in manual_filtered_ids]\n",
        "                print(f\"After manual filter, total records: {len(self.filter_pool)}\")\n",
        "\n",
        "def input_prime_surname(last_prime_surname=None):\n",
        "    if last_prime_surname:\n",
        "        last_name = input(f\"Enter prime_surname (default: {last_prime_surname}): \")\n",
        "        if not last_name:\n",
        "            last_name = last_prime_surname\n",
        "    else:\n",
        "        last_name = input(\"Enter prime_surname: \")\n",
        "    return last_name\n",
        "\n",
        "def select_gedcom_file():\n",
        "    gedcom_files = glob.glob('*.ged')\n",
        "    if not gedcom_files:\n",
        "        print(\"No GEDCOM files found.\")\n",
        "        return None\n",
        "\n",
        "    print(\"Automatically selecting the first GEDCOM file.\")\n",
        "    return gedcom_files[0]\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            selected_num = int(input(\"Enter the number of the GEDCOM file you want to use: \"))\n",
        "            if 1 <= selected_num <= len(gedcom_files):\n",
        "                return gedcom_files[selected_num - 1]\n",
        "            else:\n",
        "                print(\"Invalid number. Please enter a valid number from the list.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a valid number.\")\n",
        "\n",
        "gedcom_file_path = select_gedcom_file() # Call the function to let the user select the GEDCOM file\n",
        "if gedcom_file_path:\n",
        "    # Use the selected GEDCOM file path to create an instance of the Gedcom class\n",
        "    gedcom_instance = Gedcom(gedcom_file_path)\n",
        "    gedcom_instance.parse_gedcom()\n",
        "\n",
        "    individuals = []  # Initialize the list of individuals\n",
        "\n",
        "    for dataset in gedcom_instance.filter_pool:    # Iterate over the filter_pool list,add each last name and ID to list\n",
        "        individual_id = dataset.get_gen_person()\n",
        "        last_name = dataset.get_anchor_gen1()\n",
        "        individuals.append((last_name, individual_id))\n",
        "\n",
        "#    print(f'Records tagged and filtered by NPFX: {len(individuals)}')\n",
        "\n",
        "    with open(gedcom_file_path, 'r') as file:    # Read the GEDCOM file and split it into individual and family records\n",
        "        data = file.read()\n",
        "    data = data.split('\\n0 ')\n",
        "    records = {extract_id(record): record for record in data}\n",
        "\n",
        "def has_both_parents(records, mother_id, father_id):\n",
        "    return mother_id in records and father_id in records\n",
        "\n",
        "visited_pairs = set()\n",
        "generation_table = []\n",
        "\n",
        "def find_parents(individual_id, generation, records):\n",
        "    if individual_id not in records:\n",
        "        return\n",
        "    record = records[individual_id]\n",
        "    famc_start = record.find('1 FAMC @') + 8\n",
        "    famc_end = record.find('@', famc_start)\n",
        "    famc_id = record[famc_start:famc_end]\n",
        "    if famc_id not in records:\n",
        "        return\n",
        "\n",
        "    fam_record = records[famc_id]\n",
        "    wife_start = fam_record.find('1 WIFE @') + 8\n",
        "    wife_end = fam_record.find('@', wife_start)\n",
        "    mother_id = fam_record[wife_start:wife_end]\n",
        "\n",
        "    husb_start = fam_record.find('1 HUSB @') + 8\n",
        "    husb_end = fam_record.find('@', husb_start)\n",
        "    father_id = fam_record[husb_start:husb_end]\n",
        "\n",
        "    if mother_id and mother_id in records and father_id and father_id in records:\n",
        "        parent_pair = (father_id, mother_id)\n",
        "        if parent_pair not in visited_pairs:\n",
        "            visited_pairs.add(parent_pair)\n",
        "            generation_table.append((generation, parent_pair))\n",
        "\n",
        "    if mother_id:\n",
        "        find_parents(mother_id, generation + 1, records)\n",
        "\n",
        "    if father_id:\n",
        "        find_parents(father_id, generation + 1, records)\n",
        "\n",
        "def extract_name(record):\n",
        "    name_start = record.find('1 NAME ') + 6\n",
        "    name_end = record.find('\\n', name_start)\n",
        "    name = record[name_start:name_end]\n",
        "    first_name, last_name = name.split('/', 1)\n",
        "    first_name = first_name[:10]\n",
        "    last_name = last_name[:10].rstrip('/')\n",
        "    return last_name.replace(\" \", \"\") + first_name.replace(\" \", \"\")\n",
        "\n",
        "def find_distant_ancestors(individual_id, records, path=None):\n",
        "    path = path if path is not None else []\n",
        "    if path is None:\n",
        "        path = [individual_id]\n",
        "    else:\n",
        "        path.append(individual_id)\n",
        "\n",
        "    if individual_id not in records:\n",
        "        return []\n",
        "\n",
        "    record = records[individual_id]\n",
        "    famc_start = record.find('1 FAMC @') + 8\n",
        "    famc_end = record.find('@', famc_start)\n",
        "    famc_id = record[famc_start:famc_end]\n",
        "\n",
        "    if famc_id not in records:\n",
        "        return [path]\n",
        "\n",
        "    fam_record = records[famc_id]\n",
        "    wife_start = fam_record.find('1 WIFE @') + 8\n",
        "    wife_end = fam_record.find('@', wife_start)\n",
        "    mother_id = fam_record[wife_start:wife_end]\n",
        "\n",
        "    husb_start = fam_record.find('1 HUSB @') + 8\n",
        "    husb_end = fam_record.find('@', husb_start)\n",
        "    father_id = fam_record[husb_start:husb_end]\n",
        "\n",
        "    if father_id is None and mother_id is None:\n",
        "        return [path]\n",
        "\n",
        "    paths = []\n",
        "    if father_id:\n",
        "        new_path = list(path)\n",
        "        paths.extend(find_distant_ancestors(father_id, records, new_path))\n",
        "\n",
        "    if mother_id:\n",
        "        new_path = list(path)\n",
        "        paths.extend(find_distant_ancestors(mother_id, records, new_path))\n",
        "\n",
        "#    print(f\"Distant ancestors paths for {individual_id}: {paths}\")\n",
        "\n",
        "    return paths\n",
        "filtered_datasets = gedcom_instance.filter_pool\n",
        "\n",
        "#global generation_table\n",
        "#global visited_pairs\n",
        "\n",
        "def calculate_score(distant_ancestors_paths, records):\n",
        "    name_paths = []\n",
        "    for path in distant_ancestors_paths:\n",
        "        name_path = [extract_name(records.get(id, '')) for id in path]\n",
        "        name_paths.append(name_path)\n",
        "\n",
        "    path_scores = {}\n",
        "    for idx, name_path in enumerate(name_paths):\n",
        "        score = 0\n",
        "        for generation, name in enumerate(name_path):\n",
        "            if 'Yates' in name:\n",
        "                score += 1 * (generation + 1)\n",
        "        path_scores[idx] = score\n",
        "\n",
        "    if path_scores:\n",
        "        winning_path_index = max(path_scores, key=path_scores.get)\n",
        "        winning_path_score = path_scores[winning_path_index]\n",
        "        winning_path_names = name_paths[winning_path_index]\n",
        "        winning_path_ids = distant_ancestors_paths[winning_path_index]\n",
        "    else:\n",
        "        winning_path_index = None\n",
        "        winning_path_score = 0\n",
        "        winning_path_names = []\n",
        "        winning_path_ids = []\n",
        "\n",
        "    return winning_path_score, winning_path_names, winning_path_ids\n",
        "\n",
        "def filter_ancestral_line(winning_path_ids, generation_table):\n",
        "    matching_table = []\n",
        "\n",
        "    for generation, pair in generation_table:\n",
        "        id1, id2 = pair\n",
        "        if id1 in winning_path_ids or id2 in winning_path_ids:\n",
        "            matching_table.append((generation, pair))\n",
        "\n",
        "    return matching_table\n",
        "\n",
        "def filter_ancestral_line(winning_path_ids, generation_table):\n",
        "    matching_table = []\n",
        "    for generation, pair in generation_table:\n",
        "        id1, id2 = pair\n",
        "        if id1 in winning_path_ids or id2 in winning_path_ids:\n",
        "            matching_table.append((generation, pair))\n",
        "    return matching_table\n",
        "\n",
        "# Main Loop\n",
        "for dataset in filtered_datasets:\n",
        "    individual_id = dataset.get_gen_person()\n",
        "\n",
        "    visited_pairs = set()\n",
        "    generation_table = []\n",
        "\n",
        "    find_parents(individual_id, 1, records)\n",
        "    distant_ancestors_paths = find_distant_ancestors(individual_id, records)\n",
        "    winning_path_score, winning_path_names, winning_path_ids = calculate_score(distant_ancestors_paths, records)\n",
        "    filtered_ancestral_line = filter_ancestral_line(winning_path_ids, generation_table)\n",
        "    filtered_ancestral_line.sort(key=lambda x: x[0])\n",
        "    filtered_ancestral_line_names = []\n",
        "    for generation, pair in filtered_ancestral_line:\n",
        "        name_pair = [extract_name(records.get(id, '')) for id in pair]\n",
        "        formatted_name_pair = f\"{name_pair[0]}&{name_pair[1]}\"\n",
        "        filtered_ancestral_line_names.append(formatted_name_pair)\n",
        "\n",
        "    filtered_ancestral_line_names.reverse()\n",
        "#    filtered_ancestral_line_str = \"|\".join(filtered_ancestral_line_names)\n",
        "#    print(f\"Filtered Ancestral Line for {individual_id}: {filtered_ancestral_line_str}\")\n",
        "\n",
        "def process_individual(individual_id, gedcom_instance, records):\n",
        "    global generation_table\n",
        "    global visited_pairs\n",
        "    global anchor_gen1  # Declare that we're using the global variable\n",
        "\n",
        "    generation_table = []\n",
        "    visited_pairs = set()\n",
        "\n",
        "    find_parents(individual_id, 1, records)\n",
        "    distant_ancestors_paths = find_distant_ancestors(individual_id, records)\n",
        "    winning_path_score, winning_path_names, winning_path_ids = calculate_score(distant_ancestors_paths, records)\n",
        "    filtered_ancestral_line = filter_ancestral_line(winning_path_ids, generation_table)\n",
        "    filtered_ancestral_line.sort(key=lambda x: x[0])\n",
        "    filtered_ancestral_line_names = []\n",
        "    for dataset in gedcom_instance.filter_pool:\n",
        "        if dataset.get_gen_person() == individual_id:\n",
        "            cm_value = dataset.get_extractable_cm()\n",
        "            sort_value = dataset.get_extractable_sort()\n",
        "            anchor_gen1 = dataset.get_anchor_gen1()  # Update anchor_gen1 locally here\n",
        "            break\n",
        "    else:\n",
        "        cm_value = 'N/A'\n",
        "        sort_value = 'N/A'\n",
        "\n",
        "    if anchor_gen1 is not None:\n",
        "        filtered_ancestral_line_names.insert(0, anchor_gen1)\n",
        "\n",
        "    for generation, pair in filtered_ancestral_line:\n",
        "        name_pair = [extract_name(records.get(id, '')) for id in pair]\n",
        "        formatted_name_pair = f\"{name_pair[0]}&{name_pair[1]}\"\n",
        "        filtered_ancestral_line_names.append(formatted_name_pair)\n",
        "\n",
        "    filtered_ancestral_line_names.reverse()\n",
        "    filtered_ancestral_line_str = \"~~\".join(filtered_ancestral_line_names)\n",
        "\n",
        "    individual_data = {\n",
        "        'cM': cm_value,\n",
        "        'Sort': sort_value,\n",
        "        'Filtered Ancestral Line': filtered_ancestral_line_str\n",
        "    }\n",
        "\n",
        "    return individual_data, filtered_ancestral_line_str\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Global variables\n",
        "visited_pairs = set()\n",
        "combined_df_rows = []  # Initialize your empty combined_df_rows list\n",
        "\n",
        "# Main Loop\n",
        "for dataset in gedcom_instance.filter_pool:  # Assuming filter_pool is iterable\n",
        "    individual_id = dataset.get_gen_person()\n",
        "\n",
        "    # Reset global variables for each new individual\n",
        "    visited_pairs.clear()\n",
        "    generation_table = []\n",
        "\n",
        "    # Process Individual and Get Data\n",
        "    individual_data, filtered_ancestral_line_str = process_individual(individual_id, gedcom_instance, records)\n",
        "    cm = individual_data['cM']\n",
        "    sort = individual_data['Sort']\n",
        "    individual_name = extract_name(records.get(individual_id, ''))\n",
        "    # Append to DataFrame Rows\n",
        "    combined_df_rows.append([individual_id, sort, individual_name, cm, filtered_ancestral_line_str])\n",
        "\n",
        "# Create DataFrame\n",
        "columns = ['ID#', 'Match to', 'Name', 'cM', 'Yates DNA Ancestral Line']\n",
        "combined_df = pd.DataFrame(combined_df_rows, columns=columns)\n",
        "\n",
        "# Initialize LUN# column\n",
        "combined_df['LUN#'] = combined_df['ID#']\n",
        "\n",
        "# Function to remove the named prefix from the 'Yates DNA Ancestral Line' column\n",
        "def remove_prefix(row):\n",
        "    ancestral_line = row['Yates DNA Ancestral Line']\n",
        "    prefix_to_remove = 'YatesRichard&AshendonJoan~~YatesJohn&HydeAlice~~YatesThomas&WhiteFrances~~'\n",
        "    if ancestral_line.startswith(prefix_to_remove):\n",
        "        row['Yates DNA Ancestral Line'] = ancestral_line[len(prefix_to_remove):]\n",
        "    return row\n",
        "\n",
        "# Apply the function to remove the prefix\n",
        "combined_df = combined_df.apply(remove_prefix, axis=1)\n",
        "\n",
        "# Function to add hotlinks\n",
        "def create_hotlink(row):\n",
        "    url_base = \"https://yates.one-name.net/tng/verticalchart.php?personID=\"\n",
        "    additional_params = \"&tree=tree1&parentset=0&display=vertical&generations=15\"\n",
        "    if '*' in row['LUN#']:\n",
        "        return f'<a href=\"{url_base}{row[\"ID#\"]}{additional_params}\">{row[\"LUN#\"]}</a>'\n",
        "    return f'<a href=\"{url_base}{row[\"ID#\"]}{additional_params}\">{row[\"ID#\"]}</a>'\n",
        "\n",
        "# Apply the hotlink function\n",
        "combined_df['LUN#'] = combined_df.apply(create_hotlink, axis=1)\n",
        "\n",
        "# Reorder Columns\n",
        "ordered_columns = ['ID#', 'Match to', 'Name', 'cM', 'LUN#', 'Yates DNA Ancestral Line']\n",
        "combined_df = combined_df[ordered_columns]\n",
        "\n",
        "# Update index and sort\n",
        "combined_df.index += 1\n",
        "combined_df.sort_values(by=['Match to', 'Yates DNA Ancestral Line'], ascending=[False, True], inplace=True)\n",
        "\n",
        "# Only keep this line for saving the DataFrame to Excel\n",
        "output_path = '/content/output.xlsx'\n",
        "combined_df.to_excel(output_path, index=False)\n",
        "\n",
        "# Print DataFrame\n",
        "print(combined_df)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "#STATS***********************\n",
        "\n",
        "def generate_pair_stats(df):\n",
        "    pair_count = {}\n",
        "    base_position = {}\n",
        "    total_rows = len(df)\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        ancestral_line = row['Yates DNA Ancestral Line']\n",
        "        pairs = ancestral_line.split('~~')\n",
        "\n",
        "        for pos, pair in enumerate(pairs, 1):\n",
        "            pair_count[pair] = pair_count.get(pair, 0) + 1\n",
        "\n",
        "            if pair not in base_position:\n",
        "                base_position[pair] = pos\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    stats_df = pd.DataFrame(list(pair_count.items()), columns=['Parent Pair', 'Frequency'])\n",
        "\n",
        "    # Add Base Position\n",
        "    stats_df['Column #'] = stats_df['Parent Pair'].map(base_position)\n",
        "\n",
        "    # Sort by Frequency\n",
        "    stats_df.sort_values(by=['Frequency', 'Column #'], ascending=[False, True], inplace=True)\n",
        "\n",
        "    # Add Percentage and convert to integer\n",
        "    stats_df['Percentage'] = (stats_df['Frequency'] / total_rows * 100).astype(int)\n",
        "\n",
        "    # Filter parent pairs with Frequency >= 3\n",
        "    stats_df = stats_df[stats_df['Frequency'] >= 3]\n",
        "\n",
        "    return stats_df\n",
        "\n",
        "# Assuming `combined_df` is your DataFrame with 419 rows\n",
        "stats_df = generate_pair_stats(combined_df)\n",
        "\n",
        "# Display the statistics\n",
        "#print(\"=== Parent Pair Statistics (Count >= 3) ===\")\n",
        "#print(stats_df)\n",
        "\n",
        "# Display the top 30 parent pairs based on frequency\n",
        "print(\"=== Top 30 Parent Pairs (Frequency Count >= 3) ===\")\n",
        "print(stats_df.head(30))\n",
        "\n",
        "# DATA********************************************\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Bar Chart: Top 20 parent pairs by frequency\n",
        "#plt.figure(figsize=(15, 8))\n",
        "#stats_df.head(20).plot(x='Parent Pair', y='Frequency', kind='bar', color='teal', edgecolor='black')\n",
        "#plt.title(\"Top 20 Parent Pairs by Frequency\")\n",
        "#plt.ylabel(\"Frequency\")\n",
        "#plt.xlabel(\"Parent Pair\")\n",
        "#plt.xticks(rotation=45, ha=\"right\")\n",
        "#plt.tight_layout()\n",
        "#plt.show()\n",
        "\n",
        "# Pie Chart: Distribution of top 10 parent pairs by frequency\n",
        "#plt.figure(figsize=(12, 12))\n",
        "#top_pairs.set_index(\"Parent Pair\")['Frequency'].plot.pie(startangle=90, autopct='%1.1f%%', wedgeprops=dict(width=0.3))\n",
        "#plt.title(\"Distribution of Top 10 Parent Pairs by Frequency\")\n",
        "#plt.ylabel(None)\n",
        "#plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install python-gedcom\n",
        "!pip install openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik3CzJtgxuXH",
        "outputId": "2a74f9e3-b3c8-4b97-f70a-364523473f2f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Collecting python-gedcom\n",
            "  Downloading python_gedcom-1.0.0-py2.py3-none-any.whl (35 kB)\n",
            "Installing collected packages: python-gedcom\n",
            "Successfully installed python-gedcom-1.0.0\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n"
          ]
        }
      ]
    }
  ]
}