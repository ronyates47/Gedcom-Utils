{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtdBp9cXQRF6prlaTpDgFq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronyates47/Gedcom-Utils/blob/main/A_v_18_Yates_Primary_2023_gedcom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsVWCghMxefi",
        "outputId": "f9ecb4b2-6604-42af-a056-270af5d86112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically selecting the first GEDCOM file.\n",
            "GEDCOM contained 50938 total records\n",
            "Records tagged and filtered by NPFX: 400\n",
            "filtered_ids.xlsx not found. Skipping second-level manual filter.\n",
            "        ID#       Match to              Name   cM  \\\n",
            "165  I47241  yatesjamesrob   StanleyMiltonTh   16   \n",
            "170  I47306  yatesjamesrob      MyersDianaJo   15   \n",
            "179  I47416  yatesjamesrob  StrattonJudithMa   17   \n",
            "386  I50806  yatesjamesrob   SummerfielJason  260   \n",
            "174  I47350  yatesjamesrob       LaxTinaMari   13   \n",
            "..      ...            ...               ...  ...   \n",
            "365  I50364  addison,david  HumphriesBrandon   18   \n",
            "364  I50355  addison,david     HunterSamuelF   19   \n",
            "362  I50309  addison,david     YatesDonaldFr   13   \n",
            "366  I50369  addison,david    MillerMyraBell   13   \n",
            "367  I50375  addison,david      MyersRichard   15   \n",
            "\n",
            "                                                  LUN#  \\\n",
            "165  <a href=\"https://yates.one-name.net/tng/vertic...   \n",
            "170  <a href=\"https://yates.one-name.net/tng/vertic...   \n",
            "179  <a href=\"https://yates.one-name.net/tng/vertic...   \n",
            "386  <a href=\"https://yates.one-name.net/tng/vertic...   \n",
            "174  <a href=\"https://yates.one-name.net/tng/vertic...   \n",
            "..                                                 ...   \n",
            "365  <a href=\"https://yates.one-name.net/tng/vertic...   \n",
            "364  <a href=\"https://yates.one-name.net/tng/vertic...   \n",
            "362  <a href=\"https://yates.one-name.net/tng/vertic...   \n",
            "366  <a href=\"https://yates.one-name.net/tng/vertic...   \n",
            "367  <a href=\"https://yates.one-name.net/tng/vertic...   \n",
            "\n",
            "                              Yates DNA Ancestral Line  \n",
            "165  YatesJohn~YatesLukeBarf~YatesElizabeth~LeeBenj...  \n",
            "170  YatesRichard~YatesJohn~YatesThomas~YatesFranci...  \n",
            "179  YatesRichard~YatesJohn~YatesThomas~YatesFranci...  \n",
            "386  YatesRichard~YatesJohn~YatesThomas~YatesFranci...  \n",
            "174  YatesRichard~YatesJohn~YatesThomas~YatesFranci...  \n",
            "..                                                 ...  \n",
            "365  YatesRichard~YatesJohn~YatesThomas~YatesFranci...  \n",
            "364  YatesRichard~YatesJohn~YatesThomas~YatesFranci...  \n",
            "362  YatesRichard~YatesJohn~YatesThomas~YatesFranci...  \n",
            "366  YatesThomas~YatesWilliam~YatesThomas~YatesNeze...  \n",
            "367  YatesThomas~YatesWilliam~YatesThomas~YatesNeze...  \n",
            "\n",
            "[400 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import glob\n",
        "from gedcom.element.individual import IndividualElement\n",
        "from gedcom.parser import Parser\n",
        "import pandas as pd\n",
        "\n",
        "class GedcomDataset:\n",
        "    def __init__(self, gen_person):\n",
        "        self.gen_person = gen_person\n",
        "        self.extractable_detail = {}\n",
        "\n",
        "    def add_extractable_detail(self, key, value):\n",
        "        self.extractable_detail[key] = value\n",
        "\n",
        "    def get_gen_person(self):\n",
        "        name = self.extractable_detail.get('NAME', '')\n",
        "        parts = name.split('/', 1)\n",
        "        first_name = parts[0].split(' ')[0]\n",
        "        last_name = parts[1].rstrip('/') if len(parts) > 1 else \"\"\n",
        "        self.anchor_gen1 = last_name.replace(\" \", \"\") + first_name.replace(\" \", \"\")\n",
        "        return self.gen_person.strip('@')\n",
        "\n",
        "    def get_anchor_gen1(self):\n",
        "        return self.anchor_gen1\n",
        "\n",
        "    def get_extractable_NPFX(self):\n",
        "        return self.extractable_detail.get('NPFX', '')\n",
        "\n",
        "    def get_extractable_cm(self):\n",
        "        npfx_value = self.extractable_detail.get('NPFX', '')\n",
        "        if '&' in npfx_value:\n",
        "            cm_value = npfx_value.split('&')[0].strip()\n",
        "        else:\n",
        "            cm_value = npfx_value.strip()\n",
        "        try:\n",
        "            int(cm_value)\n",
        "            return cm_value\n",
        "        except ValueError:\n",
        "            return 'error'\n",
        "\n",
        "    def get_extractable_sort(self):\n",
        "        npfx_value = self.extractable_detail.get('NPFX', '')\n",
        "        if '&' in npfx_value:\n",
        "            sort_value = npfx_value.split('&')[1].strip()\n",
        "            return sort_value\n",
        "        else:\n",
        "            return ''\n",
        "\n",
        "    def get_extractable_FAMC(self):\n",
        "        return self.extractable_detail.get('FAMC', '').strip('@')\n",
        "\n",
        "# Function definitions\n",
        "def extract_id(record):\n",
        "    id_start = record.find('@') + 1\n",
        "    id_end = record.find('@', id_start)\n",
        "    return record[id_start:id_end]\n",
        "\n",
        "def extract_name(record):\n",
        "    name_start = record.find('1 NAME ') + 6\n",
        "    name_end = record.find('\\n', name_start)\n",
        "    name = record[name_start:name_end]\n",
        "    first_name, last_name = name.split('/', 1)\n",
        "    first_name = first_name[:10] # Use slicing syntax to extract the first 10 characters of the first_name variable\n",
        "    last_name = last_name[:10].rstrip('/') # Use slicing syntax to extract the first 10 characters of the last_name variable\n",
        "    return last_name.replace(\" \", \"\") + first_name.replace(\" \", \"\")\n",
        "\n",
        "class Gedcom:\n",
        "    def __init__(self, file_name):\n",
        "        self.file_name = file_name\n",
        "        self.gedcom_datasets = []\n",
        "        self.filter_pool = []\n",
        "\n",
        "    @staticmethod\n",
        "    def get_standard_name(file_path):\n",
        "        file_name = file_path.split('/')[-1]\n",
        "        if '.' in file_name:\n",
        "            file_name = file_name.rsplit('.', 1)[0]\n",
        "        standard_name = file_name.replace(' ', '_').lower()\n",
        "        return standard_name\n",
        "\n",
        "    def parse_gedcom(self):  # Note the correct indentation here\n",
        "        with open(self.file_name, 'r', encoding='utf-8-sig') as f:\n",
        "            gedcom_lines = f.readlines()\n",
        "        current_dataset = None\n",
        "        npfx_count = 0\n",
        "        total_count = 0\n",
        "        for line in gedcom_lines:\n",
        "            parts = line.strip().split(' ', 2)\n",
        "            level = int(parts[0])\n",
        "            tag = parts[1]\n",
        "            value = parts[2] if len(parts) > 2 else None\n",
        "\n",
        "            if level == 0 and tag.startswith('@') and tag.endswith('@') and value == 'INDI':\n",
        "                total_count += 1\n",
        "                current_dataset = GedcomDataset(tag)\n",
        "                self.gedcom_datasets.append(current_dataset)\n",
        "#                print(f\"New individual dataset created with tag {tag}\")\n",
        "            elif current_dataset is not None:\n",
        "                if level == 1 and tag in ['NAME', 'FAMC']:\n",
        "                    current_key = tag\n",
        "                    current_dataset.add_extractable_detail(current_key, value)\n",
        "#                    print(f\"Added detail: {current_key} = {value}\")\n",
        "                elif level == 2 and tag == 'NPFX':\n",
        "                    npfx_count += 1\n",
        "                    current_dataset.add_extractable_detail(tag, value)\n",
        "#                    print(f\"Added NPFX: {value}\")\n",
        "\n",
        "        print(f'GEDCOM contained {total_count} total records')\n",
        "        print(f'Records tagged and filtered by NPFX: {npfx_count}')\n",
        "\n",
        "        # First level of filtering: Filter those with NPFX\n",
        "        for dataset in self.gedcom_datasets:\n",
        "            if dataset.get_extractable_NPFX():\n",
        "                self.filter_pool.append(dataset)\n",
        "\n",
        "        # Check if manual filtering should be applied\n",
        "        manual_filter_activated = True  # or False depending on your situation\n",
        "\n",
        "        # Second level of filtering: Apply manual filter from Excel sheet\n",
        "        if manual_filter_activated:\n",
        "            import pandas as pd  # Assuming you haven't imported it yet\n",
        "            try:\n",
        "                df = pd.read_excel('filtered_ids.xlsx')\n",
        "            except FileNotFoundError:\n",
        "                print(\"filtered_ids.xlsx not found. Skipping second-level manual filter.\")\n",
        "            else:\n",
        "                manual_filtered_ids = set(df['ID'])\n",
        "                print(f\"Manual filter IDs loaded: {len(manual_filtered_ids) - 1}\")\n",
        "\n",
        "                self.filter_pool = [dataset for dataset in self.filter_pool if dataset.get_gen_person() in manual_filtered_ids]\n",
        "                print(f\"After manual filter, total records: {len(self.filter_pool)}\")\n",
        "\n",
        "def input_prime_surname(last_prime_surname=None):\n",
        "    if last_prime_surname:\n",
        "        last_name = input(f\"Enter prime_surname (default: {last_prime_surname}): \")\n",
        "        if not last_name:\n",
        "            last_name = last_prime_surname\n",
        "    else:\n",
        "        last_name = input(\"Enter prime_surname: \")\n",
        "    return last_name\n",
        "\n",
        "def select_gedcom_file():\n",
        "    gedcom_files = glob.glob('*.ged')\n",
        "    if not gedcom_files:\n",
        "        print(\"No GEDCOM files found.\")\n",
        "        return None\n",
        "\n",
        "    print(\"Automatically selecting the first GEDCOM file.\")\n",
        "    return gedcom_files[0]\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            selected_num = int(input(\"Enter the number of the GEDCOM file you want to use: \"))\n",
        "            if 1 <= selected_num <= len(gedcom_files):\n",
        "                return gedcom_files[selected_num - 1]\n",
        "            else:\n",
        "                print(\"Invalid number. Please enter a valid number from the list.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a valid number.\")\n",
        "\n",
        "gedcom_file_path = select_gedcom_file() # Call the function to let the user select the GEDCOM file\n",
        "if gedcom_file_path:\n",
        "    # Use the selected GEDCOM file path to create an instance of the Gedcom class\n",
        "    gedcom_instance = Gedcom(gedcom_file_path)\n",
        "    gedcom_instance.parse_gedcom()\n",
        "\n",
        "    individuals = []  # Initialize the list of individuals\n",
        "\n",
        "    for dataset in gedcom_instance.filter_pool:    # Iterate over the filter_pool list,add each last name and ID to list\n",
        "        individual_id = dataset.get_gen_person()\n",
        "        last_name = dataset.get_anchor_gen1()\n",
        "        individuals.append((last_name, individual_id))\n",
        "\n",
        "#    print(f'Records tagged and filtered by NPFX: {len(individuals)}')\n",
        "\n",
        "    with open(gedcom_file_path, 'r') as file:    # Read the GEDCOM file and split it into individual and family records\n",
        "        data = file.read()\n",
        "    data = data.split('\\n0 ')\n",
        "    records = {extract_id(record): record for record in data}\n",
        "\n",
        "def has_both_parents(records, mother_id, father_id):\n",
        "    return mother_id in records and father_id in records\n",
        "\n",
        "def find_parents(individual_id, generation, records):\n",
        "    if individual_id not in records:\n",
        "        return\n",
        "    record = records[individual_id]\n",
        "    famc_start = record.find('1 FAMC @') + 8\n",
        "    famc_end = record.find('@', famc_start)\n",
        "    famc_id = record[famc_start:famc_end]\n",
        "    if famc_id not in records:\n",
        "        return\n",
        "\n",
        "    fam_record = records[famc_id]\n",
        "    wife_start = fam_record.find('1 WIFE @') + 8\n",
        "    wife_end = fam_record.find('@', wife_start)\n",
        "    mother_id = fam_record[wife_start:wife_end]\n",
        "\n",
        "    husb_start = fam_record.find('1 HUSB @') + 8\n",
        "    husb_end = fam_record.find('@', husb_start)\n",
        "    father_id = fam_record[husb_start:husb_end]\n",
        "\n",
        "    if mother_id and mother_id in records:\n",
        "        mother_record = records[mother_id]\n",
        "        mother_name = extract_name(mother_record)\n",
        "    else:\n",
        "        mother_name = None\n",
        "\n",
        "    if father_id and father_id in records:\n",
        "        father_record = records[father_id]\n",
        "        father_name = extract_name(father_record)\n",
        "    else:\n",
        "        father_name = None\n",
        "\n",
        "    if mother_name is not None and father_name is not None:\n",
        "        parent_pair = father_name + \"&\" + mother_name\n",
        "        if parent_pair not in visited_pairs:\n",
        "            visited_pairs.add(parent_pair)\n",
        "            if has_both_parents(records, mother_id, father_id):\n",
        "                generation_table.loc[len(generation_table)] = [generation, parent_pair]\n",
        "\n",
        "    if mother_id:\n",
        "        find_parents(mother_id, generation + 1, records)\n",
        "\n",
        "    if father_id:\n",
        "        find_parents(father_id, generation + 1, records)\n",
        "\n",
        "def extract_name(record):\n",
        "    name_start = record.find('1 NAME ') + 6\n",
        "    name_end = record.find('\\n', name_start)\n",
        "    name = record[name_start:name_end]\n",
        "    first_name, last_name = name.split('/', 1)\n",
        "    first_name = first_name[:10]\n",
        "    last_name = last_name[:10].rstrip('/')\n",
        "    return last_name.replace(\" \", \"\") + first_name.replace(\" \", \"\")\n",
        "\n",
        "def find_distant_ancestors(individual_id, records, path=None):\n",
        "    if path is None:\n",
        "        path = [individual_id]\n",
        "    else:\n",
        "        path.append(individual_id)\n",
        "\n",
        "    if individual_id not in records:\n",
        "        return []\n",
        "\n",
        "    record = records[individual_id]\n",
        "    famc_start = record.find('1 FAMC @') + 8\n",
        "    famc_end = record.find('@', famc_start)\n",
        "    famc_id = record[famc_start:famc_end]\n",
        "\n",
        "    if famc_id not in records:\n",
        "        return [path]\n",
        "\n",
        "    fam_record = records[famc_id]\n",
        "    wife_start = fam_record.find('1 WIFE @') + 8\n",
        "    wife_end = fam_record.find('@', wife_start)\n",
        "    mother_id = fam_record[wife_start:wife_end]\n",
        "\n",
        "    husb_start = fam_record.find('1 HUSB @') + 8\n",
        "    husb_end = fam_record.find('@', husb_start)\n",
        "    father_id = fam_record[husb_start:husb_end]\n",
        "\n",
        "    if father_id is None and mother_id is None:\n",
        "        return [path]\n",
        "\n",
        "    paths = []\n",
        "    if father_id:\n",
        "        new_path = list(path)\n",
        "        paths.extend(find_distant_ancestors(father_id, records, new_path))\n",
        "\n",
        "    if mother_id:\n",
        "        new_path = list(path)\n",
        "        paths.extend(find_distant_ancestors(mother_id, records, new_path))\n",
        "\n",
        "    return paths\n",
        "filtered_datasets = gedcom_instance.filter_pool\n",
        "\n",
        "# Additional Function to isolate score calculation logic\n",
        "def calculate_score(distant_ancestors_paths, records):\n",
        "    name_paths = []\n",
        "    for path in distant_ancestors_paths:\n",
        "        name_path = [extract_name(records.get(id, '')) for id in path]\n",
        "        name_paths.append(name_path)\n",
        "\n",
        "    path_scores = {}\n",
        "    for idx, name_path in enumerate(name_paths):\n",
        "        score = 0\n",
        "        for generation, name in enumerate(name_path):\n",
        "            if 'Yates' in name:\n",
        "                score += 1 * (generation + 1)\n",
        "        path_scores[idx] = score\n",
        "\n",
        "    if path_scores:\n",
        "        winning_path_index = max(path_scores, key=path_scores.get)\n",
        "        winning_path_score = path_scores[winning_path_index]\n",
        "        winning_path_names = name_paths[winning_path_index]\n",
        "    else:\n",
        "        winning_path_index = None\n",
        "        winning_path_score = 0\n",
        "        winning_path_names = []\n",
        "\n",
        "    return winning_path_score, winning_path_names\n",
        "\n",
        "# Start your main loop\n",
        "for dataset in filtered_datasets:\n",
        "    individual_id = dataset.get_gen_person()\n",
        "    distant_ancestors_paths = find_distant_ancestors(individual_id, records)\n",
        "\n",
        "    # Calculate score\n",
        "    winning_path_score, winning_path_names = calculate_score(distant_ancestors_paths, records)\n",
        "\n",
        "    # Translate IDs to Names\n",
        "    name_paths = []\n",
        "    for path in distant_ancestors_paths:\n",
        "        name_path = [extract_name(records.get(id, '')) for id in path]\n",
        "        name_paths.append(name_path)\n",
        "\n",
        "    # Reverse the names for output formatting\n",
        "    winning_path_names.reverse()\n",
        "\n",
        "    # After score calculation, you do your output formatting\n",
        "    spouse_names = ['322'] * len(winning_path_names)\n",
        "    formatted_names = [f\"{name}&{spouse}\" for name, spouse in zip(winning_path_names, spouse_names)]\n",
        "    final_output = \"|\".join(formatted_names)\n",
        "\n",
        "# Inside your existing process_individual function\n",
        "def process_individual(individual_id, gedcom_instance, records):\n",
        "    global generation_table\n",
        "    global visited_pairs\n",
        "\n",
        "    # Resetting the variables for each individual\n",
        "    generation_table = pd.DataFrame(columns=['Generation', 'Parent Pair'])\n",
        "    visited_pairs = set()\n",
        "\n",
        "    # No recursive call here; simply proceed with the rest of the function\n",
        "    find_parents(individual_id, 1, records)\n",
        "    distant_ancestors_paths = find_distant_ancestors(individual_id, records)\n",
        "\n",
        "    # Call the isolated score calculation function\n",
        "    winning_path_score, winning_path_names = calculate_score(distant_ancestors_paths, records)\n",
        "\n",
        "    for dataset in records:  # Use passed-in records instead of gedcom_instance.filter_pool\n",
        "        if dataset.get_gen_person() == individual_id:\n",
        "            anchor_gen1 = dataset.get_anchor_gen1()\n",
        "            generation_table.loc[0] = [1, anchor_gen1]\n",
        "            break\n",
        "\n",
        "    winning_path_score, winning_path_names = calculate_score(distant_ancestors_paths, records)    # Call the isolated score calculation function\n",
        "\n",
        "    individual_data = {}\n",
        "    for dataset in gedcom_instance.filter_pool:\n",
        "        if dataset.get_gen_person() == individual_id:\n",
        "            individual_data['cM'] = dataset.get_extractable_cm()\n",
        "            individual_data['Sort'] = dataset.get_extractable_sort()\n",
        "            break  # Update for multiple records. The score and filtered line do not come from here...\n",
        "\n",
        "    filtered_parent_pairs = [row['Parent Pair'] for index, row in generation_table.iterrows() if any(parent in final_output for parent in row['Parent Pair'].split())]\n",
        "    selected_dna_branch_parents = set(parent.split('&')[0] for parent in final_output.split('|'))\n",
        "\n",
        "    filtered_parent_pairs = {}\n",
        "    for index, row in generation_table.iterrows():\n",
        "        generation = row['Generation']\n",
        "        parent_pair = row['Parent Pair']\n",
        "        for parent in parent_pair.split('&'):\n",
        "            if parent in selected_dna_branch_parents:\n",
        "                filtered_parent_pairs[generation] = parent_pair\n",
        "                break\n",
        "\n",
        "    # Convert filtered_parent_pairs to a string format, omitting generation numbers\n",
        "    filtered_parent_pairs_str = '|'.join(filtered_parent_pairs.values())\n",
        "    individual_data['Filtered Ancestral Line'] = filtered_parent_pairs_str    # Add it to individual_data\n",
        "\n",
        "    return individual_data\n",
        "\n",
        "\n",
        "#print(final_output)\n",
        "#filtered_parent_pairs = [row['370-Parent Pair'] for index, row in generation_table.iterrows() if any(parent in final_output for parent in row['Parent Pair'].split())]\n",
        "#print(filtered_parent_pairs)\n",
        "#for index, row in generation_table.iterrows():\n",
        "#    print(\"373-Parent Pair in generation_table:\", row['Parent Pair'].split())\n",
        "#    print(\"374-Parent in final_output:\", [parent for parent in row['Parent Pair'].split() if parent in final_output])\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Global variables\n",
        "visited_pairs = set()\n",
        "\n",
        "# Assuming gedcom_instance and path_scores variables are already defined\n",
        "filtered_individuals = [(dataset.get_anchor_gen1(), dataset.get_gen_person()) for dataset in gedcom_instance.filter_pool]\n",
        "\n",
        "combined_df_rows = []  # Initialize your empty combined_df_rows list\n",
        "\n",
        "# Start your main loop\n",
        "for dataset in filtered_datasets:\n",
        "    individual_id = dataset.get_gen_person()\n",
        "    individual_name = extract_name(records.get(individual_id, ''))\n",
        "\n",
        "    distant_ancestors_paths = find_distant_ancestors(individual_id, records)\n",
        "    winning_path_score, winning_path_names = calculate_score(distant_ancestors_paths, records)\n",
        "\n",
        "    # Translate IDs to Names\n",
        "    name_paths = []\n",
        "    for path in distant_ancestors_paths:\n",
        "        name_path = [extract_name(records.get(id, '')) for id in path]\n",
        "        name_paths.append(name_path)\n",
        "\n",
        "    winning_path_names.reverse()    # Reverse the names for output formatting\n",
        "\n",
        "    formatted_names = [f\"{name}\" for name in winning_path_names]\n",
        "    final_output = \"~\".join(formatted_names)\n",
        "\n",
        "    individual_data = process_individual(individual_id, gedcom_instance, gedcom_instance.filter_pool)\n",
        "    cm = individual_data['cM']\n",
        "    sort = individual_data['Sort']\n",
        "\n",
        "    # Swapping the positions of 'individual_name' and 'sort' in the output\n",
        "    combined_df_rows.append([individual_id, sort, individual_name, cm, final_output])\n",
        "\n",
        "# Define whether to use hotlinks or not\n",
        "USE_HOTLINK = True  # Set this to False if you don't want to use hotlinks\n",
        "\n",
        "def create_hotlink(row):\n",
        "    if USE_HOTLINK:\n",
        "        url_base = \"https://yates.one-name.net/tng/verticalchart.php?personID=\"\n",
        "        additional_params = \"&tree=tree1&parentset=0&display=vertical&generations=15\"\n",
        "        person_id = row['ID#']\n",
        "        hotlink_url = f'{url_base}{person_id}{additional_params}'\n",
        "        return f'<a href=\"{hotlink_url}\">{person_id}</a>'\n",
        "    else:\n",
        "        return row['ID#']\n",
        "\n",
        "combined_df = pd.DataFrame(combined_df_rows, columns=['ID#', 'Match to', 'Name', 'cM', 'Yates DNA Ancestral Line'])  # Excluded 'Score' from columns\n",
        "\n",
        "combined_df['LUN#'] = combined_df.apply(lambda row: create_hotlink(row), axis=1)\n",
        "\n",
        "ordered_columns = ['ID#', 'Match to', 'Name', 'cM', 'LUN#', 'Yates DNA Ancestral Line']  # Removed 'Score' from ordered columns\n",
        "combined_df = combined_df[ordered_columns]\n",
        "\n",
        "combined_df.index = combined_df.index + 1\n",
        "\n",
        "# Sort the DataFrame as you wanted\n",
        "combined_df = combined_df.sort_values(by=['Match to', 'Yates DNA Ancestral Line'], ascending=[False, True])\n",
        "\n",
        "print(combined_df)\n",
        "\n",
        "combined_df.to_excel('/content/output.xlsx', index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install python-gedcom\n",
        "!pip install openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik3CzJtgxuXH",
        "outputId": "2a8b10a4-0cd2-4516-e670-4c86aa6c9f45"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Collecting python-gedcom\n",
            "  Downloading python_gedcom-1.0.0-py2.py3-none-any.whl (35 kB)\n",
            "Installing collected packages: python-gedcom\n",
            "Successfully installed python-gedcom-1.0.0\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n"
          ]
        }
      ]
    }
  ]
}