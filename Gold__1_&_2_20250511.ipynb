{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgC4yXKov5YBM87kcoCJbM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronyates47/Gedcom-Utils/blob/main/Gold__1_%26_2_20250511.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT5s4n9S5ZpZ",
        "outputId": "3bd02dda-1ca7-4bb5-8446-399f699ca14e",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting python-gedcom\n",
            "  Downloading python_gedcom-1.0.0-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Downloading python_gedcom-1.0.0-py2.py3-none-any.whl (35 kB)\n",
            "Installing collected packages: python-gedcom\n",
            "Successfully installed python-gedcom-1.0.0\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "Downloading XlsxWriter-3.2.3-py3-none-any.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.3\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.11/dist-packages (0.23.4)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.15.3)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.1->mlxtend) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install python-gedcom\n",
        "!pip install openpyxl\n",
        "!pip install xlsxwriter\n",
        "!pip install mlxtend\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#credentials\n",
        "\n",
        "import os\n",
        "\n",
        "# Gmail SMTP creds\n",
        "os.environ['GMAIL_USER']         = 'yatesvilleron@gmail.com'\n",
        "os.environ['GMAIL_APP_PASSWORD'] = 'qtziwiblytgrlzvx'\n",
        "\n",
        "# FTPS upload creds — make sure FTP_PASS is exactly your password, no < or >\n",
        "os.environ['FTP_HOST']       = 'ftp.one-name.net'\n",
        "os.environ['FTP_PORT']       = '21'\n",
        "os.environ['FTP_USER']       = 'admin@yates.one-name.net'\n",
        "os.environ['FTP_PASS']       = 'v(i83lfQB@dB'\n"
      ],
      "metadata": {
        "id": "971jlPTnBVfk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1 20250513\n",
        "#!/usr/bin/env python\n",
        "\"\"\"\n",
        "GEDCOM Composite Score Script using:\n",
        " - Chunk-based Parallel Processing for Speed (Stage 1: genealogical line creation)\n",
        " - A Trie-based approach, then final \"Value\" = 5 * (number of couples with node.count >=2) + (total couples)\n",
        "\n",
        "For ancestral lines where none of the couples are repeated (a one-off line), the Value is still computed.\n",
        "Now, instead of composite scoring, two new columns are added:\n",
        "  - Value Range (the numeric bracket)\n",
        "  - Value Label (a descriptive label)\n",
        "\n",
        "Exports final CSV/HTML sorted by \"Yates DNA Ancestral Line\", including a 'haplogroup' column.\n",
        "\"\"\"\n",
        "import csv\n",
        "import glob\n",
        "import logging\n",
        "import functools\n",
        "import os\n",
        "from datetime import datetime\n",
        "from collections import defaultdict, Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from tqdm import tqdm\n",
        "from IPython.display import display, Javascript\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "###############################################################################\n",
        "# Global Variables\n",
        "###############################################################################\n",
        "anchor_gen1 = None\n",
        "visited_pairs = set()\n",
        "generation_table = []\n",
        "\n",
        "###############################################################################\n",
        "# Trie Data Structure\n",
        "###############################################################################\n",
        "class TrieNode:\n",
        "    \"\"\"A simple Trie node for storing a couple and counting how many lines pass here.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.count = 0\n",
        "        self.children = {}\n",
        "\n",
        "class Trie:\n",
        "    def __init__(self):\n",
        "        self.root = TrieNode()\n",
        "\n",
        "    def insert_line(self, couples_list):\n",
        "        current = self.root\n",
        "        for couple in couples_list:\n",
        "            if couple not in current.children:\n",
        "                current.children[couple] = TrieNode()\n",
        "            current = current.children[couple]\n",
        "            current.count += 1\n",
        "\n",
        "    def get_couple_count(self, couples_list):\n",
        "        counts = []\n",
        "        current = self.root\n",
        "        for couple in couples_list:\n",
        "            if couple in current.children:\n",
        "                current = current.children[couple]\n",
        "                counts.append(current.count)\n",
        "            else:\n",
        "                counts.append(0)\n",
        "                break\n",
        "        return counts\n",
        "\n",
        "###############################################################################\n",
        "# Utility: chunk generator\n",
        "###############################################################################\n",
        "def chunks(lst, n):\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]\n",
        "\n",
        "###############################################################################\n",
        "# GedcomDataset\n",
        "###############################################################################\n",
        "class GedcomDataset:\n",
        "    def __init__(self, gen_person):\n",
        "        self.gen_person = gen_person\n",
        "        self.extractable_detail = {}\n",
        "        self.anchor_gen1 = None\n",
        "\n",
        "    def add_extractable_detail(self, key, value):\n",
        "        self.extractable_detail[key] = value\n",
        "\n",
        "    def get_gen_person(self):\n",
        "        name = self.extractable_detail.get('NAME', '')\n",
        "        parts = name.split('/', 1)\n",
        "        first_name = parts[0].split(' ')[0]\n",
        "        last_name = parts[1].rstrip('/') if len(parts) > 1 else \"\"\n",
        "        self.anchor_gen1 = last_name.replace(\" \", \"\") + first_name.replace(\" \", \"\")\n",
        "        global anchor_gen1\n",
        "        anchor_gen1 = self.anchor_gen1\n",
        "        return self.gen_person.strip('@')\n",
        "\n",
        "    def get_extractable_NPFX(self):\n",
        "        return self.extractable_detail.get('NPFX', '')\n",
        "\n",
        "    def get_extractable_cm(self):\n",
        "        npfx_value = self.extractable_detail.get('NPFX', '')\n",
        "        if '&' in npfx_value:\n",
        "            cm_value = npfx_value.split('&')[0].strip()\n",
        "        elif '**' in npfx_value:\n",
        "            cm_value = npfx_value.split('**')[0].strip()\n",
        "        else:\n",
        "            cm_value = npfx_value.strip()\n",
        "        try:\n",
        "            int(cm_value)\n",
        "            return cm_value\n",
        "        except ValueError:\n",
        "            return ''\n",
        "\n",
        "    def get_extractable_sort(self):\n",
        "        npfx_value = self.extractable_detail.get('NPFX', '')\n",
        "        if '&' in npfx_value:\n",
        "            sort_part = npfx_value.split('&')[1]\n",
        "            if '**' in sort_part:\n",
        "                sort_value = sort_part.split('**')[0].strip()\n",
        "            else:\n",
        "                sort_value = sort_part.strip()\n",
        "            return sort_value\n",
        "        return ''\n",
        "\n",
        "    def get_extractable_YDNA(self):\n",
        "        npfx_value = self.extractable_detail.get('NPFX', '')\n",
        "        if '**' in npfx_value:\n",
        "            ydna_value = npfx_value.split('**')[1].strip()\n",
        "            return ydna_value\n",
        "        return ''\n",
        "\n",
        "    def get_extractable_FAMC(self):\n",
        "        return self.extractable_detail.get('FAMC', '').strip('@')\n",
        "\n",
        "###############################################################################\n",
        "# Gedcom Class\n",
        "###############################################################################\n",
        "class Gedcom:\n",
        "    def __init__(self, file_name):\n",
        "        self.file_name = file_name\n",
        "        self.gedcom_datasets = []\n",
        "        self.filter_pool = []\n",
        "\n",
        "    def parse_gedcom(self):\n",
        "        with open(self.file_name, 'r', encoding='utf-8-sig') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        current_dataset = None\n",
        "        npfx_count = 0\n",
        "        ydna_count = 0\n",
        "        total_count = 0\n",
        "\n",
        "        for line in lines:\n",
        "            parts = line.strip().split(' ', 2)\n",
        "            level = int(parts[0])\n",
        "            tag = parts[1]\n",
        "            value = parts[2] if len(parts) > 2 else None\n",
        "\n",
        "            if level == 0 and tag.startswith('@') and tag.endswith('@') and value == 'INDI':\n",
        "                total_count += 1\n",
        "                current_dataset = GedcomDataset(tag)\n",
        "                self.gedcom_datasets.append(current_dataset)\n",
        "            elif current_dataset is not None:\n",
        "                if level == 1 and tag in ['NAME', 'FAMC']:\n",
        "                    current_dataset.add_extractable_detail(tag, value)\n",
        "                elif level == 2 and tag == 'NPFX':\n",
        "                    npfx_count += 1\n",
        "                    current_dataset.add_extractable_detail(tag, value)\n",
        "                    if '**' in value:\n",
        "                        ydna_count += 1\n",
        "\n",
        "        autosomal_count = npfx_count - ydna_count\n",
        "        print(f\"GEDCOM contained {total_count} total records\")\n",
        "        print(f\"Records tagged and filtered by NPFX: {npfx_count}\")\n",
        "        print(f\"Records with YDNA information: {ydna_count}\")\n",
        "        print(f\"Autosomal matches: {autosomal_count}\")\n",
        "\n",
        "        for ds in self.gedcom_datasets:\n",
        "            if ds.get_extractable_NPFX():\n",
        "                self.filter_pool.append(ds)\n",
        "\n",
        "        manual_filter_activated = True\n",
        "        if manual_filter_activated:\n",
        "            try:\n",
        "                df = pd.read_excel('filtered_ids.xlsx')\n",
        "            except FileNotFoundError:\n",
        "                logger.warning(\"filtered_ids.xlsx not found. Skipping second-level manual filter.\")\n",
        "            else:\n",
        "                manual_filtered_ids = set(df['ID'])\n",
        "                self.filter_pool = [d for d in self.filter_pool if d.get_gen_person() in manual_filtered_ids]\n",
        "                print(f\"After manual filter, total records: {len(self.filter_pool)}\")\n",
        "                logger.info(f\"After manual filter, total records: {len(self.filter_pool)}\")\n",
        "\n",
        "        return autosomal_count\n",
        "\n",
        "###############################################################################\n",
        "# quick_extract_name\n",
        "###############################################################################\n",
        "def quick_extract_name(full_text):\n",
        "    name_marker = \"\\n1 NAME \"\n",
        "    idx = full_text.find(name_marker)\n",
        "    if idx == -1:\n",
        "        if full_text.startswith(\"1 NAME \"):\n",
        "            idx = 0\n",
        "        else:\n",
        "            return \"UnknownName\"\n",
        "    start = idx + len(name_marker)\n",
        "    end = full_text.find('\\n', start)\n",
        "    if end == -1:\n",
        "        end = len(full_text)\n",
        "    name_line = full_text[start:end].strip()\n",
        "    if '/' not in name_line:\n",
        "        return name_line[:10].replace(\" \", \"\")\n",
        "    first_name, last_name = name_line.split('/', 1)\n",
        "    last_name = last_name.replace(\"/\", \"\").strip()\n",
        "    return last_name[:10].replace(\" \", \"\") + first_name[:10].replace(\" \", \"\")\n",
        "\n",
        "###############################################################################\n",
        "# Parents & Ancestors\n",
        "###############################################################################\n",
        "def find_parents(individual_id, generation, parents_map):\n",
        "    global visited_pairs, generation_table\n",
        "    if individual_id not in parents_map:\n",
        "        return\n",
        "    father_id, mother_id = parents_map[individual_id]\n",
        "    if not father_id and not mother_id:\n",
        "        return\n",
        "    pair = (father_id, mother_id)\n",
        "    if pair not in visited_pairs:\n",
        "        visited_pairs.add(pair)\n",
        "        generation_table.append((generation, pair))\n",
        "    if father_id:\n",
        "        find_parents(father_id, generation+1, parents_map)\n",
        "    if mother_id:\n",
        "        find_parents(mother_id, generation+1, parents_map)\n",
        "\n",
        "def find_distant_ancestors(individual_id, parents_map, path=None):\n",
        "    if path is None:\n",
        "        path = []\n",
        "    path.append(individual_id)\n",
        "    if individual_id not in parents_map:\n",
        "        return [path]\n",
        "    father_id, mother_id = parents_map[individual_id]\n",
        "    if not father_id and not mother_id:\n",
        "        return [path]\n",
        "    paths = []\n",
        "    if father_id:\n",
        "        paths.extend(find_distant_ancestors(father_id, parents_map, path[:]))\n",
        "    if mother_id:\n",
        "        paths.extend(find_distant_ancestors(mother_id, parents_map, path[:]))\n",
        "    return paths if paths else [path]\n",
        "\n",
        "###############################################################################\n",
        "# filter_ancestral_line\n",
        "###############################################################################\n",
        "def filter_ancestral_line(winning_path_ids, generation_table_local, names_map):\n",
        "    matching_table = []\n",
        "    for generation, pair in generation_table_local:\n",
        "        id1, id2 = pair\n",
        "        if id1 in winning_path_ids or id2 in winning_path_ids:\n",
        "            matching_table.append((generation, pair))\n",
        "    matching_table.sort(key=lambda x: x[0])\n",
        "    lines = []\n",
        "    for gen, pair in matching_table:\n",
        "        name_pair = [names_map.get(pid, \"UnknownName\") for pid in pair]\n",
        "        lines.append(f\"{name_pair[0]}&{name_pair[1]}\")\n",
        "    lines.reverse()\n",
        "    return \"~~~\".join(lines)\n",
        "\n",
        "###############################################################################\n",
        "# process_record_wrapper (parallel) - STAGE 1\n",
        "###############################################################################\n",
        "def process_record_wrapper(individual_id, gedcom_instance, parents_map, names_map):\n",
        "    global generation_table, visited_pairs, anchor_gen1\n",
        "    generation_table = []\n",
        "    visited_pairs = set()\n",
        "\n",
        "    find_parents(individual_id, 1, parents_map)\n",
        "    distant_anc_paths = find_distant_ancestors(individual_id, parents_map)\n",
        "\n",
        "    best_score = None\n",
        "    best_path = None\n",
        "    for path in distant_anc_paths:\n",
        "        name_path = [names_map.get(pid, \"UnknownName\") for pid in path]\n",
        "        score = sum((idx+1) for idx, nm in enumerate(name_path) if 'Yates' in nm)\n",
        "        if best_score is None or score > best_score:\n",
        "            best_score = score\n",
        "            best_path = path\n",
        "\n",
        "    if not best_path:\n",
        "        best_path = []\n",
        "\n",
        "    best_path_cleaned = [pid for pid in best_path if pid != individual_id]\n",
        "    line_str = filter_ancestral_line(set(best_path_cleaned), generation_table, names_map)\n",
        "\n",
        "    cm_value = ''\n",
        "    sort_value = ''\n",
        "    ydna_value = ''\n",
        "    for ds in gedcom_instance.filter_pool:\n",
        "        if ds.get_gen_person() == individual_id:\n",
        "            cm_value = ds.get_extractable_cm()\n",
        "            sort_value = ds.get_extractable_sort()\n",
        "            ydna_value = ds.get_extractable_YDNA()\n",
        "            break\n",
        "\n",
        "    short_name = names_map.get(individual_id, \"UnknownName\")\n",
        "    # Return columns: ID#, Match to, Name, cM, Yates DNA Ancestral Line, haplogroup\n",
        "    return [individual_id, sort_value, short_name, cm_value, line_str, ydna_value]\n",
        "\n",
        "###############################################################################\n",
        "# main()\n",
        "###############################################################################\n",
        "def main():\n",
        "    def select_gedcom():\n",
        "        files = glob.glob(\"*.ged\")\n",
        "        if not files:\n",
        "            print(\"No GEDCOM files found.\")\n",
        "            return None\n",
        "        print(\"Automatically selecting the first GEDCOM file.\")\n",
        "        return files[0]\n",
        "\n",
        "    gedcom_file_path = select_gedcom()\n",
        "    if not gedcom_file_path:\n",
        "        print(\"No GEDCOM file selected; exiting.\")\n",
        "        return\n",
        "\n",
        "    ged = Gedcom(gedcom_file_path)\n",
        "    autosomal_count = ged.parse_gedcom()\n",
        "    filter_count = len(ged.filter_pool)\n",
        "\n",
        "    with open(\"autosomal_count.txt\", \"w\") as f:\n",
        "        f.write(str(autosomal_count))\n",
        "\n",
        "    print(\"Records tagged and filtered by NPFX:\", filter_count)\n",
        "\n",
        "    with open(gedcom_file_path, 'r', encoding='utf-8') as f:\n",
        "        raw_data = f.read()\n",
        "\n",
        "    blocks = raw_data.split('\\n0 ')\n",
        "    all_records = {}\n",
        "    for blk in blocks:\n",
        "        blk = blk.strip()\n",
        "        if not blk:\n",
        "            continue\n",
        "        flend = blk.find('\\n')\n",
        "        if flend == -1:\n",
        "            flend = len(blk)\n",
        "        first_line = blk[:flend]\n",
        "        if '@' in first_line:\n",
        "            start = first_line.find('@') + 1\n",
        "            end = first_line.find('@', start)\n",
        "            rec_id = first_line[start:end].strip()\n",
        "            all_records[rec_id] = blk\n",
        "\n",
        "    parents_map = {}\n",
        "    names_map = {}\n",
        "    for rec_id, txt in all_records.items():\n",
        "        nm = quick_extract_name(\"\\n\" + txt)\n",
        "        names_map[rec_id] = nm\n",
        "\n",
        "    families = {}\n",
        "    for rec_id, txt in all_records.items():\n",
        "        if 'FAM' in txt[:50]:\n",
        "            father_idx = txt.find('1 HUSB @')\n",
        "            husb_id = txt[father_idx+len('1 HUSB @'):txt.find('@', father_idx+len('1 HUSB @'))] if father_idx != -1 else None\n",
        "            wife_idx = txt.find('1 WIFE @')\n",
        "            wife_id = txt[wife_idx+len('1 WIFE @'):txt.find('@', wife_idx+len('1 WIFE @'))] if wife_idx != -1 else None\n",
        "            kids = [ln.split('@')[1] for ln in txt.split('\\n') if ln.strip().startswith('1 CHIL @')]\n",
        "            families[rec_id] = (husb_id, wife_id, kids)\n",
        "\n",
        "    for fam_id, (f_id, m_id, k_list) in families.items():\n",
        "        for kid in k_list:\n",
        "            parents_map[kid] = (f_id, m_id)\n",
        "\n",
        "    individual_ids = [d.get_gen_person() for d in ged.filter_pool]\n",
        "    print(f\"Processing {len(individual_ids)} individuals with chunk-based parallel...\")\n",
        "\n",
        "    combined_rows = []\n",
        "    chunk_size = 50\n",
        "    max_workers = os.cpu_count() or 4\n",
        "    logger.info(\"Starting chunk-based parallel processing with %d workers.\", max_workers)\n",
        "\n",
        "    with ProcessPoolExecutor(max_workers=max_workers) as executor, tqdm(total=len(individual_ids), desc=\"Building Yates Lines (Stage 1)\") as pbar:\n",
        "        for chunk in chunks(individual_ids, chunk_size):\n",
        "            func = functools.partial(process_record_wrapper, gedcom_instance=ged, parents_map=parents_map, names_map=names_map)\n",
        "            results = list(executor.map(func, chunk))\n",
        "            combined_rows.extend(results)\n",
        "            pbar.update(len(chunk))\n",
        "\n",
        "    columns = [\"ID#\", \"Match to\", \"Name\", \"cM\", \"Yates DNA Ancestral Line\", \"haplogroup\"]\n",
        "    df = pd.DataFrame(combined_rows, columns=columns)\n",
        "    df.index += 1\n",
        "\n",
        "    def remove_specific_prefix(row):\n",
        "        prefix = \"YatesJohn&SearchingStill~~~YatesWilliam&SearchingStill~~~YatesWilliam&SearchingStill~~~YatesEdmund&CornellMargaret~~~YatesRichard&AshendonJoan~~~YatesJohn&HydeAlice~~~YatesThomas&WhiteFrances~~~\"\n",
        "        if row[\"Yates DNA Ancestral Line\"].startswith(prefix):\n",
        "            row[\"Yates DNA Ancestral Line\"] = row[\"Yates DNA Ancestral Line\"][len(prefix):]\n",
        "        return row\n",
        "\n",
        "    df = df.apply(remove_specific_prefix, axis=1)\n",
        "\n",
        "    logger.info(\"Building Trie from reversed lines...\")\n",
        "    trie = Trie()\n",
        "    for _, row in df.iterrows():\n",
        "        line_str = row[\"Yates DNA Ancestral Line\"]\n",
        "        if pd.notna(line_str) and line_str.strip():\n",
        "            trie.insert_line([x.strip() for x in line_str.split(\"~~~\") if x.strip()])\n",
        "\n",
        "    values, prefix_counts = [], []\n",
        "    logger.info(\"Computing 'Value' = 5*(#couples with node.count >=2) + (total couples) ...\")\n",
        "    for _, row in df.iterrows():\n",
        "        line_str = row[\"Yates DNA Ancestral Line\"]\n",
        "        if pd.isna(line_str) or not line_str.strip():\n",
        "            values.append(0)\n",
        "            prefix_counts.append(0)\n",
        "        else:\n",
        "            couples_list = [x.strip() for x in line_str.split(\"~~~\") if x.strip()]\n",
        "            node_counts = trie.get_couple_count(couples_list)\n",
        "            prefix_count = sum(1 for c in node_counts if c >= 2)\n",
        "            values.append(5 * prefix_count + len(couples_list))\n",
        "            prefix_counts.append(prefix_count)\n",
        "\n",
        "    df[\"Value\"], df[\"PrefixCount\"] = values, prefix_counts\n",
        "\n",
        "    def assign_value_range_label(val):\n",
        "        try:\n",
        "            v = float(val)\n",
        "        except:\n",
        "            return \"\", \"\"\n",
        "        if v >= 60: return \">=60\", \"1-likely correct\"\n",
        "        if 47 <= v <= 59: return \"59~47\", \"2-lines forming\"\n",
        "        if 34 <= v <= 46: return \"46~34\", \"3-patterns emerging\"\n",
        "        if 21 <= v <= 33: return \"33~21\", \"4-notable patterns\"\n",
        "        if 8 <= v <= 20: return \"20~8\", \"5-patterns stable\"\n",
        "        if 1 <= v <= 7:  return f\"{v:.0f}\", \"6-need research\"\n",
        "        return f\"{v:.0f}\", \"0-uncategorized\"\n",
        "\n",
        "    ranges, labels = zip(*(assign_value_range_label(v) for v in df[\"Value\"]))\n",
        "    df[\"Value Range\"], df[\"Value Label\"] = ranges, labels\n",
        "\n",
        "    df.sort_values(by=[\"Yates DNA Ancestral Line\"], inplace=True)\n",
        "    df.drop(\"PrefixCount\", axis=1, inplace=True)\n",
        "\n",
        "    csv_name = \"final_combined_df_with_value_labels.csv\"\n",
        "    df.to_csv(csv_name, index=False)\n",
        "    logger.info(\"Exported final DataFrame to '%s'.\", csv_name)\n",
        "\n",
        "    html_name = \"HTML_combined_df_with_value_labels.html\"\n",
        "    css_style = \"\"\"\n",
        "    <style>\n",
        "    table { width: 100%; border-collapse: collapse; margin: 20px 0; }\n",
        "    table, th, td { border: 1px solid #333; }\n",
        "    th, td { padding: 8px 12px; text-align: center; }\n",
        "    th { background-color: #f2f2f2; }\n",
        "    /* Left-align the last column */\n",
        "    td:nth-child(7) { text-align: left; }\n",
        "    </style>\n",
        "    \"\"\"\n",
        "    final_cols = [\"ID#\", \"cM\", \"haplogroup\", \"Match to\", \"Value Range\", \"Value Label\", \"Yates DNA Ancestral Line\"]\n",
        "    html_content = css_style + df.to_html(index=False, columns=final_cols, escape=False)\n",
        "    with open(html_name, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(html_content)\n",
        "    logger.info(\"Exported HTML to '%s'.\", html_name)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "    try:\n",
        "        display(Javascript('alert(\"✅ GEDCOM processing (and HTML export) is complete!\");'))\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "import smtplib, ssl\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "def send_email(subject, body, to_addr):\n",
        "    smtp_server = 'smtp.gmail.com'\n",
        "    port = 465\n",
        "    sender = os.environ['GMAIL_USER']\n",
        "    password = os.environ['GMAIL_APP_PASSWORD']\n",
        "    msg = MIMEText(body)\n",
        "    msg['Subject'] = subject\n",
        "    msg['From'] = sender\n",
        "    msg['To'] = to_addr\n",
        "    context = ssl.create_default_context()\n",
        "    with smtplib.SMTP_SSL(smtp_server, port, context=context) as server:\n",
        "        server.login(sender, password)\n",
        "        server.send_message(msg)\n",
        "\n",
        "# Email summary\n",
        "df_summary = pd.read_csv(\"final_combined_df_with_value_labels.csv\")\n",
        "total = len(df_summary)\n",
        "top5 = df_summary.sort_values('Value', ascending=False).head(5)['Yates DNA Ancestral Line'].tolist()\n",
        "summary = f\"GEDCOM processing complete!\\n\\nTotal lines: {total}\\nTop 5 lines:\\n\" + \"\\n\".join(f\"- {line}\" for line in top5)\n",
        "send_email(subject=\"✅ GEDCOM Report Ready\", body=summary, to_addr=os.environ['GMAIL_USER'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "Qh13Q-WUmVu3",
        "outputId": "dafb876b-b0ce-40f5-ff80-efa630c3c8f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically selecting the first GEDCOM file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:filtered_ids.xlsx not found. Skipping second-level manual filter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GEDCOM contained 60235 total records\n",
            "Records tagged and filtered by NPFX: 1463\n",
            "Records with YDNA information: 91\n",
            "Autosomal matches: 1372\n",
            "Records tagged and filtered by NPFX: 1463\n",
            "Processing 1463 individuals with chunk-based parallel...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Yates Lines (Stage 1): 100%|██████████| 1463/1463 [14:18<00:00,  1.70it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "alert(\"✅ GEDCOM processing (and HTML export) is complete!\");"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: XHTML Template + Export + Root FTP Upload 20250513\n",
        "\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from zoneinfo import ZoneInfo\n",
        "from ftplib import FTP_TLS\n",
        "import os\n",
        "\n",
        "# ————— Load Data —————\n",
        "df = pd.read_csv(\"final_combined_df_with_value_labels.csv\")\n",
        "\n",
        "# ————— Blank out any NaN haplogroups —————\n",
        "df['haplogroup'] = df['haplogroup'].fillna('')\n",
        "\n",
        "\n",
        "# ————— Hyperlink haplogroup values, send all Y- designations to a single overview page —————\n",
        "hap_base = \"file:///C:/Users/yates/Dropbox/website%20related%20content/One-name-study/gengen/haplogroup/\"\n",
        "ydna_overview = \"file:///C:/Users/yates/Dropbox/website%20related%20content/One-name-study/gengen/Y-designation-overview.htm\"\n",
        "\n",
        "df['haplogroup'] = (\n",
        "    df['haplogroup']\n",
        "      .fillna(\"\")\n",
        "      .apply(lambda x: (\n",
        "          f'<a href=\"{ydna_overview}\" target=\"_blank\">{x}</a>'\n",
        "            if x.startswith(\"Y-\") else\n",
        "          f'<a href=\"{hap_base}{x}.htm\" target=\"_blank\">{x}</a>'\n",
        "            if x else\n",
        "          \"\"\n",
        "      ))\n",
        ")\n",
        "\n",
        "\n",
        "# ————— Load counts —————\n",
        "try:\n",
        "    with open(\"autosomal_count.txt\", \"r\") as f:\n",
        "        autosomal_count = int(f.read().strip())\n",
        "except Exception:\n",
        "    autosomal_count = None\n",
        "\n",
        "prev_count = None\n",
        "additional_str = \"\"\n",
        "if os.path.exists(\"autosomal_count_prev.txt\"):\n",
        "    try:\n",
        "        with open(\"autosomal_count_prev.txt\", \"r\") as f:\n",
        "            prev_count = int(f.read().strip())\n",
        "        if autosomal_count is not None and prev_count is not None:\n",
        "            diff_count = autosomal_count - prev_count\n",
        "            additional_str = f\" (+{diff_count} since last run)\"\n",
        "    except Exception:\n",
        "        additional_str = \"\"\n",
        "\n",
        "# ————— Get current Eastern time & formatted timestamp —————\n",
        "now = datetime.now(ZoneInfo(\"America/New_York\"))\n",
        "updated_str = now.strftime(\"%d %B %Y at %H%M hours EDT\")\n",
        "\n",
        "# ————— XHTML Template —————\n",
        "full_html_template = \"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        "  \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"en\" lang=\"en\">\n",
        "<head>\n",
        "  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"/>\n",
        "  <meta name=\"GENERATOR\" content=\"Yatesville\"/>\n",
        "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"/>\n",
        "  <title>DNA Report Card</title>\n",
        "  <script src=\"../sorttable.js\" type=\"text/javascript\"></script>\n",
        "  <style type=\"text/css\">\n",
        "    body { font-family: Arial, Helvetica, sans-serif; font-size: 14px; background-color: #faf9d3; }\n",
        "    .output-table table {\n",
        "      width:100%; border-collapse:collapse; margin:15px 0; background-color:#faf9d3;\n",
        "    }\n",
        "    .output-table table, .output-table th, .output-table td {\n",
        "      border:1px solid #333; text-align:center; padding:5px 8px; background-color:#faf9d3;\n",
        "    }\n",
        "    .output-table th { background-color:#ffffcc; white-space:nowrap; }\n",
        "    .output-table th:hover { background-color:#ffeb99; }\n",
        "    .output-table td:nth-child(6) { min-width:180px; }\n",
        "    .output-table td:last-child, .output-table th:last-child {\n",
        "      text-align:left; white-space:nowrap;\n",
        "    }\n",
        "    /* make the haplogroup (3rd) column wider by ~6 characters */\n",
        "    .output-table th:nth-child(3),\n",
        "    .output-table td:nth-child(3) {\n",
        "  min-width: 140px;\n",
        "}\n",
        "\n",
        "  </style>\n",
        "</head>\n",
        "<body>\n",
        "<div align=\"center\">\n",
        "  <table class=\"fullpage-definedsection\" cellpadding=\"0\"><tr valign=\"top\"><td>\n",
        "    <table class=\"headersection\" cellpadding=\"0\"><tr valign=\"top\"><td></td></tr></table>\n",
        "    <table class=\"mainsection\" cellpadding=\"7\">\n",
        "      <tr valign=\"top\"><td>\n",
        "        <h2>A report card for your DNA family tree</h2>\n",
        "        <font size=\"-2\">\n",
        "          Return to <a href=\"https://yates.one-name.net/gengen/dna_cousin_surname_study.htm\">Study Home</a>\n",
        "          &nbsp;|&nbsp;\n",
        "          Autosomal matches: {autosomal_count}{additional_str}\n",
        "          &nbsp;|&nbsp;\n",
        "          Updated: {updated_timestamp}\n",
        "        </font>\n",
        "        <p>Imagine you have a report card for your family tree that tells you how your family tree compares to other collateral family tree lines.<br><br>Here is how we break it down:</p>\n",
        "        <p>Think of value like the total number of points you get from finding all the important family connections in your tree<br>\n",
        "        and comparing them to all the other trees included in the Yates study.</p>\n",
        "        <p>We then group them as a way to signal which ones seem to have potential for study:\n",
        "          <b>>60:</b> likely correct, <b>59–47:</b> lines forming, <b>46–34:</b> patterns emerging,\n",
        "          <b>33–21:</b> notable patterns, <b>20–8:</b> patterns stable, <b>7–1:</b> and 6-need research.</p>\n",
        "        <p><b><i><font size=\"-1\">Click on the header to sort any column</font></i></b>\n",
        "          (And, remember <a href=\"https://yates.one-name.net/gengen/dna_theory_of_the_case.htm\" target=\"_blank\">what this is telling</a> us....)</p>\n",
        "\n",
        "      </td></tr>\n",
        "    </table>\n",
        "    <div class=\"output-table\" style=\"margin-top:10px;\">\n",
        "      <!-- TABLE_PLACEHOLDER -->\n",
        "    </div>\n",
        "  </td></tr></table>\n",
        "</div>\n",
        "<button onclick=\"topFunction()\" id=\"myBtn\" title=\"Go to top\"\n",
        "  style=\"position:fixed;bottom:40px;right:40px;z-index:99;background-color:red;color:white;\n",
        "         padding:12px 20px;border:none;border-radius:10px;cursor:pointer;font-size:16px;\">\n",
        "  Top\n",
        "</button>\n",
        "<script>\n",
        "let mybutton = document.getElementById(\"myBtn\");\n",
        "window.onscroll = function() {\n",
        "  if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {\n",
        "    mybutton.style.display = \"block\";\n",
        "  } else {\n",
        "    mybutton.style.display = \"none\";\n",
        "  }\n",
        "};\n",
        "function topFunction() {\n",
        "  document.body.scrollTop = 0;\n",
        "  document.documentElement.scrollTop = 0;\n",
        "}\n",
        "</script>\n",
        "</body>\n",
        "</html>\"\"\"\n",
        "\n",
        "# ————— Build and inject table, counts, and timestamp —————\n",
        "final_cols = [\"ID#\", \"cM\", \"haplogroup\", \"Match to\", \"Value Range\", \"Value Label\", \"Yates DNA Ancestral Line\"]\n",
        "df.sort_values(by=final_cols[-1], inplace=True)\n",
        "\n",
        "html_table = df.to_html(\n",
        "    index=False,\n",
        "    columns=final_cols,\n",
        "    escape=False,\n",
        "    classes=\"dataframe sortable\"\n",
        ")\n",
        "\n",
        "final_html = (\n",
        "    full_html_template\n",
        "    .replace(\"{autosomal_count}\", str(autosomal_count or \"Unknown\"))\n",
        "    .replace(\"{additional_str}\", additional_str)\n",
        "    .replace(\"{updated_timestamp}\", updated_str)\n",
        ")\n",
        "final_html = final_html.replace(\"<!-- TABLE_PLACEHOLDER -->\", html_table)\n",
        "\n",
        "# ————— Save to local files —————\n",
        "with open(\"HTML_combined_df_with_value_labels.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final_html)\n",
        "\n",
        "with open(\"dna_cousin_surname_app.htm\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final_html)\n",
        "\n",
        "# ————— FTP Upload to ROOT —————\n",
        "ftp_host = os.environ['FTP_HOST']\n",
        "ftp_port = int(os.environ.get('FTP_PORT', 21))\n",
        "ftp_user = os.environ['FTP_USER']\n",
        "ftp_pass = os.environ['FTP_PASS']\n",
        "\n",
        "def upload_to_root(filenames):\n",
        "    ftps = FTP_TLS()\n",
        "    ftps.connect(ftp_host, ftp_port)\n",
        "    ftps.login(ftp_user, ftp_pass)\n",
        "    ftps.prot_p()\n",
        "    for fname in filenames:\n",
        "        try:\n",
        "            ftps.delete(fname)\n",
        "        except Exception:\n",
        "            pass\n",
        "        with open(fname, 'rb') as f:\n",
        "            print(f\"→ uploading {fname} …\", end=' ')\n",
        "            ftps.storbinary(f\"STOR {fname}\", f)\n",
        "            print(\"done\")\n",
        "        try:\n",
        "            ftps.sendcmd(f\"SITE CHMOD 644 {fname}\")\n",
        "        except Exception:\n",
        "            pass\n",
        "    ftps.quit()\n",
        "    print(\"✅ All files uploaded to One Name Study.\")\n",
        "\n",
        "# Run upload\n",
        "upload_to_root([\"dna_cousin_surname_app.htm\"])\n",
        "\n",
        "# ————— Update previous autosomal count for next run —————\n",
        "if autosomal_count is not None:\n",
        "    with open(\"autosomal_count_prev.txt\", \"w\") as f:\n",
        "        f.write(str(autosomal_count))\n"
      ],
      "metadata": {
        "id": "3_8LbmegEYhU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "575ebc48-048c-41fd-9a14-9667bf231fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ uploading dna_cousin_surname_app.htm … done\n",
            "✅ All files uploaded to One Name Study.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Autosomal Note with Hard CE ≥ 1800 Cutoff\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# ————— Parameters —————\n",
        "generation_years      = 27\n",
        "autosomal_generations = 6\n",
        "autosomal_span        = generation_years * autosomal_generations  # 162 years\n",
        "cutoff_year           = 1800  # only CE dates >= 1800 qualify\n",
        "\n",
        "# ————— File paths (local Colab files) —————\n",
        "input_csv            = \"y_dna_comparison.csv\"\n",
        "output_csv           = \"y_dna_comparison_updated.csv\"\n",
        "output_html_snippet  = \"y_dna_comparison_table.html\"\n",
        "\n",
        "# ————— Description column name —————\n",
        "desc_col = \"Description of mutation events and the human migrations and social identities\"\n",
        "\n",
        "# ————— Load & normalize headers —————\n",
        "df = pd.read_csv(input_csv, sep=\",\", engine=\"python\", skipinitialspace=True)\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# ————— Ensure user columns exist & blank NaNs —————\n",
        "for col in ['i1-Big','i58945-Big']:\n",
        "    if col not in df.columns:\n",
        "        raise KeyError(f\"Expected column '{col}' not found!\")\n",
        "df[['i1-Big','i58945-Big']] = df[['i1-Big','i58945-Big']].fillna(\"\")\n",
        "\n",
        "# ————— Extract only “around|circa … CE” dates —————\n",
        "def extract_ce_year(desc):\n",
        "    m = re.search(r\"(?:around|circa)\\s*([\\d,]+)\\s*CE\", desc)\n",
        "    return int(m.group(1).replace(\",\", \"\")) if m else None\n",
        "\n",
        "df['approx_year'] = df[desc_col].apply(extract_ce_year)\n",
        "\n",
        "# ————— Define bold-italic autosomal note —————\n",
        "note = (\n",
        "    f\" <b><i>This potentially allows for autosomal DNA detection \"\n",
        "    f\"for roughly {autosomal_generations} generations \"\n",
        "    f\"(~{autosomal_span} years).</i></b>\"\n",
        ")\n",
        "\n",
        "# ————— Conditionally append note for CE dates ≥ 1800 —————\n",
        "def maybe_append(desc, yr):\n",
        "    return desc + note if yr is not None and yr >= cutoff_year else desc\n",
        "\n",
        "df[desc_col] = df.apply(lambda r: maybe_append(r[desc_col], r['approx_year']), axis=1)\n",
        "\n",
        "# ————— Clean up & export updated CSV —————\n",
        "df.drop(columns=['approx_year'], inplace=True)\n",
        "df.to_csv(output_csv, index=False)\n",
        "\n",
        "# ————— Render HTML table snippet —————\n",
        "html_table = df.to_html(index=False, classes=\"ydna-table sortable\", border=1, escape=False)\n",
        "\n",
        "# ————— Inject CSS for styling —————\n",
        "style = \"\"\"\n",
        "<style>\n",
        "  table.ydna-table { width:100%; border-collapse:collapse; }\n",
        "  th, td { border:1px solid #ccc; padding:8px; vertical-align:top; }\n",
        "  /* center & widen user columns */\n",
        "  th:nth-child(1), th:nth-child(2),\n",
        "  td:nth-child(1), td:nth-child(2) {\n",
        "    text-align:center; min-width:10ch;\n",
        "  }\n",
        "  /* dark grey blank cells in user columns */\n",
        "  td:nth-child(1):empty, td:nth-child(2):empty {\n",
        "    background-color:#666; color:#fff;\n",
        "  }\n",
        "  th { background-color:#f2f2f2; }\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "final_html = style + html_table\n",
        "\n",
        "# ————— Save & display —————\n",
        "with open(output_html_snippet, 'w', encoding='utf-8') as f:\n",
        "    f.write(final_html)\n",
        "\n",
        "display(HTML(final_html))\n",
        "print(f\"» Updated CSV saved as {output_csv}\")\n",
        "print(f\"» HTML snippet saved as {output_html_snippet}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "giWEhobHq6ud",
        "outputId": "c93af442-07aa-4aa0-a4fc-0fcd72bff9b0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "  table.ydna-table { width:100%; border-collapse:collapse; }\n",
              "  th, td { border:1px solid #ccc; padding:8px; vertical-align:top; }\n",
              "  /* center & widen user columns */\n",
              "  th:nth-child(1), th:nth-child(2),\n",
              "  td:nth-child(1), td:nth-child(2) {\n",
              "    text-align:center; min-width:10ch;\n",
              "  }\n",
              "  /* dark grey blank cells in user columns */\n",
              "  td:nth-child(1):empty, td:nth-child(2):empty {\n",
              "    background-color:#666; color:#fff;\n",
              "  }\n",
              "  th { background-color:#f2f2f2; }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe ydna-table sortable\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>i1-Big</th>\n",
              "      <th>i58945-Big</th>\n",
              "      <th>Description of mutation events and the human migrations and social identities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>R-M207</td>\n",
              "      <td>R-M207</td>\n",
              "      <td>Originating around 27,000 BCE, carriers belonged to Upper Paleolithic hunter-gatherer bands across Eastern Europe and Central Asia. They hunted giant game on the mammoth-steppe and likely used clan totems or landmark-based nicknames to identify kin.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>M173</td>\n",
              "      <td>M173</td>\n",
              "      <td>Emerging around 25,000 BCE during the Last Glacial Maximum, M173 carriers were small ice-age survival groups roaming Siberia and western Russia. They used seasonal camp names or game-based epithets to distinguish kin.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>M343 (R1b)</td>\n",
              "      <td>M343 (R1b)</td>\n",
              "      <td>Dating to roughly 22,000 BCE, M343 (R1b) groups clustered in the Franco-Cantabrian refugium of southwestern Europe. Cro-Magnon communities painted caves and hunted reindeer, naming bands after rock shelters or streams.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>L754</td>\n",
              "      <td>L754</td>\n",
              "      <td>Arising about 20,000 BCE as post-glacial populations expanded north from refugia, L754 carriers explored new western European landscapes. They used local topographical features—caves, rivers—as informal clan identifiers.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>L761</td>\n",
              "      <td>L761</td>\n",
              "      <td>Splitting around 18,500 BCE among settlers in Iberia and southern France, L761 carriers repopulated thawed lands. Seasonal hunting grounds and coastal landmarks provided the band names marking each sister line.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>L389</td>\n",
              "      <td>L389</td>\n",
              "      <td>Appearing near 17,000 BCE with Magdalenian societies in France and northern Spain, L389 carriers inhabited tool-making camps and decorated caves. These camps and painting sites doubled as clan identifiers.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>P297</td>\n",
              "      <td>P297</td>\n",
              "      <td>Originating around 14,000 BCE in post-glacial western European plains, P297 carriers followed game migrations and seasonal fish runs. Animal-track totems and fishing-site names served to distinguish lineages.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>M269</td>\n",
              "      <td>M269</td>\n",
              "      <td>Dating to about 12,000 BCE, M269 spread rapidly with Mesolithic foragers across Europe. Tribal identities formed around seasonal gatherings and ancestral cave names.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>L23</td>\n",
              "      <td>L23</td>\n",
              "      <td>Emerging around 10,000 BCE among early Neolithic pioneers in the Balkans, L23 carriers brought farming into central Europe. Kinship groups often took names from local rivers or earthen longhouses.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>L51</td>\n",
              "      <td>L51</td>\n",
              "      <td>Arising roughly 9,000 BCE along Atlantic-coast settlements, L51 carriers built megalithic structures. Passage-grave sites and distinctive pottery styles served as clan labels.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>P310</td>\n",
              "      <td>P310</td>\n",
              "      <td>Splitting around 8,000 BCE amid proto-Indo-European chiefdoms in central Europe, P310 carriers used emerging dialect words for “leader” or “father” as formal modes of address. These early hierarchy titles defined kin relations.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>L151</td>\n",
              "      <td>L151</td>\n",
              "      <td>Branching about 7,000 BCE with Bell Beaker metal-working groups, L151 carriers spread across Europe. They adopted clan names tied to their distinctive drinking-vessel styles.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>U106</td>\n",
              "      <td></td>\n",
              "      <td>Arising around 4,300 BCE among Proto-Germanic forebears in northern Europe, U106 carriers formed warrior tribes along the Rhine and into Scandinavia. Honorifics like “faðēr” (“father”) and “deiws” (“god”) appeared in their greetings.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Z2265</td>\n",
              "      <td></td>\n",
              "      <td>Splitting circa 3,500 BCE in the Nordic Bronze Age, Z2265 carriers used farmstead names or warrior-style nicknames as identifiers. These names reflected status and local landmarks.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>BY30097</td>\n",
              "      <td></td>\n",
              "      <td>Evolving around 3,000 BCE among Iron Age tribal federations in Denmark and northern Germany, BY30097 carriers used lineage titles like “kuningaz” (king) or “hlaiba” (clan). These formal titles distinguished leaders and kin.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>FTT8</td>\n",
              "      <td></td>\n",
              "      <td>Branching about 2,800 BCE in the Schleswig region, FTT8 carriers spoke early proto-Scandinavian. Terms like “drengr” (warrior) and “þegn” (thane) were common forms of address.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Z381</td>\n",
              "      <td></td>\n",
              "      <td>Emerging around 2,600 BCE on the Scandinavian peninsula, Z381 carriers thrived in Bronze Age trade networks. Mariner and metal-worker titles often served as clan identifiers.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Z301</td>\n",
              "      <td></td>\n",
              "      <td>Originating near 2,400 BCE among Unetice culture groups in northern Germany, Z301 carriers spoke early Indo-European dialects. Kinship was reinforced with titles meaning “brother” or “ally.”</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>L48</td>\n",
              "      <td></td>\n",
              "      <td>Arising about 2,200 BCE along North Sea coastlines, L48 carriers built fishing and ship-building settlements. Clan names often referenced local fishing grounds or ship sheds.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Y37962</td>\n",
              "      <td></td>\n",
              "      <td>Dating to around 2,000 BCE in Pre-Roman Iron Age Scandinavia, Y37962 carriers met in tribal assemblies using place-based descriptors like “fjord,” “valley,” or “mountain.” These geographic monikers became informal clan names.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>S23189</td>\n",
              "      <td></td>\n",
              "      <td>Splitting around 1,700 BCE among coastal Germanic groups in northwest Germany, S23189 carriers honored lineage heroes in their clan names. Ancestral heroes’ names were invoked in daily greetings.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>FT6679</td>\n",
              "      <td></td>\n",
              "      <td>Originating around 1,300 BCE during early Migration Period movements into Britain and Ireland, FT6679 carriers used Gaelic and Brittonic terms for “son” (“mapos,” “mac”) as personal identifiers. These patronyms marked paternal descent.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>L200</td>\n",
              "      <td></td>\n",
              "      <td>Arising circa 1,000 BCE with the Hallstatt culture, L200 carriers belonged to Celtic tribes using titles like “rig” (king) and “dux” (leader). These honorifics defined social roles.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>A11431</td>\n",
              "      <td></td>\n",
              "      <td>Evolving around 700 BCE in southern Scandinavia, A11431 carriers spoke Proto-Norse and used nicknames like “Stone,” “Arrow,” or “Wolf” to distinguish kinsmen. These monikers reflected personal traits or deeds.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>ACT920</td>\n",
              "      <td></td>\n",
              "      <td>Splitting about 400 BCE in Pre-Viking Age Scandinavia, ACT920 carriers identified clans by farmstead names (“gārd”) or warrior-band titles (“hird”). This practice tied families to ancestral lands.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>BY15306</td>\n",
              "      <td></td>\n",
              "      <td>Emerging around 200 CE in Roman-era Britain among Brythonic tribes, BY15306 carriers used titles like “rigos” (king) and “sens” (lord) in Brittonic dialects. These ranks formed the core of social structure.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>BY15314</td>\n",
              "      <td></td>\n",
              "      <td>Originating circa 800 CE during the Viking Age, BY15314 carriers bore Old Norse names like “Björn,” “Einar,” and “Guðrún” as clan identifiers. Personal names doubled as formal designations in warrior society.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>BY92194</td>\n",
              "      <td></td>\n",
              "      <td>Arising around 1,100 CE in the High Middle Ages, BY92194 carriers adopted occupational bynames like “Smith,” “Carpenter,” or “de la Mare.” These bynames became hereditary family names.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>FT8553</td>\n",
              "      <td></td>\n",
              "      <td>Splitting around 1,300 CE in late-medieval England, FT8553 carriers saw hereditary surnames become the norm, using fixed names like “Yates,” “Clarke,” or “Baker.” This marked the rise of modern family identity.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>FT8982</td>\n",
              "      <td></td>\n",
              "      <td>Evolving circa 1,500 CE during the Tudor era, FT8982 carriers appeared in parish records that solidified surnames. Neighbors addressed each other by their family names—Thomas Yates, John Clarke, etc.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>FT267444</td>\n",
              "      <td></td>\n",
              "      <td>Originating around 1,600 CE in the early Stuart period, FT267444 carriers included colonists moving to America. Legal records recorded full given names plus surnames like William Yates, Mary Clarke.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>FTF17042</td>\n",
              "      <td></td>\n",
              "      <td>Arising around 1,800 CE during the Georgian era, FTF17042 carriers participated in a global diaspora using first-name-last-name conventions—James Yates, Robert Clarke. <b><i>This potentially allows for autosomal DNA detection for roughly 6 generations (~162 years).</i></b></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>FT266579</td>\n",
              "      <td></td>\n",
              "      <td>Emerging circa 1,900 CE in the Victorian period, FT266579 carriers reflected modern record-keeping, addressing individuals by full legal names—John William Yates, Elizabeth Anne Clarke. <b><i>This potentially allows for autosomal DNA detection for roughly 6 generations (~162 years).</i></b></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td></td>\n",
              "      <td>P312</td>\n",
              "      <td>Originating around 5,000 BCE with Late Neolithic farming cultures along Western Europe’s Atlantic coast, P312 carriers built megaliths and early Bronze Age settlements. They likely used settlement names or pastoral-based epithets—“River Kin” or “Stone Circle Tribe” to identify clans.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td></td>\n",
              "      <td>Z46516</td>\n",
              "      <td>Splitting around 3,000 BCE in the Early Bronze Age across Britain and western France, Z46516 carriers formed proto-Celtic clans known for metalwork and trade. Tribal sept names and regional landmarks like “Hillfort People” or “Coast Guard” distinguished members.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td></td>\n",
              "      <td>ZZ11</td>\n",
              "      <td>Emerging near 2,500 BCE within Atlantic Bronze Age societies of southwestern Britain and Brittany, ZZ11 carriers controlled coastal trade routes. Chiefs and fishermen addressed one another by place-based names—“Harbor Clan” or “Dune Band” reflecting maritime lifeways.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td></td>\n",
              "      <td>U152</td>\n",
              "      <td>Branching around 2,500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "» Updated CSV saved as y_dna_comparison_updated.csv\n",
            "» HTML snippet saved as y_dna_comparison_table.html\n"
          ]
        }
      ]
    }
  ]
}