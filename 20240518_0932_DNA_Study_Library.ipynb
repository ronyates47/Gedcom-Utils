{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0swwpF35Duwy+5ALdjdjP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronyates47/Gedcom-Utils/blob/main/20240518_0932_DNA_Study_Library.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT5s4n9S5ZpZ",
        "outputId": "0ece9ef4-8fc2-4de9-e476-22c00a9ba25a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Collecting python-gedcom\n",
            "  Downloading python_gedcom-1.0.0-py2.py3-none-any.whl (35 kB)\n",
            "Installing collected packages: python-gedcom\n",
            "Successfully installed python-gedcom-1.0.0\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install python-gedcom\n",
        "!pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 20240518-0932_DNA_Study_Library\n",
        "\n",
        "import csv\n",
        "import glob\n",
        "from gedcom.element.individual import IndividualElement\n",
        "from gedcom.parser import Parser\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Hard-coded interval scheme\n",
        "interval_scheme = [\n",
        "    (1000, 1), (1025, 2), (1050, 3), (1075, 4), (1100, 5),\n",
        "    (1125, 6), (1150, 7), (1175, 8), (1200, 9), (1225, 10),\n",
        "    (1250, 11), (1275, 12), (1300, 13), (1325, 14), (1350, 15),\n",
        "    (1375, 16), (1400, 17), (1425, 18), (1450, 19), (1475, 20),\n",
        "    (1500, 21), (1525, 22), (1550, 23), (1575, 24), (1600, 25),\n",
        "    (1625, 26), (1650, 27), (1675, 28), (1700, 29), (1725, 30),\n",
        "    (1750, 31), (1775, 32), (1800, 33), (1825, 34), (1850, 35),\n",
        "    (1875, 36), (1900, 37), (1925, 38), (1950, 39), (1975, 40),\n",
        "    (2000, 41), (2025, 42), (2050, 43), (2075, 44)\n",
        "]\n",
        "\n",
        "# Function to assign interval based on birthdate\n",
        "def assign_interval(birth_date, interval_scheme):\n",
        "    if pd.isnull(birth_date):\n",
        "        return 99\n",
        "    try:\n",
        "        birth_year = int(birth_date[-4:])\n",
        "    except ValueError:\n",
        "        return 99\n",
        "    for year, interval in interval_scheme:\n",
        "        if birth_year <= year:\n",
        "            return interval\n",
        "    return 99\n",
        "\n",
        "# Update the GedcomDataset class\n",
        "class GedcomDataset:\n",
        "    def __init__(self, gen_person):\n",
        "        self.gen_person = gen_person\n",
        "        self.extractable_detail = {}\n",
        "        self.anchor_gen1 = None  # Initialize anchor_gen1 here\n",
        "\n",
        "    def add_extractable_detail(self, key, value):\n",
        "        self.extractable_detail[key] = value\n",
        "\n",
        "    def get_gen_person(self):\n",
        "        name = self.extractable_detail.get('NAME', '')\n",
        "        parts = name.split('/', 1)\n",
        "        first_name = parts[0].split(' ')[0]\n",
        "        last_name = parts[1].rstrip('/') if len(parts) > 1 else \"\"\n",
        "        self.anchor_gen1 = last_name.replace(\" \", \"\") + first_name.replace(\" \", \"\")\n",
        "        global anchor_gen1  # Declare that we're using the global variable\n",
        "        anchor_gen1 = self.anchor_gen1  # Update the global variable\n",
        "        return self.gen_person.strip('@')\n",
        "\n",
        "    def get_anchor_gen1(self):\n",
        "        return self.anchor_gen1\n",
        "\n",
        "    def get_extractable_NPFX(self):\n",
        "        return self.extractable_detail.get('NPFX', '')\n",
        "\n",
        "    def get_extractable_cm(self):\n",
        "        npfx_value = self.extractable_detail.get('NPFX', '')\n",
        "        if '&' in npfx_value:\n",
        "            cm_value = npfx_value.split('&')[0].strip()\n",
        "        else:\n",
        "            cm_value = npfx_value.strip()\n",
        "        try:\n",
        "            int(cm_value)\n",
        "            return cm_value\n",
        "        except ValueError:\n",
        "            return 'error'\n",
        "\n",
        "    def get_extractable_sort(self):\n",
        "        npfx_value = self.extractable_detail.get('NPFX', '')\n",
        "        if '&' in npfx_value:\n",
        "            sort_value = npfx_value.split('&')[1].strip()\n",
        "            return sort_value\n",
        "        else:\n",
        "            return ''\n",
        "\n",
        "    def get_extractable_FAMC(self):\n",
        "        return self.extractable_detail.get('FAMC', '').strip('@')\n",
        "\n",
        "    def get_birth_date(self):\n",
        "        return self.extractable_detail.get('BIRTH_DATE', '')\n",
        "\n",
        "    def get_fams(self):\n",
        "        return self.extractable_detail.get('FAMS', '').strip('@')\n",
        "\n",
        "# Function definitions\n",
        "def extract_id(record):\n",
        "    id_start = record.find('@') + 1\n",
        "    id_end = record.find('@', id_start)\n",
        "    return record[id_start:id_end]\n",
        "\n",
        "def extract_name(record):\n",
        "    name_start = record.find('1 NAME ') + 6\n",
        "    name_end = record.find('\\n', name_start)\n",
        "    name = record[name_start:name_end]\n",
        "    first_name, last_name = name.split('/', 1)\n",
        "    first_name = first_name[:20]\n",
        "    last_name = last_name[:20].rstrip('/')\n",
        "    return last_name.replace(\" \", \"\") + first_name.replace(\" \", \"\")\n",
        "\n",
        "name_to_id = {}   # Global dictionary to hold name to ID mapping\n",
        "\n",
        "class Gedcom:\n",
        "    def __init__(self, file_name):\n",
        "        self.file_name = file_name\n",
        "        self.gedcom_datasets = []\n",
        "        self.filter_pool = []\n",
        "\n",
        "    @staticmethod\n",
        "    def get_standard_name(file_path):\n",
        "        file_name = file_path.split('/')[-1]\n",
        "        if '.' in file_name:\n",
        "            file_name = file_name.rsplit('.', 1)[0]\n",
        "        standard_name = file_name.replace(' ', '_').lower()\n",
        "        return standard_name\n",
        "\n",
        "    def parse_gedcom(self):\n",
        "        global name_to_id  # Declare name_to_id as global to modify it\n",
        "        with open(self.file_name, 'r', encoding='utf-8-sig') as f:\n",
        "            gedcom_lines = f.readlines()\n",
        "        current_dataset = None\n",
        "        npfx_count = 0\n",
        "        total_count = 0\n",
        "\n",
        "        for line in gedcom_lines:\n",
        "            parts = line.strip().split(' ', 2)\n",
        "            level = int(parts[0])\n",
        "            tag = parts[1]\n",
        "            value = parts[2] if len(parts) > 2 else None\n",
        "\n",
        "            if level == 0 and tag.startswith('@') and tag.endswith('@') and value == 'INDI':\n",
        "                total_count += 1\n",
        "                current_dataset = GedcomDataset(tag)\n",
        "                self.gedcom_datasets.append(current_dataset)\n",
        "\n",
        "                # Populate name_to_id\n",
        "                individual_name = current_dataset.get_anchor_gen1()\n",
        "                individual_id = current_dataset.get_gen_person()\n",
        "                name_to_id[individual_name] = individual_id\n",
        "\n",
        "            elif current_dataset is not None:\n",
        "                if level == 1 and tag in ['NAME', 'FAMC', 'FAMS', 'BIRT', 'SEX']:\n",
        "                    current_key = tag\n",
        "                    current_dataset.add_extractable_detail(current_key, value)\n",
        "\n",
        "                elif level == 2 and tag == 'DATE' and current_key == 'BIRT':\n",
        "                    current_dataset.add_extractable_detail('BIRTH_DATE', value)\n",
        "\n",
        "                elif level == 2 and tag == 'NPFX':\n",
        "                    npfx_count += 1\n",
        "                    current_dataset.add_extractable_detail(tag, value)\n",
        "\n",
        "        print(f'GEDCOM contained {total_count} total records')\n",
        "        print(f'Records tagged and filtered by NPFX: {npfx_count}')\n",
        "\n",
        "        # First level of filtering: Filter those with NPFX\n",
        "        for dataset in self.gedcom_datasets:\n",
        "            if dataset.get_extractable_NPFX():\n",
        "                self.filter_pool.append(dataset)\n",
        "\n",
        "        # Check if manual filtering should be applied\n",
        "        manual_filter_activated = True  # or False depending on your situation\n",
        "\n",
        "        # Second level of filtering: Apply manual filter from Excel sheet\n",
        "        if manual_filter_activated:\n",
        "            import pandas as pd  # Assuming you haven't imported it yet\n",
        "            try:\n",
        "                df = pd.read_excel('filtered_ids.xlsx')\n",
        "            except FileNotFoundError:\n",
        "                print(\"filtered_ids.xlsx not found. Skipping second-level manual filter.\")\n",
        "            else:\n",
        "                manual_filtered_ids = set(df['ID'])\n",
        "                print(f\"Manual filter IDs loaded: {len(manual_filtered_ids) - 1}\")\n",
        "\n",
        "                self.filter_pool = [dataset for dataset in self.filter_pool if dataset.get_gen_person() in manual_filtered_ids]\n",
        "                print(f\"After manual filter, total records: {len(self.filter_pool)}\")\n",
        "\n",
        "    def apply_manual_filter(self):\n",
        "        manual_filter_activated = True\n",
        "        if manual_filter_activated:\n",
        "            import pandas as pd\n",
        "            try:\n",
        "                df = pd.read_excel('filtered_ids.xlsx')\n",
        "                manual_filtered_ids = set(df['ID'].astype(str))  # Ensure IDs are strings\n",
        "                print(f\"Manual filter IDs loaded: {len(manual_filtered_ids)}\")\n",
        "            except FileNotFoundError:\n",
        "                print(\"filtered_ids.xlsx not found. Skipping second-level manual filter.\")\n",
        "            else:\n",
        "                # Debug output to verify IDs before filtering\n",
        "                print(\"IDs before manual filter:\", [ds.get_gen_person() for ds in self.filter_pool][:10])\n",
        "                self.filter_pool = [ds for ds in self.filter_pool if str(ds.get_gen_person()) in manual_filtered_ids]\n",
        "                print(\"IDs after manual filter:\", [ds.get_gen_person() for ds in self.filter_pool][:10])\n",
        "                print(f\"After manual filter, total records: {len(self.filter_pool)}\")\n",
        "\n",
        "    def check_and_apply_exclusion_filter(self):\n",
        "        \"\"\"Apply exclusion filter if '/exclude_ids.xlsx' is present.\"\"\"\n",
        "        file_path = '/content/exclude_ids.xlsx'  # Updated path\n",
        "        if os.path.exists(file_path):\n",
        "            try:\n",
        "                df_exclude = pd.read_excel(file_path)\n",
        "                if 'ID' in df_exclude.columns:\n",
        "                    exclude_ids = set(df_exclude['ID'].astype(str))  # Ensure conversion to string\n",
        "                    print(f\"Exclusion filter IDs loaded: {len(exclude_ids)}\")\n",
        "                    print(f\"Sample of IDs to exclude: {list(exclude_ids)[:5]}\")  # Print some sample IDs\n",
        "                    # Apply the exclusion filter\n",
        "                    initial_count = len(self.filter_pool)\n",
        "                    self.filter_pool = [ds for ds in self.filter_pool if str(ds.get_gen_person()) not in exclude_ids]\n",
        "                    print(f\"Excluded {initial_count - len(self.filter_pool)} records based on exclusion IDs.\")\n",
        "                else:\n",
        "                    print(\"Column 'ID' not found in the Excel file.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to apply exclusion filter: {str(e)}\")\n",
        "        else:\n",
        "            print(f\"No exclusion filter applied, '{file_path}' not found. Check the path and ensure the file is uploaded to Colab.\")\n",
        "\n",
        "def input_prime_surname(last_prime_surname=None):\n",
        "    if last_prime_surname:\n",
        "        last_name = input(f\"Enter prime_surname (default: {last_prime_surname}): \")\n",
        "        if not last_name:\n",
        "            last_name = last_prime_surname\n",
        "    else:\n",
        "        last_name = input(\"Enter prime_surname: \")\n",
        "    return last_name\n",
        "\n",
        "def select_gedcom_file():\n",
        "    gedcom_files = glob.glob('*.ged')\n",
        "    if not gedcom_files:\n",
        "        print(\"No GEDCOM files found.\")\n",
        "        return None\n",
        "\n",
        "    print(\"Automatically selecting the first GEDCOM file.\")\n",
        "    return gedcom_files[0]\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            selected_num = int(input(\"Enter the number of the GEDCOM file you want to use: \"))\n",
        "            if 1 <= selected_num <= len(gedcom_files):\n",
        "                return gedcom_files[selected_num - 1]\n",
        "            else:\n",
        "                print(\"Invalid number. Please enter a valid number from the list.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a valid number.\")\n",
        "\n",
        "gedcom_file_path = select_gedcom_file() # Call the function to let the user select the GEDCOM file\n",
        "if gedcom_file_path:\n",
        "    # Use the selected GEDCOM file path to create an instance of the Gedcom class\n",
        "    gedcom_instance = Gedcom(gedcom_file_path)\n",
        "    gedcom_instance.parse_gedcom()\n",
        "\n",
        "    individuals = []  # Initialize the list of individuals\n",
        "\n",
        "    for dataset in gedcom_instance.filter_pool:    # Iterate over the filter_pool list, add each last name and ID to list\n",
        "        individual_id = dataset.get_gen_person()\n",
        "        last_name = dataset.get_anchor_gen1()\n",
        "        individuals.append((last_name, individual_id))\n",
        "\n",
        "    print(f'Records tagged and filtered by NPFX: {len(individuals)}')\n",
        "\n",
        "    with open(gedcom_file_path, 'r') as file:    # Read the GEDCOM file and split it into individual and family records\n",
        "        data = file.read()\n",
        "    data = data.split('\\n0 ')\n",
        "    records = {extract_id(record): record for record in data}\n",
        "\n",
        "def has_both_parents(records, mother_id, father_id):\n",
        "    return mother_id in records and father_id in records\n",
        "\n",
        "visited_pairs = set()\n",
        "generation_table = []\n",
        "\n",
        "def find_parents(individual_id, generation, records):\n",
        "    if individual_id not in records:\n",
        "        return\n",
        "    record = records[individual_id]\n",
        "    famc_start = record.find('1 FAMC @') + 8\n",
        "    famc_end = record.find('@', famc_start)\n",
        "    famc_id = record[famc_start:famc_end]\n",
        "    if famc_id not in records:\n",
        "        return\n",
        "\n",
        "    fam_record = records[famc_id]\n",
        "    wife_start = fam_record.find('1 WIFE @') + 8\n",
        "    wife_end = fam_record.find('@', wife_start)\n",
        "    mother_id = fam_record[wife_start:wife_end]\n",
        "\n",
        "    husb_start = fam_record.find('1 HUSB @') + 8\n",
        "    husb_end = fam_record.find('@', husb_start)\n",
        "    father_id = fam_record[husb_start:husb_end]\n",
        "\n",
        "    if mother_id and mother_id in records and father_id and father_id in records:\n",
        "        parent_pair = (father_id, mother_id)\n",
        "        if parent_pair not in visited_pairs:\n",
        "            visited_pairs.add(parent_pair)\n",
        "            generation_table.append((generation, parent_pair))\n",
        "\n",
        "    if mother_id:\n",
        "        find_parents(mother_id, generation + 1, records)\n",
        "\n",
        "    if father_id:\n",
        "        find_parents(father_id, generation + 1, records)\n",
        "\n",
        "def extract_name(record):\n",
        "    name_start = record.find('1 NAME ') + 6\n",
        "    name_end = record.find('\\n', name_start)\n",
        "    name = record[name_start:name_end]\n",
        "    first_name, last_name = name.split('/', 1)\n",
        "    first_name = first_name[:20]\n",
        "    last_name = last_name[:20].rstrip('/')\n",
        "    return last_name.replace(\" \", \"\") + first_name.replace(\" \", \"\")\n",
        "\n",
        "def find_distant_ancestors(individual_id, records, path=None):\n",
        "    path = path if path is not None else []\n",
        "    if path is None:\n",
        "        path = [individual_id]\n",
        "    else:\n",
        "        path.append(individual_id)\n",
        "\n",
        "    if individual_id not in records:\n",
        "        return []\n",
        "\n",
        "    record = records[individual_id]\n",
        "    famc_start = record.find('1 FAMC @') + 8\n",
        "    famc_end = record.find('@', famc_start)\n",
        "    famc_id = record[famc_start:famc_end]\n",
        "\n",
        "    if famc_id not in records:\n",
        "        return [path]\n",
        "\n",
        "    fam_record = records[famc_id]\n",
        "    wife_start = fam_record.find('1 WIFE @') + 8\n",
        "    wife_end = fam_record.find('@', wife_start)\n",
        "    mother_id = fam_record[wife_start:wife_end]\n",
        "\n",
        "    husb_start = fam_record.find('1 HUSB @') + 8\n",
        "    husb_end = fam_record.find('@', husb_start)\n",
        "    father_id = fam_record[husb_start:husb_end]\n",
        "\n",
        "    if father_id is None and mother_id is None:\n",
        "        return [path]\n",
        "\n",
        "    paths = []\n",
        "    if father_id:\n",
        "        new_path = list(path)\n",
        "        paths.extend(find_distant_ancestors(father_id, records, new_path))\n",
        "\n",
        "    if mother_id:\n",
        "        new_path = list(path)\n",
        "        paths.extend(find_distant_ancestors(mother_id, records, new_path))\n",
        "\n",
        "#    print(f\"Distant ancestors paths for {individual_id}: {paths}\")\n",
        "\n",
        "    return paths\n",
        "filtered_datasets = gedcom_instance.filter_pool\n",
        "\n",
        "#global generation_table\n",
        "#global visited_pairs\n",
        "\n",
        "def calculate_score(distant_ancestors_paths, records):\n",
        "    name_paths = []\n",
        "    for path in distant_ancestors_paths:\n",
        "        name_path = [extract_name(records.get(id, '')) for id in path]\n",
        "        name_paths.append(name_path)\n",
        "\n",
        "    path_scores = {}\n",
        "    for idx, name_path in enumerate(name_paths):\n",
        "        score = 0\n",
        "        for generation, name in enumerate(name_path):\n",
        "            if 'Yates' in name:\n",
        "                score += 1 * (generation + 1)\n",
        "        path_scores[idx] = score\n",
        "\n",
        "    if path_scores:\n",
        "        winning_path_index = max(path_scores, key=path_scores.get)\n",
        "        winning_path_score = path_scores[winning_path_index]\n",
        "        winning_path_names = name_paths[winning_path_index]\n",
        "        winning_path_ids = distant_ancestors_paths[winning_path_index]\n",
        "    else:\n",
        "        winning_path_index = None\n",
        "        winning_path_score = 0\n",
        "        winning_path_names = []\n",
        "        winning_path_ids = []\n",
        "\n",
        "    return winning_path_score, winning_path_names, winning_path_ids\n",
        "\n",
        "def filter_ancestral_line(winning_path_ids, generation_table):\n",
        "    matching_table = []\n",
        "\n",
        "    for generation, pair in generation_table:\n",
        "        id1, id2 = pair\n",
        "        if id1 in winning_path_ids or id2 in winning_path_ids:\n",
        "            matching_table.append((generation, pair))\n",
        "\n",
        "    return matching_table\n",
        "\n",
        "def filter_ancestral_line(winning_path_ids, generation_table):\n",
        "    matching_table = []\n",
        "    for generation, pair in generation_table:\n",
        "        id1, id2 = pair\n",
        "        if id1 in winning_path_ids or id2 in winning_path_ids:\n",
        "            matching_table.append((generation, pair))\n",
        "    return matching_table\n",
        "\n",
        "# Main Loop\n",
        "for dataset in filtered_datasets:\n",
        "    individual_id = dataset.get_gen_person()\n",
        "\n",
        "    visited_pairs = set()\n",
        "    generation_table = []\n",
        "\n",
        "    find_parents(individual_id, 1, records)\n",
        "    distant_ancestors_paths = find_distant_ancestors(individual_id, records)\n",
        "    winning_path_score, winning_path_names, winning_path_ids = calculate_score(distant_ancestors_paths, records)\n",
        "    filtered_ancestral_line = filter_ancestral_line(winning_path_ids, generation_table)\n",
        "    filtered_ancestral_line.sort(key=lambda x: x[0])\n",
        "    filtered_ancestral_line_names = []\n",
        "    for generation, pair in filtered_ancestral_line:\n",
        "        name_pair = [extract_name(records.get(id, '')) for id in pair]\n",
        "        formatted_name_pair = f\"{name_pair[0]}&{name_pair[1]}\"\n",
        "        filtered_ancestral_line_names.append(formatted_name_pair)\n",
        "\n",
        "    filtered_ancestral_line_names.reverse()\n",
        "#    filtered_ancestral_line_str = \"|\".join(filtered_ancestral_line_names)\n",
        "#    print(f\"Filtered Ancestral Line for {individual_id}: {filtered_ancestral_line_str}\")\n",
        "\n",
        "def process_individual(individual_id, gedcom_instance, records, interval_scheme):\n",
        "    global generation_table\n",
        "    global visited_pairs\n",
        "    global anchor_gen1  # Declare that we're using the global variable\n",
        "\n",
        "    generation_table = []\n",
        "    visited_pairs = set()\n",
        "\n",
        "    find_parents(individual_id, 1, records)\n",
        "    distant_ancestors_paths = find_distant_ancestors(individual_id, records)\n",
        "    winning_path_score, winning_path_names, winning_path_ids = calculate_score(distant_ancestors_paths, records)\n",
        "    filtered_ancestral_line = filter_ancestral_line(winning_path_ids, generation_table)\n",
        "    filtered_ancestral_line.sort(key=lambda x: x[0])\n",
        "    filtered_ancestral_line_names = []\n",
        "    birth_date = None  # Initialize birth_date\n",
        "\n",
        "    # Extract cm_value, sort_value, anchor_gen1, and birth_date\n",
        "    for dataset in gedcom_instance.filter_pool:\n",
        "        if dataset.get_gen_person() == individual_id:\n",
        "            cm_value = dataset.get_extractable_cm()\n",
        "            sort_value = dataset.get_extractable_sort()\n",
        "            anchor_gen1 = dataset.get_anchor_gen1()  # Update anchor_gen1 locally here\n",
        "            birth_date = dataset.extractable_detail.get('BIRTH_DATE')  # Get birth date\n",
        "            break\n",
        "    else:\n",
        "        cm_value = 'N/A'\n",
        "        sort_value = 'N/A'\n",
        "        birth_date = 'N/A'  # Set default if not found\n",
        "\n",
        "    if anchor_gen1 is not None:\n",
        "        filtered_ancestral_line_names.insert(0, anchor_gen1)\n",
        "\n",
        "    ancestors_data = []\n",
        "\n",
        "    # Extract ancestor information\n",
        "    for generation, pair in filtered_ancestral_line:\n",
        "        name_pair = [extract_name(records.get(id, '')) for id in pair]\n",
        "        formatted_name_pair = f\"{name_pair[0]}&{name_pair[1]}\"\n",
        "        filtered_ancestral_line_names.append(formatted_name_pair)\n",
        "\n",
        "        # Extract details for each ancestor in the pair\n",
        "        for ancestor_id in pair:\n",
        "            if ancestor_id in records:\n",
        "                ancestor_record = records[ancestor_id]\n",
        "                ancestor_name = extract_name(ancestor_record)\n",
        "                ancestor_sex = 'M' if '1 SEX M' in ancestor_record else 'F' if '1 SEX F' in ancestor_record else ''\n",
        "                birth_date_start = ancestor_record.find('2 DATE ') + 7\n",
        "                birth_date_end = ancestor_record.find('\\n', birth_date_start)\n",
        "                ancestor_birth_date = ancestor_record[birth_date_start:birth_date_end].strip() if birth_date_start != -1 else 'N/A'\n",
        "                ancestor_date_interval = assign_interval(ancestor_birth_date, interval_scheme)\n",
        "\n",
        "                ancestors_data.append({\n",
        "                    'ID': ancestor_id,\n",
        "                    'Name': ancestor_name,\n",
        "                    'Sex': ancestor_sex,\n",
        "                    'Birth Date': ancestor_birth_date,\n",
        "                    'Date Interval': ancestor_date_interval\n",
        "                })\n",
        "\n",
        "    filtered_ancestral_line_names.reverse()\n",
        "    filtered_ancestral_line_str = \"~~~\".join(filtered_ancestral_line_names)\n",
        "\n",
        "    # Assign date interval\n",
        "    date_interval = assign_interval(birth_date, interval_scheme)\n",
        "\n",
        "    individual_data = {\n",
        "        'ID': individual_id,\n",
        "        'Name': extract_name(records[individual_id]),\n",
        "        'Sex': dataset.extractable_detail.get('SEX', ''),\n",
        "        'Birth Date': birth_date,\n",
        "        'Date Interval': date_interval,\n",
        "        'FAMS': dataset.get_fams(),\n",
        "        'FAMC': dataset.get_extractable_FAMC(),\n",
        "        'Ancestors': ancestors_data  # Add ancestors data to individual data\n",
        "    }\n",
        "\n",
        "    return individual_data, filtered_ancestral_line_str\n",
        "\n",
        "# Initialize the dictionary to store individual data\n",
        "DNA_Study_Library = {}\n",
        "\n",
        "# Process individuals and populate the dictionary\n",
        "for dataset in gedcom_instance.filter_pool:  # Assuming filter_pool is iterable\n",
        "    individual_id = dataset.get_gen_person()\n",
        "\n",
        "    # Reset global variables for each new individual\n",
        "    visited_pairs.clear()\n",
        "    generation_table = []\n",
        "\n",
        "    # Process Individual and Get Data\n",
        "    individual_data, filtered_ancestral_line_str = process_individual(individual_id, gedcom_instance, records, interval_scheme)\n",
        "\n",
        "    # Store the data in the dictionary\n",
        "    DNA_Study_Library[individual_id] = individual_data\n",
        "\n",
        "# Output the first 5 records in a columnar format\n",
        "print(f\"{'ID':<10}{'Name':<20}{'Sex':<5}{'Birth Date':<12}{'Date Interval':<15}{'FAMS':<10}{'FAMC':<10}{'Ancestors':<30}\")\n",
        "for idx, (individual_id, data) in enumerate(DNA_Study_Library.items()):\n",
        "    if idx >= 25:\n",
        "        break\n",
        "    # Replace None values with empty strings\n",
        "    name = data['Name'] or ''\n",
        "    sex = data['Sex'] or ''\n",
        "    birth_date = data['Birth Date'] or ''\n",
        "    date_interval = data['Date Interval'] or ''\n",
        "    fams = data['FAMS'] or ''\n",
        "    famc = data['FAMC'] or ''\n",
        "    ancestors = ', '.join([f\"{ancestor['Name']} ({ancestor['ID']})\" for ancestor in data['Ancestors']])\n",
        "    print(f\"{individual_id:<10}{name:<20}{sex:<5}{birth_date:<12}{date_interval:<15}{fams:<10}{famc:<10}{ancestors:<30}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6G3pF_sx6btx",
        "outputId": "263ce94e-8d33-4ec3-d335-0ef2f756c329"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically selecting the first GEDCOM file.\n",
            "GEDCOM contained 55730 total records\n",
            "Records tagged and filtered by NPFX: 1045\n",
            "filtered_ids.xlsx not found. Skipping second-level manual filter.\n",
            "Records tagged and filtered by NPFX: 1045\n",
            "ID        Name                Sex  Birth Date  Date Interval  FAMS      FAMC      Ancestors                     \n",
            "I73       YatesJamesRobert    M    24 MAR 2018 42             F90       F6        YatesHarryElmer (I4), TingleyOrliaGeorgeann (I27), YatesJamesWilson (I5), OttMaryEllen (I11), YatesJohnE (I6), RobersonElizabeth (I10), YatesJohn (I3097), SwiftMary (I3098), YatesJohn (I1498), SearchingStill (I22324), YatesBenjamin (I19677), SearchingStill (I54742), YatesBenjamin (I18175), SearchingStill (I55721)\n",
            "I80       YatesPatriciaLynn   F    1 JUL 1951  40             F98       F3        YatesCarlBernell (I3), CarpenterLuellaMay (I7), YatesHarryElmer (I4), LaswellJessieLeah (I12), YatesJamesWilson (I5), OttMaryEllen (I11), YatesJohnE (I6), RobersonElizabeth (I10), YatesJohn (I3097), SwiftMary (I3098), YatesJohn (I1498), SearchingStill (I22324), YatesBenjamin (I19677), SearchingStill (I54742), YatesBenjamin (I18175), SearchingStill (I55721)\n",
            "I82       YatesTimothyJoseph  M    15 DEC 2023 42             F99       F85       YatesFredAllen (I69), GeorgeBarbaraAnn (I85), YatesHarryElmer (I4), LaswellJessieLeah (I12), YatesJamesWilson (I5), OttMaryEllen (I11), YatesJohnE (I6), RobersonElizabeth (I10), YatesJohn (I3097), SwiftMary (I3098), YatesJohn (I1498), SearchingStill (I22324), YatesBenjamin (I19677), SearchingStill (I54742), YatesBenjamin (I18175), SearchingStill (I55721)\n",
            "I84       YatesAndreaLynn     F    17 JUN 1952 40             F101      F85       YatesFredAllen (I69), GeorgeBarbaraAnn (I85), YatesHarryElmer (I4), LaswellJessieLeah (I12), YatesJamesWilson (I5), OttMaryEllen (I11), YatesJohnE (I6), RobersonElizabeth (I10), YatesJohn (I3097), SwiftMary (I3098), YatesJohn (I1498), SearchingStill (I22324), YatesBenjamin (I19677), SearchingStill (I54742), YatesBenjamin (I18175), SearchingStill (I55721)\n",
            "I613      WaldrupGlendaKay    F    28 APR 2020 42             F523      F514      WaldrupMurrayFranklin (I37378), YatesShirleyJean (I611), YatesCharlesElmer (I41), JeffersLucyNancy (I538), YatesArthurLee (I20), HarmanEllaL. (I37), YatesJamesWilson (I5), OttMaryEllen (I11), YatesJohnE (I6), RobersonElizabeth (I10), YatesJohn (I3097), SwiftMary (I3098), YatesJohn (I1498), SearchingStill (I22324), YatesBenjamin (I19677), SearchingStill (I54742), YatesBenjamin (I18175), SearchingStill (I55721)\n",
            "I687      SarlesGaryBernell   M    6 NOV 1967  40             F560      F556      SarlesOrvilleBernell (I677), WaltsBettyImogene (I678), SarlesOrin (I508), YatesGoldieLucille (I22), YatesJamesWilson (I5), OttMaryEllen (I11), YatesJohnE (I6), RobersonElizabeth (I10), YatesJohn (I3097), SwiftMary (I3098), YatesJohn (I1498), SearchingStill (I22324), YatesBenjamin (I19677), SearchingStill (I54742), YatesBenjamin (I18175), SearchingStill (I55721)\n",
            "I800      WeberWayneWilliam   M    18 JAN 1990 41                       F617      WeberWayne (I797), YatesTinaMarie (I796), YatesRichardEugene (I514), AlexanderConstanceMaxine (I795), YatesHarryEugene (I68), WynnErnaGeraldine (I79), YatesHarryElmer (I4), LaswellJessieLeah (I12), YatesJamesWilson (I5), OttMaryEllen (I11), YatesJohnE (I6), RobersonElizabeth (I10), YatesJohn (I3097), SwiftMary (I3098), YatesJohn (I1498), SearchingStill (I22324), YatesBenjamin (I19677), SearchingStill (I54742), YatesBenjamin (I18175), SearchingStill (I55721)\n",
            "I808      ScroghamWadeA.      M    27 JAN 1976 41             F626      F100      ScroghamJamesW. (I807), YatesAndreaLynn (I84), YatesFredAllen (I69), GeorgeBarbaraAnn (I85), YatesHarryElmer (I4), LaswellJessieLeah (I12), YatesJamesWilson (I5), OttMaryEllen (I11), YatesJohnE (I6), RobersonElizabeth (I10), YatesJohn (I3097), SwiftMary (I3098), YatesJohn (I1498), SearchingStill (I22324), YatesBenjamin (I19677), SearchingStill (I54742), YatesBenjamin (I18175), SearchingStill (I55721)\n",
            "I836      YatesHolleeBeth     F    6 DEC 1985  41                       F636      YatesJamesPatrick (I833), GoodwinCindyAnn (I834), YatesJamesRobert (I73), CarrollRuthEmaline (I74), YatesHarryElmer (I4), TingleyOrliaGeorgeann (I27), YatesJamesWilson (I5), OttMaryEllen (I11), YatesJohnE (I6), RobersonElizabeth (I10), YatesJohn (I3097), SwiftMary (I3098), YatesJohn (I1498), SearchingStill (I22324), YatesBenjamin (I19677), SearchingStill (I54742), YatesBenjamin (I18175), SearchingStill (I55721)\n",
            "I837      YatesMitchellStephenM    20 JAN 1988 41                       F636      YatesJamesPatrick (I833), GoodwinCindyAnn (I834), YatesJamesRobert (I73), CarrollRuthEmaline (I74), YatesHarryElmer (I4), TingleyOrliaGeorgeann (I27), YatesJamesWilson (I5), OttMaryEllen (I11), YatesJohnE (I6), RobersonElizabeth (I10), YatesJohn (I3097), SwiftMary (I3098), YatesJohn (I1498), SearchingStill (I22324), YatesBenjamin (I19677), SearchingStill (I54742), YatesBenjamin (I18175), SearchingStill (I55721)\n",
            "I869      YatesTimothyBrian   M    1 MAR 2024  42             F657      F655      YatesColonelC (I866), HarrisBerniceJ. (I867), YatesJohnLogan (I864), LongestFanningEmmilene (I865), YatesThomasJefferson (I30), ScottRozella (I863), YatesJohnE (I6), RobersonElizabeth (I10), YatesJohn (I3097), SwiftMary (I3098), YatesJohn (I1498), SearchingStill (I22324), YatesBenjamin (I19677), SearchingStill (I54742), YatesBenjamin (I18175), SearchingStill (I55721)\n",
            "I2133     GirtainAlmaIrene    F    9 DEC 2021  42             F1430     F1431     GirtainEdgarFikes (I25354), SchwalmAnnaMarie (I26502), GirtainRobertPernal (I25353), YatesLouisaFrambes (I25210), YatesWilliamC (I25160), ReeseCarolineW (I25208), YatesAbraham (I25159), SearchingStill (I55026), YatesAbraham (I25164), SearchingStill (I55027)\n",
            "I2911     WeeksJerriLynn      F    23 APR 1960 40             F1849     F1829     WeeksLarryGordon (I3394), EvansEdith (I2871), EvansEmmettNoble (I3065), YatesIdaGrace (I1942), YatesBarney (I2812), WeathersEmmaElizabeth (I2927), YatesJohnHenry (I1473), RhodesIdaCordellia (I1479), YatesAlbert (I1470), AustinSusanE (I1471), YatesSilasW (I1468), BellLavina (I1469), YatesRobert (I1485), ByersMaryAnn (I1486), YatesJohn (I1498), SearchingStill (I22324), YatesBenjamin (I19677), SearchingStill (I54742), YatesBenjamin (I18175), SearchingStill (I55721)\n",
            "I3396     BakerHalieMarie     F    16 JAN 1986 41                       F1849     BakerKeithLeonard (I3063), WeeksJerriLynn (I2911), WeeksLarryGordon (I3394), EvansEdith (I2871), EvansEmmettNoble (I3065), YatesIdaGrace (I1942), YatesBarney (I2812), WeathersEmmaElizabeth (I2927), YatesJohnHenry (I1473), RhodesIdaCordellia (I1479), YatesAlbert (I1470), AustinSusanE (I1471), YatesSilasW (I1468), BellLavina (I1469), YatesRobert (I1485), ByersMaryAnn (I1486), YatesJohn (I1498), SearchingStill (I22324), YatesBenjamin (I19677), SearchingStill (I54742), YatesBenjamin (I18175), SearchingStill (I55721)\n",
            "I4433     HenryCheryl         F    15 FEB 1958 40             F2653     F2654     HenryGaylordDennis (I4439), DavisShirleyJean (I33419), DavisRaymond (I4808), KochMaryFrancis (I4750), DavisRileyDexter (I4811), LeeFlorenceEllen (I4815), LeeLeviFrank (I4835), WishardNancyCatherine (I5806), WishardSilasW (I24213), YatesMinerva (I24212), YatesJohn (I3097), SwiftMary (I3098), YatesJohn (I1498), SearchingStill (I22324), YatesBenjamin (I19677), SearchingStill (I54742), YatesBenjamin (I18175), SearchingStill (I55721)\n",
            "I5323     LongestHelenKay     F    18 SEP 1943 39             F3154     F1293     LongestJesseFerris (I2340), SturgeonTrueNoahlanel (I1926), LongestJesse (I1927), BennettRebecca (I3029), BennettSanford (I3741), YatesCatherine (I3101), YatesJames (I1499), ButlerMaryAnn (I1502), YatesJohn (I1498), SearchingStill (I22324), YatesBenjamin (I19677), SearchingStill (I54742), YatesBenjamin (I18175), SearchingStill (I55721)\n",
            "I5968     YatesKelly          F    25 SEP 1966 40             F3461     F3462     YatesDarrellRay (I5972), FergusonDebraAnn (I42598), YatesStewartDelbert (I5971), FransIlahDee (I5967), YatesBenjaminAlbert (I1867), RailsBlondia (I1868), YatesDaniel (I3381), RobersonNancy (I1437), YatesJohn (I3097), SwiftMary (I3098), YatesJohn (I1498), SearchingStill (I22324), YatesBenjamin (I19677), SearchingStill (I54742), YatesBenjamin (I18175), SearchingStill (I55721)\n",
            "I6106     BoykenCalvin        M    ABT 1950    39                       F3512     BoykenCalvinLee (I6221), MorrisBettyJoyce (I6172), NashWilliamArmstrong (I6278), HallHellenFrancis (I6227), NashMoses (I6318), HughesMaryA. (I1959), HughesJamesArmstrong (I1496), YatesRachel (I1492), YatesRobert (I1485), ByersMaryAnn (I1486), YatesJohn (I1498), SearchingStill (I22324), YatesBenjamin (I19677), SearchingStill (I54742), YatesBenjamin (I18175), SearchingStill (I55721)\n",
            "I6670     O'BryanStevenAllen  M    8 JAN 1963  40             F3671     F574      O'BryanVerneRay (I714), LongPatriciaMae (I41956), O'BryanMarshall (I703), HallCarmenBeatrice (I520), HallJamesParis (I515), YatesLillyAnn (I23), YatesJamesWilson (I5), OttMaryEllen (I11), YatesJohnE (I6), RobersonElizabeth (I10), YatesJohn (I3097), SwiftMary (I3098), YatesJohn (I1498), SearchingStill (I22324), YatesBenjamin (I19677), SearchingStill (I54742), YatesBenjamin (I18175), SearchingStill (I55721)\n",
            "I7200     YatesRobertDavid    M    18 OCT 2023 42             F3981     F3982     YatesRussellJosiah (I7366), HarringtonMargaretAnn (I35709), YatesHarryGeorge (I7782), SheldonGraceAmy (I7514)\n",
            "I10434    CareySandraJo       F    18 FEB 1950 39             F5109     F5111     CareyHerbertFrancis (I10432), ByrdMaryKathryn (I25751), ByrdDouglasNewton (I3690), McElroyAliceGrace (I9814), ByrdBryant (I1464), YatesKathryn (I1457), YatesTolbertThompson (I1489), McCraneyJennyJane (I1494), YatesRobert (I1485), ByersMaryAnn (I1486), YatesJohn (I1498), SearchingStill (I22324), YatesBenjamin (I19677), SearchingStill (I54742), YatesBenjamin (I18175), SearchingStill (I55721)\n",
            "I13817    YatesWilliamHenry   M    8 JUL 1992  41             F6523     F6522     YatesSamAndersonHaywoo (I13815), MooreMartha (I13816), YatesWilliamWesley (I13813), BozemanBarbaraJane (I13814), YatesJohnJ (I13811), YatesAgnesAnn (I13812)\n",
            "I17239    YatesJacalynMarie   F    1 NOV 1965  40             F7564     F1865     YatesHarold (I2954), ZinzerEleanorRose (I17233), YatesBarney (I2812), WeathersEmmaElizabeth (I2927), YatesJohnHenry (I1473), RhodesIdaCordellia (I1479), YatesAlbert (I1470), AustinSusanE (I1471), YatesSilasW (I1468), BellLavina (I1469), YatesRobert (I1485), ByersMaryAnn (I1486), YatesJohn (I1498), SearchingStill (I22324), YatesBenjamin (I19677), SearchingStill (I54742), YatesBenjamin (I18175), SearchingStill (I55721)\n",
            "I17354    HaysJonP.           M    ABT 1963    40                       F7596     HaysJamesBruce (I17884), TryonLilaM. (I17659), HaysJamesHobart (I17930), PriceArtemisseMay (I17905), HaysGeorgeEdward (I18004), RiggleMahalaElizabeth (I12568), RiggleJames (I5403), RobersonRachael (I1438), RobersonBenjaminM. (I1430), YatesSarah (I1432), YatesJohn (I1498), SearchingStill (I22324), YatesBenjamin (I19677), SearchingStill (I54742), YatesBenjamin (I18175), SearchingStill (I55721)\n",
            "I18236    YatesNelsonFrank    M    7 APR 1928  39             F7886     F7882     YatesFrankNelson (I18219), RestivoSarahRosalie (I18232), YatesGalenusMarion (I13863), BurnerNellieAnn (I13864), YatesJohnMinor (I6372), JenkinsMaryJane (I11182), YatesGerardMarkwood (I11640), CrawfordMatilda (I11641), YatesJamesLewis (I11346), PartlowLucy (I11639), YatesGeorge (I5027), LewisFrancesFielding (I9936), YatesGeorge (I5028), GuineyAnne (I9932), YatesGeorge (I9912), WarfieldRachael (I9913), YatesGeorge (I9914), WellsMary (I9915), YatesJohn (I11798), TettershallMaryElizabeth (I11797), YatesThomas (I24380), StephensDorothy (I24381), YatesFrancis (I24382), TichborneJane (I24383), YatesThomas (I24502), WhiteFrances (I24503), YatesJohn (I47548), HydeAlice (I47553), YatesRichard (I47549), AshendonJoan (I47550), YatesEdmund (I47569), CornellMargaret (I47641), YatesWilliam (I47570), SearchingStill (I55587), YatesWilliam (I47666), SearchingStill (I55586), YatesJohn (I47640), SearchingStill (I55585)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Super visualize 20240517-2008\n",
        "\n",
        "import pandas as pd\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.utils.dataframe import dataframe_to_rows\n",
        "from openpyxl.styles import Border, Side, Alignment, PatternFill\n",
        "\n",
        "def process_data(filepath):\n",
        "    \"\"\"Load data, process it to expand 'Yates DNA Ancestral Line', calculate FQ and QI, sort by frequency, and save results with visual separators.\"\"\"\n",
        "    # Load the DataFrame\n",
        "    df = pd.read_excel(filepath)\n",
        "\n",
        "    # Prepare to expand and process\n",
        "    expanded_data = []\n",
        "    parents_stack = []\n",
        "    starting_plane = 0\n",
        "\n",
        "    # Process each row to expand and calculate\n",
        "    for index, row in df.iterrows():\n",
        "        nodes = row['Yates DNA Ancestral Line'].split('~~~')\n",
        "        for i, node in enumerate(nodes):\n",
        "            plane = i + starting_plane\n",
        "            if len(parents_stack) > i:\n",
        "                parents_stack[i] = node\n",
        "            else:\n",
        "                parents_stack.append(node)\n",
        "            parent = parents_stack[i-1] if i > 0 else None\n",
        "            expanded_data.append({\n",
        "                'Gen #': plane,\n",
        "                'Offspring & Spouse': node,\n",
        "                'Parents': parent,\n",
        "                'cM': row['cM'],\n",
        "                'ID': row.get('ID', '')  # Ensure ID is optionally included\n",
        "            })\n",
        "\n",
        "    # Convert the list to a DataFrame\n",
        "    expanded_df = pd.DataFrame(expanded_data)\n",
        "\n",
        "    # Group by 'Gen #' and 'Parents' and calculate FQ and QI\n",
        "    results_df = expanded_df.groupby(['Gen #', 'Parents', 'Offspring & Spouse']).agg(\n",
        "        FQ=('Offspring & Spouse', 'size'),\n",
        "        QI=('cM', 'mean')\n",
        "    ).reset_index()\n",
        "    results_df['QI'] = pd.to_numeric(results_df['QI'], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "    # Filter results where FQ is greater than or equal to 3\n",
        "    final_results_df = results_df[results_df['FQ'] >= 3].copy()\n",
        "\n",
        "    # Sort data by 'Gen #', 'FQ', and then 'Offspring & Spouse' for proper ranking\n",
        "    final_results_df.sort_values(by=['Gen #', 'FQ', 'Offspring & Spouse'], ascending=[True, False, True], inplace=True)\n",
        "\n",
        "    # Create an Excel file with openpyxl\n",
        "    wb = Workbook()\n",
        "    ws = wb.active\n",
        "\n",
        "    # Adding rows to worksheet\n",
        "    headers = ['Gen #', 'Parents', 'Offspring & Spouse', 'FQ', 'QI']\n",
        "    ws.append(headers)\n",
        "\n",
        "    # Initialize variables to track last seen parent and generation\n",
        "    last_gen = None\n",
        "    last_parent = None\n",
        "    parent_seen = set()\n",
        "\n",
        "    for r in dataframe_to_rows(final_results_df, index=False, header=False):\n",
        "        current_gen, current_parent = r[0], r[1]\n",
        "\n",
        "        if current_parent not in parent_seen:\n",
        "            parent_seen.add(current_parent)\n",
        "            ws.append(r)\n",
        "        else:\n",
        "            r[1] = ''  # Clear parent name for repeated entries within the same generation\n",
        "            ws.append(r)\n",
        "\n",
        "    # Adding borders, alignment, and fill colors for readability\n",
        "    thin = Side(border_style=\"thin\", color=\"000000\")\n",
        "    thick = Side(border_style=\"thick\", color=\"000000\")\n",
        "    center_alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
        "\n",
        "    # Define fill colors for different generations\n",
        "    colors = ['FFCCCB', 'CCFFCC']  # Alternate colors for different generations\n",
        "    color_idx = 0\n",
        "\n",
        "    # Apply borders, alignment, and fill colors within the sheet\n",
        "    last_gen = None\n",
        "    for row in ws.iter_rows(min_row=2, max_col=len(headers), max_row=ws.max_row):\n",
        "        current_gen = row[0].value\n",
        "        current_parent = row[1].value\n",
        "\n",
        "        if last_gen is not None and current_gen != last_gen:\n",
        "            color_idx = (color_idx + 1) % len(colors)\n",
        "            for cell in row:\n",
        "                cell.border = Border(top=thick, left=thin, right=thin, bottom=thin)\n",
        "        else:\n",
        "            for cell in row:\n",
        "                if cell.column_letter != 'B':  # Avoid placing borders on the parent column\n",
        "                    cell.border = Border(top=thin, left=thin, right=thin, bottom=thin)\n",
        "\n",
        "        fill = PatternFill(start_color=colors[color_idx], end_color=colors[color_idx], fill_type=\"solid\")\n",
        "        for cell in row:\n",
        "            cell.alignment = center_alignment\n",
        "            cell.fill = fill\n",
        "\n",
        "        last_gen = current_gen\n",
        "\n",
        "    # Apply thick border after each parent group\n",
        "    for row in ws.iter_rows(min_row=2, max_col=len(headers), max_row=ws.max_row):\n",
        "        current_parent = row[1].value\n",
        "        if current_parent and current_parent != last_parent:\n",
        "            for cell in row:\n",
        "                cell.border = Border(top=thick, left=thin, right=thin, bottom=thin)\n",
        "        last_parent = current_parent\n",
        "\n",
        "    # Save the workbook\n",
        "    output_file = '/content/4_generations_chart_styled.xlsx'\n",
        "    wb.save(output_file)\n",
        "    print(f\"Results successfully saved with styled borders to {output_file}\")\n",
        "\n",
        "# Specify the file path for the data\n",
        "input_file_path = '/content/3_generations_fq-qi.xlsx'\n",
        "\n",
        "# Process the data\n",
        "process_data(input_file_path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t45DEfA4LOxb",
        "outputId": "70d2669c-d4a7-41f4-c646-50bd403aecf3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results successfully saved with styled borders to /content/4_generations_chart_styled.xlsx\n"
          ]
        }
      ]
    }
  ]
}