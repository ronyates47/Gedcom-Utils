{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7oB3eXbjYchP4NcugNdbj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronyates47/Gedcom-Utils/blob/main/GOLD_May.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT5s4n9S5ZpZ",
        "outputId": "f3090f77-8fe9-44a1-e8a5-2163f89bf6d7",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting python-gedcom\n",
            "  Downloading python_gedcom-1.0.0-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Downloading python_gedcom-1.0.0-py2.py3-none-any.whl (35 kB)\n",
            "Installing collected packages: python-gedcom\n",
            "Successfully installed python-gedcom-1.0.0\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "Downloading XlsxWriter-3.2.3-py3-none-any.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.3\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.11/dist-packages (0.23.4)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.15.2)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.1->mlxtend) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install python-gedcom\n",
        "!pip install openpyxl\n",
        "!pip install xlsxwriter\n",
        "!pip install mlxtend\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Gmail SMTP creds\n",
        "os.environ['GMAIL_USER']         = 'yatesvilleron@gmail.com'\n",
        "os.environ['GMAIL_APP_PASSWORD'] = 'qtziwiblytgrlzvx'\n",
        "\n",
        "# FTPS upload creds — make sure FTP_PASS is exactly your password, no < or >\n",
        "os.environ['FTP_HOST']       = 'ftp.one-name.net'\n",
        "os.environ['FTP_PORT']       = '21'\n",
        "os.environ['FTP_USER']       = 'admin@yates.one-name.net'\n",
        "os.environ['FTP_PASS']       = 'v(i83lfQB@dB'\n",
        "os.environ['FTP_REMOTE_DIR'] = '/public_html/gengen/'\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ww9zCZpAEmon"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GOLD_May.ipynb\n",
        "\n",
        "#!/usr/bin/env python\n",
        "\"\"\"\n",
        "GEDCOM Composite Score Script using:\n",
        " - Chunk-based Parallel Processing for Speed (Stage 1: genealogical line creation)\n",
        " - A Trie-based approach, then final \"Value\" = 5 * (number of couples with node.count >=2) + (total couples)\n",
        "\n",
        "For ancestral lines where none of the couples are repeated (a one-off line), the Value is still computed.\n",
        "Now, instead of composite scoring, two new columns are added:\n",
        "  - Value Range (the numeric bracket)\n",
        "  - Value Label (a descriptive label)\n",
        "\n",
        "Exports final CSV/HTML sorted by \"Yates DNA Ancestral Line\".\n",
        "\"\"\"\n",
        "import csv\n",
        "import glob\n",
        "import logging\n",
        "import functools\n",
        "import os\n",
        "from datetime import datetime\n",
        "from collections import defaultdict, Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from tqdm import tqdm\n",
        "from IPython.display import display, Javascript\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "###############################################################################\n",
        "# Global Variables\n",
        "###############################################################################\n",
        "anchor_gen1 = None\n",
        "visited_pairs = set()\n",
        "generation_table = []\n",
        "\n",
        "###############################################################################\n",
        "# Trie Data Structure\n",
        "###############################################################################\n",
        "class TrieNode:\n",
        "    \"\"\"A simple Trie node for storing a couple and counting how many lines pass here.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.count = 0\n",
        "        self.children = {}\n",
        "\n",
        "class Trie:\n",
        "    def __init__(self):\n",
        "        self.root = TrieNode()\n",
        "\n",
        "    def insert_line(self, couples_list):\n",
        "        current = self.root\n",
        "        for couple in couples_list:\n",
        "            if couple not in current.children:\n",
        "                current.children[couple] = TrieNode()\n",
        "            current = current.children[couple]\n",
        "            current.count += 1\n",
        "\n",
        "    def get_couple_count(self, couples_list):\n",
        "        counts = []\n",
        "        current = self.root\n",
        "        for couple in couples_list:\n",
        "            if couple in current.children:\n",
        "                current = current.children[couple]\n",
        "                counts.append(current.count)\n",
        "            else:\n",
        "                counts.append(0)\n",
        "                break\n",
        "        return counts\n",
        "\n",
        "###############################################################################\n",
        "# Utility: chunk generator\n",
        "###############################################################################\n",
        "def chunks(lst, n):\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]\n",
        "\n",
        "###############################################################################\n",
        "# GedcomDataset & Gedcom Classes\n",
        "###############################################################################\n",
        "class GedcomDataset:\n",
        "    def __init__(self, gen_person):\n",
        "        self.gen_person = gen_person\n",
        "        self.extractable_detail = {}\n",
        "        self.anchor_gen1 = None\n",
        "\n",
        "    def add_extractable_detail(self, key, value):\n",
        "        self.extractable_detail[key] = value\n",
        "\n",
        "    def get_gen_person(self):\n",
        "        name = self.extractable_detail.get('NAME', '')\n",
        "        parts = name.split('/', 1)\n",
        "        first_name = parts[0].split(' ')[0]\n",
        "        last_name = parts[1].rstrip('/') if len(parts) > 1 else \"\"\n",
        "        self.anchor_gen1 = last_name.replace(\" \", \"\") + first_name.replace(\" \", \"\")\n",
        "        global anchor_gen1\n",
        "        anchor_gen1 = self.anchor_gen1\n",
        "        return self.gen_person.strip('@')\n",
        "\n",
        "    def get_anchor_gen1(self):\n",
        "        return self.anchor_gen1\n",
        "\n",
        "    def get_extractable_NPFX(self):\n",
        "        return self.extractable_detail.get('NPFX', '')\n",
        "\n",
        "    def get_extractable_cm(self):\n",
        "        npfx_value = self.extractable_detail.get('NPFX', '')\n",
        "        if '&' in npfx_value:\n",
        "            cm_value = npfx_value.split('&')[0].strip()\n",
        "        elif '**' in npfx_value:\n",
        "            cm_value = npfx_value.split('**')[0].strip()\n",
        "        else:\n",
        "            cm_value = npfx_value.strip()\n",
        "        try:\n",
        "            int(cm_value)\n",
        "            return cm_value\n",
        "        except ValueError:\n",
        "            return ''\n",
        "\n",
        "    def get_extractable_sort(self):\n",
        "        npfx_value = self.extractable_detail.get('NPFX', '')\n",
        "        if '&' in npfx_value:\n",
        "            sort_part = npfx_value.split('&')[1]\n",
        "            if '**' in sort_part:\n",
        "                sort_value = sort_part.split('**')[0].strip()\n",
        "            else:\n",
        "                sort_value = sort_part.strip()\n",
        "            return sort_value\n",
        "        return ''\n",
        "\n",
        "    def get_extractable_YDNA(self):\n",
        "        npfx_value = self.extractable_detail.get('NPFX', '')\n",
        "        if '**' in npfx_value:\n",
        "            return npfx_value.split('**')[1].strip()\n",
        "        return ''\n",
        "\n",
        "    def get_extractable_FAMC(self):\n",
        "        return self.extractable_detail.get('FAMC', '').strip('@')\n",
        "\n",
        "class Gedcom:\n",
        "    def __init__(self, file_name):\n",
        "        self.file_name = file_name\n",
        "        self.gedcom_datasets = []\n",
        "        self.filter_pool = []\n",
        "        # will be set in parse_gedcom():\n",
        "        self.total_count = 0\n",
        "        self.npfx_count  = 0\n",
        "        self.ydna_count  = 0\n",
        "\n",
        "    def parse_gedcom(self):\n",
        "        with open(self.file_name, 'r', encoding='utf-8-sig') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        current_dataset = None\n",
        "        npfx_count = 0\n",
        "        ydna_count = 0\n",
        "        total_count = 0\n",
        "\n",
        "        for line in lines:\n",
        "            parts = line.strip().split(' ', 2)\n",
        "            level = int(parts[0])\n",
        "            tag = parts[1]\n",
        "            value = parts[2] if len(parts) > 2 else None\n",
        "\n",
        "            if level == 0 and tag.startswith('@') and tag.endswith('@') and value == 'INDI':\n",
        "                total_count += 1\n",
        "                current_dataset = GedcomDataset(tag)\n",
        "                self.gedcom_datasets.append(current_dataset)\n",
        "            elif current_dataset is not None:\n",
        "                if level == 1 and tag in ['NAME', 'FAMC']:\n",
        "                    current_dataset.add_extractable_detail(tag, value)\n",
        "                elif level == 2 and tag == 'NPFX':\n",
        "                    npfx_count += 1\n",
        "                    current_dataset.add_extractable_detail(tag, value)\n",
        "                    if '**' in value:\n",
        "                        ydna_count += 1\n",
        "\n",
        "        self.total_count = total_count\n",
        "        self.npfx_count  = npfx_count\n",
        "        self.ydna_count  = ydna_count\n",
        "\n",
        "        # build filter_pool\n",
        "        for ds in self.gedcom_datasets:\n",
        "            if ds.get_extractable_NPFX():\n",
        "                self.filter_pool.append(ds)\n",
        "\n",
        "        # manual filter\n",
        "        try:\n",
        "            df_manual = pd.read_excel('filtered_ids.xlsx')\n",
        "            manual_ids = set(df_manual['ID'])\n",
        "            self.filter_pool = [\n",
        "                d for d in self.filter_pool if d.get_gen_person() in manual_ids\n",
        "            ]\n",
        "        except FileNotFoundError:\n",
        "            logger.warning(\"filtered_ids.xlsx not found; skipping manual filter.\")\n",
        "\n",
        "        # return autosomal_count\n",
        "        return npfx_count - ydna_count\n",
        "\n",
        "###############################################################################\n",
        "# Ancestor-finding Helpers\n",
        "###############################################################################\n",
        "def quick_extract_name(full_text):\n",
        "    name_marker = \"\\n1 NAME \"\n",
        "    idx = full_text.find(name_marker)\n",
        "    if idx == -1:\n",
        "        if full_text.startswith(\"1 NAME \"):\n",
        "            idx = 0\n",
        "        else:\n",
        "            return \"UnknownName\"\n",
        "    start = idx + len(name_marker)\n",
        "    end = full_text.find('\\n', start)\n",
        "    if end == -1:\n",
        "        end = len(full_text)\n",
        "    name_line = full_text[start:end].strip()\n",
        "    if '/' not in name_line:\n",
        "        return name_line[:10].replace(\" \", \"\")\n",
        "    first_name, last_name = name_line.split('/', 1)\n",
        "    last_name = last_name.replace(\"/\", \"\").strip()\n",
        "    return last_name[:10].replace(\" \", \"\") + first_name[:10].replace(\" \", \"\")\n",
        "\n",
        "def find_parents(individual_id, generation, parents_map):\n",
        "    global visited_pairs, generation_table\n",
        "    if individual_id not in parents_map:\n",
        "        return\n",
        "    father_id, mother_id = parents_map[individual_id]\n",
        "    if not father_id and not mother_id:\n",
        "        return\n",
        "    pair = (father_id, mother_id)\n",
        "    if pair not in visited_pairs:\n",
        "        visited_pairs.add(pair)\n",
        "        generation_table.append((generation, pair))\n",
        "    if father_id:\n",
        "        find_parents(father_id, generation+1, parents_map)\n",
        "    if mother_id:\n",
        "        find_parents(mother_id, generation+1, parents_map)\n",
        "\n",
        "def find_distant_ancestors(individual_id, parents_map, path=None):\n",
        "    if path is None:\n",
        "        path = []\n",
        "    path.append(individual_id)\n",
        "    if individual_id not in parents_map:\n",
        "        return [path]\n",
        "    father_id, mother_id = parents_map[individual_id]\n",
        "    if not father_id and not mother_id:\n",
        "        return [path]\n",
        "    paths = []\n",
        "    if father_id:\n",
        "        paths.extend(find_distant_ancestors(father_id, parents_map, path[:]))\n",
        "    if mother_id:\n",
        "        paths.extend(find_distant_ancestors(mother_id, parents_map, path[:]))\n",
        "    return paths\n",
        "\n",
        "def filter_ancestral_line(winning_ids, gen_table, names_map):\n",
        "    # only include valid pairs and guard against None or missing keys\n",
        "    matches = [\n",
        "        (g, (id1, id2))\n",
        "        for g, (id1, id2) in gen_table\n",
        "        if (id1 in winning_ids and id1 is not None) or (id2 in winning_ids and id2 is not None)\n",
        "    ]\n",
        "    matches.sort(key=lambda x: x[0])\n",
        "    lines = []\n",
        "    for _, (id1, id2) in matches:\n",
        "        if id1 is None or id2 is None:\n",
        "            continue\n",
        "        name1 = names_map.get(id1, \"Unknown\")\n",
        "        name2 = names_map.get(id2, \"Unknown\")\n",
        "        lines.append(f\"{name1}&{name2}\")\n",
        "    lines.reverse()\n",
        "    return \"~~~\".join(lines)\n",
        "\n",
        "def process_record_wrapper(individual_id, ged, parents_map, names_map):\n",
        "    global generation_table, visited_pairs\n",
        "    generation_table = []\n",
        "    visited_pairs = set()\n",
        "\n",
        "    find_parents(individual_id, 1, parents_map)\n",
        "    paths = find_distant_ancestors(individual_id, parents_map)\n",
        "\n",
        "    best_path, best_score = [], None\n",
        "    for path in paths:\n",
        "        score = sum((i+1) for i, pid in enumerate(path) if 'Yates' in names_map.get(pid, \"\"))\n",
        "        if best_score is None or score > best_score:\n",
        "            best_score, best_path = score, path\n",
        "\n",
        "    cleaned = [pid for pid in best_path if pid != individual_id]\n",
        "    line_str = filter_ancestral_line(set(cleaned), generation_table, names_map)\n",
        "\n",
        "    cm = sort_val = ydna = anchor = \"\"\n",
        "    for ds in ged.filter_pool:\n",
        "        if ds.get_gen_person() == individual_id:\n",
        "            cm = ds.get_extractable_cm()\n",
        "            sort_val = ds.get_extractable_sort()\n",
        "            ydna = ds.get_extractable_YDNA()\n",
        "            anchor = ds.get_anchor_gen1()\n",
        "            break\n",
        "\n",
        "    return [individual_id, sort_val, names_map.get(individual_id, \"Unknown\"), cm, line_str]\n",
        "\n",
        "###############################################################################\n",
        "# Main\n",
        "###############################################################################\n",
        "def main():\n",
        "    def select_gedcom():\n",
        "        files = glob.glob(\"*.ged\")\n",
        "        if not files:\n",
        "            print(\"No GEDCOM files found.\")\n",
        "            return None\n",
        "        return files[0]\n",
        "\n",
        "    gedfile = select_gedcom()\n",
        "    if not gedfile:\n",
        "        return\n",
        "\n",
        "    ged = Gedcom(gedfile)\n",
        "    autosomal_count = ged.parse_gedcom()\n",
        "    filter_count = len(ged.filter_pool)\n",
        "\n",
        "    # --- print counts once ---\n",
        "    print(f\"GEDCOM contained {ged.total_count} total records\")\n",
        "    print(f\"Records tagged by NPFX: {ged.npfx_count}\")\n",
        "    print(f\"Records with YDNA information: {ged.ydna_count}\")\n",
        "    print(f\"Records after manual filter: {filter_count}\")\n",
        "\n",
        "    # handle previous-run counts\n",
        "    prev = None\n",
        "    if os.path.exists(\"autosomal_count.txt\"):\n",
        "        try:\n",
        "            prev = int(open(\"autosomal_count.txt\").read().strip())\n",
        "        except:\n",
        "            prev = None\n",
        "    if prev is not None:\n",
        "        open(\"autosomal_count_prev.txt\", \"w\").write(str(prev))\n",
        "    open(\"autosomal_count.txt\", \"w\").write(str(autosomal_count))\n",
        "\n",
        "    # print autosomal matches\n",
        "    if prev is not None:\n",
        "        diff = autosomal_count - prev\n",
        "        print(f\"Autosomal matches: {autosomal_count} (+{diff} since last run)\")\n",
        "    else:\n",
        "        print(f\"Autosomal matches: {autosomal_count}\")\n",
        "\n",
        "    # build parents_map & names_map\n",
        "    raw = open(gedfile, 'r', encoding='utf-8').read()\n",
        "    blocks = [b.strip() for b in raw.split('\\n0 ') if b.strip()]\n",
        "    all_recs = {}\n",
        "    for blk in blocks:\n",
        "        header = blk.split('\\n', 1)[0]\n",
        "        if '@' in header:\n",
        "            rid = header.split('@')[1]\n",
        "            all_recs[rid] = blk\n",
        "\n",
        "    parents_map, names_map = {}, {}\n",
        "    for rid, blk in all_recs.items():\n",
        "        names_map[rid] = quick_extract_name(\"\\n\" + blk)\n",
        "        if '1 HUSB @' in blk or '1 WIFE @' in blk:\n",
        "            husb = blk.split('1 HUSB @')[1].split('@')[0] if '1 HUSB @' in blk else None\n",
        "            wife = blk.split('1 WIFE @')[1].split('@')[0] if '1 WIFE @' in blk else None\n",
        "            kids = [ln.split('@')[1] for ln in blk.split('\\n') if ln.startswith('1 CHIL @')]\n",
        "            for k in kids:\n",
        "                parents_map[k] = (husb, wife)\n",
        "\n",
        "    ids = [d.get_gen_person() for d in ged.filter_pool]\n",
        "    print(f\"Processing {len(ids)} individuals...\")\n",
        "\n",
        "    # parallel processing\n",
        "    rows = []\n",
        "    with ProcessPoolExecutor(max_workers=os.cpu_count() or 4) as exe, tqdm(total=len(ids), desc=\"Building Yates Lines\") as pbar:\n",
        "        for chunk in chunks(ids, 50):\n",
        "            func = functools.partial(process_record_wrapper, ged=ged, parents_map=parents_map, names_map=names_map)\n",
        "            res = list(exe.map(func, chunk))\n",
        "            rows.extend(res)\n",
        "            pbar.update(len(chunk))\n",
        "\n",
        "    df = pd.DataFrame(rows, columns=[\"ID#\", \"Match to\", \"Name\", \"cM\", \"Yates DNA Ancestral Line\"])\n",
        "    df.index += 1\n",
        "\n",
        "    # remove prefix\n",
        "    def fix_pref(r):\n",
        "        pref = (\"YatesJohn&SearchingStill~~~YatesWilliam&SearchingStill~~~\"\n",
        "                \"YatesWilliam&SearchingStill~~~YatesEdmund&CornellMargaret~~~\"\n",
        "                \"YatesRichard&AshendonJoan~~~YatesJohn&HydeAlice~~~\"\n",
        "                \"YatesThomas&WhiteFrances~~~\")\n",
        "        if r[\"Yates DNA Ancestral Line\"].startswith(pref):\n",
        "            r[\"Yates DNA Ancestral Line\"] = r[\"Yates DNA Ancestral Line\"][len(pref):]\n",
        "        return r\n",
        "    df = df.apply(fix_pref, axis=1)\n",
        "\n",
        "    # build trie, compute Value\n",
        "    trie = Trie()\n",
        "    for _, r in df.iterrows():\n",
        "        line = r[\"Yates DNA Ancestral Line\"]\n",
        "        if not line.strip():\n",
        "            continue\n",
        "        couples = [x for x in line.split(\"~~~\") if x.strip()]\n",
        "        trie.insert_line(couples)\n",
        "\n",
        "    vals, pcs = [], []\n",
        "    for _, r in df.iterrows():\n",
        "        line = r[\"Yates DNA Ancestral Line\"]\n",
        "        if not line.strip():\n",
        "            vals.append(0)\n",
        "            pcs.append(0)\n",
        "        else:\n",
        "            couples = [x for x in line.split(\"~~~\") if x.strip()]\n",
        "            counts = trie.get_couple_count(couples)\n",
        "            pc = sum(1 for c in counts if c >= 2)\n",
        "            vals.append(5 * pc + len(couples))\n",
        "            pcs.append(pc)\n",
        "    df[\"Value\"], df[\"PrefixCount\"] = vals, pcs\n",
        "\n",
        "    # assign labels\n",
        "    def label(v):\n",
        "        v = float(v)\n",
        "        if v >= 60:\n",
        "            return \">=60\", \"1-likely correct\"\n",
        "        if 47 <= v <= 59:\n",
        "            return \"59~47\", \"2-lines forming\"\n",
        "        if 34 <= v <= 46:\n",
        "            return \"46~34\", \"3-patterns emerging\"\n",
        "        if 21 <= v <= 33:\n",
        "            return \"33~21\", \"4-notable patterns\"\n",
        "        if 8 <= v <= 20:\n",
        "            return \"20~8\", \"5-patterns stable\"\n",
        "        if 1 <= v <= 7:\n",
        "            return f\"{v:.0f}\", \"6-need research\"\n",
        "        return f\"{v:.0f}\", \"0-uncategorized\"\n",
        "\n",
        "    ranges, labels = [], []\n",
        "    for v in df[\"Value\"]:\n",
        "        r, l = label(v)\n",
        "        ranges.append(r)\n",
        "        labels.append(l)\n",
        "    df[\"Value Range\"], df[\"Value Label\"] = ranges, labels\n",
        "\n",
        "    df.sort_values(\"Yates DNA Ancestral Line\", inplace=True)\n",
        "    df.drop(\"PrefixCount\", axis=1, inplace=True)\n",
        "    df.to_csv(\"final_combined_df_with_value_labels.csv\", index=False)\n",
        "    css = \"\"\"\n",
        "    <style>table{width:100%;border-collapse:collapse;margin:20px 0;}\n",
        "    th,td{border:1px solid #333;padding:8px 12px;text-align:center;}\n",
        "    th{background:#f2f2f2;}td:nth-child(6){text-align:left;}</style>\"\"\"\n",
        "    html = css + df.to_html(\n",
        "        index=False,\n",
        "        columns=[\"ID#\", \"cM\", \"Match to\", \"Value Range\", \"Value Label\", \"Yates DNA Ancestral Line\"],\n",
        "        escape=False\n",
        "    )\n",
        "    with open(\"HTML_combined_df_with_value_labels.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(html)\n",
        "    logger.info(\"Export complete.\")\n",
        "\n",
        "    # optional email\n",
        "    import smtplib, ssl\n",
        "    from email.mime.text import MIMEText\n",
        "    def send_email(sub, body, to):\n",
        "        srv, pt = 'smtp.gmail.com', 465\n",
        "        snd, pw = os.environ['GMAIL_USER'], os.environ['GMAIL_APP_PASSWORD']\n",
        "        msg = MIMEText(body); msg['Subject'] = sub; msg['From'] = snd; msg['To'] = to\n",
        "        ctx = ssl.create_default_context()\n",
        "        with smtplib.SMTP_SSL(srv, pt, context=ctx) as s:\n",
        "            s.login(snd, pw); s.send_message(msg)\n",
        "\n",
        "    total = len(df)\n",
        "    send_email(\"✅ GEDCOM Report Ready\", f\"Processed {total} lines\", os.environ['GMAIL_USER'])\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49d150e7-fcf7-4122-9b70-01a23173c9ad",
        "id": "TOB9IqmDeMKi"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GEDCOM contained 60113 total records\n",
            "Records tagged by NPFX: 1446\n",
            "Records with YDNA information: 90\n",
            "Records after manual filter: 78\n",
            "Autosomal matches: 1356 (+0 since last run)\n",
            "Processing 78 individuals...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Yates Lines: 100%|██████████| 78/78 [00:44<00:00,  1.77it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#KEEP THIS TO REFERENCE CELL 1 TO RUN CELL 2 AUTOMATICLLY\n",
        "# Cell 2: XHTML Template + Export + Root FTP Upload\n",
        "\n",
        "import pandas as pd\n",
        "from IPython.display import Javascript  # comment out alert if not needed\n",
        "from datetime import datetime\n",
        "from zoneinfo import ZoneInfo\n",
        "from ftplib import FTP_TLS\n",
        "import os\n",
        "\n",
        "# ————— Load Data —————\n",
        "df = pd.read_csv(\"final_combined_df_with_value_labels.csv\")\n",
        "\n",
        "# ————— Load counts —————\n",
        "try:\n",
        "    with open(\"autosomal_count.txt\", \"r\") as f:\n",
        "        autosomal_count = int(f.read().strip())\n",
        "except Exception:\n",
        "    autosomal_count = None\n",
        "\n",
        "prev_count = None\n",
        "additional_str = \"\"\n",
        "if os.path.exists(\"autosomal_count_prev.txt\"):\n",
        "    try:\n",
        "        with open(\"autosomal_count_prev.txt\", \"r\") as f:\n",
        "            prev_count = int(f.read().strip())\n",
        "        if autosomal_count is not None:\n",
        "            diff_count = autosomal_count - prev_count\n",
        "            additional_str = f\" (+{diff_count} since last run)\"\n",
        "    except Exception:\n",
        "        additional_str = \"\"\n",
        "\n",
        "# ————— Current EST timestamp —————\n",
        "now_est = datetime.now(ZoneInfo(\"America/New_York\"))\n",
        "updated_timestamp = now_est.strftime('%Y-%m-%d %H:%M:%S %Z')\n",
        "\n",
        "# ————— Build HTML —————\n",
        "full_html_template = \"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        "  \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"en\" lang=\"en\">\n",
        "<head>\n",
        "  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"/>\n",
        "  <meta name=\"GENERATOR\" content=\"Yatesville\"/>\n",
        "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"/>\n",
        "  <title>DNA Report Card</title>\n",
        "  <script src=\"../sorttable.js\" type=\"text/javascript\"></script>\n",
        "  <style type=\"text/css\">\n",
        "    body { font-family: Arial, Helvetica, sans-serif; font-size: 14px; background-color: #faf9d3; }\n",
        "    .output-table table {\n",
        "      width:100%; border-collapse:collapse; margin:15px 0; background-color:#faf9d3;\n",
        "    }\n",
        "    .output-table table, .output-table th, .output-table td {\n",
        "      border:1px solid #333; text-align:center; padding:5px 8px; background-color:#faf9d3;\n",
        "    }\n",
        "    .output-table th { background-color:#ffffcc; white-space:nowrap; }\n",
        "    .output-table th:hover { background-color:#ffeb99; }\n",
        "    .output-table td:nth-child(5) { min-width:180px; }\n",
        "    .output-table td:last-child, .output-table th:last-child {\n",
        "      text-align:left; white-space:nowrap;\n",
        "    }\n",
        "  </style>\n",
        "</head>\n",
        "<body>\n",
        "<div align=\"center\">\n",
        "  <table class=\"fullpage-definedsection\" cellpadding=\"0\"><tr valign=\"top\"><td>\n",
        "    <table class=\"headersection\" cellpadding=\"0\"><tr valign=\"top\"><td></td></tr></table>\n",
        "    <table class=\"mainsection\" cellpadding=\"7\">\n",
        "      <tr valign=\"top\"><td>\n",
        "        <h2>A report card for your DNA family tree</h2>\n",
        "        <font size=\"-2\">\n",
        "          Return to <a href=\"https://yates.one-name.net/gengen/dna_cousin_surname_study.htm\">Study Home</a>\n",
        "          &nbsp;|&nbsp;\n",
        "          Autosomal matches: {autosomal_count}{additional_str}\n",
        "          &nbsp;|&nbsp;\n",
        "          Updated: {updated_timestamp}\n",
        "        </font>\n",
        "        <p>Imagine you have a report card for your family tree that tells you how your family tree compares to other collateral family tree lines.<br><br>Here is how we break it down:</p>\n",
        "        <p>Think of value like the total number of points you get from finding all the important family connections in your tree<br>\n",
        "        and comparing them to all the other trees included in the Yates study.</p>\n",
        "        <p>We then group them as a way to signal which ones seem to have potential for study:\n",
        "          <b>>60:</b> likely correct, <b>59–47:</b> lines forming, <b>46–34:</b> patterns emerging,\n",
        "          <b>33–21:</b> notable patterns, <b>20–8:</b> patterns stable, <b>7–1:</b> and 6-need research.</p>\n",
        "        <p><b><i><font size=\"-1\">Click on the header to sort any column</font></i></b>\n",
        "          (And, remember <a href=\"https://yates.one-name.net/gengen/dna_theory_of_the_case.htm\" target=\"_blank\">what this is telling</a> us....)</p>\n",
        "      </td></tr>\n",
        "    </table>\n",
        "    <div class=\"output-table\" style=\"margin-top:10px;\">\n",
        "      <!-- TABLE_PLACEHOLDER -->\n",
        "    </div>\n",
        "  </td></tr></table>\n",
        "</div>\n",
        "<button onclick=\"topFunction()\" id=\"myBtn\" title=\"Go to top\"\n",
        "  style=\"position:fixed;bottom:40px;right:40px;z-index:99;background-color:red;color:white;\n",
        "         padding:12px 20px;border:none;border-radius:10px;cursor:pointer;font-size:16px;\">\n",
        "  Top\n",
        "</button>\n",
        "<script>\n",
        "let mybutton = document.getElementById(\"myBtn\");\n",
        "window.onscroll = function() {\n",
        "  if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {\n",
        "    mybutton.style.display = \"block\";\n",
        "  } else {\n",
        "    mybutton.style.display = \"none\";\n",
        "  }\n",
        "};\n",
        "function topFunction() {\n",
        "  document.body.scrollTop = 0;\n",
        "  document.documentElement.scrollTop = 0;\n",
        "}\n",
        "</script>\n",
        "</body>\n",
        "</html>\"\"\"\n",
        "\n",
        "final_cols = [\"ID#\", \"cM\", \"Match to\", \"Value Range\", \"Value Label\", \"Yates DNA Ancestral Line\"]\n",
        "df.sort_values(by=[\"Yates DNA Ancestral Line\"], inplace=True)\n",
        "html_table = df.to_html(index=False, columns=final_cols, escape=False, classes=\"dataframe sortable\")\n",
        "\n",
        "# Inject counts and timestamp\n",
        "final_html = (\n",
        "    full_html_template\n",
        "    .replace(\"{autosomal_count}\", str(autosomal_count or \"Unknown\"))\n",
        "    .replace(\"{additional_str}\", additional_str)\n",
        "    .replace(\"{updated_timestamp}\", updated_timestamp)\n",
        ")\n",
        "final_html = final_html.replace(\"<!-- TABLE_PLACEHOLDER -->\", html_table)\n",
        "\n",
        "# Save locally\n",
        "with open(\"dna_cousin_surname_app.htm\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final_html)\n",
        "\n",
        "# Notebook-level alert (commented out)\n",
        "# display(Javascript('alert(\"✅ DNA Report Card generated locally.\");'))\n",
        "\n",
        "# ————— FTP Upload to ROOT —————\n",
        "ftp_host = os.environ['FTP_HOST']\n",
        "ftp_port = int(os.environ.get('FTP_PORT', 21))\n",
        "ftp_user = os.environ['FTP_USER']\n",
        "ftp_pass = os.environ['FTP_PASS']\n",
        "\n",
        "def upload_to_root(filenames):\n",
        "    ftps = FTP_TLS()\n",
        "    ftps.connect(ftp_host, ftp_port)\n",
        "    ftps.login(ftp_user, ftp_pass)\n",
        "    ftps.prot_p()\n",
        "    for fname in filenames:\n",
        "        try:\n",
        "            ftps.delete(fname)\n",
        "        except:\n",
        "            pass\n",
        "        with open(fname, 'rb') as f:\n",
        "            print(f\"→ uploading {fname} …\", end=' ')\n",
        "            ftps.storbinary(f\"STOR {fname}\", f)\n",
        "            print(\"done\")\n",
        "        try:\n",
        "            ftps.sendcmd(f\"SITE CHMOD 644 {fname}\")\n",
        "        except:\n",
        "            pass\n",
        "    ftps.quit()\n",
        "    print(\"✅ All files uploaded to One Name Study.\")\n",
        "\n",
        "# Run upload\n",
        "upload_to_root([\"dna_cousin_surname_app.htm\"])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "09SUUSG55K4F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e97f40f-f554-47da-eb1f-bf0665bb0380"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ uploading dna_cousin_surname_app.htm … done\n",
            "✅ All files uploaded to One Name Study.\n"
          ]
        }
      ]
    }
  ]
}