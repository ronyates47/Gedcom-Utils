{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgtfZxwoWFe2cpdAz8Iy2A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronyates47/Gedcom-Utils/blob/main/GOLD_20250426.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT5s4n9S5ZpZ",
        "outputId": "c2941409-d179-4065-bfdc-73ab1fcd9257",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting python-gedcom\n",
            "  Downloading python_gedcom-1.0.0-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Downloading python_gedcom-1.0.0-py2.py3-none-any.whl (35 kB)\n",
            "Installing collected packages: python-gedcom\n",
            "Successfully installed python-gedcom-1.0.0\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "Downloading XlsxWriter-3.2.3-py3-none-any.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.3\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.11/dist-packages (0.23.4)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.15.2)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.1->mlxtend) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install python-gedcom\n",
        "!pip install openpyxl\n",
        "!pip install xlsxwriter\n",
        "!pip install mlxtend\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Gmail SMTP creds\n",
        "os.environ['GMAIL_USER']         = 'yatesvilleron@gmail.com'\n",
        "os.environ['GMAIL_APP_PASSWORD'] = 'qtziwiblytgrlzvx'\n",
        "\n",
        "# FTPS upload creds — make sure FTP_PASS is exactly your password, no < or >\n",
        "os.environ['FTP_HOST']       = 'ftp.one-name.net'\n",
        "os.environ['FTP_PORT']       = '21'\n",
        "os.environ['FTP_USER']       = 'admin@yates.one-name.net'\n",
        "os.environ['FTP_PASS']       = 'v(i83lfQB@dB'\n",
        "os.environ['FTP_REMOTE_DIR'] = '/public_html/gengen/'\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ww9zCZpAEmon"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 04_18_2025_1500\n",
        "\n",
        "#!/usr/bin/env python\n",
        "\"\"\"\n",
        "GEDCOM Composite Score Script using:\n",
        " - Chunk-based Parallel Processing for Speed (Stage 1: genealogical line creation)\n",
        " - A Trie-based approach, then final \"Value\" = 5 * (number of couples with node.count >=2) + (total couples)\n",
        "\n",
        "For ancestral lines where none of the couples are repeated (a one-off line), the Value is still computed.\n",
        "Now, instead of composite scoring, two new columns are added:\n",
        "  - Value Range (the numeric bracket)\n",
        "  - Value Label (a descriptive label)\n",
        "\n",
        "Exports final CSV/HTML sorted by \"Yates DNA Ancestral Line\".\n",
        "\"\"\"\n",
        "import csv\n",
        "import glob\n",
        "import logging\n",
        "import functools\n",
        "import os\n",
        "from datetime import datetime\n",
        "from collections import defaultdict, Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from tqdm import tqdm\n",
        "# At the very top of the cell (alongside your other imports):\n",
        "from IPython.display import display, Javascript\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "###############################################################################\n",
        "# Global Variables\n",
        "###############################################################################\n",
        "anchor_gen1 = None\n",
        "visited_pairs = set()\n",
        "generation_table = []\n",
        "\n",
        "###############################################################################\n",
        "# Trie Data Structure\n",
        "###############################################################################\n",
        "class TrieNode:\n",
        "    \"\"\"A simple Trie node for storing a couple and counting how many lines pass here.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.count = 0\n",
        "        self.children = {}  # maps couple string -> TrieNode\n",
        "\n",
        "class Trie:\n",
        "    def __init__(self):\n",
        "        self.root = TrieNode()\n",
        "\n",
        "    def insert_line(self, couples_list):\n",
        "        \"\"\"\n",
        "        Insert a reversed line (list of couples) into the trie.\n",
        "        Increment .count for each node visited.\n",
        "        \"\"\"\n",
        "        current = self.root\n",
        "        for couple in couples_list:\n",
        "            if couple not in current.children:\n",
        "                current.children[couple] = TrieNode()\n",
        "            current = current.children[couple]\n",
        "            current.count += 1\n",
        "\n",
        "    def get_couple_count(self, couples_list):\n",
        "        \"\"\"\n",
        "        For each couple in this line, retrieve the node.count if it exists.\n",
        "        Returns a list of node.count values, in order.\n",
        "        \"\"\"\n",
        "        counts = []\n",
        "        current = self.root\n",
        "        for couple in couples_list:\n",
        "            if couple in current.children:\n",
        "                current = current.children[couple]\n",
        "                counts.append(current.count)\n",
        "            else:\n",
        "                counts.append(0)\n",
        "                break\n",
        "        return counts\n",
        "\n",
        "###############################################################################\n",
        "# Utility: chunk generator\n",
        "###############################################################################\n",
        "def chunks(lst, n):\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]\n",
        "\n",
        "###############################################################################\n",
        "# GedcomDataset\n",
        "###############################################################################\n",
        "class GedcomDataset:\n",
        "    def __init__(self, gen_person):\n",
        "        self.gen_person = gen_person\n",
        "        self.extractable_detail = {}\n",
        "        self.anchor_gen1 = None\n",
        "\n",
        "    def add_extractable_detail(self, key, value):\n",
        "        self.extractable_detail[key] = value\n",
        "\n",
        "    def get_gen_person(self):\n",
        "        name = self.extractable_detail.get('NAME', '')\n",
        "        parts = name.split('/', 1)\n",
        "        first_name = parts[0].split(' ')[0]\n",
        "        last_name = parts[1].rstrip('/') if len(parts) > 1 else \"\"\n",
        "        self.anchor_gen1 = last_name.replace(\" \", \"\") + first_name.replace(\" \", \"\")\n",
        "        global anchor_gen1\n",
        "        anchor_gen1 = self.anchor_gen1\n",
        "        return self.gen_person.strip('@')\n",
        "\n",
        "    def get_anchor_gen1(self):\n",
        "        return self.anchor_gen1\n",
        "\n",
        "    def get_extractable_NPFX(self):\n",
        "        return self.extractable_detail.get('NPFX', '')\n",
        "\n",
        "    def get_extractable_cm(self):\n",
        "        \"\"\"\n",
        "        Extract cM from NPFX field. If NPFX has a format like \"175&someSort**someYDNA\",\n",
        "        the cM is '175'. If it doesn't parse cleanly, returns blank.\n",
        "        \"\"\"\n",
        "        npfx_value = self.extractable_detail.get('NPFX', '')\n",
        "        if '&' in npfx_value:\n",
        "            cm_value = npfx_value.split('&')[0].strip()\n",
        "        elif '**' in npfx_value:\n",
        "            cm_value = npfx_value.split('**')[0].strip()\n",
        "        else:\n",
        "            cm_value = npfx_value.strip()\n",
        "        try:\n",
        "            int(cm_value)\n",
        "            return cm_value\n",
        "        except ValueError:\n",
        "            return ''\n",
        "\n",
        "    def get_extractable_sort(self):\n",
        "        \"\"\"\n",
        "        If NPFX has \"xxx&sortVal**ydnaVal\", returns sortVal. If not found, blank.\n",
        "        \"\"\"\n",
        "        npfx_value = self.extractable_detail.get('NPFX', '')\n",
        "        if '&' in npfx_value:\n",
        "            sort_part = npfx_value.split('&')[1]\n",
        "            if '**' in sort_part:\n",
        "                sort_value = sort_part.split('**')[0].strip()\n",
        "            else:\n",
        "                sort_value = sort_part.strip()\n",
        "            return sort_value\n",
        "        return ''\n",
        "\n",
        "    def get_extractable_YDNA(self):\n",
        "        \"\"\"\n",
        "        If NPFX has something like \"...**ydnaVal\", return ydnaVal. If not found, blank.\n",
        "        \"\"\"\n",
        "        npfx_value = self.extractable_detail.get('NPFX', '')\n",
        "        if '**' in npfx_value:\n",
        "            ydna_value = npfx_value.split('**')[1].strip()\n",
        "            return ydna_value\n",
        "        return ''\n",
        "\n",
        "    def get_extractable_FAMC(self):\n",
        "        return self.extractable_detail.get('FAMC', '').strip('@')\n",
        "\n",
        "###############################################################################\n",
        "# Gedcom Class\n",
        "###############################################################################\n",
        "class Gedcom:\n",
        "    def __init__(self, file_name):\n",
        "        self.file_name = file_name\n",
        "        self.gedcom_datasets = []\n",
        "        self.filter_pool = []\n",
        "\n",
        "    def parse_gedcom(self):\n",
        "        with open(self.file_name, 'r', encoding='utf-8-sig') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        current_dataset = None\n",
        "        npfx_count = 0\n",
        "        ydna_count = 0\n",
        "        total_count = 0\n",
        "\n",
        "        for line in lines:\n",
        "            parts = line.strip().split(' ', 2)\n",
        "            level = int(parts[0])\n",
        "            tag = parts[1]\n",
        "            value = parts[2] if len(parts) > 2 else None\n",
        "\n",
        "            if level == 0 and tag.startswith('@') and tag.endswith('@') and value == 'INDI':\n",
        "                total_count += 1\n",
        "                current_dataset = GedcomDataset(tag)\n",
        "                self.gedcom_datasets.append(current_dataset)\n",
        "            elif current_dataset is not None:\n",
        "                if level == 1 and tag in ['NAME', 'FAMC']:\n",
        "                    current_dataset.add_extractable_detail(tag, value)\n",
        "                elif level == 2 and tag == 'NPFX':\n",
        "                    npfx_count += 1\n",
        "                    current_dataset.add_extractable_detail(tag, value)\n",
        "                    if '**' in value:\n",
        "                        ydna_count += 1\n",
        "\n",
        "        autosomal_count = npfx_count - ydna_count\n",
        "        print(f\"GEDCOM contained {total_count} total records\")\n",
        "        print(f\"Records tagged and filtered by NPFX: {npfx_count}\")\n",
        "        print(f\"Records with YDNA information: {ydna_count}\")\n",
        "        print(f\"Autosomal matches: {autosomal_count}\")\n",
        "\n",
        "        for ds in self.gedcom_datasets:\n",
        "            if ds.get_extractable_NPFX():\n",
        "                self.filter_pool.append(ds)\n",
        "\n",
        "        # Optional second-level filter\n",
        "        manual_filter_activated = True\n",
        "        if manual_filter_activated:\n",
        "            try:\n",
        "                df = pd.read_excel('filtered_ids.xlsx')\n",
        "            except FileNotFoundError:\n",
        "                logger.warning(\"filtered_ids.xlsx not found. Skipping second-level manual filter.\")\n",
        "            else:\n",
        "                manual_filtered_ids = set(df['ID'])\n",
        "                self.filter_pool = [\n",
        "                    d for d in self.filter_pool if d.get_gen_person() in manual_filtered_ids\n",
        "                ]\n",
        "                print(f\"After manual filter, total records: {len(self.filter_pool)}\")\n",
        "                logger.info(f\"After manual filter, total records: {len(self.filter_pool)}\")\n",
        "\n",
        "        return autosomal_count\n",
        "\n",
        "###############################################################################\n",
        "# quick_extract_name\n",
        "###############################################################################\n",
        "def quick_extract_name(full_text):\n",
        "    \"\"\"\n",
        "    Minimal function to extract a short name from a GEDCOM chunk.\n",
        "    \"\"\"\n",
        "    name_marker = \"\\n1 NAME \"\n",
        "    idx = full_text.find(name_marker)\n",
        "    if idx == -1:\n",
        "        if full_text.startswith(\"1 NAME \"):\n",
        "            idx = 0\n",
        "        else:\n",
        "            return \"UnknownName\"\n",
        "    start = idx + len(name_marker)\n",
        "    end = full_text.find('\\n', start)\n",
        "    if end == -1:\n",
        "        end = len(full_text)\n",
        "    name_line = full_text[start:end].strip()\n",
        "    if '/' not in name_line:\n",
        "        return name_line[:10].replace(\" \", \"\")\n",
        "    first_name, last_name = name_line.split('/', 1)\n",
        "    last_name = last_name.replace(\"/\", \"\").strip()\n",
        "    return last_name[:10].replace(\" \", \"\") + first_name[:10].replace(\" \", \"\")\n",
        "\n",
        "###############################################################################\n",
        "# Parents, Ancestors\n",
        "###############################################################################\n",
        "def find_parents(individual_id, generation, parents_map):\n",
        "    global visited_pairs, generation_table\n",
        "    if individual_id not in parents_map:\n",
        "        return\n",
        "    father_id, mother_id = parents_map[individual_id]\n",
        "    if not father_id and not mother_id:\n",
        "        return\n",
        "    pair = (father_id, mother_id)\n",
        "    if pair not in visited_pairs:\n",
        "        visited_pairs.add(pair)\n",
        "        generation_table.append((generation, pair))\n",
        "    if father_id:\n",
        "        find_parents(father_id, generation+1, parents_map)\n",
        "    if mother_id:\n",
        "        find_parents(mother_id, generation+1, parents_map)\n",
        "\n",
        "def find_distant_ancestors(individual_id, parents_map, path=None):\n",
        "    if path is None:\n",
        "        path = []\n",
        "    path.append(individual_id)\n",
        "    if individual_id not in parents_map:\n",
        "        return [path]\n",
        "    father_id, mother_id = parents_map[individual_id]\n",
        "    if not father_id and not mother_id:\n",
        "        return [path]\n",
        "    paths = []\n",
        "    if father_id:\n",
        "        paths.extend(find_distant_ancestors(father_id, parents_map, path[:]))\n",
        "    if mother_id:\n",
        "        paths.extend(find_distant_ancestors(mother_id, parents_map, path[:]))\n",
        "    return paths if paths else [path]\n",
        "\n",
        "###############################################################################\n",
        "# filter_ancestral_line\n",
        "###############################################################################\n",
        "def filter_ancestral_line(winning_path_ids, generation_table_local, names_map):\n",
        "    matching_table = []\n",
        "    for generation, pair in generation_table_local:\n",
        "        id1, id2 = pair\n",
        "        if id1 in winning_path_ids or id2 in winning_path_ids:\n",
        "            matching_table.append((generation, pair))\n",
        "    matching_table.sort(key=lambda x: x[0])\n",
        "    lines = []\n",
        "    for gen, pair in matching_table:\n",
        "        name_pair = [names_map.get(pid, \"UnknownName\") for pid in pair]\n",
        "        lines.append(f\"{name_pair[0]}&{name_pair[1]}\")\n",
        "    lines.reverse()\n",
        "    return \"~~~\".join(lines)\n",
        "\n",
        "###############################################################################\n",
        "# process_record_wrapper (parallel) - STAGE 1\n",
        "###############################################################################\n",
        "def process_record_wrapper(individual_id, gedcom_instance, parents_map, names_map):\n",
        "    \"\"\"\n",
        "    This is the function used in parallel for 'Processing individuals' stage.\n",
        "    It gathers and builds the 'Yates DNA Ancestral Line' for each ID.\n",
        "    \"\"\"\n",
        "    global generation_table, visited_pairs, anchor_gen1\n",
        "    generation_table = []\n",
        "    visited_pairs = set()\n",
        "\n",
        "    find_parents(individual_id, 1, parents_map)\n",
        "    distant_anc_paths = find_distant_ancestors(individual_id, parents_map)\n",
        "\n",
        "    best_score = None\n",
        "    best_path = None\n",
        "    for path in distant_anc_paths:\n",
        "        name_path = [names_map.get(pid, \"UnknownName\") for pid in path]\n",
        "        score = 0\n",
        "        for idx, nm in enumerate(name_path):\n",
        "            if 'Yates' in nm:\n",
        "                score += (idx + 1)\n",
        "        if best_score is None or score > best_score:\n",
        "            best_score = score\n",
        "            best_path = path\n",
        "\n",
        "    if not best_path:\n",
        "        best_path = []\n",
        "\n",
        "    # remove individual's own ID\n",
        "    best_path_cleaned = [pid for pid in best_path if pid != individual_id]\n",
        "\n",
        "    line_str = filter_ancestral_line(set(best_path_cleaned), generation_table, names_map)\n",
        "\n",
        "    cm_value = ''\n",
        "    sort_value = ''\n",
        "    ydna_value = ''\n",
        "    anchor_name = ''\n",
        "    for ds in gedcom_instance.filter_pool:\n",
        "        if ds.get_gen_person() == individual_id:\n",
        "            cm_value = ds.get_extractable_cm()\n",
        "            sort_value = ds.get_extractable_sort()\n",
        "            ydna_value = ds.get_extractable_YDNA()\n",
        "            anchor_name = ds.get_anchor_gen1()\n",
        "            break\n",
        "\n",
        "    short_name = names_map.get(individual_id, \"UnknownName\")\n",
        "    # Return columns: ID#, Match to, Name, cM, Yates DNA Ancestral Line\n",
        "    return [individual_id, sort_value, short_name, cm_value, line_str]\n",
        "\n",
        "###############################################################################\n",
        "# main()\n",
        "###############################################################################\n",
        "def main():\n",
        "    def select_gedcom():\n",
        "        files = glob.glob(\"*.ged\")\n",
        "        if not files:\n",
        "            print(\"No GEDCOM files found.\")\n",
        "            return None\n",
        "        print(\"Automatically selecting the first GEDCOM file.\")\n",
        "        return files[0]\n",
        "\n",
        "    gedcom_file_path = select_gedcom()\n",
        "    if not gedcom_file_path:\n",
        "        print(\"No GEDCOM file selected; exiting.\")\n",
        "        return\n",
        "\n",
        "    # 1) Parse GEDCOM and capture autosomal_count\n",
        "    ged = Gedcom(gedcom_file_path)\n",
        "    autosomal_count = ged.parse_gedcom()  # <-- autosomal_count returned now\n",
        "    filter_count = len(ged.filter_pool)\n",
        "\n",
        "    with open(\"autosomal_count.txt\", \"w\") as f:\n",
        "        f.write(str(autosomal_count))\n",
        "\n",
        "    print(\"Records tagged and filtered by NPFX:\", filter_count)\n",
        "\n",
        "       # 2) Build parents_map, names_map from raw GEDCOM\n",
        "    with open(gedcom_file_path, 'r', encoding='utf-8') as f:\n",
        "        raw_data = f.read()\n",
        "\n",
        "    blocks = raw_data.split('\\n0 ')\n",
        "    all_records = {}\n",
        "    for blk in blocks:\n",
        "        blk = blk.strip()\n",
        "        if not blk:\n",
        "            continue\n",
        "        flend = blk.find('\\n')\n",
        "        if flend == -1:\n",
        "            flend = len(blk)\n",
        "        first_line = blk[:flend]\n",
        "        if '@' in first_line:\n",
        "            start = first_line.find('@') + 1\n",
        "            end = first_line.find('@', start)\n",
        "            rec_id = first_line[start:end].strip()\n",
        "            all_records[rec_id] = blk\n",
        "\n",
        "    parents_map = {}\n",
        "    names_map = {}\n",
        "\n",
        "    for rec_id, txt in all_records.items():\n",
        "        nm = quick_extract_name(\"\\n\" + txt)\n",
        "        names_map[rec_id] = nm\n",
        "\n",
        "    # gather families\n",
        "    families = {}\n",
        "    for rec_id, txt in all_records.items():\n",
        "        if 'FAM' in txt[:50]:\n",
        "            father_idx = txt.find('1 HUSB @')\n",
        "            if father_idx != -1:\n",
        "                start = father_idx + len('1 HUSB @')\n",
        "                end = txt.find('@', start)\n",
        "                husb_id = txt[start:end]\n",
        "            else:\n",
        "                husb_id = None\n",
        "\n",
        "            wife_idx = txt.find('1 WIFE @')\n",
        "            if wife_idx != -1:\n",
        "                start = wife_idx + len('1 WIFE @')\n",
        "                end = txt.find('@', start)\n",
        "                wife_id = txt[start:end]\n",
        "            else:\n",
        "                wife_id = None\n",
        "\n",
        "            kids = []\n",
        "            lines_ = txt.split('\\n')\n",
        "            for ln in lines_:\n",
        "                if ln.strip().startswith('1 CHIL @'):\n",
        "                    s2 = ln.strip().split('1 CHIL @')[1]\n",
        "                    kid_id = s2.split('@')[0]\n",
        "                    kids.append(kid_id)\n",
        "\n",
        "            families[rec_id] = (husb_id, wife_id, kids)\n",
        "\n",
        "    for fam_id, (f_id, m_id, k_list) in families.items():\n",
        "        for kid in k_list:\n",
        "            parents_map[kid] = (f_id, m_id)\n",
        "\n",
        "    # 3) Gather ID list\n",
        "    individual_ids = [d.get_gen_person() for d in ged.filter_pool]\n",
        "    print(f\"Processing {len(individual_ids)} individuals with chunk-based parallel...\")\n",
        "\n",
        "    # 4) Stage 1: Chunk-based parallel to build lines\n",
        "    combined_rows = []\n",
        "    chunk_size = 50\n",
        "    max_workers = os.cpu_count() or 4\n",
        "    logger.info(\"Starting chunk-based parallel processing with %d workers.\", max_workers)\n",
        "\n",
        "    total_records = len(individual_ids)\n",
        "    from functools import partial\n",
        "\n",
        "    with ProcessPoolExecutor(max_workers=max_workers) as executor, \\\n",
        "         tqdm(total=total_records, desc=\"Building Yates Lines (Stage 1)\") as pbar:\n",
        "        for chunk in chunks(individual_ids, chunk_size):\n",
        "            func = partial(\n",
        "                process_record_wrapper,\n",
        "                gedcom_instance=ged,\n",
        "                parents_map=parents_map,\n",
        "                names_map=names_map\n",
        "            )\n",
        "            results = list(executor.map(func, chunk))\n",
        "            combined_rows.extend(results)\n",
        "            pbar.update(len(chunk))\n",
        "\n",
        "    # combined_rows now has 5 columns: [ID#, \"Match to\", \"Name\", \"cM\", \"Yates DNA Ancestral Line\"]\n",
        "    columns = [\"ID#\", \"Match to\", \"Name\", \"cM\", \"Yates DNA Ancestral Line\"]\n",
        "    df = pd.DataFrame(combined_rows, columns=columns)\n",
        "\n",
        "    df.index += 1\n",
        "\n",
        "    def remove_specific_prefix(row):\n",
        "        \"\"\"\n",
        "        Removes a specific hardcoded prefix from the 'Yates DNA Ancestral Line' if it matches exactly.\n",
        "        \"\"\"\n",
        "        prefix = \"YatesJohn&SearchingStill~~~YatesWilliam&SearchingStill~~~YatesWilliam&SearchingStill~~~YatesEdmund&CornellMargaret~~~YatesRichard&AshendonJoan~~~YatesJohn&HydeAlice~~~YatesThomas&WhiteFrances~~~\"\n",
        "        line = row.get(\"Yates DNA Ancestral Line\", \"\")\n",
        "\n",
        "        if line.startswith(prefix):\n",
        "            row[\"Yates DNA Ancestral Line\"] = line[len(prefix):]  # Trim the prefix\n",
        "        return row\n",
        "\n",
        "    # Apply this to your DataFrame\n",
        "    df = df.apply(remove_specific_prefix, axis=1)\n",
        "\n",
        "\n",
        "    # 5) Build a Trie from all reversed lines\n",
        "    logger.info(\"Building Trie from reversed lines...\")\n",
        "    trie = Trie()\n",
        "    num_lines_inserted = 0\n",
        "    for _, row in df.iterrows():\n",
        "        line_str = row[\"Yates DNA Ancestral Line\"]\n",
        "        if pd.isna(line_str) or not line_str.strip():\n",
        "            continue\n",
        "        couples_list = [x.strip() for x in line_str.split(\"~~~\") if x.strip()]\n",
        "        trie.insert_line(couples_list)\n",
        "        num_lines_inserted += 1\n",
        "    logger.info(\"Inserted %d lines into the trie.\", num_lines_inserted)\n",
        "\n",
        "    # 6) Compute final \"Value\" = 5*(#couples with node.count >=2) + (total couples)\n",
        "    values = []\n",
        "    prefix_counts = []  # store the count of couples with node.count >=2 for each line\n",
        "    logger.info(\"Computing 'Value' = 5*(#couples with node.count >=2) + (total couples) ...\")\n",
        "    for idx, row in df.iterrows():\n",
        "        line_str = row[\"Yates DNA Ancestral Line\"]\n",
        "        if pd.isna(line_str) or not line_str.strip():\n",
        "            values.append(0)\n",
        "            prefix_counts.append(0)\n",
        "        else:\n",
        "            couples_list = [x.strip() for x in line_str.split(\"~~~\") if x.strip()]\n",
        "            line_length = len(couples_list)\n",
        "            node_counts = trie.get_couple_count(couples_list)\n",
        "            # Count only couples that appear in at least two lines\n",
        "            prefix_count = sum(1 for c in node_counts if c >= 2)\n",
        "            val = 5 * prefix_count + line_length\n",
        "            values.append(val)\n",
        "            prefix_counts.append(prefix_count)\n",
        "    df[\"Value\"] = values\n",
        "    df[\"PrefixCount\"] = prefix_counts\n",
        "\n",
        "\n",
        "\n",
        "    # 7) Assign Value Range and Value Label based on the calculated Value\n",
        "    def assign_value_range_label(val):\n",
        "      try:\n",
        "          val = float(val)\n",
        "      except (ValueError, TypeError):\n",
        "          return \"\", \"\"\n",
        "\n",
        "      if val >= 60:\n",
        "        return \">=60\", \"1-likely correct\"\n",
        "\n",
        "      elif 47 <= val <= 59:\n",
        "          return \"59~47\", \"2-lines forming\"\n",
        "      elif 34 <= val <= 46:\n",
        "          return \"46~34\", \"3-patterns emerging\"\n",
        "      elif 21 <= val <= 33:\n",
        "          return \"33~21\", \"4-notable patterns\"\n",
        "      elif 8 <= val <= 20:\n",
        "          return \"20~8\", \"5-patterns stable\"\n",
        "      elif 1 <= val <= 7:\n",
        "          return f\"{val:.0f}\", \"6-need research\"\n",
        "      else:\n",
        "          return f\"{val:.0f}\", \"0-uncategorized\"\n",
        "\n",
        "\n",
        "\n",
        "    value_ranges = []\n",
        "    value_labels = []\n",
        "    for v in df[\"Value\"]:\n",
        "        rng, lbl = assign_value_range_label(v)\n",
        "        value_ranges.append(rng)\n",
        "        value_labels.append(lbl)\n",
        "    df[\"Value Range\"] = value_ranges\n",
        "    df[\"Value Label\"] = value_labels\n",
        "\n",
        "    # 8) Sort final by \"Yates DNA Ancestral Line\"\n",
        "    df.sort_values(by=[\"Yates DNA Ancestral Line\"], ascending=True, inplace=True)\n",
        "\n",
        "    # Remove the temporary PrefixCount column from the final output\n",
        "    df.drop(\"PrefixCount\", axis=1, inplace=True)\n",
        "\n",
        "# final_cols = [\n",
        "#     \"ID#\",\n",
        "#     \"cM\",\n",
        "#     \"Match to\",\n",
        "#     \"Value\",\n",
        "#     \"Value Range\",\n",
        "#     \"Value Label\",\n",
        "#     \"Yates DNA Ancestral Line\"\n",
        "# ]\n",
        "\n",
        "    final_cols = [\n",
        "      \"ID#\",\n",
        "      \"cM\",\n",
        "      \"Match to\",\n",
        "      \"Value Range\",\n",
        "      \"Value Label\",\n",
        "      \"Yates DNA Ancestral Line\"\n",
        "]\n",
        "\n",
        "    logger.info(\"Final DataFrame columns: %s\", df.columns.tolist())\n",
        "    print(df.head(10))\n",
        "\n",
        "#    print(df[[\"ID#\", \"Yates DNA Ancestral Line\"]].head(32))\n",
        "\n",
        "\n",
        "    # 10) Export CSV and HTML\n",
        "    csv_name = \"final_combined_df_with_value_labels.csv\"\n",
        "    df.to_csv(csv_name, index=False)\n",
        "    logger.info(\"Exported final DataFrame to '%s'.\", csv_name)\n",
        "\n",
        "    html_name = \"HTML_combined_df_with_value_labels.html\"\n",
        "    css_style = \"\"\"\n",
        "    <style>\n",
        "    table {\n",
        "      width: 100%;\n",
        "      border-collapse: collapse;\n",
        "      margin: 20px 0;\n",
        "    }\n",
        "    table, th, td {\n",
        "      border: 1px solid #333;\n",
        "    }\n",
        "    th, td {\n",
        "      padding: 8px 12px;\n",
        "      text-align: center;\n",
        "    }\n",
        "    th {\n",
        "      background-color: #f2f2f2;\n",
        "    }\n",
        "    /* Left-align the last column */\n",
        "    td:nth-child(6) {\n",
        "      text-align: left;\n",
        "}\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\"\n",
        "    html_content = css_style + df.to_html(\n",
        "        index=False,\n",
        "        columns=final_cols,\n",
        "        escape=False\n",
        "    )\n",
        "    with open(html_name, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(html_content)\n",
        "    logger.info(\"Exported HTML to '%s'.\", html_name)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n",
        "    try:\n",
        "        display(Javascript('alert(\"✅ GEDCOM processing (and HTML export) is complete!\");'))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "import smtplib, ssl\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "def send_email(subject, body, to_addr):\n",
        "    smtp_server = 'smtp.gmail.com'\n",
        "    port = 465\n",
        "    sender = os.environ['GMAIL_USER']\n",
        "    password = os.environ['GMAIL_APP_PASSWORD']\n",
        "\n",
        "    msg = MIMEText(body)\n",
        "    msg['Subject'] = subject\n",
        "    msg['From'] = sender\n",
        "    msg['To'] = to_addr\n",
        "\n",
        "    context = ssl.create_default_context()\n",
        "    with smtplib.SMTP_SSL(smtp_server, port, context=context) as server:\n",
        "        server.login(sender, password)\n",
        "        server.send_message(msg)\n",
        "\n",
        "# … after the Javascript alert …\n",
        "\n",
        "# --- Email summary via Gmail SMTP ---\n",
        "import os, smtplib, ssl\n",
        "from email.mime.text import MIMEText\n",
        "import pandas as pd\n",
        "\n",
        "def send_email(subject, body, to_addr):\n",
        "    smtp_server = 'smtp.gmail.com'\n",
        "    port = 465\n",
        "    sender = os.environ['GMAIL_USER']\n",
        "    password = os.environ['GMAIL_APP_PASSWORD']\n",
        "\n",
        "    msg = MIMEText(body)\n",
        "    msg['Subject'] = subject\n",
        "    msg['From'] = sender\n",
        "    msg['To'] = to_addr\n",
        "\n",
        "    context = ssl.create_default_context()\n",
        "    with smtplib.SMTP_SSL(smtp_server, port, context=context) as server:\n",
        "        server.login(sender, password)\n",
        "        server.send_message(msg)\n",
        "\n",
        "# Re-load the final DataFrame from CSV\n",
        "df_summary = pd.read_csv(\"final_combined_df_with_value_labels.csv\")\n",
        "\n",
        "# Build the quick summary\n",
        "total = len(df_summary)\n",
        "counts = df_summary['Value Range'].value_counts().to_dict()\n",
        "top5 = (\n",
        "    df_summary\n",
        "    .sort_values('Value', ascending=False)\n",
        "    .head(5)['Yates DNA Ancestral Line']\n",
        "    .tolist()\n",
        ")\n",
        "summary = (\n",
        "    f\"GEDCOM processing complete!\\n\\n\"\n",
        "    f\"Total lines: {total}\\n\"\n",
        "#    f\"Counts by range: {counts}\\n\"\n",
        "#    f\"Top 5 lines:\\n\" + \"\\n\".join(f\"- {line}\" for line in top5)\n",
        ")\n",
        "\n",
        "# Send it\n",
        "send_email(\n",
        "    subject=\"✅ GEDCOM Report Ready\",\n",
        "    body=summary,\n",
        "    to_addr=os.environ['GMAIL_USER']\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "outputId": "881a074d-b7db-4452-e6a8-b72bfe70d84d",
        "id": "TOB9IqmDeMKi"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically selecting the first GEDCOM file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:filtered_ids.xlsx not found. Skipping second-level manual filter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GEDCOM contained 60094 total records\n",
            "Records tagged and filtered by NPFX: 1443\n",
            "Records with YDNA information: 90\n",
            "Autosomal matches: 1353\n",
            "Records tagged and filtered by NPFX: 1443\n",
            "Processing 1443 individuals with chunk-based parallel...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Yates Lines (Stage 1): 100%|██████████| 1443/1443 [13:23<00:00,  1.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         ID#         Match to               Name  cM  \\\n",
            "892   I53693          fridine   RosenbalmJessica  20   \n",
            "676   I51586     hendricksjas     CrossFrancesCa  29   \n",
            "1349  I59027       yeatesd_ws    JordanTravisLil  28   \n",
            "1031  I54946       yatesjohnh      SloverDeborah  25   \n",
            "1035  I54968  girtain,kathryn     BurchNaomiEuge  25   \n",
            "88    I38493            Y-DNA    BurtonMerrittCa  01   \n",
            "1407  I59628       yeatesd_tm    StewartLisaJean  11   \n",
            "271   I46128    yates,andreal     JonesMaryKathe  23   \n",
            "944   I54181           marmar      ReedLindaGail  21   \n",
            "739   I52241          klingal  PhillipsPatriciaK  24   \n",
            "\n",
            "                               Yates DNA Ancestral Line  Value Value Range  \\\n",
            "892   ArvinWilliamHe&YatesMargaretE~~~ArvinJohnAmbro...      5           5   \n",
            "676   BaileyWilliam&YatesRhoda~~~CrossJamesMadi&Bail...      5           5   \n",
            "1349  BelkThomas&YatesElizabeth~~~HelmsAsa&BelkHanna...      6           6   \n",
            "1031  BennettWilliamBu&YatesElllen~~~CarmeliaEmanuel...      6           6   \n",
            "1035  BronsonJamesRobe&YatesAgnesMarg~~~BronsonHenry...      4           4   \n",
            "88    BurtonJohn&TorkingtonHarriet~~~BurtonSanfordSa...      4           4   \n",
            "1407  ColliverJames&YatesNancy~~~ColliverJesseB&Dogg...     16        20~8   \n",
            "271   ColliverJames&YatesNancy~~~ColliverJesseB&Dogg...     15        20~8   \n",
            "944   CowdenWilliam&YatesCatherine~~~MilesWilliamDa&...     10        20~8   \n",
            "739   CowdenWilliam&YatesCatherine~~~TylerAnderson&C...     10        20~8   \n",
            "\n",
            "            Value Label  \n",
            "892     6-need research  \n",
            "676     6-need research  \n",
            "1349    6-need research  \n",
            "1031    6-need research  \n",
            "1035    6-need research  \n",
            "88      6-need research  \n",
            "1407  5-patterns stable  \n",
            "271   5-patterns stable  \n",
            "944   5-patterns stable  \n",
            "739   5-patterns stable  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "alert(\"✅ GEDCOM processing (and HTML export) is complete!\");"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: XHTML Template + Export + Root FTP Upload\n",
        "\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML, Javascript\n",
        "from datetime import datetime\n",
        "from ftplib import FTP_TLS\n",
        "import os\n",
        "\n",
        "# ————— Load Data —————\n",
        "df = pd.read_csv(\"final_combined_df_with_value_labels.csv\")\n",
        "\n",
        "try:\n",
        "    with open(\"autosomal_count.txt\", \"r\") as f:\n",
        "        autosomal_count = f.read().strip()\n",
        "except FileNotFoundError:\n",
        "    autosomal_count = \"Unknown\"\n",
        "\n",
        "today_date = datetime.today().strftime('%Y-%m-%d')\n",
        "\n",
        "# ————— Build HTML —————\n",
        "full_html_template = \"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        "  \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"en\" lang=\"en\">\n",
        "<head>\n",
        "  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"/>\n",
        "  <meta name=\"GENERATOR\" content=\"Yatesville\"/>\n",
        "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"/>\n",
        "  <title>DNA Report Card</title>\n",
        "  <script src=\"../sorttable.js\" type=\"text/javascript\"></script>\n",
        "  <style type=\"text/css\">\n",
        "    body {\n",
        "      font-family: Arial, Helvetica, sans-serif;\n",
        "      font-size: 16px;\n",
        "      background-color: #faf9d3;\n",
        "    }\n",
        "    .output-table table {\n",
        "      width: 100%;\n",
        "      border-collapse: collapse;\n",
        "      margin: 15px 0;\n",
        "      background-color: #faf9d3;\n",
        "    }\n",
        "    .output-table table, .output-table th, .output-table td {\n",
        "      border: 1px solid #333;\n",
        "      text-align: center;\n",
        "      background-color: #faf9d3;\n",
        "      padding: 5px 8px;\n",
        "    }\n",
        "    .output-table th {\n",
        "      background-color: #ffffcc;\n",
        "      color: black;\n",
        "      white-space: nowrap;\n",
        "    }\n",
        "    .output-table th:hover {\n",
        "      background-color: #ffeb99;\n",
        "    }\n",
        "    .output-table td:nth-child(5) {\n",
        "      min-width: 180px;\n",
        "    }\n",
        "    .output-table td:last-child, .output-table th:last-child {\n",
        "      text-align: left;\n",
        "      white-space: nowrap;\n",
        "    }\n",
        "  </style>\n",
        "</head>\n",
        "<body>\n",
        "<div align=\"center\">\n",
        "  <table class=\"fullpage-definedsection\" cellpadding=\"0\"><tr valign=\"top\"><td>\n",
        "    <table class=\"headersection\" cellpadding=\"0\"><tr valign=\"top\"><td></td></tr></table>\n",
        "    <table class=\"mainsection\" cellpadding=\"7\">\n",
        "      <tr valign=\"top\"><td>\n",
        "        <h2>A report card for your DNA family tree</h2>\n",
        "        <font size=\"-2\">\n",
        "          Return to <a href=\"https://yates.one-name.net/gengen/dna_cousin_surname_study.htm\">Study Home</a>\n",
        "          &nbsp;|&nbsp;\n",
        "          Autosomal matches: {autosomal_count}\n",
        "          &nbsp;|&nbsp;\n",
        "          Updated: {today_date}\n",
        "        </font>\n",
        "        <p>Imagine you have a report card for your family tree that tells you how your family tree compares to other collateral family tree lines.<br><br>Here is how we break it down:</p>\n",
        "        <p>Think of value like the total number of points you get from finding all the important family connections in your tree<br>\n",
        "        and comparing them to all the other trees included in the Yates study.</p>\n",
        "        <p>We then group them as a way to signal which ones seem to have potential for study:\n",
        "          <b>>60:</b> likely correct, <b>59–47:</b><br> lines forming, <b>46–34:</b> patterns emerging,\n",
        "          <b>33–21:</b> notable patterns, <b>20–8:</b> patterns stable, <b>7–1:</b> and 6-need research.</p>\n",
        "        <p><b><i><font size=\"-1\">Click on the header to sort any column</font></i></b>\n",
        "          (And, remember <a href=\"https://yates.one-name.net/gengen/dna_theory_of_the_case.htm\" target=\"_blank\">what this is telling</a> us....)</p>\n",
        "      </td></tr>\n",
        "    </table>\n",
        "    <div class=\"output-table\" style=\"margin-top: 10px;\">\n",
        "      <!-- TABLE_PLACEHOLDER -->\n",
        "    </div>\n",
        "  </td></tr></table>\n",
        "</div>\n",
        "<button onclick=\"topFunction()\" id=\"myBtn\" title=\"Go to top\"\n",
        "  style=\"position: fixed; bottom: 40px; right: 40px; z-index: 99; background-color: red; color: white;\n",
        "         padding: 12px 20px; border: none; border-radius: 10px; cursor: pointer; font-size: 16px;\">\n",
        "  Top\n",
        "</button>\n",
        "<script>\n",
        "let mybutton = document.getElementById(\"myBtn\");\n",
        "window.onscroll = function() {\n",
        "  if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {\n",
        "    mybutton.style.display = \"block\";\n",
        "  } else {\n",
        "    mybutton.style.display = \"none\";\n",
        "  }\n",
        "};\n",
        "function topFunction() {\n",
        "  document.body.scrollTop = 0;\n",
        "  document.documentElement.scrollTop = 0;\n",
        "}\n",
        "</script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "final_cols = [\"ID#\", \"cM\", \"Match to\", \"Value Range\", \"Value Label\", \"Yates DNA Ancestral Line\"]\n",
        "df.sort_values(by=[\"Yates DNA Ancestral Line\"], inplace=True)\n",
        "\n",
        "html_table = df.to_html(index=False, columns=final_cols, escape=False, classes=\"dataframe sortable\")\n",
        "final_html = (full_html_template\n",
        "              .replace(\"{autosomal_count}\", autosomal_count)\n",
        "              .replace(\"{today_date}\", today_date)\n",
        "             )\n",
        "final_html = final_html.replace(\"<!-- TABLE_PLACEHOLDER -->\", html_table)\n",
        "\n",
        "# Save locally\n",
        "with open(\"dna_cousin_surname_app.htm\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final_html)\n",
        "\n",
        "# Notebook alert\n",
        "display(Javascript('alert(\"✅ DNA Report Card generated locally.\");'))\n",
        "\n",
        "# ————— FTP Upload to ROOT —————\n",
        "ftp_host = os.environ['FTP_HOST']\n",
        "ftp_port = int(os.environ.get('FTP_PORT', 21))\n",
        "ftp_user = os.environ['FTP_USER']\n",
        "ftp_pass = os.environ['FTP_PASS']\n",
        "\n",
        "def upload_to_root(filenames):\n",
        "    ftps = FTP_TLS()\n",
        "    ftps.connect(ftp_host, ftp_port)\n",
        "    ftps.login(ftp_user, ftp_pass)\n",
        "    ftps.prot_p()  # secure data channel\n",
        "\n",
        "    for fname in filenames:\n",
        "        # delete existing root file\n",
        "        try:\n",
        "            ftps.delete(fname)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # upload to root\n",
        "        with open(fname, 'rb') as f:\n",
        "            print(f\"→ uploading {fname} to /{fname} …\", end=' ')\n",
        "            ftps.storbinary(f\"STOR {fname}\", f)\n",
        "            print(\"done\")\n",
        "\n",
        "        # set permissions\n",
        "        try:\n",
        "            ftps.sendcmd(f\"SITE CHMOD 644 {fname}\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    ftps.quit()\n",
        "    print(\"✅ All files uploaded to One Name Study.\")\n",
        "\n",
        "# Run upload\n",
        "upload_to_root([\n",
        "    \"dna_cousin_surname_app.htm\",\n",
        "#    \"final_combined_df_with_value_labels.csv\"\n",
        "])\n"
      ],
      "metadata": {
        "id": "09SUUSG55K4F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7a141156-3413-44a5-b348-146d8bffa41f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "alert(\"✅ DNA Report Card generated locally.\");"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ uploading dna_cousin_surname_app.htm to /dna_cousin_surname_app.htm … done\n",
            "✅ All files uploaded to One Name Study.\n"
          ]
        }
      ]
    }
  ]
}