{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1RROHlBgtXAYWOqDWQkIX8NCciZBqPcV3",
      "authorship_tag": "ABX9TyOE1ZZQ0Z6zZfHYR7Zsd9GA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronyates47/Gedcom-Utils/blob/main/New_Gold__1_%26_2_%26_3_20251125_1000.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PIP"
      ],
      "metadata": {
        "id": "XtvXRl-lcavJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT5s4n9S5ZpZ",
        "outputId": "fc116f74-8c72-42e5-909d-4d69607742a4",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting python-gedcom\n",
            "  Downloading python_gedcom-1.0.0-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Downloading python_gedcom-1.0.0-py2.py3-none-any.whl (35 kB)\n",
            "Installing collected packages: python-gedcom\n",
            "Successfully installed python-gedcom-1.0.0\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Collecting xlsxwriter\n",
            "  Downloading xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\n",
            "Downloading xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.9\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.12/dist-packages (0.23.4)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (1.16.3)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (1.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (1.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.1->mlxtend) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.17.0)\n",
            "ERROR: unknown command \"caas_jupyter_tools\"\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install python-gedcom\n",
        "!pip install openpyxl\n",
        "!pip install xlsxwriter\n",
        "!pip install mlxtend\n",
        "!pip caas_jupyter_tools"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 1"
      ],
      "metadata": {
        "id": "JvOlmbj91AGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] CELL 1 — GEDCOM -> CSV + HTML + Upload (Explicit FTPS, ISO-8859-15) ===\n",
        "# RON GOLDEN RULES — CLIFF NOTES (v2025.11.14)\n",
        "# • Complete & runnable Colab Cell — one contiguous block (no fragments, no cross-refs).\n",
        "# • Source ASCII-only; outputs written with encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\".\n",
        "# • XHTML 1.0 Transitional; typography via /partials/dna_tree_styles.css (HTML export only).\n",
        "# • Deterministic audit:\n",
        "#   [CONFIRM] Golden Rules active | Cell=Cell1_FTPS_Explicit | Version=2025.11.14 | Encoding=ISO-8859-15\n",
        "# • Enforce ISO-8859-15 printable chars on writes; replace non-Latin with XML entities.\n",
        "# ==============================================================================================\n",
        "\n",
        "import os, re, glob, logging, functools, socket, traceback, hashlib\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from ftplib import FTP_TLS, all_errors\n",
        "from string import Template\n",
        "\n",
        "CELL_NAME = \"Cell1_FTPS_Explicit\"\n",
        "VERSION   = \"2025.11.14\"\n",
        "\n",
        "print(\"[CONFIRM] Golden Rules active | Cell=%s | Version=%s | Encoding=ISO-8859-15\" % (CELL_NAME, VERSION))\n",
        "\n",
        "# ---------- Logging ----------\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "logger = logging.getLogger(CELL_NAME)\n",
        "\n",
        "# ---------- Secrets (env or userdata) ----------\n",
        "def _get_env(k, default=\"\"):\n",
        "    try:\n",
        "        from google.colab import userdata  # type: ignore\n",
        "        v = userdata.get(k)\n",
        "        return v if v is not None else os.environ.get(k, default)\n",
        "    except Exception:\n",
        "        return os.environ.get(k, default)\n",
        "\n",
        "FTP_HOST = (_get_env(\"FTP_HOST\",\"\") or \"\").strip()\n",
        "FTP_USER = (_get_env(\"FTP_USER\",\"\") or \"\").strip()\n",
        "FTP_PASS = _get_env(\"FTP_PASS\",\"\") or \"\"\n",
        "FTP_PORT = int(_get_env(\"FTP_PORT\",\"21\") or \"21\")\n",
        "FTP_DIR  = (_get_env(\"FTP_DIR\",\"\") or \"\").strip().strip(\"/\")\n",
        "PASSIVE_MODE = True\n",
        "\n",
        "def _mask(s, keep=3):\n",
        "    s = \"\" if s is None else str(s)\n",
        "    if not s:\n",
        "        return \"(empty)\"\n",
        "    return (s[:keep] + \"***\" + s[-keep:]) if len(s) > keep * 2 else s[0:1] + \"***\"\n",
        "\n",
        "print(\"[ENV] HOST=%s  USER=%s  PASS=%s  PORT=%d  DIR=%s\" %\n",
        "      (_mask(FTP_HOST), _mask(FTP_USER, 2), \"***\", FTP_PORT, (\"/\" + FTP_DIR) if FTP_DIR else \"(root)\"))\n",
        "\n",
        "# ---------- FTPS (Explicit AUTH TLS) ----------\n",
        "def _ftps_connect():\n",
        "    if not (FTP_HOST and FTP_USER and FTP_PASS):\n",
        "        raise RuntimeError(\"Missing FTP_HOST/FTP_USER/FTP_PASS.\")\n",
        "    socket.setdefaulttimeout(30)\n",
        "    ftps = FTP_TLS(timeout=30)\n",
        "    ftps.connect(FTP_HOST, FTP_PORT)\n",
        "    ftps.auth()                 # Explicit FTPS: AUTH TLS before login\n",
        "    ftps.login(FTP_USER, FTP_PASS)\n",
        "    try:\n",
        "        ftps.prot_p()           # Encrypt data channel\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        ftps.set_pasv(PASSIVE_MODE)\n",
        "    except Exception:\n",
        "        pass\n",
        "    if FTP_DIR:\n",
        "        for p in [p for p in FTP_DIR.split(\"/\") if p]:\n",
        "            ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "def _ftps_ensure_dir(ftps, path):\n",
        "    if not path:\n",
        "        return\n",
        "    for p in [p for p in path.split(\"/\") if p]:\n",
        "        try:\n",
        "            ftps.cwd(p)\n",
        "        except all_errors:\n",
        "            try:\n",
        "                ftps.mkd(p)\n",
        "            except all_errors:\n",
        "                pass\n",
        "            ftps.cwd(p)\n",
        "\n",
        "def _ftps_upload(ftps, local_path, remote_name):\n",
        "    with open(local_path, \"rb\") as fh:\n",
        "        ftps.storbinary(\"STOR \" + remote_name, fh)\n",
        "    print(\"[OK] Uploaded: %s -> %s/%s\" % (local_path, ftps.pwd().rstrip(\"/\"), remote_name))\n",
        "\n",
        "# ---------- Outputs / Paths ----------\n",
        "REMOTE_DIR        = \"partials\"\n",
        "CSV_OUT_LOCAL     = \"final_combined_df_with_value_labels.csv\"\n",
        "HTML_OUT_LOCAL    = \"cell1_work_table.htm\"\n",
        "ABS_CSV_URL       = \"/%s/%s\" % (REMOTE_DIR, os.path.basename(CSV_OUT_LOCAL))\n",
        "ABS_HOME_URL      = \"/index.htm\"\n",
        "\n",
        "# NEW: vitals file for Cell 2\n",
        "VITALS_CSV_PATH   = \"dna_vitals.csv\"\n",
        "\n",
        "# ---------- Minimal GEDCOM parse helpers ----------\n",
        "anchor_gen1 = None\n",
        "visited_pairs = set()\n",
        "generation_table = []\n",
        "\n",
        "class GedcomDataset:\n",
        "    def __init__(self, gen_person):\n",
        "        self.gen_person = gen_person\n",
        "        self.extractable_detail = {}\n",
        "        self.anchor_gen1 = None\n",
        "\n",
        "    def add_extractable_detail(self, key, value):\n",
        "        self.extractable_detail[key] = value\n",
        "\n",
        "    def get_gen_person(self):\n",
        "        name = self.extractable_detail.get(\"NAME\", \"\") or \"\"\n",
        "        parts = name.split(\"/\", 1)\n",
        "        first_name = parts[0].split(\" \")[0] if parts else \"\"\n",
        "        last_name  = parts[1].rstrip(\"/\") if len(parts) > 1 else \"\"\n",
        "        self.anchor_gen1 = last_name.replace(\" \", \"\") + first_name.replace(\" \", \"\")\n",
        "        global anchor_gen1\n",
        "        anchor_gen1 = self.anchor_gen1\n",
        "        return self.gen_person.strip(\"@\")\n",
        "\n",
        "    def get_extractable_NPFX(self):\n",
        "        return self.extractable_detail.get(\"NPFX\", \"\") or \"\"\n",
        "\n",
        "    def get_extractable_cm(self):\n",
        "        v = self.extractable_detail.get(\"NPFX\", \"\") or \"\"\n",
        "        if \"&\" in v:\n",
        "            cm = v.split(\"&\")[0].strip()\n",
        "        elif \"**\" in v:\n",
        "            cm = v.split(\"**\")[0].strip()\n",
        "        else:\n",
        "            cm = v.strip()\n",
        "        try:\n",
        "            int(cm)\n",
        "            return cm\n",
        "        except Exception:\n",
        "            return \"\"\n",
        "\n",
        "    def get_extractable_sort(self):\n",
        "        v = self.extractable_detail.get(\"NPFX\", \"\") or \"\"\n",
        "        if \"&\" in v:\n",
        "            s = v.split(\"&\")[1]\n",
        "            return (s.split(\"**\")[0] if \"**\" in s else s).strip()\n",
        "        return \"\"\n",
        "\n",
        "    def get_extractable_YDNA(self):\n",
        "        v = self.extractable_detail.get(\"NPFX\", \"\") or \"\"\n",
        "        return v.split(\"**\")[1].strip() if \"**\" in v else \"\"\n",
        "\n",
        "    def get_extractable_FAMC(self):\n",
        "        return (self.extractable_detail.get(\"FAMC\", \"\") or \"\").strip(\"@\")\n",
        "\n",
        "class Gedcom:\n",
        "    def __init__(self, file_name):\n",
        "        self.file_name = file_name\n",
        "        self.gedcom_datasets = []\n",
        "        self.filter_pool = []\n",
        "\n",
        "        # Counters / vitals\n",
        "        self.total_records = 0\n",
        "        self.npfx_count = 0\n",
        "        self.ydna_count = 0\n",
        "        self.autosomal_count = 0\n",
        "        self.after_manual_filter_total = 0\n",
        "\n",
        "    def parse_gedcom(self):\n",
        "        with open(self.file_name, \"r\", encoding=\"utf-8-sig\") as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        current = None\n",
        "        npfx_count = 0\n",
        "        ydna_count = 0\n",
        "        total = 0\n",
        "\n",
        "        for line in lines:\n",
        "            parts = line.strip().split(\" \", 2)\n",
        "            if not parts or not parts[0].isdigit():\n",
        "                continue\n",
        "            level = int(parts[0])\n",
        "            tag = parts[1]\n",
        "            value = parts[2] if len(parts) > 2 else None\n",
        "\n",
        "            if level == 0 and tag.startswith(\"@\") and tag.endswith(\"@\") and value == \"INDI\":\n",
        "                total += 1\n",
        "                current = GedcomDataset(tag)\n",
        "                self.gedcom_datasets.append(current)\n",
        "            elif current is not None:\n",
        "                if level == 1 and tag in [\"NAME\", \"FAMC\"]:\n",
        "                    current.add_extractable_detail(tag, value)\n",
        "                elif level == 2 and tag == \"NPFX\":\n",
        "                    npfx_count += 1\n",
        "                    current.add_extractable_detail(tag, value)\n",
        "                    if value and \"**\" in value:\n",
        "                        ydna_count += 1\n",
        "\n",
        "        autosomal = npfx_count - ydna_count\n",
        "\n",
        "        # Store vitals on the instance\n",
        "        self.total_records = total\n",
        "        self.npfx_count = npfx_count\n",
        "        self.ydna_count = ydna_count\n",
        "        self.autosomal_count = autosomal\n",
        "\n",
        "        print(\"GEDCOM contained %d total records\" % total)\n",
        "        print(\"Records tagged and filtered by NPFX: %d\" % npfx_count)\n",
        "        print(\"Records with YDNA information: %d\" % ydna_count)\n",
        "        print(\"Autosomal matches: %d\" % autosomal)\n",
        "\n",
        "        # First-level filter: keep only records with NPFX\n",
        "        for ds in self.gedcom_datasets:\n",
        "            if ds.get_extractable_NPFX():\n",
        "                self.filter_pool.append(ds)\n",
        "\n",
        "        # Second-level manual filter via filtered_ids.xlsx (if present)\n",
        "        try:\n",
        "            df_filter = pd.read_excel(\"filtered_ids.xlsx\")\n",
        "            manual_ids = set(str(x) for x in df_filter[\"ID\"])\n",
        "            self.filter_pool = [d for d in self.filter_pool if d.get_gen_person() in manual_ids]\n",
        "            print(\"After manual filter, total records: %d\" % len(self.filter_pool))\n",
        "        except FileNotFoundError:\n",
        "            logger.warning(\"filtered_ids.xlsx not found. Skipping second-level manual filter.\")\n",
        "\n",
        "        # Final: record the post-filter count as a vital\n",
        "        self.after_manual_filter_total = len(self.filter_pool)\n",
        "\n",
        "        return autosomal\n",
        "\n",
        "def _chunks(lst, n):\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]\n",
        "\n",
        "def _quick_extract_name(full_text):\n",
        "    name_marker = \"\\n1 NAME \"\n",
        "    idx = full_text.find(name_marker)\n",
        "    if idx == -1:\n",
        "        if full_text.startswith(\"1 NAME \"):\n",
        "            idx = 0\n",
        "        else:\n",
        "            return \"UnknownName\"\n",
        "    start = idx + len(name_marker)\n",
        "    end = full_text.find(\"\\n\", start)\n",
        "    end = len(full_text) if end == -1 else end\n",
        "    name_line = full_text[start:end].strip()\n",
        "    if \"/\" not in name_line:\n",
        "        return name_line[:10].replace(\" \", \"\")\n",
        "    first_name, last_name = name_line.split(\"/\", 1)\n",
        "    last_name = last_name.replace(\"/\", \"\").strip()\n",
        "    return last_name[:10].replace(\" \", \"\") + first_name[:10].replace(\" \", \"\")\n",
        "\n",
        "def _find_parents(individual_id, generation, parents_map):\n",
        "    global visited_pairs, generation_table\n",
        "    if individual_id not in parents_map:\n",
        "        return\n",
        "    father_id, mother_id = parents_map[individual_id]\n",
        "    if not father_id and not mother_id:\n",
        "        return\n",
        "    pair = (father_id, mother_id)\n",
        "    if pair not in visited_pairs:\n",
        "        visited_pairs.add(pair)\n",
        "        generation_table.append((generation, pair))\n",
        "    if father_id:\n",
        "        _find_parents(father_id, generation + 1, parents_map)\n",
        "    if mother_id:\n",
        "        _find_parents(mother_id, generation + 1, parents_map)\n",
        "\n",
        "def _find_distant(individual_id, parents_map, path=None):\n",
        "    if path is None:\n",
        "        path = []\n",
        "    path.append(individual_id)\n",
        "    if individual_id not in parents_map:\n",
        "        return [path]\n",
        "    father_id, mother_id = parents_map[individual_id]\n",
        "    if not father_id and not mother_id:\n",
        "        return [path]\n",
        "    paths = []\n",
        "    if father_id:\n",
        "        paths.extend(_find_distant(father_id, parents_map, path[:]))\n",
        "    if mother_id:\n",
        "        paths.extend(_find_distant(mother_id, parents_map, path[:]))\n",
        "    return paths if paths else [path]\n",
        "\n",
        "def _filter_lineage(winning_ids, gen_table, names_map):\n",
        "    matching = []\n",
        "    for generation, pair in gen_table:\n",
        "        id1, id2 = pair\n",
        "        if id1 in winning_ids or id2 in winning_ids:\n",
        "            matching.append((generation, pair))\n",
        "    matching.sort(key=lambda x: x[0])\n",
        "    lines = []\n",
        "    for _, pair in matching:\n",
        "        name_pair = [names_map.get(pid, \"UnknownName\") for pid in pair]\n",
        "        lines.append(\"%s&%s\" % (name_pair[0], name_pair[1]))\n",
        "    lines.reverse()\n",
        "    return \"~~~\".join(lines)\n",
        "\n",
        "def _process_record(individual_id, ged, parents_map, names_map):\n",
        "    global generation_table, visited_pairs, anchor_gen1\n",
        "    generation_table = []\n",
        "    visited_pairs = set()\n",
        "    _find_parents(individual_id, 1, parents_map)\n",
        "    paths = _find_distant(individual_id, parents_map)\n",
        "    best_score, best_path = None, None\n",
        "    for path in paths:\n",
        "        name_path = [names_map.get(pid, \"UnknownName\") for pid in path]\n",
        "        score = sum((idx + 1) for idx, nm in enumerate(name_path) if \"Yates\" in nm)\n",
        "        if best_score is None or score > best_score:\n",
        "            best_score, best_path = score, path\n",
        "    best_path = best_path or []\n",
        "    best_ids  = [pid for pid in best_path if pid != individual_id]\n",
        "    line_str  = _filter_lineage(set(best_ids), generation_table, names_map)\n",
        "    cm_value = \"\"\n",
        "    sort_value = \"\"\n",
        "    ydna_value = \"\"\n",
        "    for ds in ged.filter_pool:\n",
        "        if ds.get_gen_person() == individual_id:\n",
        "            cm_value   = ds.get_extractable_cm()\n",
        "            sort_value = ds.get_extractable_sort()\n",
        "            ydna_value = ds.get_extractable_YDNA()\n",
        "            break\n",
        "    short_name = names_map.get(individual_id, \"UnknownName\")\n",
        "    return [individual_id, sort_value, short_name, cm_value, line_str, ydna_value]\n",
        "\n",
        "# ---------- Main build ----------\n",
        "def main():\n",
        "    files = glob.glob(\"*.ged\")\n",
        "    if not files:\n",
        "        print(\"No GEDCOM files found.\")\n",
        "        return False\n",
        "    print(\"Automatically selecting the first GEDCOM file.\")\n",
        "    gedcom_path = files[0]\n",
        "\n",
        "    # Parse GEDCOM, build datasets, and compute vitals\n",
        "    ged = Gedcom(gedcom_path)\n",
        "    autosomal_count = ged.parse_gedcom()\n",
        "\n",
        "    # Local autosomal_count.txt (legacy; Cell 2 no longer uploads it, but we keep it)\n",
        "    with open(\"autosomal_count.txt\", \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(str(autosomal_count))\n",
        "\n",
        "    # NEW: dna_vitals.csv based on actual parsed counts\n",
        "    npfx_count = int(ged.npfx_count)\n",
        "    after_manual_filter_total = int(ged.after_manual_filter_total or len(ged.filter_pool))\n",
        "\n",
        "    print(\"Records tagged and filtered by NPFX: %d\" % npfx_count)\n",
        "    print(\"After manual filter, total records: %d\" % after_manual_filter_total)\n",
        "\n",
        "    vitals_lines = [\n",
        "        \"Records tagged and filtered by NPFX: %d\" % npfx_count,\n",
        "        \"After manual filter, total records: %d\" % after_manual_filter_total,\n",
        "    ]\n",
        "    vitals_df = pd.DataFrame({\"line\": vitals_lines})\n",
        "    vitals_df.to_csv(\n",
        "        VITALS_CSV_PATH,\n",
        "        index=False,\n",
        "        encoding=\"iso-8859-15\",\n",
        "        errors=\"xmlcharrefreplace\",\n",
        "    )\n",
        "    print(\"[OK] Wrote dna_vitals.csv -> %s\" % os.path.abspath(VITALS_CSV_PATH))\n",
        "\n",
        "    # Re-read GEDCOM raw text for ancestor-building\n",
        "    with open(gedcom_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        raw = f.read()\n",
        "\n",
        "    blocks = raw.split(\"\\n0 \")\n",
        "    all_records = {}\n",
        "    for blk in blocks:\n",
        "        blk = blk.strip()\n",
        "        if not blk:\n",
        "            continue\n",
        "        flend = blk.find(\"\\n\")\n",
        "        flend = len(blk) if flend == -1 else flend\n",
        "        first_line = blk[:flend]\n",
        "        if \"@\" in first_line:\n",
        "            s = first_line.find(\"@\") + 1\n",
        "            e = first_line.find(\"@\", s)\n",
        "            rec_id = first_line[s:e].strip()\n",
        "            all_records[rec_id] = blk\n",
        "\n",
        "    parents_map, names_map, families = {}, {}, {}\n",
        "    for rec_id, txt in all_records.items():\n",
        "        if \"FAM\" in txt[:50]:\n",
        "            father_idx = txt.find(\"1 HUSB @\")\n",
        "            husb_id = txt[father_idx + len(\"1 HUSB @\"):txt.find(\"@\", father_idx + len(\"1 HUSB @\"))] if father_idx != -1 else None\n",
        "            wife_idx = txt.find(\"1 WIFE @\")\n",
        "            wife_id = txt[wife_idx + len(\"1 WIFE @\"):txt.find(\"@\", wife_idx + len(\"1 WIFE @\"))] if wife_idx != -1 else None\n",
        "            kids = [ln.split(\"@\")[1] for ln in txt.split(\"\\n\") if ln.strip().startswith(\"1 CHIL @\")]\n",
        "            families[rec_id] = (husb_id, wife_id, kids)\n",
        "\n",
        "    for fam_id, (f_id, m_id, k_list) in families.items():\n",
        "        for kid in k_list:\n",
        "            parents_map[kid] = (f_id, m_id)\n",
        "\n",
        "    for rec_id, txt in all_records.items():\n",
        "        names_map[rec_id] = _quick_extract_name(\"\\n\" + txt)\n",
        "\n",
        "    individual_ids = [d.get_gen_person() for d in ged.filter_pool]\n",
        "    print(\"Processing %d individuals with chunk-based parallel...\" % len(individual_ids))\n",
        "\n",
        "    combined_rows = []\n",
        "    chunk_size = 50\n",
        "    max_workers = os.cpu_count() or 4\n",
        "    from functools import partial as _partial\n",
        "\n",
        "    with ProcessPoolExecutor(max_workers=max_workers) as ex, tqdm(\n",
        "        total=len(individual_ids),\n",
        "        desc=\"Building Yates Lines (Stage 1)\"\n",
        "    ) as pbar:\n",
        "        for chunk in _chunks(individual_ids, chunk_size):\n",
        "            func = _partial(_process_record, ged=ged, parents_map=parents_map, names_map=names_map)\n",
        "            results = list(ex.map(func, chunk))\n",
        "            combined_rows.extend(results)\n",
        "            pbar.update(len(chunk))\n",
        "\n",
        "    columns = [\"ID#\", \"Match to\", \"Name\", \"cM\", \"Yates DNA Ancestral Line\", \"haplogroup\"]\n",
        "    df = pd.DataFrame(combined_rows, columns=columns)\n",
        "    df.index += 1\n",
        "\n",
        "    def _trim_prefix(row):\n",
        "        prefix = (\n",
        "            \"YatesJohn&SearchingStill~~~\"\n",
        "            \"YatesWilliam&SearchingStill~~~\"\n",
        "            \"YatesWilliam&SearchingStill~~~\"\n",
        "            \"YatesEdmund&CornellMargaret~~~\"\n",
        "            \"YatesRichard&AshendonJoan~~~\"\n",
        "            \"YatesJohn&HydeAlice~~~\"\n",
        "            \"YatesThomas&FauconerElizabeth~~~\"\n",
        "        )\n",
        "        s = str(row[\"Yates DNA Ancestral Line\"])\n",
        "        if s.startswith(prefix):\n",
        "            row[\"Yates DNA Ancestral Line\"] = s[len(prefix):]\n",
        "        return row\n",
        "\n",
        "    df = df.apply(_trim_prefix, axis=1)\n",
        "    df.sort_values(by=[\"Yates DNA Ancestral Line\"], inplace=True)\n",
        "\n",
        "    # CSV (ISO-8859-15 as required)\n",
        "    with open(CSV_OUT_LOCAL, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(df.to_csv(index=False))\n",
        "    logger.info(\"Exported CSV -> %s\", CSV_OUT_LOCAL)\n",
        "\n",
        "    # HTML (XHTML 1.0 Transitional; Times via external CSS is implied; inline minimal styles ok)\n",
        "    final_cols = [\"ID#\", \"cM\", \"haplogroup\", \"Match to\", \"Yates DNA Ancestral Line\"]\n",
        "    table_html = df.to_html(index=False, columns=final_cols, escape=False, border=1)\n",
        "\n",
        "    page_tpl = Template(\"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "<title>Cell 1 Working Table</title>\n",
        "<link rel=\"stylesheet\" type=\"text/css\" href=\"/partials/dna_tree_styles.css\" />\n",
        "<style type=\"text/css\">\n",
        "  html { scroll-behavior: smooth; }\n",
        "  body { background:#ffffff; color:#222; margin:0; padding:20px; }\n",
        "  h1 { margin:0 0 8px 0; font-size:24px; line-height:1.2; text-align:center; }\n",
        "  .meta { text-align:center; font-size:12px; color:#555; margin:2px 0 12px 0; }\n",
        "  .downloads { text-align:center; margin:4px 0 12px 0; font-size:13px; }\n",
        "  a { color:#154b8b; text-decoration:none; }\n",
        "  a:hover { text-decoration:underline; }\n",
        "  table { width:100%; border-collapse:collapse; }\n",
        "  th, td { border:1px solid #333; padding:6px 8px; vertical-align:top; }\n",
        "  th { background:#e3eaf8; text-align:left; }\n",
        "  td:nth-child(5) { text-align:left; white-space:normal; }\n",
        "</style>\n",
        "<script type=\"text/javascript\">\n",
        "//<![CDATA[\n",
        "(function(){ function z(n){return (n<10?'0':'')+n;}\n",
        "document.addEventListener('DOMContentLoaded', function(){\n",
        "  var el = document.getElementById('last-updated');\n",
        "  if(el){\n",
        "    var d = new Date(document.lastModified || new Date());\n",
        "    el.innerHTML = d.getFullYear() + '-' + z(d.getMonth()+1) + '-' + z(d.getDate()) +\n",
        "                   ' ' + z(d.getHours()) + ':' + z(d.getMinutes());\n",
        "  }\n",
        "}, false); })();\n",
        "//]]>\n",
        "</script>\n",
        "</head>\n",
        "<body>\n",
        "  <h1>Cell 1 Working Table</h1>\n",
        "  <div class=\"meta\">\n",
        "    <a href=\"$HOME\" target=\"_blank\" rel=\"noopener\">Home</a>\n",
        "    &nbsp;|&nbsp; Last updated: <span id=\"last-updated\"></span>\n",
        "    &nbsp;|&nbsp; Download: <a href=\"$CSV\">$CSV</a>\n",
        "  </div>\n",
        "  <div class=\"downloads\"><a href=\"$CSV\">/partials/$CSV_NAME</a></div>\n",
        "  $TABLE\n",
        "</body>\n",
        "</html>\"\"\")\n",
        "\n",
        "    page = page_tpl.safe_substitute(\n",
        "        HOME=ABS_HOME_URL,\n",
        "        CSV=ABS_CSV_URL,\n",
        "        CSV_NAME=os.path.basename(ABS_CSV_URL),\n",
        "        TABLE=table_html,\n",
        "    )\n",
        "\n",
        "    with open(HTML_OUT_LOCAL, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(page)\n",
        "    logger.info(\"Exported HTML -> %s\", HTML_OUT_LOCAL)\n",
        "\n",
        "    print(\"[SUMMARY] GEDCOM total records: %d\" % ged.total_records)\n",
        "    print(\"[SUMMARY] NPFX-tagged records: %d\" % ged.npfx_count)\n",
        "    print(\"[SUMMARY] Autosomal matches (NPFX minus YDNA): %d\" % ged.autosomal_count)\n",
        "    print(\"[SUMMARY] After manual filter, total records: %d\" % ged.after_manual_filter_total)\n",
        "\n",
        "    return True\n",
        "\n",
        "ok = main()\n",
        "\n",
        "# ---------- Upload to /partials (Explicit FTPS AUTH TLS) ----------\n",
        "if ok and FTP_HOST and FTP_USER and FTP_PASS:\n",
        "    print(\"[INFO] Uploading artifacts to /partials/ ...\")\n",
        "    try:\n",
        "        ftps = _ftps_connect()\n",
        "        _ftps_ensure_dir(ftps, \"partials\")\n",
        "        try:\n",
        "            _ftps_upload(ftps, CSV_OUT_LOCAL, os.path.basename(CSV_OUT_LOCAL))\n",
        "        except Exception as e:\n",
        "            print(\"[ERROR] CSV upload failed:\", e)\n",
        "        try:\n",
        "            _ftps_upload(ftps, HTML_OUT_LOCAL, os.path.basename(HTML_OUT_LOCAL))\n",
        "        except Exception as e:\n",
        "            print(\"[ERROR] HTML upload failed:\", e)\n",
        "        try:\n",
        "            ftps.quit()\n",
        "        except Exception:\n",
        "            pass\n",
        "        print(\"[OK] Uploads complete to /partials/\")\n",
        "    except Exception as e:\n",
        "        print(\"[ERROR] FTP session failed:\", e)\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"[INFO] Skipping FTP upload (missing creds or build failed).\")\n",
        "\n",
        "print(\"\\n--- Cell 1 Complete: CSV + HTML + dna_vitals built with ISO-8859-15; explicit FTPS used. ---\")\n",
        "# ====== CUT STOP  [1/1] CELL 1 — GEDCOM -> CSV + HTML + Upload (Explicit FTPS, ISO-8859-15) ===\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eX_1S0fHxbF",
        "outputId": "7f59026d-575f-4839-e6bd-18032fee2ab6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CONFIRM] Golden Rules active | Cell=Cell1_FTPS_Explicit | Version=2025.11.14 | Encoding=ISO-8859-15\n",
            "[ENV] HOST=ftp***net  USER=ad***et  PASS=***  PORT=21  DIR=(root)\n",
            "Automatically selecting the first GEDCOM file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:Cell1_FTPS_Explicit:filtered_ids.xlsx not found. Skipping second-level manual filter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GEDCOM contained 62484 total records\n",
            "Records tagged and filtered by NPFX: 1596\n",
            "Records with YDNA information: 0\n",
            "Autosomal matches: 1596\n",
            "Records tagged and filtered by NPFX: 1596\n",
            "After manual filter, total records: 1596\n",
            "[OK] Wrote dna_vitals.csv -> /content/dna_vitals.csv\n",
            "Processing 1596 individuals with chunk-based parallel...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Yates Lines (Stage 1): 100%|██████████| 1596/1596 [12:20<00:00,  2.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUMMARY] GEDCOM total records: 62484\n",
            "[SUMMARY] NPFX-tagged records: 1596\n",
            "[SUMMARY] Autosomal matches (NPFX minus YDNA): 1596\n",
            "[SUMMARY] After manual filter, total records: 1596\n",
            "[INFO] Uploading artifacts to /partials/ ...\n",
            "[OK] Uploaded: final_combined_df_with_value_labels.csv -> /partials/final_combined_df_with_value_labels.csv\n",
            "[OK] Uploaded: cell1_work_table.htm -> /partials/cell1_work_table.htm\n",
            "[OK] Uploads complete to /partials/\n",
            "\n",
            "--- Cell 1 Complete: CSV + HTML + dna_vitals built with ISO-8859-15; explicit FTPS used. ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 2"
      ],
      "metadata": {
        "id": "TKAmqiIIDaxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] CELL 2 — Build + Publish DNA Register (All styling via stylesheet) ======\n",
        "# RON GOLDEN RULES — CLIFF NOTES (v2025.11.25-G1)\n",
        "# - Complete and runnable Colab cell, one contiguous block.\n",
        "# - Source ASCII-only; outputs written with encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\".\n",
        "# - XHTML 1.0 Transitional; typography/layout via /partials/dna_tree_styles.css (this cell writes it).\n",
        "# - Deterministic audit:\n",
        "#   [CONFIRM] Golden Rules active | Cell=Cell2_AllStyles_ExternalCSS | Version=2025.11.25-G1 | Encoding=ISO-8859-15\n",
        "# - Enforce ISO-8859-15 printable chars on writes.\n",
        "\n",
        "print(\"[CONFIRM] Golden Rules active | Cell=Cell2_AllStyles_ExternalCSS | Version=2025.11.25-G1 | Encoding=ISO-8859-15\")\n",
        "\n",
        "import os, re, posixpath, socket, traceback, urllib.parse as _u\n",
        "from ftplib import FTP_TLS\n",
        "import pandas as pd\n",
        "import html as _html\n",
        "from string import Template\n",
        "\n",
        "# ---------- A) LAYOUT CONTROL BLOCK (ONE PLACE TO TUNE WIDTHS) ----------\n",
        "# Logical columns:\n",
        "#   Col 1 = Match to\n",
        "#   Col 2 = Name\n",
        "#   Col 3 = cM\n",
        "#   Col 4 = Match Summary\n",
        "#   Col 5 = Website\n",
        "#   Col 6 = Yates DNA Ancestral Lines\n",
        "#\n",
        "# For HTML display we currently RENDER ONLY columns 1, 4, and 6.\n",
        "# Columns 2, 3, and 5 remain in the CSV/XLSX exports but are not shown in the HTML table.\n",
        "\n",
        "COL_1_PX = 80\n",
        "COL_2_PX = 220\n",
        "COL_3_PX = 60\n",
        "COL_4_PX = 1200\n",
        "COL_5_PX = 120\n",
        "COL_6_PX = 1800\n",
        "\n",
        "COL_WIDTHS = [COL_1_PX, COL_2_PX, COL_3_PX, COL_4_PX, COL_5_PX, COL_6_PX]\n",
        "\n",
        "# Indices of columns we render in the HTML table: 0=Match to, 3=Match Summary, 5=Lineage\n",
        "VISIBLE_COL_INDEXES = [0, 3, 5]\n",
        "\n",
        "TABLE_TOTAL_WIDTH_PX = sum(COL_WIDTHS[i] for i in VISIBLE_COL_INDEXES)\n",
        "\n",
        "print(\"[LAYOUT] TABLE_TOTAL_WIDTH_PX=%d\" % TABLE_TOTAL_WIDTH_PX)\n",
        "print(\"[LAYOUT] Column widths (px): 1=%d 2=%d 3=%d 4=%d 5=%d 6=%d\" %\n",
        "      (COL_1_PX, COL_2_PX, COL_3_PX, COL_4_PX, COL_5_PX, COL_6_PX))\n",
        "print(\"[LAYOUT] Visible HTML columns (0-based indexes): %s\" % VISIBLE_COL_INDEXES)\n",
        "\n",
        "# ---------- 0) Secrets ----------\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ[\"FTP_HOST\"] = userdata.get(\"FTP_HOST\")\n",
        "    os.environ[\"FTP_USER\"] = userdata.get(\"FTP_USER\")\n",
        "    os.environ[\"FTP_PASS\"] = userdata.get(\"FTP_PASS\")\n",
        "    try:\n",
        "        os.environ[\"FTP_DIR\"] = userdata.get(\"FTP_DIR\")\n",
        "    except Exception:\n",
        "        os.environ.setdefault(\"FTP_DIR\", \"\")\n",
        "    try:\n",
        "        os.environ[\"FTP_PORT\"] = userdata.get(\"FTP_PORT\")\n",
        "    except Exception:\n",
        "        os.environ.setdefault(\"FTP_PORT\", \"21\")\n",
        "except Exception:\n",
        "    os.environ.setdefault(\"FTP_HOST\", \"\")\n",
        "    os.environ.setdefault(\"FTP_USER\", \"\")\n",
        "    os.environ.setdefault(\"FTP_PASS\", \"\")\n",
        "    os.environ.setdefault(\"FTP_DIR\", \"\")\n",
        "    os.environ.setdefault(\"FTP_PORT\", \"21\")\n",
        "\n",
        "# ---------- 1) Config ----------\n",
        "CSV_IN = \"final_combined_df_with_value_labels.csv\"\n",
        "\n",
        "# NOTE: main register pages now .shtml (SSI pages only)\n",
        "LOCAL_HTML        = \"yates_ancestor_register.shtml\"\n",
        "REMOTE_HTML_CANON = posixpath.join(\"partials\", \"yates_ancestor_register.shtml\")\n",
        "REMOTE_HTML_LEG   = posixpath.join(\"partials\", \"ons_yates_dna_register.shtml\")\n",
        "\n",
        "DNA_REGISTER_ABS = \"https://yates.one-name.net/partials/ons_yates_dna_register.shtml\"\n",
        "TREES_ABS        = \"https://yates.one-name.net/partials/just-trees.htm\"\n",
        "\n",
        "EXPORT_BASENAME = \"yates_ancestor_register\"\n",
        "LOCAL_CSV  = \"%s.csv\"  % EXPORT_BASENAME\n",
        "LOCAL_XLSX = \"%s.xlsx\" % EXPORT_BASENAME\n",
        "REMOTE_CSV  = posixpath.join(\"partials\", os.path.basename(LOCAL_CSV))\n",
        "REMOTE_XLSX = posixpath.join(\"partials\", os.path.basename(LOCAL_XLSX))\n",
        "\n",
        "FTP_DIR  = (os.environ.get(\"FTP_DIR\", \"\") or \"\").strip()\n",
        "TNG_BASE = \"https://yates.one-name.net/tng\"\n",
        "TNG_TREE = \"tree1\"\n",
        "\n",
        "# Name-page now .shtml as well\n",
        "HOME_URL = \"https://yates.one-name.net/partials/yates_ancestor_register.shtml\"\n",
        "REMOTE_NAME_ABS = HOME_URL\n",
        "\n",
        "ARROW_ENTITY         = \"&rarr;\"\n",
        "REMOVE_PERIOD_AT_END = True\n",
        "\n",
        "SERVER_PARTIALS_DIR        = \"partials\"\n",
        "SERVER_MAPPING_BASENAME    = \"match_to_unmasked.csv\"\n",
        "SERVER_MAPPING_REMOTE      = posixpath.join(SERVER_PARTIALS_DIR, SERVER_MAPPING_BASENAME)\n",
        "SERVER_MAPPING_LOCAL_CACHE = \"match_to_unmasked.server.csv\"\n",
        "\n",
        "# Stylesheet\n",
        "STYLESHEET_BASENAME = \"dna_tree_styles.css\"\n",
        "STYLESHEET_LOCAL    = os.path.join(\"partials\", STYLESHEET_BASENAME)\n",
        "STYLESHEET_REMOTE   = posixpath.join(\"partials\", STYLESHEET_BASENAME)\n",
        "CSS_VERSION         = \"v2025-11-25-g1\"\n",
        "STYLESHEET_HREF     = \"/partials/%s?%s\" % (STYLESHEET_BASENAME, CSS_VERSION)\n",
        "HEAD_LINK           = '<link rel=\"stylesheet\" type=\"text/css\" href=\"%s\" />' % STYLESHEET_HREF\n",
        "\n",
        "# Path for vitals from Cell 1\n",
        "VITALS_CSV = \"dna_vitals.csv\"\n",
        "\n",
        "# ---------- 2) FTP ----------\n",
        "FTP_TIMEOUT = int(os.environ.get(\"FTP_TIMEOUT\", \"30\"))\n",
        "FTP_PASSIVE = True\n",
        "\n",
        "def ftp_connect() -> FTP_TLS:\n",
        "    ftps = FTP_TLS(timeout=FTP_TIMEOUT)\n",
        "    socket.setdefaulttimeout(FTP_TIMEOUT)\n",
        "    ftps.connect(os.environ.get(\"FTP_HOST\", \"\"), int(os.environ.get(\"FTP_PORT\", 21)))\n",
        "    ftps.login(os.environ.get(\"FTP_USER\", \"\"), os.environ.get(\"FTP_PASS\", \"\"))\n",
        "    try:\n",
        "        ftps.prot_p()\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        ftps.set_pasv(FTP_PASSIVE)\n",
        "    except Exception:\n",
        "        pass\n",
        "    if FTP_DIR:\n",
        "        for p in [p for p in FTP_DIR.split(\"/\") if p]:\n",
        "            try:\n",
        "                ftps.mkd(p)\n",
        "            except Exception:\n",
        "                pass\n",
        "            ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "def _remote_path(name: str) -> str:\n",
        "    return posixpath.join(FTP_DIR, name) if FTP_DIR else name\n",
        "\n",
        "def ensure_remote_dirs(ftps, remote_path):\n",
        "    if \"/\" not in remote_path:\n",
        "        return\n",
        "    pwd0 = ftps.pwd()\n",
        "    for seg in [p for p in remote_path.split(\"/\")[:-1] if p and p != \".\"]:\n",
        "        try:\n",
        "            ftps.cwd(seg)\n",
        "        except Exception:\n",
        "            try:\n",
        "                ftps.mkd(seg)\n",
        "            except Exception:\n",
        "                pass\n",
        "            ftps.cwd(seg)\n",
        "    ftps.cwd(pwd0)\n",
        "\n",
        "def ftp_download_if_exists(ftps, remote_name, local_name) -> bool:\n",
        "    try:\n",
        "        with open(local_name, \"wb\") as f:\n",
        "            ftps.retrbinary(\"RETR %s\" % remote_name, f.write)\n",
        "        print(\"[PULL] %s -> %s\" % (remote_name, os.path.abspath(local_name)))\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            if os.path.exists(local_name):\n",
        "                os.remove(local_name)\n",
        "        except Exception:\n",
        "            pass\n",
        "        print(\"[MISS] %s (%s)\" % (remote_name, e))\n",
        "        return False\n",
        "\n",
        "def ftp_upload_overwrite(ftps, local_path, remote_name):\n",
        "    ensure_remote_dirs(ftps, remote_name)\n",
        "    with open(local_path, \"rb\") as fh:\n",
        "        ftps.storbinary(\"STOR %s\" % remote_name, fh)\n",
        "    print(\"[PUT] %s -> %s\" % (local_path, remote_name))\n",
        "\n",
        "def ftp_size(ftps, remote_name):\n",
        "    try:\n",
        "        sz = ftps.size(remote_name)\n",
        "        return int(sz) if sz is not None else None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# ---------- 3) Resolver ----------\n",
        "def _read_mapping_csv(path: str) -> pd.DataFrame:\n",
        "    encs = (\"iso-8859-15\", \"utf-8-sig\", \"utf-8\", \"cp1252\", \"latin1\")\n",
        "    last = None\n",
        "    df = None\n",
        "    for enc in encs:\n",
        "        try:\n",
        "            df = pd.read_csv(path, encoding=enc, dtype=str, keep_default_na=False)\n",
        "            break\n",
        "        except Exception as e:\n",
        "            last = e\n",
        "            df = None\n",
        "    if df is None:\n",
        "        raise RuntimeError(\"Unable to read mapping CSV %s: %s\" % (path, last))\n",
        "    if df.shape[1] < 2:\n",
        "        raise RuntimeError(\"Mapping CSV must have at least two columns: code, unmasked\")\n",
        "    df = df.iloc[:, :2].copy()\n",
        "    df.columns = [\"code\", \"unmasked\"]\n",
        "    df[\"code\"]     = df[\"code\"].astype(str).str.strip().str.lower()\n",
        "    df[\"unmasked\"] = df[\"unmasked\"].astype(str).str.strip()\n",
        "    df = df[df[\"code\"] != \"\"].drop_duplicates(subset=[\"code\"], keep=\"first\")\n",
        "    if df.empty:\n",
        "        raise RuntimeError(\"Mapping CSV empty after normalization.\")\n",
        "    return df\n",
        "\n",
        "def load_resolver_from_server() -> dict:\n",
        "    with ftp_connect() as ftps:\n",
        "        try:\n",
        "            ftps.cwd(SERVER_PARTIALS_DIR)\n",
        "        except Exception:\n",
        "            pass\n",
        "        ok = ftp_download_if_exists(ftps, SERVER_MAPPING_BASENAME, SERVER_MAPPING_LOCAL_CACHE)\n",
        "        try:\n",
        "            ftps.quit()\n",
        "        except Exception:\n",
        "            pass\n",
        "    if not ok:\n",
        "        raise RuntimeError(\n",
        "            \"Resolver not found on server: /%s. Upload match_to_unmasked.csv into /partials/ and re-run.\"\n",
        "            % _remote_path(SERVER_MAPPING_REMOTE)\n",
        "        )\n",
        "    df_map = _read_mapping_csv(SERVER_MAPPING_LOCAL_CACHE)\n",
        "    print(\"[OK] Resolver loaded: %d codes\" % len(df_map))\n",
        "    return dict(zip(df_map[\"code\"], df_map[\"unmasked\"]))\n",
        "\n",
        "MATCH_TO_UNMASKED = {}\n",
        "\n",
        "def _setup_resolver():\n",
        "    global MATCH_TO_UNMASKED\n",
        "    if not MATCH_TO_UNMASKED:\n",
        "        MATCH_TO_UNMASKED = load_resolver_from_server()\n",
        "\n",
        "def resolve_match_to(code: str) -> str:\n",
        "    if not isinstance(code, str):\n",
        "        return \"\"\n",
        "    return MATCH_TO_UNMASKED.get(code.strip().lower(), code)\n",
        "\n",
        "# ---------- 4) Name/text utils ----------\n",
        "SEP_RE = re.compile(r\"\\s*(?:\\u2192|&rarr;|;|>|,|~{2,}|/{2,}|\\|{2,})\\s*\")\n",
        "\n",
        "def split_tokens(s):\n",
        "    if pd.isna(s):\n",
        "        return []\n",
        "    if not isinstance(s, str):\n",
        "        s = str(s)\n",
        "    return [p.strip() for p in SEP_RE.split(s) if str(p).strip()]\n",
        "\n",
        "def _clean_piece(text: str) -> str:\n",
        "    t = re.sub(r\"~+\", \" \", str(text))\n",
        "    t = re.sub(r\"\\s+\", \" \", t)\n",
        "    return t.strip()\n",
        "\n",
        "_PARTICLES = {\n",
        "    \"de\", \"del\", \"della\", \"der\", \"van\", \"von\", \"da\", \"dos\", \"das\", \"di\", \"la\", \"le\", \"du\", \"of\"\n",
        "}\n",
        "\n",
        "def _smart_title(token: str) -> str:\n",
        "    if not token:\n",
        "        return token\n",
        "    token = re.sub(\n",
        "        r\"(^|\\b)([a-z])(['’])([a-z])\",\n",
        "        lambda m: m.group(1) + m.group(2).upper() + m.group(3) + m.group(4).upper(),\n",
        "        token.lower(),\n",
        "    )\n",
        "    token = \"-\".join([w.capitalize() for w in token.split(\"-\")])\n",
        "    token = re.sub(r\"\\bmc([a-z])\",  lambda m: \"Mc\"  + m.group(1).upper(), token)\n",
        "    token = re.sub(r\"\\bmac([a-z])\", lambda m: \"Mac\" + m.group(1).upper(), token)\n",
        "    return token\n",
        "\n",
        "def smart_titlecase(name: str) -> str:\n",
        "    name = _clean_piece(name)\n",
        "    if not name:\n",
        "        return name\n",
        "    if \",\" in name:\n",
        "        last, first = [p.strip() for p in name.split(\",\", 1)]\n",
        "        pieces = (first + \" \" + last).split()\n",
        "    else:\n",
        "        pieces = name.split()\n",
        "    out = []\n",
        "    for i, w in enumerate(pieces):\n",
        "        if i > 0 and w.lower() in _PARTICLES:\n",
        "            out.append(w.lower())\n",
        "        else:\n",
        "            out.append(_smart_title(w))\n",
        "    return \" \".join(out)\n",
        "\n",
        "def surname_given_from_token(token):\n",
        "    token = token.strip()\n",
        "    idx = None\n",
        "    for i in range(1, len(token)):\n",
        "        if token[i-1].islower() and token[i].isupper():\n",
        "            idx = i\n",
        "            break\n",
        "    if idx is None:\n",
        "        for i in range(1, len(token)):\n",
        "            if token[i].isupper():\n",
        "                idx = i\n",
        "                break\n",
        "    if idx is None:\n",
        "        return (token,)\n",
        "    surname      = token[:idx]\n",
        "    given        = token[idx:]\n",
        "    given_spaced = re.sub(r\"(?<!^)([A-Z])\", r\" \\1\", given)\n",
        "    return (\"%s %s\" % (given_spaced.strip(), surname.strip()),)\n",
        "\n",
        "def normalize_person_name(s: str) -> str:\n",
        "    if pd.isna(s):\n",
        "        return \"\"\n",
        "    s = _clean_piece(str(s))\n",
        "    if \",\" in s:\n",
        "        last, first = [p.strip() for p in s.split(\",\", 1)]\n",
        "        s = \"%s %s\" % (first, last)\n",
        "    if \" \" not in s and s.isalpha():\n",
        "        return smart_titlecase(surname_given_from_token(s)[0])\n",
        "    return smart_titlecase(s)\n",
        "\n",
        "_CAMEL_WORDS = re.compile(r\"[A-Z][a-z]*|[A-Z]+(?![a-z])|[a-z]+\")\n",
        "\n",
        "def norm_matchee_name(raw: str) -> str:\n",
        "    raw = str(raw or \"\").strip()\n",
        "    if not raw:\n",
        "        return \"\"\n",
        "    if \" \" in raw or \",\" in raw:\n",
        "        nm    = smart_titlecase(raw)\n",
        "        parts = nm.split()\n",
        "        if len(parts) == 1:\n",
        "            return nm\n",
        "        return (\"%s %s\" % (parts[0], parts[-1])).strip()\n",
        "    words = _CAMEL_WORDS.findall(raw)\n",
        "    while words and len(words[0]) == 1:\n",
        "        words.pop(0)\n",
        "    if not words:\n",
        "        nm = smart_titlecase(surname_given_from_token(raw)[0])\n",
        "        ps = nm.split()\n",
        "        if len(ps) == 1:\n",
        "            return nm\n",
        "        return (\"%s %s\" % (ps[0], ps[-1])).strip()\n",
        "    surname          = smart_titlecase(words[0])\n",
        "    given_candidates = [w for w in words[1:] if w.lower() != surname.lower()]\n",
        "    if not given_candidates:\n",
        "        return surname\n",
        "    return (\"%s %s\" % (smart_titlecase(given_candidates[0]), surname)).strip()\n",
        "\n",
        "def derive_common_from_first_token(tokens):\n",
        "    if not tokens:\n",
        "        return (\"\", \"\")\n",
        "    first = _clean_piece(tokens[0])\n",
        "    parts = re.split(r\"\\s*(?:&| and )\\s*\", first, maxsplit=1, flags=re.I)\n",
        "    if len(parts) != 2:\n",
        "        return (\"\", \"\")\n",
        "    def _norm(s):\n",
        "        if \" \" in s:\n",
        "            return smart_titlecase(s)\n",
        "        return smart_titlecase(surname_given_from_token(s)[0])\n",
        "    return (_norm(parts[0]), _norm(parts[1]))\n",
        "\n",
        "def degree_label_from_generations(g):\n",
        "    if g <= 1:\n",
        "        return \"parents\" if g == 1 else \"self\"\n",
        "    if g == 2:\n",
        "        return \"grandparents\"\n",
        "    greats = g - 2\n",
        "    if greats == 1:\n",
        "        return \"great-grandparents\"\n",
        "    return \"%dx-great-grandparents\" % greats\n",
        "\n",
        "def build_header(subject_name_html, cm_val, matchee_name_html, gens, husband, wife):\n",
        "    try:\n",
        "        cm_str = \"%d\" % int(round(float(cm_val)))\n",
        "    except Exception:\n",
        "        cm_str = (str(cm_val).strip() or \"0\")\n",
        "    degree_label = degree_label_from_generations(gens)\n",
        "    parts = [\n",
        "        \"%s is a %s cM cousin match to %s, whose\" % (subject_name_html, cm_str, matchee_name_html),\n",
        "        \"%s (back %d Gens)\" % (degree_label, gens),\n",
        "        \"are\",\n",
        "        \"%s & %s.\" % (husband, wife),\n",
        "    ]\n",
        "    s = \" \".join(parts)\n",
        "    if REMOVE_PERIOD_AT_END:\n",
        "        s = re.sub(r\"\\.\\s*$\", \"\", s)\n",
        "    return s\n",
        "\n",
        "ID_PAT = re.compile(r\"\\bI\\d+\\b\", re.I)\n",
        "\n",
        "def extract_person_id(s: str) -> str:\n",
        "    m = ID_PAT.search(str(s or \"\"))\n",
        "    return m.group(0).upper() if m else \"\"\n",
        "\n",
        "# ---------- 5) Read CSV ----------\n",
        "def find_col(df, patterns, prefer_exact=None):\n",
        "    cols   = list(df.columns)\n",
        "    lowmap = {c.lower(): c for c in cols}\n",
        "    if prefer_exact:\n",
        "        for name in prefer_exact:\n",
        "            if name in df.columns:\n",
        "                return name\n",
        "            if name and name.lower() in lowmap:\n",
        "                return lowmap[name.lower()]\n",
        "    for pat in patterns:\n",
        "        rx = re.compile(pat, re.I)\n",
        "        for c in cols:\n",
        "            if rx.search(c):\n",
        "                return c\n",
        "    return None\n",
        "\n",
        "_encs     = (\"utf-8-sig\", \"utf-8\", \"cp1252\", \"iso-8859-15\", \"latin1\")\n",
        "_last_err = None\n",
        "df        = None\n",
        "for _e in _encs:\n",
        "    try:\n",
        "        df = pd.read_csv(CSV_IN, encoding=_e, dtype=str, keep_default_na=False)\n",
        "        break\n",
        "    except Exception as _ex:\n",
        "        _last_err = _ex\n",
        "        df        = None\n",
        "if df is None:\n",
        "    raise RuntimeError(\"Unable to read CSV: %s (%s)\" % (CSV_IN, _last_err))\n",
        "print(\"[OK] Loaded CSV: %d rows, %d cols\" % (len(df), len(df.columns)))\n",
        "\n",
        "id_col    = find_col(df, [r\"^(id#|personid)$\"], [\"ID#\", \"ID\", \"PersonID\", \"personID\"])\n",
        "match_col = find_col(df, [r\"^match\\s*to$\"], [\"Match to\", \"Match\", \"match_to\", \"Match_to\"])\n",
        "name_col  = find_col(df, [r\"^name$\"], [\"Name\"])\n",
        "cm_col    = find_col(df, [r\"^(c\\s*:?m|cm)$\", r\"centi.?morgan\"], [\"cM\", \"cm\"])\n",
        "path_col  = find_col(\n",
        "    df,\n",
        "    [r\"(yates\\s*dna\\s*ancestral\\s*line|ancestral\\s*line|lineage)\"],\n",
        "    [\"Yates DNA Ancestral Line\", \"Ancestral Line\", \"Lineage\"],\n",
        ")\n",
        "\n",
        "if not id_col:\n",
        "    raise ValueError(\"CSV missing an ID#/PersonID column.\")\n",
        "if not match_col:\n",
        "    raise ValueError(\"CSV missing 'Match to' column (try headings like 'Match to' or 'Match').\")\n",
        "if not name_col:\n",
        "    raise ValueError(\"CSV missing 'Name' column.\")\n",
        "if not cm_col:\n",
        "    raise ValueError(\"CSV missing 'cM' column.\")\n",
        "if not path_col:\n",
        "    raise ValueError(\"CSV missing lineage/path column.\")\n",
        "\n",
        "# ---------- 5.1) Read vitals from dna_vitals.csv ----------\n",
        "AUTOSOMAL_MATCHES = \"\"\n",
        "SHOWING_STATIC    = \"\"\n",
        "\n",
        "def _load_vitals(path):\n",
        "    global AUTOSOMAL_MATCHES, SHOWING_STATIC\n",
        "    if not os.path.exists(path):\n",
        "        print(\"[INFO] dna_vitals.csv not found; header will omit counts.\")\n",
        "        return\n",
        "    try:\n",
        "        vdf = pd.read_csv(path, dtype=str, encoding=\"iso-8859-15\", keep_default_na=False)\n",
        "    except Exception:\n",
        "        encs = (\"utf-8-sig\", \"utf-8\", \"cp1252\", \"latin1\")\n",
        "        last = None\n",
        "        vdf  = None\n",
        "        for enc in encs:\n",
        "            try:\n",
        "                vdf = pd.read_csv(path, dtype=str, encoding=enc, keep_default_na=False)\n",
        "                break\n",
        "            except Exception as e:\n",
        "                last = e\n",
        "        if vdf is None:\n",
        "            print(\"[WARN] Unable to read dna_vitals.csv: %s\" % last)\n",
        "            return\n",
        "\n",
        "    flat = []\n",
        "    for row in vdf.astype(str).values.tolist():\n",
        "        for cell in row:\n",
        "            flat.append(str(cell))\n",
        "\n",
        "    autosomal = None\n",
        "    showing   = None\n",
        "\n",
        "    for cell in flat:\n",
        "        s = str(cell)\n",
        "        if \"Records tagged and filtered by NPFX\" in s and autosomal is None:\n",
        "            m = re.search(r\"(\\d+)\", s)\n",
        "            if m:\n",
        "                autosomal = m.group(1)\n",
        "        if \"After manual filter, total records\" in s and showing is None:\n",
        "            m = re.search(r\"(\\d+)\", s)\n",
        "            if m:\n",
        "                showing = m.group(1)\n",
        "\n",
        "    if autosomal is None or showing is None:\n",
        "        all_text = \" \".join(flat)\n",
        "        nums = re.findall(r\"\\d+\", all_text)\n",
        "        if autosomal is None and len(nums) >= 1:\n",
        "            autosomal = nums[0]\n",
        "        if showing is None and len(nums) >= 2:\n",
        "            showing = nums[1]\n",
        "\n",
        "    AUTOSOMAL_MATCHES = autosomal or \"\"\n",
        "    SHOWING_STATIC    = showing   or \"\"\n",
        "\n",
        "    print(\"[OK] Loaded vitals from %s -> autosomal=%s, showing=%s\"\n",
        "          % (path, AUTOSOMAL_MATCHES or \"?\", SHOWING_STATIC or \"?\"))\n",
        "\n",
        "_load_vitals(VITALS_CSV)\n",
        "\n",
        "if SHOWING_STATIC:\n",
        "    try:\n",
        "        if int(SHOWING_STATIC) != len(df):\n",
        "            print(\"[WARN] dna_vitals showing (%s) != CSV rows (%d)\" %\n",
        "                  (SHOWING_STATIC, len(df)))\n",
        "    except Exception as _e:\n",
        "        print(\"[WARN] Unable to compare showing from dna_vitals.csv to CSV rows: %s\" % _e)\n",
        "\n",
        "# ---------- 6) Transform ----------\n",
        "_setup_resolver()\n",
        "\n",
        "headers          = []\n",
        "lineages         = []\n",
        "subjects         = []\n",
        "first_ancestors  = []\n",
        "display_match_to = []  # normalized \"Match to\"\n",
        "display_name     = []  # normalized Name (with link to TNG if available)\n",
        "\n",
        "LINEAGE_HEADER_SAFE = \"Yates DNA Ancestral Lines\"\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    subject_raw    = row.get(match_col, \"\")\n",
        "    subject_name   = normalize_person_name(resolve_match_to(subject_raw))\n",
        "    subject_name_b = \"<strong>%s</strong>\" % subject_name if subject_name else subject_name\n",
        "\n",
        "    pid          = extract_person_id(row.get(id_col, \"\"))\n",
        "    matchee_raw  = row.get(name_col, \"\")\n",
        "    matchee_name = norm_matchee_name(matchee_raw) or subject_name\n",
        "\n",
        "    if pid:\n",
        "        matchee_url = (\n",
        "            \"%s/verticalchart.php?personID=%s&tree=%s&parentset=0&display=vertical&generations=15\"\n",
        "            % (TNG_BASE, pid, TNG_TREE)\n",
        "        )\n",
        "        matchee_name_html = '<a href=\"%s\" target=\"_blank\" rel=\"noopener\">%s</a>' % (matchee_url, matchee_name)\n",
        "    else:\n",
        "        matchee_name_html = matchee_name\n",
        "\n",
        "    cm_val      = row.get(cm_col, \"0\")\n",
        "    tokens      = split_tokens(row.get(path_col, \"\"))\n",
        "    gens_total  = len(tokens)\n",
        "    tokens_disp = tokens[:7]\n",
        "\n",
        "    if \"common_husband\" in df.columns and \"common_wife\" in df.columns:\n",
        "        husband_raw = str(row.get(\"common_husband\", \"\")).strip()\n",
        "        wife_raw    = str(row.get(\"common_wife\", \"\")).strip()\n",
        "        if not husband_raw and not wife_raw:\n",
        "            husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "    else:\n",
        "        husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "\n",
        "    header_html = build_header(subject_name_b or subject_name, cm_val, matchee_name_html, gens_total, husband_raw, wife_raw)\n",
        "    if tokens_disp:\n",
        "        tokens_disp[0] = \"<strong>%s</strong>\" % tokens_disp[0]\n",
        "    sep          = \" %s \" % ARROW_ENTITY\n",
        "    lineage_text = sep.join(tokens_disp) if tokens_disp else \"\"\n",
        "\n",
        "    headers.append(header_html)\n",
        "    lineages.append(lineage_text)\n",
        "    subjects.append(subject_name)\n",
        "    first_ancestors.append(tokens[0] if tokens else \"\")\n",
        "\n",
        "    display_match_to.append(subject_name)\n",
        "    display_name.append(matchee_name_html)\n",
        "\n",
        "df[\"Match Summary\"]      = headers\n",
        "df[LINEAGE_HEADER_SAFE]  = lineages\n",
        "df[\"Subject\"]            = subjects\n",
        "df[\"First Ancestor\"]     = [_clean_piece(x) for x in first_ancestors]\n",
        "\n",
        "# ---------- 6.1) Clean exports ----------\n",
        "TAG_RE = re.compile(r\"<[^>]+>\")\n",
        "\n",
        "def _html_to_text(s: str) -> str:\n",
        "    t = TAG_RE.sub(\"\", str(s or \"\"))\n",
        "    t = _html.unescape(t)\n",
        "    t = t.replace(\"\\u2192\", \"->\")\n",
        "    t = re.sub(r\"\\s+\", \" \", t)\n",
        "    return t.strip()\n",
        "\n",
        "def _extract_find_url(subject_name: str) -> str:\n",
        "    if not subject_name:\n",
        "        return \"\"\n",
        "    q = _u.quote(subject_name)\n",
        "    return \"%s?q=%s\" % (REMOTE_NAME_ABS, q)\n",
        "\n",
        "website_urls = [_extract_find_url(subj) for subj in df[\"Subject\"].tolist()]\n",
        "\n",
        "export_df = pd.DataFrame({\n",
        "    \"Match to\"      : df[match_col].tolist(),\n",
        "    \"Name\"          : df[name_col].tolist(),\n",
        "    \"cM\"            : df[cm_col].tolist(),\n",
        "    \"Match Summary\" : [_html_to_text(v) for v in df[\"Match Summary\"].tolist()],\n",
        "    \"Website URL\"   : website_urls,\n",
        "    \"Lineage\"       : [_html_to_text(v) for v in df[LINEAGE_HEADER_SAFE].tolist()],\n",
        "})\n",
        "\n",
        "export_df.to_csv(LOCAL_CSV, index=False, encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\")\n",
        "try:\n",
        "    export_df.to_excel(LOCAL_XLSX, index=False)\n",
        "except Exception:\n",
        "    with pd.ExcelWriter(LOCAL_XLSX) as _writer:\n",
        "        export_df.to_excel(_writer, index=False)\n",
        "print(\"[OK] Wrote exports: %s and %s\" % (os.path.abspath(LOCAL_CSV), os.path.abspath(LOCAL_XLSX)))\n",
        "\n",
        "# ---------- 7) Stylesheet content (with mobile single-scroll behavior) ----------\n",
        "CSS_TEXT = \"\"\"/* yates.one-name.net - DNA pages (unified stylesheet)\n",
        "   Version: %s\n",
        "   Note: Typography, layout, colors, borders - centralized here. */\n",
        "\n",
        ":root {\n",
        "  --table-width-px: %dpx;\n",
        "  --brand-blue: #5b79b8;\n",
        "  --brand-blue-dark: #4668aa;\n",
        "  --line: #dddddd;\n",
        "  --line-strong: #999999;\n",
        "}\n",
        "\n",
        "html, body {\n",
        "  margin:0; padding:0;\n",
        "  font-family: \"Times New Roman\", Times, serif;\n",
        "  font-size: 16px; line-height: 1.35;\n",
        "  color:#111111; background:#ffffff;\n",
        "}\n",
        "\n",
        ".wrap {\n",
        "  max-width:100%%;\n",
        "  margin:0 auto;\n",
        "  background:#ffffff;\n",
        "  padding:16px;\n",
        "  padding-bottom:48px;\n",
        "}\n",
        ".centerline { text-align:center; }\n",
        "\n",
        ".downloads { text-align:center; margin:4px 0 10px 0; font-size: 13px; }\n",
        ".updated   { font-size: 12px; color:#555555; text-align:center; margin:2px 0 10px 0; }\n",
        "\n",
        ".left-align { text-align:left; }\n",
        "\n",
        "/* Simple header alignment helpers */\n",
        "th.center-header { text-align:center; }\n",
        "th.left-header   { text-align:left; }\n",
        "\n",
        "/* Wrapper for top and bottom scroll sync */\n",
        ".table-scroll-wrapper {\n",
        "  width:100%%;\n",
        "  max-width:100%%;\n",
        "  margin:0 auto;\n",
        "}\n",
        "\n",
        "/* Top visible horizontal scrollbar (desktop / large screens) */\n",
        ".scroll-sync-top {\n",
        "  width:100%%;\n",
        "  max-width:100%%;\n",
        "  overflow-x:auto;\n",
        "  overflow-y:hidden;\n",
        "  border:1px solid var(--line);\n",
        "  border-bottom:none;\n",
        "  height:18px;\n",
        "  -webkit-overflow-scrolling:touch;\n",
        "}\n",
        ".scroll-sync-top-inner {\n",
        "  height:1px;\n",
        "}\n",
        "\n",
        "/* Bottom scroll container: real scroll, scrollbar hidden visually by default */\n",
        ".table-scroll {\n",
        "  width:100%%;\n",
        "  max-width:100%%;\n",
        "  max-height:80vh;\n",
        "  overflow-x:auto;\n",
        "  overflow-y:auto;\n",
        "  border:1px solid var(--line);\n",
        "  border-top:none;\n",
        "  position:relative;\n",
        "  -webkit-overflow-scrolling:touch;\n",
        "  scrollbar-width:none;          /* Firefox */\n",
        "  -ms-overflow-style:none;       /* IE/Edge legacy */\n",
        "}\n",
        ".table-scroll::-webkit-scrollbar {\n",
        "  display:none;                  /* WebKit / Blink */\n",
        "}\n",
        "\n",
        "/* Table: let widths and content drive horizontal size */\n",
        "table.sortable {\n",
        "  border-collapse:separate;\n",
        "  border-spacing:0;\n",
        "}\n",
        "\n",
        "table.sortable th,\n",
        "table.sortable td {\n",
        "  border:1px solid var(--line);\n",
        "  padding:6px 8px;\n",
        "  vertical-align:top;\n",
        "  white-space:nowrap;\n",
        "}\n",
        "\n",
        "/* Sticky header row (desktop and iOS) */\n",
        "table.sortable th {\n",
        "  background:#e3eaf8;\n",
        "  position:-webkit-sticky;   /* iOS Safari */\n",
        "  position:sticky;\n",
        "  top:0;\n",
        "  z-index:5;\n",
        "  box-shadow:0 1px 0 #cccccc;\n",
        "  cursor:pointer;\n",
        "}\n",
        "\n",
        "/* Sticky first column (Match to) for DNA Register table */\n",
        "table.dna-register-table th:nth-child(1),\n",
        "table.dna-register-table td:nth-child(1) {\n",
        "  position:-webkit-sticky;   /* iOS Safari */\n",
        "  position:sticky;\n",
        "  left:0;\n",
        "  z-index:6;\n",
        "  background:#ffffff;\n",
        "}\n",
        "table.dna-register-table th:nth-child(1) {\n",
        "  z-index:7;\n",
        "}\n",
        "\n",
        "/* First data row marker */\n",
        "#first-row td { border-top:2px solid var(--line-strong); }\n",
        "\n",
        "/* Back-to-top button */\n",
        ".back-to-top {\n",
        "  position:fixed; right:16px; bottom:16px; padding:6px 10px;\n",
        "  border:1px solid #3e5a97; background:var(--brand-blue);\n",
        "  color:#ffffff; cursor:pointer; border-radius:6px; display:none; z-index:9999;\n",
        "}\n",
        ".back-to-top:hover { background:var(--brand-blue-dark); }\n",
        "\n",
        "/* Controls */\n",
        ".controls { text-align:center; }\n",
        ".controls-spaced { margin:6px 0 10px 0; }\n",
        ".search { font-size: 14px; padding:5px 8px; }\n",
        "\n",
        "/* Old-school blue nav menu */\n",
        ".oldnav {\n",
        "  margin:8px auto 6px auto; padding:0; background:var(--brand-blue);\n",
        "  border-radius:6px; overflow:hidden; max-width: var(--table-width-px);\n",
        "}\n",
        ".oldnav ul { list-style:none; margin:0; padding:0; display:flex; flex-wrap:wrap; }\n",
        ".oldnav li { margin:0; padding:0; }\n",
        ".oldnav a, .oldnav a:link, .oldnav a:visited, .oldnav a:active { color:#ffffff !important; }\n",
        ".oldnav a {\n",
        "  display:block;\n",
        "  padding:8px 12px;\n",
        "  text-decoration:none;\n",
        "  white-space:nowrap;\n",
        "  border-right:1px solid #ffffff;\n",
        "  font-weight:600;\n",
        "}\n",
        ".oldnav li:last-child a { border-right:none; }\n",
        ".oldnav a:hover { background:var(--brand-blue-dark); color:#ffffff !important; }\n",
        "\n",
        "/* Responsive tweaks */\n",
        "@media screen and (min-width: 1200px) {\n",
        "  .wrap { max-width: var(--table-width-px); }\n",
        "}\n",
        "@media screen and (max-width: 1199px) {\n",
        "  .oldnav { border-radius:0; }\n",
        "}\n",
        "@media screen and (max-width: 700px) {\n",
        "  table.sortable th, table.sortable td { padding:5px 6px; }\n",
        "}\n",
        "\n",
        "/* Mobile single-scroll optimization (iPhone/iPad and small screens):\n",
        "   - Hide the fake top scrollbar\n",
        "   - Use the native horizontal scrollbar on the bottom container\n",
        "   - Keep sticky header and sticky first column */\n",
        "@media screen and (max-width: 1024px) {\n",
        "  .scroll-sync-top {\n",
        "    display:none;\n",
        "  }\n",
        "  .table-scroll {\n",
        "    -webkit-overflow-scrolling:touch;\n",
        "    scrollbar-width:auto;\n",
        "  }\n",
        "  .table-scroll::-webkit-scrollbar {\n",
        "    display:block;\n",
        "  }\n",
        "}\n",
        "\"\"\" % (\n",
        "    CSS_VERSION,\n",
        "    TABLE_TOTAL_WIDTH_PX,\n",
        ")\n",
        "\n",
        "os.makedirs(\"partials\", exist_ok=True)\n",
        "with open(STYLESHEET_LOCAL, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as _css:\n",
        "    _css.write(CSS_TEXT)\n",
        "print(\"[OK] Wrote stylesheet: %s\" % os.path.abspath(STYLESHEET_LOCAL))\n",
        "\n",
        "# ---------- 8) Main HTML ----------\n",
        "page_tpl = Template(\"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "<title>ONS Yates Study Autosomal DNA Register</title>\n",
        "$HEAD_LINK\n",
        "</head>\n",
        "<body id=\"top\">\n",
        "<div class=\"wrap\">\n",
        "  <h1 class=\"centerline\">ONS Yates Study Autosomal DNA Register</h1>\n",
        "  $DOWNLOADS_BLOCK\n",
        "  $UPDATED_BLOCK\n",
        "  $NAV_BLOCK\n",
        "  $CONTROLS_BLOCK\n",
        "  $SCROLL_WRAPPER\n",
        "</div>\n",
        "<button id=\"back-to-top\" class=\"back-to-top\">&#9650; Top</button>\n",
        "<script type=\"text/javascript\">\n",
        "//<![CDATA[\n",
        "(function(){\n",
        "  function textOf(cell){\n",
        "    return (cell && (cell.textContent || cell.innerText) || '')\n",
        "      .replace(/\\\\s+/g,' ')\n",
        "      .trim()\n",
        "      .toLowerCase();\n",
        "  }\n",
        "\n",
        "  function sortTable(tbl, colIndex, dir){\n",
        "    var tb = tbl && tbl.tBodies ? tbl.tBodies[0] : null;\n",
        "    if(!tb) return;\n",
        "    var rows = Array.prototype.slice.call(tb.rows || []);\n",
        "    var asc  = (dir === 'asc');\n",
        "\n",
        "    rows.sort(function(a,b){\n",
        "      var A = textOf(a.cells[colIndex]),\n",
        "          B = textOf(b.cells[colIndex]);\n",
        "\n",
        "      var nA = parseFloat(A.replace(/[^0-9.\\\\-]/g,'')),\n",
        "          nB = parseFloat(B.replace(/[^0-9.\\\\-]/g,''));\n",
        "\n",
        "      if(!isNaN(nA) && !isNaN(nB)){\n",
        "        return asc ? (nA - nB) : (nB - nA);\n",
        "      }\n",
        "      if (A < B) return asc ? -1 : 1;\n",
        "      if (A > B) return asc ?  1 : -1;\n",
        "      return 0;\n",
        "    });\n",
        "\n",
        "    var frag = document.createDocumentFragment();\n",
        "    for(var i=0;i<rows.length;i++){\n",
        "      frag.appendChild(rows[i]);\n",
        "    }\n",
        "    tb.appendChild(frag);\n",
        "  }\n",
        "\n",
        "  function bindHeaderSort(){\n",
        "    var tbl = document.getElementById('refactor-table');\n",
        "    if(!(tbl && tbl.tHead && tbl.tHead.rows.length)) return;\n",
        "\n",
        "    var ths = tbl.tHead.rows[0].cells;\n",
        "    if(!ths) return;\n",
        "\n",
        "    for(var i=0;i<ths.length;i++){\n",
        "      (function(idx){\n",
        "        var th  = ths[idx];\n",
        "        var dir = 'asc';\n",
        "        th.addEventListener('click', function(){\n",
        "          dir = (dir === 'asc') ? 'desc' : 'asc';\n",
        "\n",
        "          for (var j = 0; j < ths.length; j++){\n",
        "            ths[j].innerHTML = ths[j].innerHTML.replace(/\\\\s+\\\\(asc\\\\)|\\\\s+\\\\(desc\\\\)/,'');\n",
        "          }\n",
        "          th.innerHTML += (dir === 'asc' ? ' (asc)' : ' (desc)');\n",
        "          sortTable(tbl, idx, dir);\n",
        "        }, false);\n",
        "      })(i);\n",
        "    }\n",
        "  }\n",
        "\n",
        "  function getParam(name){\n",
        "    var m = location.search.match(new RegExp('[?&]'+name+'=([^&]+)'));\n",
        "    return m ? decodeURIComponent(m[1].replace(/\\\\+/g,' ')) : '';\n",
        "  }\n",
        "\n",
        "  function bindSearch(){\n",
        "    var box = document.getElementById('search-box');\n",
        "    var tbl = document.getElementById('refactor-table');\n",
        "    if(!(box && tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "\n",
        "    var tb   = tbl.tBodies[0];\n",
        "    var rows = Array.prototype.slice.call(tb.rows || []);\n",
        "\n",
        "    function rowText(tr){\n",
        "      var t = '';\n",
        "      for(var i=0;i<tr.cells.length;i++){\n",
        "        t += ' ' + (tr.cells[i].textContent || tr.cells[i].innerText || '');\n",
        "      }\n",
        "      return t.replace(/\\\\s+/g,' ').toLowerCase();\n",
        "    }\n",
        "\n",
        "    function apply(q){\n",
        "      q = String(q || '').toLowerCase();\n",
        "      for(var i=0;i<rows.length;i++){\n",
        "        var txt  = rowText(rows[i]);\n",
        "        var show = !q || txt.indexOf(q) > -1;\n",
        "        rows[i].style.display = show ? '' : 'none';\n",
        "      }\n",
        "    }\n",
        "\n",
        "    var to = null;\n",
        "    function onInput(){\n",
        "      if(to) clearTimeout(to);\n",
        "      to = setTimeout(function(){ apply(box.value); }, 60);\n",
        "    }\n",
        "\n",
        "    box.addEventListener('input',  onInput, false);\n",
        "    box.addEventListener('search', onInput, false);\n",
        "\n",
        "    var q0 = getParam('q');\n",
        "    if(q0){\n",
        "      box.value = q0;\n",
        "      apply(q0);\n",
        "      try{ history.replaceState(null,'',location.pathname); }catch(e){}\n",
        "    } else {\n",
        "      box.value = '';\n",
        "      apply('');\n",
        "    }\n",
        "  }\n",
        "\n",
        "  function bindBackToTop(){\n",
        "    var btn = document.getElementById('back-to-top');\n",
        "    if(!btn) return;\n",
        "\n",
        "    window.addEventListener('scroll', function(){\n",
        "      btn.style.display = (window.pageYOffset > 200 ? 'block' : 'none');\n",
        "    }, false);\n",
        "\n",
        "    btn.addEventListener('click', function(){\n",
        "      try{\n",
        "        window.scrollTo({top:0, behavior:'smooth'});\n",
        "      } catch(e){\n",
        "        window.scrollTo(0,0);\n",
        "      }\n",
        "    }, false);\n",
        "  }\n",
        "\n",
        "  function bindScrollSync(){\n",
        "    var top    = document.getElementById('top-scroll');\n",
        "    var bottom = document.getElementById('bottom-scroll');\n",
        "    if(!(top && bottom)) return;\n",
        "\n",
        "    var ignore = false;\n",
        "\n",
        "    top.addEventListener('scroll', function(){\n",
        "      if(ignore) return;\n",
        "      ignore = true;\n",
        "      bottom.scrollLeft = top.scrollLeft;\n",
        "      ignore = false;\n",
        "    }, false);\n",
        "\n",
        "    bottom.addEventListener('scroll', function(){\n",
        "      if(ignore) return;\n",
        "      ignore = true;\n",
        "      top.scrollLeft = bottom.scrollLeft;\n",
        "      ignore = false;\n",
        "    }, false);\n",
        "  }\n",
        "\n",
        "  function initLastUpdated(){\n",
        "    var el = document.getElementById('last-updated');\n",
        "    if(!el) return;\n",
        "\n",
        "    var d = new Date(document.lastModified || new Date());\n",
        "    var months = ['January','February','March','April','May','June','July','August','September','October','November','December'];\n",
        "    var day   = d.getDate();\n",
        "    var month = months[d.getMonth()];\n",
        "    var year  = d.getFullYear();\n",
        "    var hour  = d.getHours();\n",
        "    var min   = d.getMinutes();\n",
        "    var ampm  = hour >= 12 ? 'pm' : 'am';\n",
        "\n",
        "    hour = hour % 12;\n",
        "    hour = hour ? hour : 12;\n",
        "    var minStr = min < 10 ? '0' + min : String(min);\n",
        "\n",
        "    el.innerHTML = day + ' ' + month + ', ' + year +\n",
        "                   ' at ' + hour + ':' + minStr + ' ' + ampm;\n",
        "  }\n",
        "\n",
        "  document.addEventListener('DOMContentLoaded', function(){\n",
        "    initLastUpdated();\n",
        "    bindHeaderSort();\n",
        "    bindSearch();\n",
        "    bindBackToTop();\n",
        "    bindScrollSync();\n",
        "  });\n",
        "})();\n",
        "//]]>\n",
        "</script>\n",
        "\n",
        "</body>\n",
        "</html>\n",
        "\"\"\")\n",
        "\n",
        "# ---------- 8.1) Build HTML table manually with inline widths ----------\n",
        "website_links = []\n",
        "for subj in df[\"Subject\"].tolist():\n",
        "    url = _extract_find_url(subj)\n",
        "    if url:\n",
        "        website_links.append('<a href=\"%s\" target=\"_blank\" rel=\"noopener\">Website</a>' % _html.escape(url, quote=True))\n",
        "    else:\n",
        "        website_links.append(\"\")\n",
        "\n",
        "# Full logical headers/data for possible future use\n",
        "col_headers_full = [\n",
        "    (\"Match to\", \"center\"),\n",
        "    (\"Name\", \"center\"),\n",
        "    (\"cM\", \"center\"),\n",
        "    (\"Match Summary\", \"center\"),\n",
        "    (\"Website\", \"center\"),\n",
        "    (\"Yates DNA Ancestral Lines\", \"left\"),\n",
        "]\n",
        "\n",
        "col_data_full = [\n",
        "    display_match_to,\n",
        "    display_name,\n",
        "    df[cm_col].tolist(),\n",
        "    df[\"Match Summary\"].tolist(),\n",
        "    website_links,\n",
        "    df[LINEAGE_HEADER_SAFE].tolist(),\n",
        "]\n",
        "\n",
        "# Restrict HTML table to visible columns only (1, 4, 6 -> indexes 0, 3, 5)\n",
        "col_headers = [col_headers_full[i] for i in VISIBLE_COL_INDEXES]\n",
        "col_data    = [col_data_full[i]    for i in VISIBLE_COL_INDEXES]\n",
        "\n",
        "thead_cells = []\n",
        "for (idx, (hdr, align)) in enumerate(col_headers):\n",
        "    src_idx = VISIBLE_COL_INDEXES[idx]\n",
        "    wpx     = COL_WIDTHS[src_idx]\n",
        "    if align == \"center\":\n",
        "        cell_html = '<th class=\"center-header\" style=\"width:%dpx;\">%s</th>' % (wpx, hdr)\n",
        "    else:\n",
        "        cell_html = '<th class=\"left-header\" style=\"width:%dpx;\">%s</th>' % (wpx, hdr)\n",
        "    thead_cells.append(cell_html)\n",
        "thead_html = \"<thead>\\n  <tr>\" + \"\".join(thead_cells) + \"</tr>\\n</thead>\"\n",
        "\n",
        "nrows = len(df)\n",
        "tbody_lines = [\"<tbody>\"]\n",
        "for r in range(nrows):\n",
        "    tr_open = '  <tr id=\"first-row\">' if r == 0 else '  <tr>'\n",
        "    cells = []\n",
        "    for idx in range(len(col_headers)):\n",
        "        src_idx = VISIBLE_COL_INDEXES[idx]\n",
        "        wpx     = COL_WIDTHS[src_idx]\n",
        "        val     = col_data[idx][r]\n",
        "        val_str = \"\" if val is None else str(val)\n",
        "        cells.append('<td style=\"width:%dpx;\">%s</td>' % (wpx, val_str))\n",
        "    tbody_lines.append(tr_open + \"\".join(cells) + \"</tr>\")\n",
        "tbody_lines.append(\"</tbody>\")\n",
        "tbody_html = \"\\n\".join(tbody_lines)\n",
        "\n",
        "html_table = (\n",
        "    '<table border=\"1\" class=\"dataframe sortable dna-register-table\" id=\"refactor-table\">'\n",
        "    + thead_html +\n",
        "    \"\\n\" +\n",
        "    tbody_html +\n",
        "    \"</table>\"\n",
        ")\n",
        "\n",
        "# Scroll wrapper: top visible bar (desktop) and bottom real scroll\n",
        "SCROLL_WRAPPER = (\n",
        "    '<div class=\"table-scroll-wrapper\">'\n",
        "    '<div id=\"top-scroll\" class=\"scroll-sync-top\">'\n",
        "    '<div class=\"scroll-sync-top-inner\" style=\"width:%dpx;\"></div>'\n",
        "    '</div>'\n",
        "    '<div class=\"table-scroll\" id=\"bottom-scroll\">%s</div>'\n",
        "    '</div>'\n",
        ") % (TABLE_TOTAL_WIDTH_PX, html_table)\n",
        "\n",
        "# ---------- 8.2) Page assembly ----------\n",
        "_updated_parts = [\n",
        "    'Last updated: <span id=\"last-updated\"></span>'\n",
        "]\n",
        "if AUTOSOMAL_MATCHES:\n",
        "    _updated_parts.append('Autosomal matches: %s' % _html.escape(AUTOSOMAL_MATCHES))\n",
        "if SHOWING_STATIC:\n",
        "    _updated_parts.append('Showing: %s' % _html.escape(SHOWING_STATIC))\n",
        "\n",
        "UPDATED_BLOCK = (\n",
        "    '<div class=\"updated centerline\">' +\n",
        "    ' &nbsp;|&nbsp; '.join(_updated_parts) +\n",
        "    '</div>'\n",
        ")\n",
        "\n",
        "DOWNLOADS_BLOCK = \"\"  # no Download: CSV | Excel paragraph on the page\n",
        "\n",
        "NAV_BLOCK = '<!--#include virtual=\"/partials/nav_block.shtml\" -->'\n",
        "\n",
        "CONTROLS_BLOCK = (\n",
        "  '<div class=\"controls controls-spaced centerline\">'\n",
        "  '<input type=\"text\" id=\"search-box\" class=\"search\" size=\"28\" value=\"\" placeholder=\"Search&amp;hellip;\" />'\n",
        "  '</div>'\n",
        ")\n",
        "\n",
        "final_html = page_tpl.safe_substitute(\n",
        "    HEAD_LINK       = HEAD_LINK,\n",
        "    UPDATED_BLOCK   = UPDATED_BLOCK,\n",
        "    NAV_BLOCK       = NAV_BLOCK,\n",
        "    CONTROLS_BLOCK  = CONTROLS_BLOCK,\n",
        "    DOWNLOADS_BLOCK = DOWNLOADS_BLOCK,\n",
        "    SCROLL_WRAPPER  = SCROLL_WRAPPER,\n",
        ")\n",
        "\n",
        "with open(LOCAL_HTML, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(final_html)\n",
        "print(\"[OK] Saved canonical render: %s\" % os.path.abspath(LOCAL_HTML))\n",
        "\n",
        "# ---------- 9) Upload ----------\n",
        "def save_and_upload_all():\n",
        "    if not all(os.environ.get(k) for k in [\"FTP_HOST\", \"FTP_USER\", \"FTP_PASS\"]):\n",
        "        print(\"[SKIP] Missing FTP creds; uploads skipped.\")\n",
        "        return\n",
        "    try:\n",
        "        ftps = ftp_connect()\n",
        "\n",
        "        try:\n",
        "            ftp_upload_overwrite(ftps, STYLESHEET_LOCAL, _remote_path(STYLESHEET_REMOTE))\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload stylesheet failed: %s\" % e)\n",
        "\n",
        "        try:\n",
        "            ftp_upload_overwrite(ftps, LOCAL_HTML, _remote_path(REMOTE_HTML_CANON))\n",
        "            ftp_upload_overwrite(ftps, LOCAL_HTML, _remote_path(REMOTE_HTML_LEG))\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload main HTML failed: %s\" % e)\n",
        "\n",
        "        try:\n",
        "            if os.path.exists(LOCAL_CSV):\n",
        "                ftp_upload_overwrite(ftps, LOCAL_CSV, _remote_path(REMOTE_CSV))\n",
        "            if os.path.exists(LOCAL_XLSX):\n",
        "                ftp_upload_overwrite(ftps, LOCAL_XLSX, _remote_path(REMOTE_XLSX))\n",
        "            print(\"[OK] Uploaded CSV/XLSX -> /partials/\")\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload CSV/XLSX failed: %s\" % e)\n",
        "\n",
        "        print(\"\\n--- SIZE Verification (if supported) ---\")\n",
        "        for p in [\n",
        "            _remote_path(REMOTE_HTML_CANON),\n",
        "            _remote_path(REMOTE_HTML_LEG),\n",
        "            _remote_path(REMOTE_CSV),\n",
        "            _remote_path(REMOTE_XLSX),\n",
        "            _remote_path(STYLESHEET_REMOTE),\n",
        "        ]:\n",
        "            sz = ftp_size(ftps, p)\n",
        "            print(\"%s : %s\" % (p, sz if sz is not None else \"(SIZE unsupported)\"))\n",
        "\n",
        "        try:\n",
        "            ftps.quit()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        print(\"\\n--- Open URLs ---\")\n",
        "        print(\"Canonical:        https://yates.one-name.net/partials/yates_ancestor_register.shtml\")\n",
        "        print(\"Legacy (ons_):    https://yates.one-name.net/partials/ons_yates_dna_register.shtml\")\n",
        "        print(\"Match Count:      https://yates.one-name.net/partials/match_count.shtml\")\n",
        "        print(\"Lineage Count:    https://yates.one-name.net/partials/lineage_count.shtml\")\n",
        "        print(\"Cousin Printable: https://yates.one-name.net/partials/cousin_list_print.htm\")\n",
        "        print(\"Trees (Cell 3):   https://yates.one-name.net/partials/just-trees.htm\")\n",
        "        print(\"Stylesheet:       https://yates.one-name.net/partials/dna_tree_styles.css\")\n",
        "        print(\"\\nBust cache once if needed by appending ?v=%s to the URL.\" % CSS_VERSION)\n",
        "    except Exception as e:\n",
        "        print(\"[FAIL] FTP session: %s\" % e)\n",
        "        traceback.print_exc()\n",
        "\n",
        "save_and_upload_all()\n",
        "# ====== CUT STOP [1/1] CELL 2 ==================================================================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE95m_jm15Q_",
        "outputId": "a607e21d-5ca8-4215-bc44-ef83c7862087"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CONFIRM] Golden Rules active | Cell=Cell2_AllStyles_ExternalCSS | Version=2025.11.25-G1 | Encoding=ISO-8859-15\n",
            "[LAYOUT] TABLE_TOTAL_WIDTH_PX=3080\n",
            "[LAYOUT] Column widths (px): 1=80 2=220 3=60 4=1200 5=120 6=1800\n",
            "[LAYOUT] Visible HTML columns (0-based indexes): [0, 3, 5]\n",
            "[OK] Loaded CSV: 1596 rows, 6 cols\n",
            "[OK] Loaded vitals from dna_vitals.csv -> autosomal=1596, showing=1596\n",
            "[PULL] match_to_unmasked.csv -> /content/match_to_unmasked.server.csv\n",
            "[OK] Resolver loaded: 83 codes\n",
            "[OK] Wrote exports: /content/yates_ancestor_register.csv and /content/yates_ancestor_register.xlsx\n",
            "[OK] Wrote stylesheet: /content/partials/dna_tree_styles.css\n",
            "[OK] Saved canonical render: /content/yates_ancestor_register.shtml\n",
            "[PUT] partials/dna_tree_styles.css -> partials/dna_tree_styles.css\n",
            "[PUT] yates_ancestor_register.shtml -> partials/yates_ancestor_register.shtml\n",
            "[PUT] yates_ancestor_register.shtml -> partials/ons_yates_dna_register.shtml\n",
            "[PUT] yates_ancestor_register.csv -> partials/yates_ancestor_register.csv\n",
            "[PUT] yates_ancestor_register.xlsx -> partials/yates_ancestor_register.xlsx\n",
            "[OK] Uploaded CSV/XLSX -> /partials/\n",
            "\n",
            "--- SIZE Verification (if supported) ---\n",
            "partials/yates_ancestor_register.shtml : 1067633\n",
            "partials/ons_yates_dna_register.shtml : 1067633\n",
            "partials/yates_ancestor_register.csv : 709879\n",
            "partials/yates_ancestor_register.xlsx : 156154\n",
            "partials/dna_tree_styles.css : 4558\n",
            "\n",
            "--- Open URLs ---\n",
            "Canonical:        https://yates.one-name.net/partials/yates_ancestor_register.shtml\n",
            "Legacy (ons_):    https://yates.one-name.net/partials/ons_yates_dna_register.shtml\n",
            "Match Count:      https://yates.one-name.net/partials/match_count.shtml\n",
            "Lineage Count:    https://yates.one-name.net/partials/lineage_count.shtml\n",
            "Cousin Printable: https://yates.one-name.net/partials/cousin_list_print.htm\n",
            "Trees (Cell 3):   https://yates.one-name.net/partials/just-trees.htm\n",
            "Stylesheet:       https://yates.one-name.net/partials/dna_tree_styles.css\n",
            "\n",
            "Bust cache once if needed by appending ?v=v2025-11-25-g1 to the URL.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 2b-Counts"
      ],
      "metadata": {
        "id": "WznUryHnICUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] CELL 2b — Build + Upload Match/Lineage Count Partials (Counts only) ======\n",
        "# RON GOLDEN RULES -- CLIFF NOTES (v2025.11.15-G6)\n",
        "# • Complete & runnable Colab cell — one contiguous block.\n",
        "# • Source ASCII-only; outputs written with encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\".\n",
        "# • XHTML 1.0 Transitional; ALL typography/layout via /partials/dna_tree_styles.css (linked only).\n",
        "# • Deterministic audit:\n",
        "#   [CONFIRM] Golden Rules active | Cell=Cell2b_Counts | Version=2025.11.15-G6 | Encoding=ISO-8859-15\n",
        "# • Enforce ISO-8859-15 printable chars on writes;\n",
        "print(\"[CONFIRM] Golden Rules active | Cell=Cell2b_Counts | Version=2025.11.15-G6 | Encoding=ISO-8859-15\")\n",
        "\n",
        "DOWNLOADS_BLOCK = \"\"  # moved into nav_block.shtml\n",
        "\n",
        "import os, re, posixpath, socket, traceback\n",
        "from ftplib import FTP_TLS\n",
        "import pandas as pd\n",
        "import html as _html\n",
        "\n",
        "# ---------- 0) Secrets ----------\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ[\"FTP_HOST\"] = userdata.get(\"FTP_HOST\")\n",
        "    os.environ[\"FTP_USER\"] = userdata.get(\"FTP_USER\")\n",
        "    os.environ[\"FTP_PASS\"] = userdata.get(\"FTP_PASS\")\n",
        "    try:\n",
        "        os.environ[\"FTP_DIR\"] = userdata.get(\"FTP_DIR\")\n",
        "    except Exception:\n",
        "        os.environ.setdefault(\"FTP_DIR\", \"\")\n",
        "    try:\n",
        "        os.environ[\"FTP_PORT\"] = userdata.get(\"FTP_PORT\")\n",
        "    except Exception:\n",
        "        os.environ.setdefault(\"FTP_PORT\", \"21\")\n",
        "except Exception:\n",
        "    os.environ.setdefault(\"FTP_HOST\", \"\")\n",
        "    os.environ.setdefault(\"FTP_USER\", \"\")\n",
        "    os.environ.setdefault(\"FTP_PASS\", \"\")\n",
        "    os.environ.setdefault(\"FTP_DIR\", \"\")\n",
        "    os.environ.setdefault(\"FTP_PORT\", \"21\")\n",
        "\n",
        "# ---------- 1) Config ----------\n",
        "CSV_IN = \"final_combined_df_with_value_labels.csv\"\n",
        "\n",
        "SERVER_PARTIALS_DIR = \"partials\"\n",
        "SERVER_MAPPING_BASENAME = \"match_to_unmasked.csv\"\n",
        "SERVER_MAPPING_REMOTE = posixpath.join(SERVER_PARTIALS_DIR, SERVER_MAPPING_BASENAME)\n",
        "SERVER_MAPPING_LOCAL_CACHE = \"match_to_unmasked.server.csv\"\n",
        "\n",
        "FTP_DIR = (os.environ.get(\"FTP_DIR\", \"\") or \"\").strip()\n",
        "\n",
        "# Shared stylesheet link (must already be present on server from Cell 2)\n",
        "STYLESHEET_BASENAME = \"dna_tree_styles.css\"\n",
        "CSS_VERSION = \"v2025-11-12-max\"\n",
        "STYLESHEET_HREF = \"/partials/%s?%s\" % (STYLESHEET_BASENAME, CSS_VERSION)\n",
        "HEAD_LINK = '<link rel=\"stylesheet\" type=\"text/css\" href=\"%s\" />' % STYLESHEET_HREF\n",
        "\n",
        "# Shared nav include (SSI)\n",
        "NAV_BLOCK = '<!--#include virtual=\"/partials/nav_block.shtml\" -->'\n",
        "\n",
        "# Count file URL for JS in partials\n",
        "REMOTE_COUNT_NAME = \"autosomal_count.txt\"\n",
        "if FTP_DIR:\n",
        "    COUNT_PUBLIC_URL = \"/%s/%s\" % (FTP_DIR, REMOTE_COUNT_NAME)\n",
        "else:\n",
        "    COUNT_PUBLIC_URL = \"/%s\" % REMOTE_COUNT_NAME\n",
        "\n",
        "# TNG settings for cousin links (match vertical chart behavior in main register)\n",
        "TNG_BASE = \"https://yates.one-name.net/tng\"\n",
        "TNG_TREE = \"tree1\"\n",
        "\n",
        "# Local partial paths\n",
        "MATCH_COUNT_LOCAL   = os.path.join(\"partials\", \"match_count.shtml\")\n",
        "LINEAGE_COUNT_LOCAL = os.path.join(\"partials\", \"lineage_count.shtml\")\n",
        "COUSIN_PRINT_LOCAL  = os.path.join(\"partials\", \"cousin_list_print.htm\")\n",
        "\n",
        "# Remote partial paths (server-side)\n",
        "MATCH_COUNT_REMOTE   = posixpath.join(\"partials\", \"match_count.shtml\")\n",
        "LINEAGE_COUNT_REMOTE = posixpath.join(\"partials\", \"lineage_count.shtml\")\n",
        "COUSIN_PRINT_REMOTE  = posixpath.join(\"partials\", \"cousin_list_print.htm\")\n",
        "\n",
        "# ---------- 2) FTP helpers ----------\n",
        "FTP_TIMEOUT = int(os.environ.get(\"FTP_TIMEOUT\", \"30\"))\n",
        "FTP_PASSIVE = True\n",
        "\n",
        "\n",
        "def ftp_connect() -> FTP_TLS:\n",
        "    ftps = FTP_TLS(timeout=FTP_TIMEOUT)\n",
        "    socket.setdefaulttimeout(FTP_TIMEOUT)\n",
        "    ftps.connect(os.environ.get(\"FTP_HOST\", \"\"), int(os.environ.get(\"FTP_PORT\", 21)))\n",
        "    ftps.login(os.environ.get(\"FTP_USER\", \"\"), os.environ.get(\"FTP_PASS\", \"\"))\n",
        "    try:\n",
        "        ftps.prot_p()\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        ftps.set_pasv(FTP_PASSIVE)\n",
        "    except Exception:\n",
        "        pass\n",
        "    if FTP_DIR:\n",
        "        for p in [p for p in FTP_DIR.split(\"/\") if p]:\n",
        "            try:\n",
        "                ftps.mkd(p)\n",
        "            except Exception:\n",
        "                pass\n",
        "            ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "\n",
        "def _remote_path(name: str) -> str:\n",
        "    return posixpath.join(FTP_DIR, name) if FTP_DIR else name\n",
        "\n",
        "\n",
        "def ensure_remote_dirs(ftps, remote_path):\n",
        "    if \"/\" not in remote_path:\n",
        "        return\n",
        "    pwd0 = ftps.pwd()\n",
        "    parts = [p for p in remote_path.split(\"/\")[:-1] if p and p != \".\"]\n",
        "    for seg in parts:\n",
        "        try:\n",
        "            ftps.cwd(seg)\n",
        "        except Exception:\n",
        "            try:\n",
        "                ftps.mkd(seg)\n",
        "            except Exception:\n",
        "                pass\n",
        "            ftps.cwd(seg)\n",
        "    ftps.cwd(pwd0)\n",
        "\n",
        "\n",
        "def ftp_download_if_exists(ftps, remote_name, local_name) -> bool:\n",
        "    try:\n",
        "        with open(local_name, \"wb\") as f:\n",
        "            ftps.retrbinary(\"RETR %s\" % remote_name, f.write)\n",
        "        print(\"[PULL] %s -> %s\" % (remote_name, os.path.abspath(local_name)))\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            if os.path.exists(local_name):\n",
        "                os.remove(local_name)\n",
        "        except Exception:\n",
        "            pass\n",
        "        print(\"[MISS] %s (%s)\" % (remote_name, e))\n",
        "        return False\n",
        "\n",
        "\n",
        "def ftp_upload_overwrite(ftps, local_path, remote_name):\n",
        "    ensure_remote_dirs(ftps, remote_name)\n",
        "    with open(local_path, \"rb\") as fh:\n",
        "        ftps.storbinary(\"STOR %s\" % remote_name, fh)\n",
        "    print(\"[PUT] %s -> %s\" % (local_path, remote_name))\n",
        "\n",
        "\n",
        "def ftp_size(ftps, remote_name):\n",
        "    try:\n",
        "        sz = ftps.size(remote_name)\n",
        "        return int(sz) if sz is not None else None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "# ---------- 3) Resolver (match_to_unmasked.csv on server) ----------\n",
        "def _read_mapping_csv(path: str) -> pd.DataFrame:\n",
        "    encs = (\"iso-8859-15\", \"utf-8-sig\", \"utf-8\", \"cp1252\", \"latin1\")\n",
        "    last = None\n",
        "    df = None\n",
        "    for enc in encs:\n",
        "        try:\n",
        "            df = pd.read_csv(path, encoding=enc, dtype=str, keep_default_na=False)\n",
        "            break\n",
        "        except Exception as e:\n",
        "            last = e\n",
        "            df = None\n",
        "    if df is None:\n",
        "        raise RuntimeError(\"Unable to read mapping CSV %s: %s\" % (path, last))\n",
        "    if df.shape[1] < 2:\n",
        "        raise RuntimeError(\"Mapping CSV must have at least two columns: code, unmasked\")\n",
        "    df = df.iloc[:, :2].copy()\n",
        "    df.columns = [\"code\", \"unmasked\"]\n",
        "    df[\"code\"] = df[\"code\"].astype(str).str.strip().str.lower()\n",
        "    df[\"unmasked\"] = df[\"unmasked\"].astype(str).str.strip()\n",
        "    df = df[df[\"code\"] != \"\"].drop_duplicates(subset=[\"code\"], keep=\"first\")\n",
        "    if df.empty:\n",
        "        raise RuntimeError(\"Mapping CSV empty after normalization.\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def load_resolver_from_server() -> dict:\n",
        "    with ftp_connect() as ftps:\n",
        "        try:\n",
        "            ftps.cwd(SERVER_PARTIALS_DIR)\n",
        "        except Exception:\n",
        "            pass\n",
        "        ok = ftp_download_if_exists(ftps, SERVER_MAPPING_BASENAME, SERVER_MAPPING_LOCAL_CACHE)\n",
        "        try:\n",
        "            ftps.quit()\n",
        "        except Exception:\n",
        "            pass\n",
        "    if not ok:\n",
        "        raise RuntimeError(\n",
        "            \"Resolver not found on server: /%s. Upload match_to_unmasked.csv into /partials/ and re-run.\"\n",
        "            % _remote_path(SERVER_MAPPING_REMOTE)\n",
        "        )\n",
        "    df_map = _read_mapping_csv(SERVER_MAPPING_LOCAL_CACHE)\n",
        "    print(\"[OK] Resolver loaded: %d codes\" % len(df_map))\n",
        "    return dict(zip(df_map[\"code\"], df_map[\"unmasked\"]))\n",
        "\n",
        "\n",
        "MATCH_TO_UNMASKED = {}\n",
        "\n",
        "\n",
        "def _setup_resolver():\n",
        "    global MATCH_TO_UNMASKED\n",
        "    if not MATCH_TO_UNMASKED:\n",
        "        MATCH_TO_UNMASKED = load_resolver_from_server()\n",
        "\n",
        "\n",
        "# ---------- 4) CSV + name helpers ----------\n",
        "def find_col(df, patterns, prefer_exact=None):\n",
        "    cols = list(df.columns)\n",
        "    lowmap = {c.lower(): c for c in cols}\n",
        "    if prefer_exact:\n",
        "        for name in prefer_exact:\n",
        "            if name in df.columns:\n",
        "                return name\n",
        "            if name and name.lower() in lowmap:\n",
        "                return lowmap[name.lower()]\n",
        "    for pat in patterns:\n",
        "        rx = re.compile(pat, re.I)\n",
        "        for c in cols:\n",
        "            if rx.search(c):\n",
        "                return c\n",
        "    return None\n",
        "\n",
        "\n",
        "SEP_RE = re.compile(r\"\\s*(?:\\u2192|&rarr;|;|>|,|~{2,}|/{2,}|\\|{2,})\\s*\")\n",
        "\n",
        "\n",
        "def split_tokens(s):\n",
        "    if pd.isna(s):\n",
        "        return []\n",
        "    if not isinstance(s, str):\n",
        "        s = str(s)\n",
        "    return [p.strip() for p in SEP_RE.split(s) if str(p).strip()]\n",
        "\n",
        "\n",
        "def _clean_piece(text: str) -> str:\n",
        "    t = re.sub(r\"~+\", \" \", str(text))\n",
        "    t = re.sub(r\"\\s+\", \" \", t)\n",
        "    return t.strip()\n",
        "\n",
        "\n",
        "_PARTICLES = {\n",
        "    \"de\",\n",
        "    \"del\",\n",
        "    \"della\",\n",
        "    \"der\",\n",
        "    \"van\",\n",
        "    \"von\",\n",
        "    \"da\",\n",
        "    \"dos\",\n",
        "    \"das\",\n",
        "    \"di\",\n",
        "    \"la\",\n",
        "    \"le\",\n",
        "    \"du\",\n",
        "    \"of\",\n",
        "}\n",
        "\n",
        "\n",
        "def _smart_title(token: str) -> str:\n",
        "    if not token:\n",
        "        return token\n",
        "    token = re.sub(\n",
        "        r\"(^|\\b)([a-z])(['’])([a-z])\",\n",
        "        lambda m: m.group(1) + m.group(2).upper() + m.group(3) + m.group(4).upper(),\n",
        "        token.lower(),\n",
        "    )\n",
        "    token = \"-\".join([w.capitalize() for w in token.split(\"-\")])\n",
        "    token = re.sub(r\"\\bmc([a-z])\", lambda m: \"Mc\" + m.group(1).upper(), token)\n",
        "    token = re.sub(r\"\\bmac([a-z])\", lambda m: \"Mac\" + m.group(1).upper(), token)\n",
        "    return token\n",
        "\n",
        "\n",
        "def smart_titlecase(name: str) -> str:\n",
        "    name = _clean_piece(name)\n",
        "    if not name:\n",
        "        return name\n",
        "    if \",\" in name:\n",
        "        last, first = [p.strip() for p in name.split(\",\", 1)]\n",
        "        pieces = (first + \" \" + last).split()\n",
        "    else:\n",
        "        pieces = name.split()\n",
        "    out = []\n",
        "    for i, w in enumerate(pieces):\n",
        "        out.append(w.lower() if (i > 0 and w.lower() in _PARTICLES) else _smart_title(w))\n",
        "    return \" \".join(out)\n",
        "\n",
        "\n",
        "def surname_given_from_token(token):\n",
        "    token = token.strip()\n",
        "    idx = None\n",
        "    for i in range(1, len(token)):\n",
        "        if token[i - 1].islower() and token[i].isupper():\n",
        "            idx = i\n",
        "            break\n",
        "    if idx is None:\n",
        "        for i in range(1, len(token)):\n",
        "            if token[i].isupper():\n",
        "                idx = i\n",
        "                break\n",
        "    if idx is None:\n",
        "        return (token,)\n",
        "    surname = token[:idx]\n",
        "    given = token[idx:]\n",
        "    given_spaced = re.sub(r\"(?<!^)([A-Z])\", r\" \\1\", given)\n",
        "    return (\"%s %s\" % (given_spaced.strip(), surname.strip()),)\n",
        "\n",
        "\n",
        "_CAMEL_WORDS = re.compile(r\"[A-Z][a-z]*|[A-Z]+(?![a-z])|[a-z]+\")\n",
        "\n",
        "\n",
        "def norm_matchee_name(raw: str) -> str:\n",
        "    raw = str(raw or \"\").strip()\n",
        "    if not raw:\n",
        "        return \"\"\n",
        "    if \" \" in raw or \",\" in raw:\n",
        "        nm = smart_titlecase(raw)\n",
        "        parts = nm.split()\n",
        "        if len(parts) == 1:\n",
        "            return nm\n",
        "        return (\"%s %s\" % (parts[0], parts[-1])).strip()\n",
        "    words = _CAMEL_WORDS.findall(raw)\n",
        "    while words and len(words[0]) == 1:\n",
        "        words.pop(0)\n",
        "    if not words:\n",
        "        nm = smart_titlecase(surname_given_from_token(raw)[0])\n",
        "        ps = nm.split()\n",
        "        if len(ps) == 1:\n",
        "            return nm\n",
        "        return (\"%s %s\" % (ps[0], ps[-1])).strip()\n",
        "    surname = smart_titlecase(words[0])\n",
        "    given_candidates = [w for w in words[1:] if w.lower() != surname.lower()]\n",
        "    if not given_candidates:\n",
        "        return surname\n",
        "    return (\"%s %s\" % (smart_titlecase(given_candidates[0]), surname)).strip()\n",
        "\n",
        "\n",
        "def normalize_person_name(s: str) -> str:\n",
        "    if pd.isna(s):\n",
        "        return \"\"\n",
        "    s = _clean_piece(str(s))\n",
        "    if \",\" in s:\n",
        "        last, first = [p.strip() for p in s.split(\",\", 1)]\n",
        "        s = \"%s %s\" % (first, last)\n",
        "    if \" \" not in s and s.isalpha():\n",
        "        return smart_titlecase(surname_given_from_token(s)[0])\n",
        "    return smart_titlecase(s)\n",
        "\n",
        "\n",
        "ID_PAT = re.compile(r\"\\bI\\d+\\b\", re.I)\n",
        "\n",
        "\n",
        "def extract_person_id(s: str) -> str:\n",
        "    m = ID_PAT.search(str(s or \"\"))\n",
        "    return m.group(0).upper() if m else \"\"\n",
        "\n",
        "\n",
        "def derive_common_from_first_token(tokens):\n",
        "    if not tokens:\n",
        "        return (\"\", \"\")\n",
        "    first = _clean_piece(tokens[0])\n",
        "    parts = re.split(r\"\\s*(?:&| and )\\s*\", first, maxsplit=1, flags=re.I)\n",
        "    if len(parts) != 2:\n",
        "        return (\"\", \"\")\n",
        "\n",
        "    def _norm(s):\n",
        "        return smart_titlecase(s) if \" \" in s else smart_titlecase(surname_given_from_token(s)[0])\n",
        "\n",
        "    return (_norm(parts[0]), _norm(parts[1]))\n",
        "\n",
        "\n",
        "def degree_label_from_generations(g):\n",
        "    if g <= 1:\n",
        "        return \"parents\" if g == 1 else \"self\"\n",
        "    if g == 2:\n",
        "        return \"grandparents\"\n",
        "    greats = g - 2\n",
        "    if greats == 1:\n",
        "        return \"great-grandparents\"\n",
        "    return \"%dx-great-grandparents\" % greats\n",
        "\n",
        "\n",
        "def build_header(subject_name_html, cm_val, matchee_name_html, gens, husband, wife):\n",
        "    try:\n",
        "        cm_str = \"%d\" % int(round(float(cm_val)))\n",
        "    except Exception:\n",
        "        cm_str = (str(cm_val).strip() or \"0\")\n",
        "    degree_label = degree_label_from_generations(gens)\n",
        "    parts = [\n",
        "        \"%s is a %s cM cousin match to %s, whose\" % (subject_name_html, cm_str, matchee_name_html),\n",
        "        \"%s (back %d Gens)\" % (degree_label, gens),\n",
        "        \"are\",\n",
        "        \"%s & %s.\" % (husband, wife),\n",
        "    ]\n",
        "    s = \" \".join(parts)\n",
        "    s = re.sub(r\"\\.\\s*$\", \"\", s)\n",
        "    return s\n",
        "\n",
        "# ---------- 5) Count helpers + partial HTML shells ----------\n",
        "def _norm_code_for_count(s):\n",
        "    t = str(s or \"\").strip()\n",
        "    if (t.startswith('\"') and t.endswith('\"')) or (t.startswith(\"'\") and t.endswith(\"'\")):\n",
        "        t = t[1:-1]\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n",
        "    return t\n",
        "\n",
        "\n",
        "def _partial_head(title):\n",
        "    return (\n",
        "        \"<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Transitional//EN\\\"\\n\"\n",
        "        \" \\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\\\">\\n\"\n",
        "        \"<html xmlns=\\\"http://www.w3.org/1999/xhtml\\\" lang=\\\"en\\\">\\n<head>\\n\"\n",
        "        \"%s\\n\" % HEAD_LINK\n",
        "        + \"<meta http-equiv=\\\"Content-Type\\\" content=\\\"text/html; charset=iso-8859-15\\\" />\\n\"\n",
        "        + \"<title>%s</title>\\n\" % _html.escape(title)\n",
        "        + \"</head>\\n<body>\\n<div class=\\\"wrap\\\">\\n\"\n",
        "        + \"<h1 class=\\\"centerline\\\">%s</h1>\\n\" % _html.escape(title)\n",
        "        + \"<div class=\\\"updated centerline\\\">Last updated: \"\n",
        "          \"<span id=\\\"last-updated\\\"></span> &nbsp;|&nbsp; \"\n",
        "          \"Autosomal matches: <span id=\\\"auto-count\\\">&mdash;</span></div>\\n\"\n",
        "        + NAV_BLOCK + \"\\n\"\n",
        "        + \"<div class=\\\"selection-menu centerline\\\">\"\n",
        "          \"<a href=\\\"#\\\" onclick=\\\"return ySelShowSelected('ref-tb');\\\">Show selected</a> &nbsp;|&nbsp; \"\n",
        "          \"<a href=\\\"#\\\" onclick=\\\"return ySelShowAll('ref-tb');\\\">Show all</a> &nbsp;|&nbsp; \"\n",
        "          \"<a href=\\\"#\\\" onclick=\\\"return ySelReset('ref-tb');\\\">Reset</a>\"\n",
        "          \"</div>\\n\"\n",
        "        + \"<div class=\\\"table-scroll\\\">\\n\"\n",
        "    )\n",
        "\n",
        "\n",
        "def _partial_tail():\n",
        "    safe_count = COUNT_PUBLIC_URL.replace(\"'\", \"%27\")\n",
        "    return (\n",
        "        \"</div>\\n</div>\\n\"\n",
        "        \"<script type=\\\"text/javascript\\\">\\n//<![CDATA[\\n\"\n",
        "        \"(function(){\"\n",
        "        \"function stamp(){var el=document.getElementById('last-updated');\"\n",
        "        \" if(!el) return; var d=new Date(document.lastModified||new Date());\"\n",
        "        \" var months=['January','February','March','April','May','June','July','August','September','October','November','December'];\"\n",
        "        \" var day=d.getDate(); var month=months[d.getMonth()]; var year=d.getFullYear();\"\n",
        "        \" var hour=d.getHours(); var min=d.getMinutes(); var ampm = hour >= 12 ? 'pm' : 'am';\"\n",
        "        \" hour = hour % 12; hour = hour ? hour : 12;\"\n",
        "        \" var minStr = min < 10 ? '0' + min : min;\"\n",
        "        \" el.innerHTML = day + ' ' + month + ', ' + year + ' at ' + hour + ':' + minStr + ' ' + ampm;}\"\n",
        "        \"function load(){var el=document.getElementById('auto-count'); if(!el) return;\"\n",
        "        \" var URL='\" + safe_count + \"';\"\n",
        "        \" try{var xhr=new XMLHttpRequest();\"\n",
        "        \" xhr.open('GET', URL+(URL.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true);\"\n",
        "        \" xhr.onreadystatechange=function(){if(xhr.readyState===4){\"\n",
        "        \" if(xhr.status>=200&&xhr.status<300){var m=(xhr.responseText||'').match(/(\\\\d+)/);\"\n",
        "        \" el.textContent=(m?m[1]:'');}\"\n",
        "        \" else {el.textContent='(unavailable)';}}}; xhr.send(null);}catch(e){el.textContent='(unavailable)';}}\"\n",
        "        \"function ySelEachRow(tb, cb){\"\n",
        "        \" if(!tb) return;\"\n",
        "        \" var rows=tb.getElementsByTagName('tr');\"\n",
        "        \" for(var i=0;i<rows.length;i++){cb(rows[i]);}\"\n",
        "        \"}\"\n",
        "        \"function ySelClear(tr){\"\n",
        "        \" if(!tr) return;\"\n",
        "        \" tr.removeAttribute('data-selected');\"\n",
        "        \" var cls=tr.className||'';\"\n",
        "        \" cls=cls.replace(/\\\\bsel-row\\\\b/g,'').replace(/\\\\s{2,}/g,' ').replace(/^\\\\s+|\\\\s+$/g,'');\"\n",
        "        \" tr.className=cls;\"\n",
        "        \"}\"\n",
        "        \"function ySelToggle(a){\"\n",
        "        \" var tr=a;\"\n",
        "        \" while(tr&&tr.tagName&&tr.tagName.toLowerCase()!=='tr'){tr=tr.parentNode;}\"\n",
        "        \" if(!tr) return false;\"\n",
        "        \" var sel=tr.getAttribute('data-selected')==='1';\"\n",
        "        \" if(sel){\"\n",
        "        \"  ySelClear(tr);\"\n",
        "        \" }else{\"\n",
        "        \"  tr.setAttribute('data-selected','1');\"\n",
        "        \"  var cls=tr.className||'';\"\n",
        "        \"  if(cls.indexOf('sel-row')===-1){tr.className=(cls?(cls+' '):'')+'sel-row';}\"\n",
        "        \" }\"\n",
        "        \" return false;\"\n",
        "        \"}\"\n",
        "        \"function ySelGetTBody(tbodyId){\"\n",
        "        \" var tb=document.getElementById(tbodyId);\"\n",
        "        \" if(tb) return tb;\"\n",
        "        \" var t=document.getElementById('ref-table');\"\n",
        "        \" if(!t) return null;\"\n",
        "        \" if(t.tBodies&&t.tBodies.length){return t.tBodies[0];}\"\n",
        "        \" return t;\"\n",
        "        \"}\"\n",
        "        \"function ySelShowSelected(tbodyId){\"\n",
        "        \" var tb=ySelGetTBody(tbodyId);\"\n",
        "        \" if(!tb) return false;\"\n",
        "        \" ySelEachRow(tb,function(tr){\"\n",
        "        \"  var sel=tr.getAttribute('data-selected')==='1';\"\n",
        "        \"  tr.style.display=sel?'':'none';\"\n",
        "        \" });\"\n",
        "        \" var rl=document.getElementById('reg-list');\"\n",
        "        \" if(rl){\"\n",
        "        \"  var selVals=[];\"\n",
        "        \"  ySelEachRow(tb,function(tr){\"\n",
        "        \"    if(tr.getAttribute('data-selected')==='1'){\"\n",
        "        \"      var v=tr.getAttribute('data-filter')\"\n",
        "        \"        || tr.getAttribute('data-lineage')\"\n",
        "        \"        || tr.getAttribute('data-code')\"\n",
        "        \"        || tr.getAttribute('data-q')\"\n",
        "        \"        || '';\"\n",
        "        \"      if(v){selVals.push(v);}\"\n",
        "        \"    }\"\n",
        "        \"  });\"\n",
        "        \"  if(selVals.length===0){\"\n",
        "        \"    return false;\"\n",
        "        \"  }\"\n",
        "        \"  var rows=rl.getElementsByTagName('tr');\"\n",
        "        \"  for(var i=0;i<rows.length;i++){\"\n",
        "        \"    var r=rows[i];\"\n",
        "        \"    var lv=r.getAttribute('data-filter')\"\n",
        "        \"      || r.getAttribute('data-lineage')\"\n",
        "        \"      || r.getAttribute('data-code')\"\n",
        "        \"      || '';\"\n",
        "        \"    var show=false;\"\n",
        "        \"    for(var j=0;j<selVals.length;j++){\"\n",
        "        \"      if(lv===selVals[j]){show=true; break;}\"\n",
        "        \"    }\"\n",
        "        \"    r.style.display=show?'':'none';\"\n",
        "        \"  }\"\n",
        "        \" }\"\n",
        "        \" return false;\"\n",
        "        \"}\"\n",
        "        \"function ySelShowAll(tbodyId){\"\n",
        "        \" var tb=ySelGetTBody(tbodyId);\"\n",
        "        \" if(!tb) return false;\"\n",
        "        \" ySelEachRow(tb,function(tr){tr.style.display='';});\"\n",
        "        \" var rl=document.getElementById('reg-list');\"\n",
        "        \" if(rl){\"\n",
        "        \"  var rows=rl.getElementsByTagName('tr');\"\n",
        "        \"  for(var i=0;i<rows.length;i++){rows[i].style.display='';}\"\n",
        "        \" }\"\n",
        "        \" return false;\"\n",
        "        \"}\"\n",
        "        \"function ySelReset(tbodyId){\"\n",
        "        \" var tb=ySelGetTBody(tbodyId);\"\n",
        "        \" if(!tb) return false;\"\n",
        "        \" ySelEachRow(tb,function(tr){tr.style.display=''; ySelClear(tr);});\"\n",
        "        \" var rl=document.getElementById('reg-list');\"\n",
        "        \" if(rl){\"\n",
        "        \"  var rows=rl.getElementsByTagName('tr');\"\n",
        "        \"  for(var i=0;i<rows.length;i++){rows[i].style.display='';}\"\n",
        "        \" }\"\n",
        "        \" return false;\"\n",
        "        \"}\"\n",
        "        \"window.ySelToggle=ySelToggle;\"\n",
        "        \"window.ySelShowSelected=ySelShowSelected;\"\n",
        "        \"window.ySelShowAll=ySelShowAll;\"\n",
        "        \"window.ySelReset=ySelReset;\"\n",
        "        \"document.addEventListener('DOMContentLoaded', function(){ stamp(); load(); }, false);\"\n",
        "        \"})();\\n//]]>\\n</script>\\n</body>\\n</html>\"\n",
        "    )\n",
        "\n",
        "# ---------- 6) DNA-register-style row builder ----------\n",
        "def build_register_row(\n",
        "    row,\n",
        "    id_col: str,\n",
        "    match_col: str,\n",
        "    name_col: str,\n",
        "    cm_col: str,\n",
        "    path_col: str,\n",
        "):\n",
        "    subject_raw = row.get(match_col, \"\")\n",
        "    # Unmask subject if possible, then normalize to same style as main register\n",
        "    key = str(subject_raw).strip().lower()\n",
        "    subject_unmasked = MATCH_TO_UNMASKED.get(key, subject_raw)\n",
        "    subject_name = normalize_person_name(subject_unmasked)\n",
        "    subject_name_html = _html.escape(subject_name or \"\")\n",
        "\n",
        "    pid = extract_person_id(row.get(id_col, \"\"))\n",
        "\n",
        "    matchee_name = norm_matchee_name(row.get(name_col, \"\")) or subject_name\n",
        "    if pid:\n",
        "        name_html = (\n",
        "            '<a href=\"%s/verticalchart.php?personID=%s&tree=%s&parentset=0&display=vertical&generations=15\" '\n",
        "            'target=\"_blank\" rel=\"noopener\">%s</a>'\n",
        "            % (TNG_BASE, pid, TNG_TREE, _html.escape(matchee_name or \"\", quote=False))\n",
        "        )\n",
        "    else:\n",
        "        name_html = _html.escape(matchee_name or \"\", quote=False)\n",
        "\n",
        "    cm_val = row.get(cm_col, \"0\")\n",
        "    tokens = split_tokens(row.get(path_col, \"\"))\n",
        "    gens_total = len(tokens)\n",
        "\n",
        "    if \"common_husband\" in row.index and \"common_wife\" in row.index:\n",
        "        husband_raw = str(row.get(\"common_husband\", \"\")).strip()\n",
        "        wife_raw = str(row.get(\"common_wife\", \"\")).strip()\n",
        "        if not husband_raw and not wife_raw:\n",
        "            husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "    else:\n",
        "        husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "\n",
        "    header_html = build_header(\n",
        "        subject_name_html or subject_name,\n",
        "        cm_val,\n",
        "        name_html,\n",
        "        gens_total,\n",
        "        husband_raw,\n",
        "        wife_raw,\n",
        "    )\n",
        "\n",
        "    return subject_name_html, name_html, _html.escape(str(cm_val).strip()), header_html\n",
        "\n",
        "# ---------- 7) Match Count partial ----------\n",
        "def build_match_count_partial(\n",
        "    main_df: pd.DataFrame,\n",
        "    id_col: str,\n",
        "    match_col: str,\n",
        "    name_col: str,\n",
        "    cm_col: str,\n",
        "    path_col: str,\n",
        ") -> str:\n",
        "    codes_raw = main_df[match_col].astype(str).map(lambda x: x.strip())\n",
        "    keys_norm = codes_raw.map(_norm_code_for_count)\n",
        "\n",
        "    counts_series = keys_norm.value_counts(dropna=False)\n",
        "    counts = counts_series.reset_index()\n",
        "    if counts.shape[1] >= 2:\n",
        "        counts.columns = [\"norm_key\", \"Count\"]\n",
        "    else:\n",
        "        counts[\"norm_key\"] = counts.index.astype(str)\n",
        "        counts[\"Count\"] = counts_series.values\n",
        "        counts = counts[[\"norm_key\", \"Count\"]]\n",
        "\n",
        "    first_display = {}\n",
        "    raw_list = codes_raw.tolist()\n",
        "    norm_list = keys_norm.tolist()\n",
        "    for code_disp, k in zip(raw_list, norm_list):\n",
        "        if k not in first_display and str(k) != \"\":\n",
        "            first_display[k] = code_disp\n",
        "\n",
        "    counts[\"Code\"] = counts[\"norm_key\"].map(lambda k: first_display.get(k, k))\n",
        "    counts[\"Unmasked\"] = counts[\"norm_key\"].map(lambda k: MATCH_TO_UNMASKED.get(k, \"\"))\n",
        "\n",
        "    counts = counts.sort_values(\n",
        "        by=[\"Code\", \"Count\"],\n",
        "        ascending=[True, False],\n",
        "        kind=\"mergesort\",\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    html = []\n",
        "    html.append(_partial_head(\"Match Count\"))\n",
        "    html.append('<table id=\"ref-table\" class=\"sortable\" border=\"1\"><thead><tr>')\n",
        "    html.append(\n",
        "        '<th style=\"width:35%\">Code</th>'\n",
        "        '<th style=\"width:35%\">Unmasked</th>'\n",
        "        '<th style=\"width:30%\">Count</th>'\n",
        "    )\n",
        "    html.append(\"</tr></thead><tbody id=\\\"ref-tb\\\">\")\n",
        "\n",
        "    for _, r in counts.iterrows():\n",
        "        code = r.get(\"Code\", \"\")\n",
        "        unm = r.get(\"Unmasked\", \"\")\n",
        "        cnt = int(str(r.get(\"Count\", \"0\")).strip() or \"0\")\n",
        "        norm_key = _norm_code_for_count(code)\n",
        "        label = (unm or code).strip()\n",
        "        tr = (\n",
        "            \"<tr data-q=\\\"%s\\\" data-count=\\\"%d\\\" data-code=\\\"%s\\\" data-filter=\\\"%s\\\">\"\n",
        "            \"<td>%s</td><td>%s</td>\"\n",
        "            \"<td class=\\\"count\\\">\"\n",
        "            \"<a href=\\\"#\\\" class=\\\"count-pick\\\" onclick=\\\"return ySelToggle(this);\\\" title=\\\"Toggle select\\\">%d</a>\"\n",
        "            \"</td></tr>\"\n",
        "            % (\n",
        "                _html.escape(label, quote=True),\n",
        "                cnt,\n",
        "                _html.escape(norm_key, quote=True),\n",
        "                _html.escape(norm_key, quote=True),\n",
        "                _html.escape(code),\n",
        "                _html.escape(unm),\n",
        "                cnt,\n",
        "            )\n",
        "        )\n",
        "        html.append(tr)\n",
        "\n",
        "    html.append(\"</tbody></table>\")\n",
        "\n",
        "    # DNA Register-style table under Match Count\n",
        "    html.append('<h2 class=\"centerline\">DNA Register rows for selected code(s)</h2>')\n",
        "    html.append(\n",
        "        '<table id=\"reg-list\" class=\"sortable\" border=\"1\">'\n",
        "        '<thead><tr>'\n",
        "        '<th>Match to</th>'\n",
        "        '<th>Name</th>'\n",
        "        '<th>cM</th>'\n",
        "        '<th>Match Summary</th>'\n",
        "        '</tr></thead><tbody>'\n",
        "    )\n",
        "\n",
        "    for _, row in main_df.iterrows():\n",
        "        code_raw = str(row.get(match_col, \"\")).strip()\n",
        "        if not code_raw:\n",
        "            continue\n",
        "        norm_key = _norm_code_for_count(code_raw)\n",
        "\n",
        "        match_to_html, name_html, cm_html, header_html = build_register_row(\n",
        "            row, id_col, match_col, name_col, cm_col, path_col\n",
        "        )\n",
        "\n",
        "        tr = (\n",
        "            \"<tr data-code=\\\"%s\\\" data-filter=\\\"%s\\\">\"\n",
        "            \"<td>%s</td>\"\n",
        "            \"<td>%s</td>\"\n",
        "            \"<td>%s</td>\"\n",
        "            \"<td>%s</td>\"\n",
        "            \"</tr>\"\n",
        "            % (\n",
        "                _html.escape(norm_key, quote=True),\n",
        "                _html.escape(norm_key, quote=True),\n",
        "                match_to_html,\n",
        "                name_html,\n",
        "                cm_html,\n",
        "                header_html,\n",
        "            )\n",
        "        )\n",
        "        html.append(tr)\n",
        "\n",
        "    html.append(\"</tbody></table>\")\n",
        "    html.append(_partial_tail())\n",
        "    return \"\".join(html)\n",
        "\n",
        "# ---------- 8) Lineage Count partial ----------\n",
        "def build_lineage_count_partial(\n",
        "    main_df: pd.DataFrame,\n",
        "    id_col: str,\n",
        "    match_col: str,\n",
        "    name_col: str,\n",
        "    cm_col: str,\n",
        "    path_col: str,\n",
        ") -> str:\n",
        "    first_series = (\n",
        "        main_df.get(\"First Ancestor\", pd.Series(dtype=str))\n",
        "        .astype(str)\n",
        "        .map(lambda x: x.strip())\n",
        "    )\n",
        "    vc = first_series[first_series != \"\"].value_counts(dropna=False)\n",
        "\n",
        "    lin_df = vc.reset_index()\n",
        "    if lin_df.shape[1] >= 2:\n",
        "        lin_df.columns = [\"First Ancestor\", \"Count\"]\n",
        "    else:\n",
        "        lin_df[\"First Ancestor\"] = lin_df.index.astype(str)\n",
        "        lin_df[\"Count\"] = vc.values\n",
        "        lin_df = lin_df[[\"First Ancestor\", \"Count\"]]\n",
        "\n",
        "    lin_df = lin_df.sort_values(\n",
        "        [\"Count\", \"First Ancestor\"],\n",
        "        ascending=[False, True],\n",
        "        kind=\"mergesort\",\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    html = []\n",
        "    html.append(_partial_head(\"Lineage Count\"))\n",
        "    html.append('<table id=\"ref-table\" class=\"sortable\" border=\"1\"><thead><tr>')\n",
        "    html.append(\n",
        "        '<th style=\"width:80%\">First Ancestor</th>'\n",
        "        '<th style=\"width:20%\">Count</th>'\n",
        "    )\n",
        "    html.append(\"</tr></thead><tbody id=\\\"ref-tb\\\">\")\n",
        "\n",
        "    for _, r in lin_df.iterrows():\n",
        "        first = str(r.get(\"First Ancestor\", \"\")).strip()\n",
        "        cnt = int(str(r.get(\"Count\", \"0\")).strip() or \"0\")\n",
        "        tr = (\n",
        "            \"<tr data-q=\\\"%s\\\" data-count=\\\"%d\\\" data-lineage=\\\"%s\\\" data-filter=\\\"%s\\\">\"\n",
        "            \"<td>%s</td>\"\n",
        "            \"<td class=\\\"count\\\">\"\n",
        "            \"<a href=\\\"#\\\" class=\\\"count-pick\\\" onclick=\\\"return ySelToggle(this);\\\" title=\\\"Toggle select\\\">%d</a>\"\n",
        "            \"</td>\"\n",
        "            \"</tr>\"\n",
        "            % (\n",
        "                _html.escape(first, quote=True),\n",
        "                cnt,\n",
        "                _html.escape(first, quote=True),\n",
        "                _html.escape(first, quote=True),\n",
        "                _html.escape(first),\n",
        "                cnt,\n",
        "            )\n",
        "        )\n",
        "        html.append(tr)\n",
        "\n",
        "    html.append(\"</tbody></table>\")\n",
        "\n",
        "    # DNA Register-style table under Lineage Count\n",
        "    html.append('<h2 class=\"centerline\">DNA Register rows for selected lineage(s)</h2>')\n",
        "    html.append(\n",
        "        '<table id=\"reg-list\" class=\"sortable\" border=\"1\">'\n",
        "        '<thead><tr>'\n",
        "        '<th>Match to</th>'\n",
        "        '<th>Name</th>'\n",
        "        '<th>cM</th>'\n",
        "        '<th>Match Summary</th>'\n",
        "        '</tr></thead><tbody>'\n",
        "    )\n",
        "\n",
        "    for _, row in main_df.iterrows():\n",
        "        first = str(row.get(\"First Ancestor\", \"\")).strip()\n",
        "        if not first:\n",
        "            continue\n",
        "\n",
        "        match_to_html, name_html, cm_html, header_html = build_register_row(\n",
        "            row, id_col, match_col, name_col, cm_col, path_col\n",
        "        )\n",
        "\n",
        "        tr = (\n",
        "            \"<tr data-lineage=\\\"%s\\\" data-filter=\\\"%s\\\">\"\n",
        "            \"<td>%s</td>\"\n",
        "            \"<td>%s</td>\"\n",
        "            \"<td>%s</td>\"\n",
        "            \"<td>%s</td>\"\n",
        "            \"</tr>\"\n",
        "            % (\n",
        "                _html.escape(first, quote=True),\n",
        "                _html.escape(first, quote=True),\n",
        "                match_to_html,\n",
        "                name_html,\n",
        "                cm_html,\n",
        "                header_html,\n",
        "            )\n",
        "        )\n",
        "        html.append(tr)\n",
        "\n",
        "    html.append(\"</tbody></table>\")\n",
        "    html.append(_partial_tail())\n",
        "    return \"\".join(html)\n",
        "\n",
        "# ---------- 9) Cousin printable partial ----------\n",
        "def build_cousin_print_partial(main_df: pd.DataFrame, id_col: str, match_col: str, name_col: str, cm_col: str, path_col: str) -> str:\n",
        "    rows = []\n",
        "\n",
        "    for _, row in main_df.iterrows():\n",
        "        subject_raw = row.get(match_col, \"\")\n",
        "        subject_name = normalize_person_name(MATCH_TO_UNMASKED.get(str(subject_raw).strip().lower(), subject_raw))\n",
        "        subject_name_html = \"<strong>%s</strong>\" % subject_name if subject_name else \"\"\n",
        "\n",
        "        pid = extract_person_id(row.get(id_col, \"\"))\n",
        "\n",
        "        matchee_name = norm_matchee_name(row.get(name_col, \"\")) or subject_name\n",
        "        if pid:\n",
        "            matchee_name_html = (\n",
        "                '<a href=\"%s/verticalchart.php?personID=%s&tree=%s&parentset=0&display=vertical&generations=15\" '\n",
        "                'target=\"_blank\" rel=\"noopener\">%s</a>'\n",
        "                % (TNG_BASE, pid, TNG_TREE, matchee_name)\n",
        "            )\n",
        "        else:\n",
        "            matchee_name_html = matchee_name\n",
        "\n",
        "        cm_val = row.get(cm_col, \"0\")\n",
        "        tokens = split_tokens(row.get(path_col, \"\"))\n",
        "        gens_total = len(tokens)\n",
        "\n",
        "        if \"common_husband\" in main_df.columns and \"common_wife\" in main_df.columns:\n",
        "            husband_raw = str(row.get(\"common_husband\", \"\")).strip()\n",
        "            wife_raw = str(row.get(\"common_wife\", \"\")).strip()\n",
        "            if not husband_raw and not wife_raw:\n",
        "                husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "        else:\n",
        "            husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "\n",
        "        header_html = build_header(\n",
        "            subject_name_html or subject_name,\n",
        "            cm_val,\n",
        "            matchee_name_html,\n",
        "            gens_total,\n",
        "            husband_raw,\n",
        "            wife_raw,\n",
        "        )\n",
        "        rows.append(header_html)\n",
        "\n",
        "    rows_sorted = sorted(rows)\n",
        "\n",
        "    html_rows = [\n",
        "        '<table border=\"1\" id=\"refactor-table\" class=\"sortable\"><thead><tr><th>Match Summary</th></tr></thead><tbody>'\n",
        "    ]\n",
        "    for v in rows_sorted:\n",
        "        html_rows.append(\"<tr><td>%s</td></tr>\" % v)\n",
        "    html_rows.append(\"</tbody></table>\")\n",
        "\n",
        "    cousin_html = (\n",
        "        \"<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Transitional//EN\\\" \"\n",
        "        \"\\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\\\">\"\n",
        "        \"<html xmlns=\\\"http://www.w3.org/1999/xhtml\\\" lang=\\\"en\\\"><head>\"\n",
        "        \"%s\" % HEAD_LINK\n",
        "        + \"<meta http-equiv=\\\"Content-Type\\\" content=\\\"text/html; charset=iso-8859-15\\\" />\"\n",
        "        \"<title>Cousin List (Printable)</title>\"\n",
        "        \"</head><body onload=\\\"window.print();\\\">\"\n",
        "        \"<div class=\\\"wrap\\\">\"\n",
        "        \"<h1 class=\\\"centerline\\\">Cousin List (Printable)</h1>\"\n",
        "        \"<div class=\\\"table-scroll\\\">%s</div>\"\n",
        "        \"</div></body></html>\"\n",
        "        % \"\".join(html_rows)\n",
        "    )\n",
        "    return cousin_html\n",
        "\n",
        "# ---------- 10) Main driver ----------\n",
        "def main():\n",
        "    encs = (\"utf-8-sig\", \"utf-8\", \"cp1252\", \"iso-8859-15\", \"latin1\")\n",
        "    last_err = None\n",
        "    df = None\n",
        "    for enc in encs:\n",
        "        try:\n",
        "            df = pd.read_csv(CSV_IN, encoding=enc, dtype=str, keep_default_na=False)\n",
        "            break\n",
        "        except Exception as ex:\n",
        "            last_err = ex\n",
        "            df = None\n",
        "    if df is None:\n",
        "        raise RuntimeError(\"Unable to read CSV: %s (%s)\" % (CSV_IN, last_err))\n",
        "\n",
        "    print(\"[OK] Loaded CSV for counts: %d rows, %d cols\" % (len(df), len(df.columns)))\n",
        "\n",
        "    id_col = find_col(df, [r\"^(id#|personid)$\"], [\"ID#\", \"ID\", \"PersonID\", \"personID\"])\n",
        "    match_col = find_col(df, [r\"^match\\s*to$\"], [\"Match to\", \"Match\", \"match_to\", \"Match_to\"])\n",
        "    name_col = find_col(df, [r\"^name$\"], [\"Name\"])\n",
        "    cm_col = find_col(df, [r\"^(c\\s*:?m|cm)$\", r\"centi.?morgan\"], [\"cM\", \"cm\"])\n",
        "    path_col = find_col(\n",
        "        df,\n",
        "        [r\"(yates\\s*dna\\s*ancestral\\s*line|ancestral\\s*line|lineage)\"],\n",
        "        [\"Yates DNA Ancestral Line\", \"Ancestral Line\", \"Lineage\"],\n",
        "    )\n",
        "\n",
        "    if not match_col:\n",
        "        raise ValueError(\"CSV missing 'Match to' column (try headings like 'Match to' or 'Match').\")\n",
        "    if not path_col:\n",
        "        raise ValueError(\"CSV missing lineage/path column for First Ancestor.\")\n",
        "    if not name_col:\n",
        "        raise ValueError(\"CSV missing 'Name' column.\")\n",
        "    if not cm_col:\n",
        "        raise ValueError(\"CSV missing 'cM' column.\")\n",
        "    if not id_col:\n",
        "        raise ValueError(\"CSV missing an ID#/PersonID column.\")\n",
        "\n",
        "    # Rebuild First Ancestor column from lineage path\n",
        "    first_ancestors = []\n",
        "    for _, row in df.iterrows():\n",
        "        tokens = split_tokens(row.get(path_col, \"\"))\n",
        "        first_ancestors.append(_clean_piece(tokens[0]) if tokens else \"\")\n",
        "    df[\"First Ancestor\"] = first_ancestors\n",
        "\n",
        "    _setup_resolver()\n",
        "    os.makedirs(\"partials\", exist_ok=True)\n",
        "\n",
        "    mc_html = build_match_count_partial(df, id_col, match_col, name_col, cm_col, path_col)\n",
        "    with open(\n",
        "        MATCH_COUNT_LOCAL,\n",
        "        \"w\",\n",
        "        encoding=\"iso-8859-15\",\n",
        "        errors=\"xmlcharrefreplace\",\n",
        "    ) as f:\n",
        "        f.write(mc_html)\n",
        "    print(\"[OK] Wrote partial:\", os.path.abspath(MATCH_COUNT_LOCAL))\n",
        "\n",
        "    lc_html = build_lineage_count_partial(df, id_col, match_col, name_col, cm_col, path_col)\n",
        "    with open(\n",
        "        LINEAGE_COUNT_LOCAL,\n",
        "        \"w\",\n",
        "        encoding=\"iso-8859-15\",\n",
        "        errors=\"xmlcharrefreplace\",\n",
        "    ) as f:\n",
        "        f.write(lc_html)\n",
        "    print(\"[OK] Wrote partial:\", os.path.abspath(LINEAGE_COUNT_LOCAL))\n",
        "\n",
        "    cousin_html = build_cousin_print_partial(df, id_col, match_col, name_col, cm_col, path_col)\n",
        "    with open(\n",
        "        COUSIN_PRINT_LOCAL,\n",
        "        \"w\",\n",
        "        encoding=\"iso-8859-15\",\n",
        "        errors=\"xmlcharrefreplace\",\n",
        "    ) as f:\n",
        "        f.write(cousin_html)\n",
        "    print(\"[OK] Wrote partial:\", os.path.abspath(COUSIN_PRINT_LOCAL))\n",
        "\n",
        "    if not all(os.environ.get(k) for k in [\"FTP_HOST\", \"FTP_USER\", \"FTP_PASS\"]):\n",
        "        print(\"[SKIP] Missing FTP creds; uploads skipped.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        ftps = ftp_connect()\n",
        "\n",
        "        try:\n",
        "            ftp_upload_overwrite(ftps, MATCH_COUNT_LOCAL, _remote_path(MATCH_COUNT_REMOTE))\n",
        "            ftp_upload_overwrite(ftps, LINEAGE_COUNT_LOCAL, _remote_path(LINEAGE_COUNT_REMOTE))\n",
        "            ftp_upload_overwrite(ftps, COUSIN_PRINT_LOCAL, _remote_path(COUSIN_PRINT_REMOTE))\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload partials failed:\", e)\n",
        "\n",
        "        print(\"\\n--- SIZE Verification (if supported) ---\")\n",
        "        for p in [\n",
        "            _remote_path(MATCH_COUNT_REMOTE),\n",
        "            _remote_path(LINEAGE_COUNT_REMOTE),\n",
        "            _remote_path(COUSIN_PRINT_REMOTE),\n",
        "        ]:\n",
        "            sz = ftp_size(ftps, p)\n",
        "            print(\"%s : %s\" % (p, sz if sz is not None else \"(SIZE unsupported)\"))\n",
        "\n",
        "        try:\n",
        "            ftps.quit()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        print(\"\\n--- Open URLs ---\")\n",
        "        print(\"Match Count:      https://yates.one-name.net/partials/match_count.shtml\")\n",
        "        print(\"Lineage Count:    https://yates.one-name.net/partials/lineage_count.shtml\")\n",
        "        print(\"Cousin Printable: https://yates.one-name.net/partials/cousin_list_print.htm\")\n",
        "    except Exception as e:\n",
        "        print(\"[FAIL] FTP session:\", e)\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "# ====== CUT STOP [1/1] CELL 2b ================================================================\n"
      ],
      "metadata": {
        "id": "jPgs2q7E6bFk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6fd918b-8bcf-4ad3-ddd9-3612baf04726"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CONFIRM] Golden Rules active | Cell=Cell2b_Counts | Version=2025.11.15-G6 | Encoding=ISO-8859-15\n",
            "[OK] Loaded CSV for counts: 1596 rows, 6 cols\n",
            "[PULL] match_to_unmasked.csv -> /content/match_to_unmasked.server.csv\n",
            "[OK] Resolver loaded: 83 codes\n",
            "[OK] Wrote partial: /content/partials/match_count.shtml\n",
            "[OK] Wrote partial: /content/partials/lineage_count.shtml\n",
            "[OK] Wrote partial: /content/partials/cousin_list_print.htm\n",
            "[PUT] partials/match_count.shtml -> partials/match_count.shtml\n",
            "[PUT] partials/lineage_count.shtml -> partials/lineage_count.shtml\n",
            "[PUT] partials/cousin_list_print.htm -> partials/cousin_list_print.htm\n",
            "\n",
            "--- SIZE Verification (if supported) ---\n",
            "partials/match_count.shtml : 947703\n",
            "partials/lineage_count.shtml : 1065573\n",
            "partials/cousin_list_print.htm : 527050\n",
            "\n",
            "--- Open URLs ---\n",
            "Match Count:      https://yates.one-name.net/partials/match_count.shtml\n",
            "Lineage Count:    https://yates.one-name.net/partials/lineage_count.shtml\n",
            "Cousin Printable: https://yates.one-name.net/partials/cousin_list_print.htm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 3"
      ],
      "metadata": {
        "id": "INiJljOS1kRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] CELL 3 — Ancestor Register (Old-school Blue Menu; WHITE menu text; .shtml + SSI) ======\n",
        "# RON GOLDEN RULES -- CLIFF NOTES (v2025.11.15)\n",
        "# • Complete & runnable Colab cell -- one contiguous block.\n",
        "# • Source ASCII-only; outputs written with encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\".\n",
        "# • XHTML 1.0 Transitional; typography comes ONLY from /partials/dna_tree_styles.css.\n",
        "# • Deterministic audit:\n",
        "#   [CONFIRM] Golden Rules active | Cell=Cell3_OldSchoolMenu_WhiteText | Version=2025.11.15 | Encoding=ISO-8859-15\n",
        "# • Enforce ISO-8859-15 printable chars on writes\n",
        "print(\"[CONFIRM] Golden Rules active | Cell=Cell3_OldSchoolMenu_WhiteText | Version=2025.11.15 | Encoding=ISO-8859-15\")\n",
        "\n",
        "# ---------- Imports ----------\n",
        "import os, re, socket, posixpath, traceback\n",
        "import pandas as pd\n",
        "import html as _html\n",
        "from ftplib import FTP_TLS\n",
        "from string import Template as _T\n",
        "\n",
        "# Downloads paragraph is now suppressed (links live in nav_block.shtml)\n",
        "DOWNLOADS_BLOCK = \"\"\n",
        "\n",
        "# ---------- Secrets ----------\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ[\"FTP_HOST\"] = userdata.get(\"FTP_HOST\")\n",
        "    os.environ[\"FTP_USER\"] = userdata.get(\"FTP_USER\")\n",
        "    os.environ[\"FTP_PASS\"] = userdata.get(\"FTP_PASS\")\n",
        "    try:\n",
        "        os.environ[\"FTP_PORT\"] = userdata.get(\"FTP_PORT\")\n",
        "    except Exception:\n",
        "        os.environ.setdefault(\"FTP_PORT\", \"21\")\n",
        "    try:\n",
        "        os.environ[\"FTP_DIR\"] = userdata.get(\"FTP_DIR\")\n",
        "    except Exception:\n",
        "        os.environ.setdefault(\"FTP_DIR\", \"\")\n",
        "except Exception:\n",
        "    os.environ.setdefault(\"FTP_HOST\", \"\")\n",
        "    os.environ.setdefault(\"FTP_USER\", \"\")\n",
        "    os.environ.setdefault(\"FTP_PASS\", \"\")\n",
        "    os.environ.setdefault(\"FTP_PORT\", \"21\")\n",
        "    os.environ.setdefault(\"FTP_DIR\", \"\")\n",
        "\n",
        "FTP_DIR = os.environ.get(\"FTP_DIR\", \"\").strip().strip(\"/\")\n",
        "COUNT_PUBLIC_URL = (\"/%s/%s\" % (FTP_DIR, \"autosomal_count.txt\")) if FTP_DIR else \"/autosomal_count.txt\"\n",
        "\n",
        "# ---------- Config / Paths ----------\n",
        "INPUT_CSV = \"final_combined_df_with_value_labels.csv\"\n",
        "\n",
        "EXPORT_BASENAME = \"yates_ancestor_register\"\n",
        "LOCAL_CSV   = EXPORT_BASENAME + \".csv\"\n",
        "LOCAL_XLSX  = EXPORT_BASENAME + \".xlsx\"\n",
        "REMOTE_CSV  = posixpath.join(\"partials\", LOCAL_CSV)\n",
        "REMOTE_XLSX = posixpath.join(\"partials\", LOCAL_XLSX)\n",
        "\n",
        "# This page is now .shtml so Apache will parse SSI\n",
        "OUTPUT_NAME = \"just-trees.shtml\"\n",
        "REMOTE_HTML = posixpath.join(\"partials\", OUTPUT_NAME)\n",
        "\n",
        "# Stylesheet + cache buster (shared with Cell 2)\n",
        "STYLESHEET_HREF = \"/partials/dna_tree_styles.css\"\n",
        "CSS_VERSION     = \"v2025-11-14-g6\"\n",
        "HEAD_LINK = '<link rel=\"stylesheet\" type=\"text/css\" href=\"%s?%s\" />' % (STYLESHEET_HREF, CSS_VERSION)\n",
        "\n",
        "# Layout knob (used for top-scroll inner width)\n",
        "TABLE_WIDTH_PX = 5550\n",
        "\n",
        "# ---------- Load CSV (robust) ----------\n",
        "df = None\n",
        "_last_err = None\n",
        "for enc in (\"utf-8-sig\", \"utf-8\", \"cp1252\", \"iso-8859-15\", \"latin1\"):\n",
        "    try:\n",
        "        df = pd.read_csv(INPUT_CSV, dtype=str, keep_default_na=False, encoding=enc)\n",
        "        break\n",
        "    except Exception as e:\n",
        "        _last_err = e\n",
        "        df = None\n",
        "if df is None:\n",
        "    raise SystemExit(\"[ERROR] Unable to read CSV: %s (%r)\" % (INPUT_CSV, _last_err))\n",
        "print(\"[OK] Loaded CSV: %s rows=%d, cols=%d\" % (INPUT_CSV, len(df), len(df.columns)))\n",
        "\n",
        "# Ensure haplogroup present (harmless for this view)\n",
        "if \"haplogroup\" not in df.columns:\n",
        "    df[\"haplogroup\"] = \"\"\n",
        "else:\n",
        "    df[\"haplogroup\"] = df[\"haplogroup\"].fillna(\"\")\n",
        "\n",
        "# ---------- Resolver: Column B (masked) -> Column C (unmasked) ----------\n",
        "A_IDX = 0\n",
        "B_IDX = 1\n",
        "C_IDX = 2\n",
        "\n",
        "def _norm_code(s):\n",
        "    t = str(s or \"\").strip()\n",
        "    if (t.startswith('\"') and t.endswith('\"')) or (t.startswith(\"'\") and t.endswith(\"'\")):\n",
        "        t = t[1:-1]\n",
        "    t = t.replace(\"\\u00a0\", \" \")\n",
        "    t = re.sub(r\"\\s{2,}\", \" \", t)\n",
        "    return t.lower()\n",
        "\n",
        "# Prefer local-first resolver cached by Cell 1; fall back to server\n",
        "LOCAL_RESOLVER = \"match_to_unmasked.csv\"\n",
        "if not os.path.exists(LOCAL_RESOLVER) and os.path.exists(\"/content/partials/match_to_unmasked.csv\"):\n",
        "    LOCAL_RESOLVER = \"/content/partials/match_to_unmasked.csv\"\n",
        "\n",
        "def _pull_resolver_if_needed(local_path):\n",
        "    if os.path.exists(local_path):\n",
        "        print(\"Using resolver:\", os.path.abspath(local_path))\n",
        "        return local_path\n",
        "    print(\"Resolver not found locally; attempting server pull ...\")\n",
        "    try:\n",
        "        with FTP_TLS(timeout=30) as ftps:\n",
        "            ftps.connect(os.environ.get(\"FTP_HOST\", \"\"), int(os.environ.get(\"FTP_PORT\", \"21\")))\n",
        "            ftps.login(os.environ.get(\"FTP_USER\", \"\"), os.environ.get(\"FTP_PASS\", \"\"))\n",
        "            try:\n",
        "                ftps.prot_p()\n",
        "            except Exception:\n",
        "                pass\n",
        "            try:\n",
        "                ftps.set_pasv(True)\n",
        "            except Exception:\n",
        "                pass\n",
        "            if FTP_DIR:\n",
        "                for p in [p for p in FTP_DIR.split(\"/\") if p]:\n",
        "                    try:\n",
        "                        ftps.cwd(p)\n",
        "                    except Exception:\n",
        "                        try:\n",
        "                            ftps.mkd(p)\n",
        "                        except Exception:\n",
        "                            pass\n",
        "                        ftps.cwd(p)\n",
        "            try:\n",
        "                ftps.cwd(\"partials\")\n",
        "            except Exception:\n",
        "                pass\n",
        "            with open(\"match_to_unmasked.csv\", \"wb\") as f:\n",
        "                ftps.retrbinary(\"RETR match_to_unmasked.csv\", f.write)\n",
        "        print(\"[OK] Pulled resolver from server -> match_to_unmasked.csv\")\n",
        "        return \"match_to_unmasked.csv\"\n",
        "    except Exception as e:\n",
        "        print(\"[WARN] Could not pull resolver from server:\", e)\n",
        "        return local_path\n",
        "\n",
        "LOCAL_RESOLVER = _pull_resolver_if_needed(LOCAL_RESOLVER)\n",
        "\n",
        "def _load_resolver_to_map(path):\n",
        "    last = None\n",
        "    m = None\n",
        "    for enc in (\"utf-8-sig\", \"iso-8859-15\", \"utf-8\", \"cp1252\", \"latin1\"):\n",
        "        try:\n",
        "            m = pd.read_csv(path, dtype=str, keep_default_na=False, encoding=enc)\n",
        "            break\n",
        "        except Exception as e:\n",
        "            last = e\n",
        "            m = None\n",
        "    if m is None:\n",
        "        print(\"[WARN] Resolver not loaded:\", last)\n",
        "        return {}\n",
        "    cols = {c.lower(): c for c in m.columns}\n",
        "    if \"code\" not in cols or \"unmasked\" not in cols:\n",
        "        print(\"[WARN] Resolver missing 'code'/'unmasked' cols; skipping map.\")\n",
        "        return {}\n",
        "    m = m[[cols[\"code\"], cols[\"unmasked\"]]].copy()\n",
        "    m[\"__key__\"] = m[cols[\"code\"]].map(_norm_code)\n",
        "    m[\"__val__\"] = m[cols[\"unmasked\"]].astype(str)\n",
        "    m = m.drop_duplicates(subset=\"__key__\", keep=\"first\")\n",
        "    return dict(zip(m[\"__key__\"], m[\"__val__\"]))\n",
        "\n",
        "resolver_map = _load_resolver_to_map(LOCAL_RESOLVER) if os.path.exists(LOCAL_RESOLVER) else {}\n",
        "\n",
        "if df.shape[1] < 3:\n",
        "    raise ValueError(\"Main df must have at least 3 columns: A(ID#), B(match to), C(unmasked).\")\n",
        "\n",
        "masked_raw = df.iloc[:, B_IDX].astype(str)\n",
        "masked_key = masked_raw.map(_norm_code)\n",
        "resolved   = masked_key.map(resolver_map)\n",
        "df.iloc[:, C_IDX] = resolved.fillna(\"\")\n",
        "\n",
        "print(\n",
        "    \"[OK] Column B -> C mapping: %d / %d  unmatched: %d\"\n",
        "    % (int(resolved.notna().sum()), len(df), len(df) - int(resolved.notna().sum()))\n",
        ")\n",
        "\n",
        "# ---------- Blocks (updated, nav via SSI, controls) ----------\n",
        "UPDATED_BLOCK = (\n",
        "    '<div class=\"updated centerline\">'\n",
        "    'Last updated: <span id=\"last-updated\"></span>'\n",
        "    ' &nbsp;|&nbsp; Autosomal matches: <span id=\"auto-count\" class=\"js-count\"></span>'\n",
        "    ' &nbsp;|&nbsp; Showing: <span id=\"showing-count\"></span>'\n",
        "    \"</div>\"\n",
        ")\n",
        "\n",
        "# Shared nav now comes from SSI include on a .shtml page\n",
        "NAV_BLOCK = '<!--#include virtual=\"/partials/nav_block.shtml\" -->'\n",
        "\n",
        "CONTROLS_BLOCK = (\n",
        "    '<div class=\"controls centerline\" style=\"margin:6px 0 10px 0;\">'\n",
        "    '<input type=\"text\" id=\"search-box\" class=\"search\" size=\"28\" value=\"\" '\n",
        "    'placeholder=\"Search&amp;hellip;\" />'\n",
        "    \"</div>\"\n",
        ")\n",
        "\n",
        "# ---------- HTML table (all current Cell 3 columns, including full lineage) ----------\n",
        "visible_cols = [c for c in df.columns if c]\n",
        "\n",
        "table_html = df.to_html(\n",
        "    index=False,\n",
        "    columns=visible_cols,\n",
        "    escape=False,\n",
        "    border=1,\n",
        "    classes=\"dataframe sortable\"\n",
        ")\n",
        "\n",
        "# Robustly inject id=\"refactor-table\" on the first <table> tag, regardless of attribute order\n",
        "if 'id=\"refactor-table\"' not in table_html:\n",
        "    table_html = re.sub(r\"<table([^>]*)>\", r'<table\\1 id=\"refactor-table\">', table_html, count=1)\n",
        "\n",
        "# Ensure the table has the \"sortable\" class (defensive, in case Pandas changes class output)\n",
        "if 'class=\"dataframe sortable\"' not in table_html and \"sortable\" not in table_html:\n",
        "    table_html = table_html.replace('class=\"dataframe\"', 'class=\"dataframe sortable\"', 1)\n",
        "\n",
        "# Optional: mark first data row\n",
        "table_html = table_html.replace(\"<tbody>\\n<tr>\", \"<tbody>\\n<tr id=\\\"first-row\\\">\", 1)\n",
        "\n",
        "# ---------- Build scroll wrapper (top visible, bottom real) ----------\n",
        "SCROLL_WRAPPER = (\n",
        "    '<div class=\"table-scroll-wrapper\">'\n",
        "    '<div id=\"top-scroll\" class=\"scroll-sync-top\">'\n",
        "    '<div class=\"scroll-sync-top-inner\" style=\"width:%dpx;\"></div>'\n",
        "    '</div>'\n",
        "    '<div id=\"bottom-scroll\" class=\"table-scroll\">%s</div>'\n",
        "    '</div>'\n",
        ") % (TABLE_WIDTH_PX, table_html)\n",
        "\n",
        "# ---------- XHTML page template (top+bottom scrollbars, sticky column 2) ----------\n",
        "page_tpl = _T(\"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "<title>Ancestor Register (Trees View)</title>\n",
        "$HEAD_LINK\n",
        "<style type=\"text/css\">\n",
        "/* Sticky second column (index 2) for Trees table */\n",
        "#refactor-table th:nth-child(2),\n",
        "#refactor-table td:nth-child(2){\n",
        "  position:sticky;\n",
        "  left:0;\n",
        "  z-index:6;\n",
        "  background:#ffffff;\n",
        "}\n",
        "#refactor-table th:nth-child(2){\n",
        "  z-index:7;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body id=\"top\">\n",
        "<div class=\"wrap\">\n",
        "  <h1 class=\"centerline\">Ancestor Register (Trees View)</h1>\n",
        "  $DOWNLOADS_BLOCK\n",
        "  $UPDATED_BLOCK\n",
        "  $NAV_BLOCK\n",
        "  $CONTROLS_BLOCK\n",
        "  $SCROLL_WRAPPER\n",
        "</div>\n",
        "<button id=\"back-to-top\" class=\"back-to-top\">&#9650; Top</button>\n",
        "<script type=\"text/javascript\">\n",
        "//<![CDATA[\n",
        "(function(){\n",
        "  function textOf(cell){\n",
        "    return (cell && (cell.textContent || cell.innerText) || '').replace(/\\\\s+/g,' ').trim().toLowerCase();\n",
        "  }\n",
        "  function sortTable(tbl, colIndex, dir){\n",
        "    var tb = tbl && tbl.tBodies ? tbl.tBodies[0] : null;\n",
        "    if(!tb) return;\n",
        "    var rows = [].slice.call(tb.rows || []);\n",
        "    var asc  = (dir === 'asc');\n",
        "    rows.sort(function(a,b){\n",
        "      var A = textOf(a.cells[colIndex]), B = textOf(b.cells[colIndex]);\n",
        "      var nA = parseFloat(A.replace(/[^0-9.\\\\-]/g,'')),\n",
        "          nB = parseFloat(B.replace(/[^0-9.\\\\-]/g,''));\n",
        "      if(!isNaN(nA) && !isNaN(nB)){ return asc ? (nA-nB) : (nB-nA); }\n",
        "      if (A < B) return asc ? -1 : 1;\n",
        "      if (A > B) return asc ?  1 : -1;\n",
        "      return 0;\n",
        "    });\n",
        "    var frag = document.createDocumentFragment();\n",
        "    for(var i=0;i<rows.length;i++) frag.appendChild(rows[i]);\n",
        "    tb.appendChild(frag);\n",
        "    updateShowing();\n",
        "  }\n",
        "  function bindHeaderSort(){\n",
        "    var tbl = document.getElementById('refactor-table');\n",
        "    if(!(tbl && tbl.tHead && tbl.tHead.rows.length)) return;\n",
        "    var ths = tbl.tHead.rows[0].cells;\n",
        "    if(!ths) return;\n",
        "    for(var i=0;i<ths.length;i++)(function(idx){\n",
        "      var th = ths[idx];\n",
        "      var dir = 'asc';\n",
        "      th.addEventListener('click', function(){\n",
        "        dir = (dir === 'asc') ? 'desc' : 'asc';\n",
        "        for (var j = 0; j < ths.length; j++){\n",
        "          ths[j].innerHTML = ths[j].innerHTML.replace(/\\\\s+\\\\(asc\\\\)|\\\\s+\\\\(desc\\\\)/,'');\n",
        "        }\n",
        "        th.innerHTML += (dir === 'asc' ? ' (asc)' : ' (desc)');\n",
        "        sortTable(tbl, idx, dir);\n",
        "      }, false);\n",
        "    })(i);\n",
        "  }\n",
        "  function formatWithCommas(n){\n",
        "    try{\n",
        "      var x = parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10);\n",
        "      if(isNaN(x)) return '';\n",
        "      return x.toLocaleString('en-US');\n",
        "    }catch(e){ return String(n||''); }\n",
        "  }\n",
        "  function visibleRowCount(){\n",
        "    var tbl = document.getElementById('refactor-table');\n",
        "    if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return 0;\n",
        "    var rows = tbl.tBodies[0].rows, n = 0;\n",
        "    for(var i=0;i<rows.length;i++){\n",
        "      if(rows[i].style.display !== 'none') n++;\n",
        "    }\n",
        "    return n;\n",
        "  }\n",
        "  function updateShowing(){\n",
        "    var el = document.getElementById('showing-count');\n",
        "    if(!el) return;\n",
        "    el.textContent = formatWithCommas(visibleRowCount());\n",
        "  }\n",
        "  function getParam(name){\n",
        "    var m = location.search.match(new RegExp('[?&]'+name+'=([^&]+)'));\n",
        "    return m ? decodeURIComponent(m[1].replace(/\\\\+/g,' ')) : '';\n",
        "  }\n",
        "  function bindSearch(){\n",
        "    var box = document.getElementById('search-box');\n",
        "    var tbl = document.getElementById('refactor-table');\n",
        "    if(!(box && tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "    var tb = tbl.tBodies[0];\n",
        "    var rows = [].slice.call(tb.rows || []);\n",
        "    function rowText(tr){\n",
        "      var t = '';\n",
        "      for(var i=0;i<tr.cells.length;i++){\n",
        "        t += ' ' + (tr.cells[i].textContent || tr.cells[i].innerText || '');\n",
        "      }\n",
        "      return t.replace(/\\\\s+/g,' ').toLowerCase();\n",
        "    }\n",
        "    function apply(q){\n",
        "      q = String(q || '').toLowerCase();\n",
        "      for(var i=0;i<rows.length;i++){\n",
        "        var txt = rowText(rows[i]);\n",
        "        var show = !q || txt.indexOf(q) > -1;\n",
        "        rows[i].style.display = show ? '' : 'none';\n",
        "      }\n",
        "      updateShowing();\n",
        "    }\n",
        "    var to = null;\n",
        "    function onInput(){\n",
        "      if(to) clearTimeout(to);\n",
        "      to = setTimeout(function(){ apply(box.value); }, 60);\n",
        "    }\n",
        "    box.addEventListener('input', onInput, false);\n",
        "    box.addEventListener('search', onInput, false);\n",
        "    var q0 = getParam('q');\n",
        "    if(q0){\n",
        "      box.value = q0;\n",
        "      apply(q0);\n",
        "      try{ history.replaceState(null,'',location.pathname); }catch(e){}\n",
        "    } else {\n",
        "      box.value = '';\n",
        "      apply('');\n",
        "    }\n",
        "  }\n",
        "  function bindBackToTop(){\n",
        "    var btn = document.getElementById('back-to-top');\n",
        "    if(!btn) return;\n",
        "    function toggle(){ btn.style.display = (window.scrollY > 200 ? 'block' : 'none'); }\n",
        "    toggle();\n",
        "    window.addEventListener('scroll', toggle, {passive:true});\n",
        "    btn.addEventListener('click', function(){\n",
        "      try{\n",
        "        window.scrollTo({top:0, behavior:'smooth'});\n",
        "      } catch(e){\n",
        "        window.scrollTo(0,0);\n",
        "      }\n",
        "    }, false);\n",
        "  }\n",
        "  function stampAndCount(){\n",
        "    var el = document.getElementById('last-updated');\n",
        "    if(el){\n",
        "      var d = new Date(document.lastModified || new Date());\n",
        "      var months = ['January','February','March','April','May','June','July','August','September','October','November','December'];\n",
        "      var day = d.getDate();\n",
        "      var month = months[d.getMonth()];\n",
        "      var year = d.getFullYear();\n",
        "      var hour = d.getHours();\n",
        "      var min  = d.getMinutes();\n",
        "      var ampm = hour >= 12 ? 'pm' : 'am';\n",
        "      hour = hour % 12;\n",
        "      hour = hour ? hour : 12;\n",
        "      var minStr = min < 10 ? '0' + min : String(min);\n",
        "      el.innerHTML = day + ' ' + month + ', ' + year + ' at ' + hour + ':' + minStr + ' ' + ampm;\n",
        "    }\n",
        "    var elc = document.getElementById('auto-count');\n",
        "    if(!elc) return;\n",
        "    var URL = '$JS_COUNT_URL';\n",
        "    try{\n",
        "      var xhr = new XMLHttpRequest();\n",
        "      xhr.open('GET', URL + (URL.indexOf('?') > -1 ? '' : '?v=' + (new Date()).getTime()), true);\n",
        "      xhr.onreadystatechange = function(){\n",
        "        if(xhr.readyState === 4){\n",
        "          if(xhr.status >= 200 && xhr.status < 300){\n",
        "            var m = (xhr.responseText || '').match(/(\\\\d+)/);\n",
        "            elc.textContent = (m ? m[1] : '');\n",
        "          } else {\n",
        "            elc.textContent = '(unavailable)';\n",
        "          }\n",
        "        }\n",
        "      };\n",
        "      xhr.send(null);\n",
        "    } catch(e){\n",
        "      elc.textContent = '(unavailable)';\n",
        "    }\n",
        "  }\n",
        "  function bindSyncedScrollbars(){\n",
        "    var topScroll    = document.getElementById('top-scroll');\n",
        "    var bottomScroll = document.getElementById('bottom-scroll');\n",
        "    if(!(topScroll && bottomScroll)) return;\n",
        "    var syncing = false;\n",
        "    topScroll.addEventListener('scroll', function(){\n",
        "      if(syncing) return;\n",
        "      syncing = true;\n",
        "      bottomScroll.scrollLeft = topScroll.scrollLeft;\n",
        "      syncing = false;\n",
        "    }, false);\n",
        "    bottomScroll.addEventListener('scroll', function(){\n",
        "      if(syncing) return;\n",
        "      syncing = true;\n",
        "      topScroll.scrollLeft = bottomScroll.scrollLeft;\n",
        "      syncing = false;\n",
        "    }, false);\n",
        "  }\n",
        "  document.addEventListener('DOMContentLoaded', function(){\n",
        "    bindHeaderSort();\n",
        "    bindBackToTop();\n",
        "    bindSearch();\n",
        "    bindSyncedScrollbars();\n",
        "    stampAndCount();\n",
        "    updateShowing();\n",
        "  });\n",
        "})();\n",
        "//]]>\n",
        "</script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\")\n",
        "\n",
        "final_html = page_tpl.safe_substitute(\n",
        "    HEAD_LINK=HEAD_LINK,\n",
        "    DOWNLOADS_BLOCK=DOWNLOADS_BLOCK,\n",
        "    UPDATED_BLOCK=UPDATED_BLOCK,\n",
        "    NAV_BLOCK=NAV_BLOCK,\n",
        "    CONTROLS_BLOCK=CONTROLS_BLOCK,\n",
        "    SCROLL_WRAPPER=SCROLL_WRAPPER,\n",
        "    JS_COUNT_URL=COUNT_PUBLIC_URL\n",
        ")\n",
        "\n",
        "# ---------- Exports ----------\n",
        "export_df = df.copy()\n",
        "export_df.to_csv(LOCAL_CSV, index=False, encoding=\"iso-8859-15\")\n",
        "try:\n",
        "    export_df.to_excel(LOCAL_XLSX, index=False)\n",
        "except Exception:\n",
        "    from pandas import ExcelWriter\n",
        "    with ExcelWriter(LOCAL_XLSX) as _w:\n",
        "        export_df.to_excel(_w, index=False)\n",
        "print(\"[OK] Wrote exports:\", os.path.abspath(LOCAL_CSV), \"and\", os.path.abspath(LOCAL_XLSX))\n",
        "\n",
        "# ---------- Save page locally ----------\n",
        "try:\n",
        "    with open(OUTPUT_NAME, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(final_html)\n",
        "    print(\"[OK] Saved locally:\", os.path.abspath(OUTPUT_NAME))\n",
        "except Exception as e:\n",
        "    print(\"[ERROR] Save failed:\", e)\n",
        "    traceback.print_exc()\n",
        "\n",
        "# ---------- Upload to /partials ----------\n",
        "def _ftps_ensure_dir(ftps, path):\n",
        "    if not path:\n",
        "        return\n",
        "    for seg in [p for p in path.split(\"/\") if p]:\n",
        "        try:\n",
        "            ftps.cwd(seg)\n",
        "        except Exception:\n",
        "            try:\n",
        "                ftps.mkd(seg)\n",
        "            except Exception:\n",
        "                pass\n",
        "            ftps.cwd(seg)\n",
        "\n",
        "ftp_host = os.environ.get(\"FTP_HOST\")\n",
        "ftp_user = os.environ.get(\"FTP_USER\")\n",
        "ftp_pass = os.environ.get(\"FTP_PASS\")\n",
        "ftp_port = int(os.environ.get(\"FTP_PORT\", \"21\") or \"21\")\n",
        "\n",
        "if ftp_host and ftp_user and ftp_pass:\n",
        "    print(\"[INFO] Attempting FTP upload ...\")\n",
        "    try:\n",
        "        socket.setdefaulttimeout(30)\n",
        "        with FTP_TLS(timeout=30) as ftps:\n",
        "            ftps.connect(ftp_host, ftp_port)\n",
        "            ftps.login(ftp_user, ftp_pass)\n",
        "            try:\n",
        "                ftps.prot_p()\n",
        "            except Exception:\n",
        "                pass\n",
        "            try:\n",
        "                ftps.set_pasv(True)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "            _ftps_ensure_dir(ftps, FTP_DIR)\n",
        "            _ftps_ensure_dir(ftps, \"partials\")\n",
        "\n",
        "            # Upload HTML (.shtml for SSI)\n",
        "            with open(OUTPUT_NAME, \"rb\") as fh:\n",
        "                ftps.storbinary(\"STOR \" + os.path.basename(REMOTE_HTML), fh)\n",
        "            print(\"[OK] Uploaded HTML -> /partials/%s\" % os.path.basename(REMOTE_HTML))\n",
        "\n",
        "            # Upload CSV/XLSX\n",
        "            with open(LOCAL_CSV, \"rb\") as fh:\n",
        "                ftps.storbinary(\"STOR \" + os.path.basename(REMOTE_CSV), fh)\n",
        "            with open(LOCAL_XLSX, \"rb\") as fh:\n",
        "                ftps.storbinary(\"STOR \" + os.path.basename(REMOTE_XLSX), fh)\n",
        "            print(\"[OK] Uploaded exports -> /partials/ (%s, %s)\" % (LOCAL_CSV, LOCAL_XLSX))\n",
        "\n",
        "            print(\"\\n--- Open URLs ---\")\n",
        "            print(\"Trees page:       https://yates.one-name.net/partials/just-trees.shtml\")\n",
        "            print(\"CSV export:       https://yates.one-name.net/partials/%s\" % os.path.basename(LOCAL_CSV))\n",
        "            print(\"Excel export:     https://yates.one-name.net/partials/%s\" % os.path.basename(LOCAL_XLSX))\n",
        "    except Exception as e:\n",
        "        print(\"[ERROR] FTP session failed:\", e)\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"[INFO] Skipping FTP upload (missing credentials).\")\n",
        "\n",
        "print(\"\\n--- Cell 3 Complete (.shtml + SSI nav; TOP visible scroll + hidden bottom; sticky col 2; sortable/searchable with 'Showing' count; exports + upload ready) ---\")\n",
        "# ====== CUT STOP  [1/1] CELL 3 ==================================================================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG87x38Bgu1a",
        "outputId": "93c745a1-f680-42f1-eefa-42b6b09b4a35"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CONFIRM] Golden Rules active | Cell=Cell3_OldSchoolMenu_WhiteText | Version=2025.11.15 | Encoding=ISO-8859-15\n",
            "[OK] Loaded CSV: final_combined_df_with_value_labels.csv rows=1596, cols=6\n",
            "Using resolver: /content/match_to_unmasked.csv\n",
            "[OK] Column B -> C mapping: 1596 / 1596  unmatched: 0\n",
            "[OK] Wrote exports: /content/yates_ancestor_register.csv and /content/yates_ancestor_register.xlsx\n",
            "[OK] Saved locally: /content/just-trees.shtml\n",
            "[INFO] Attempting FTP upload ...\n",
            "[OK] Uploaded HTML -> /partials/just-trees.shtml\n",
            "[OK] Uploaded exports -> /partials/ (yates_ancestor_register.csv, yates_ancestor_register.xlsx)\n",
            "\n",
            "--- Open URLs ---\n",
            "Trees page:       https://yates.one-name.net/partials/just-trees.shtml\n",
            "CSV export:       https://yates.one-name.net/partials/yates_ancestor_register.csv\n",
            "Excel export:     https://yates.one-name.net/partials/yates_ancestor_register.xlsx\n",
            "\n",
            "--- Cell 3 Complete (.shtml + SSI nav; TOP visible scroll + hidden bottom; sticky col 2; sortable/searchable with 'Showing' count; exports + upload ready) ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Cell 1"
      ],
      "metadata": {
        "id": "z7m2W6TOv1Xy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_mz2RUXmpqto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] CELL 2 - Build + Publish DNA Register (All styling via stylesheet) ======\n",
        "# RON GOLDEN RULES - CLIFF NOTES (v2025.11.21-G3)\n",
        "# - Complete & runnable Colab cell - one contiguous block.\n",
        "# - Source ASCII-only; outputs written with encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\".\n",
        "# - XHTML 1.0 Transitional; typography/layout via /partials/dna_tree_styles.css (this cell writes it).\n",
        "# - Deterministic audit:\n",
        "#   [CONFIRM] Golden Rules active | Cell=Cell2_AllStyles_ExternalCSS | Version=2025.11.21-G3 | Encoding=ISO-8859-15\n",
        "# - Enforce ISO-8859-15 printable chars on writes.\n",
        "\n",
        "print(\"[CONFIRM] Golden Rules active | Cell=Cell2_AllStyles_ExternalCSS | Version=2025.11.21-G3 | Encoding=ISO-8859-15\")\n",
        "\n",
        "import os, re, posixpath, socket, traceback, urllib.parse as _u\n",
        "from ftplib import FTP_TLS\n",
        "import pandas as pd\n",
        "import html as _html\n",
        "from string import Template\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Configuration: paths, filenames, environment hooks\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "# Local base directory inside Colab runtime\n",
        "LOCAL_BASE_DIR          = \"/content\"\n",
        "\n",
        "# Where partials live locally (mirrors server /partials)\n",
        "LOCAL_PARTIALS_DIR      = os.path.join(LOCAL_BASE_DIR, \"partials\")\n",
        "os.makedirs(LOCAL_PARTIALS_DIR, exist_ok=True)\n",
        "\n",
        "# Server paths (relative to ftp root)\n",
        "SERVER_PARTIALS_DIR        = \"partials\"\n",
        "SERVER_MAPPING_BASENAME    = \"match_to_unmasked.csv\"\n",
        "SERVER_MAPPING_REMOTE      = posixpath.join(SERVER_PARTIALS_DIR, SERVER_MAPPING_BASENAME)\n",
        "SERVER_MAPPING_LOCAL_CACHE = \"match_to_unmasked.server.csv\"\n",
        "\n",
        "# Stylesheet\n",
        "STYLESHEET_BASENAME = \"dna_tree_styles.css\"\n",
        "STYLESHEET_LOCAL    = os.path.join(\"partials\", STYLESHEET_BASENAME)\n",
        "STYLESHEET_REMOTE   = posixpath.join(\"partials\", STYLESHEET_BASENAME)\n",
        "CSS_VERSION         = \"v2025-11-21-g3\"\n",
        "STYLESHEET_HREF     = \"/partials/%s?%s\" % (STYLESHEET_BASENAME, CSS_VERSION)\n",
        "HEAD_LINK           = '<link rel=\"stylesheet\" type=\"text/css\" href=\"%s\" />' % STYLESHEET_HREF\n",
        "\n",
        "# Output basenames (register + downloadables)\n",
        "REGISTER_HTML_BASENAME = \"ons_yates_dna_register.htm\"\n",
        "REGISTER_HTML_LOCAL    = os.path.join(\"partials\", REGISTER_HTML_BASENAME)\n",
        "REGISTER_HTML_REMOTE   = posixpath.join(\"partials\", REGISTER_HTML_BASENAME)\n",
        "\n",
        "REGISTER_CSV_BASENAME  = \"yates_ancestor_register.csv\"\n",
        "REGISTER_XLSX_BASENAME = \"yates_ancestor_register.xlsx\"\n",
        "REGISTER_CSV_LOCAL     = os.path.join(\"partials\", REGISTER_CSV_BASENAME)\n",
        "REGISTER_XLSX_LOCAL    = os.path.join(\"partials\", REGISTER_XLSX_BASENAME)\n",
        "REGISTER_CSV_REMOTE    = posixpath.join(\"partials\", REGISTER_CSV_BASENAME)\n",
        "REGISTER_XLSX_REMOTE   = posixpath.join(\"partials\", REGISTER_XLSX_BASENAME)\n",
        "\n",
        "# Main input CSV from Cell 1 (or equivalent)\n",
        "INPUT_CSV_LOCAL = os.path.join(LOCAL_BASE_DIR, \"yates_ancestor_register.csv\")\n",
        "\n",
        "# Table layout knobs\n",
        "TABLE_TOTAL_WIDTH_PX = 3480  # used to feed CSS var --table-width-px\n",
        "\n",
        "# FTP / FTPS configuration via environment variables\n",
        "FTP_HOST   = os.environ.get(\"YATES_FTP_HOST\",   \"\").strip()\n",
        "FTP_USER   = os.environ.get(\"YATES_FTP_USER\",   \"\").strip()\n",
        "FTP_PASS   = os.environ.get(\"YATES_FTP_PASS\",   \"\").strip()\n",
        "FTP_PORT   = int(os.environ.get(\"YATES_FTP_PORT\", \"21\").strip() or \"21\")\n",
        "FTP_TIMEOUT = 30\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Helper: enforce ISO-8859-15 safe writes\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def _safe_open(path, mode=\"w\", encoding=\"iso-8859-15\"):\n",
        "  \"\"\"\n",
        "  Open file with ISO-8859-15 and xmlcharrefreplace for non-Latin characters.\n",
        "  \"\"\"\n",
        "  return open(path, mode, encoding=encoding, errors=\"xmlcharrefreplace\")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Unified stylesheet (with sticky + iOS tweaks)\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "CSS_TEXT = \"\"\"/* yates.one-name.net - DNA pages (unified stylesheet)\n",
        "   Version: %s\n",
        "   Note: Typography, layout, colors, borders - centralized here. */\n",
        "\n",
        ":root {\n",
        "  /* Default; Cell 2 can overwrite this via inline style if desired */\n",
        "  --table-width-px: %dpx;\n",
        "  --brand-blue: #5b79b8;\n",
        "  --brand-blue-dark: #4668aa;\n",
        "  --line: #dddddd;\n",
        "  --line-strong: #999999;\n",
        "}\n",
        "\n",
        "/* --------------------------------------------------------- */\n",
        "/* Base typography / layout                                  */\n",
        "/* --------------------------------------------------------- */\n",
        "\n",
        "html, body {\n",
        "  margin:0;\n",
        "  padding:0;\n",
        "  font-family: \"Times New Roman\", Times, serif;\n",
        "  font-size: 16px;\n",
        "  line-height: 1.35;\n",
        "  color:#111111;\n",
        "  background:#ffffff;\n",
        "}\n",
        "\n",
        ".wrap {\n",
        "  max-width:100%%;\n",
        "  margin:0 auto;\n",
        "  background:#ffffff;\n",
        "  padding:16px;\n",
        "  padding-bottom:48px;\n",
        "}\n",
        "\n",
        ".centerline { text-align:center; }\n",
        "\n",
        ".downloads {\n",
        "  text-align:center;\n",
        "  margin:4px 0 10px 0;\n",
        "  font-size: 13px;\n",
        "}\n",
        "\n",
        ".updated {\n",
        "  font-size: 12px;\n",
        "  color:#555555;\n",
        "  text-align:center;\n",
        "  margin:2px 0 10px 0;\n",
        "}\n",
        "\n",
        ".left-align { text-align:left; }\n",
        "\n",
        "/* --------------------------------------------------------- */\n",
        "/* Two-scroll layout (main DNA register, trees view, etc.)   */\n",
        "/* --------------------------------------------------------- */\n",
        "\n",
        "/* Outer wrapper used by Cell 2 / Cell 3 */\n",
        ".table-scroll-wrapper {\n",
        "  width:100%%;\n",
        "  max-width:100%%;\n",
        "  margin:0 auto;\n",
        "}\n",
        "\n",
        "/* Top visible horizontal scrollbar (no content, just bar) */\n",
        ".scroll-sync-top {\n",
        "  width:100%%;\n",
        "  max-width:100%%;\n",
        "  overflow-x:auto;\n",
        "  overflow-y:hidden;\n",
        "  border:1px solid var(--line);\n",
        "  border-bottom:none;\n",
        "  -webkit-overflow-scrolling:touch; /* iOS Safari helper */\n",
        "}\n",
        "\n",
        ".scroll-sync-top-inner {\n",
        "  height:1px; /* no visible content; width is set inline */\n",
        "}\n",
        "\n",
        "/* Bottom scroll container holding the real table */\n",
        ".table-scroll {\n",
        "  width:100%%;\n",
        "  max-width:100%%;\n",
        "  max-height:80vh;\n",
        "  overflow-x:auto;\n",
        "  overflow-y:auto;\n",
        "  border:1px solid var(--line);\n",
        "  border-top:none;\n",
        "  position:relative;\n",
        "\n",
        "  /* iOS Safari: keep sticky + scrolling happy */\n",
        "  -webkit-overflow-scrolling:touch;\n",
        "\n",
        "  /* Hide native scrollbar where possible (visual only) */\n",
        "  scrollbar-width:none;      /* Firefox */\n",
        "  -ms-overflow-style:none;   /* IE/Edge legacy */\n",
        "}\n",
        "\n",
        ".table-scroll::-webkit-scrollbar {\n",
        "  display:none;              /* WebKit / Blink */\n",
        "}\n",
        "\n",
        "/* Single-scroll usage (partials, cousin_print, etc.) can reuse .table-scroll\n",
        "   without the .table-scroll-wrapper / .scroll-sync-top if desired. */\n",
        "\n",
        "/* --------------------------------------------------------- */\n",
        "/* Tables (Pandas / sortable / register tables)              */\n",
        "/* --------------------------------------------------------- */\n",
        "\n",
        "table.sortable {\n",
        "  border-collapse:separate;\n",
        "  border-spacing:0;\n",
        "}\n",
        "\n",
        "table.sortable th,\n",
        "table.sortable td {\n",
        "  border:1px solid var(--line);\n",
        "  padding:6px 8px;\n",
        "  vertical-align:top;\n",
        "  white-space:nowrap;\n",
        "}\n",
        "\n",
        "/* Sticky header row for all sortable tables (desktop + iOS) */\n",
        "table.sortable th {\n",
        "  background:#e3eaf8;\n",
        "  text-align:left;\n",
        "  position:-webkit-sticky;   /* iOS Safari */\n",
        "  position:sticky;\n",
        "  top:0;\n",
        "  z-index:5;\n",
        "  box-shadow:0 1px 0 #cccccc;\n",
        "  cursor:pointer;\n",
        "}\n",
        "\n",
        "/* First data row marker (for visual separation) */\n",
        "#first-row td {\n",
        "  border-top:2px solid var(--line-strong);\n",
        "}\n",
        "\n",
        "/* --------------------------------------------------------- */\n",
        "/* Sticky first column on key DNA tables                     */\n",
        "/* --------------------------------------------------------- */\n",
        "\n",
        "/* Keep the first column (codes / labels) fixed on scroll\n",
        "   for match, lineage, and refactor tables. */\n",
        "#match-table th:first-child,\n",
        "#match-table td:first-child,\n",
        "#lineage-table th:first-child,\n",
        "#lineage-table td:first-child,\n",
        "#refactor-table th:first-child,\n",
        "#refactor-table td:first-child {\n",
        "  position:-webkit-sticky;   /* iOS Safari */\n",
        "  position:sticky;\n",
        "  left:0;\n",
        "  z-index:6;\n",
        "  background:#ffffff;\n",
        "}\n",
        "\n",
        "/* Header cell that is both top-sticky and left-sticky:\n",
        "   bump z-index and keep header color. */\n",
        "#match-table thead th:first-child,\n",
        "#lineage-table thead th:first-child,\n",
        "#refactor-table thead th:first-child {\n",
        "  background:#e3eaf8;\n",
        "  z-index:7;\n",
        "}\n",
        "\n",
        "/* Optional: legacy dna-register-table class support */\n",
        "table.dna-register-table th:nth-child(1),\n",
        "table.dna-register-table td:nth-child(1) {\n",
        "  position:-webkit-sticky;\n",
        "  position:sticky;\n",
        "  left:0;\n",
        "  z-index:6;\n",
        "  background:#ffffff;\n",
        "}\n",
        "table.dna-register-table thead th:nth-child(1) {\n",
        "  background:#e3eaf8;\n",
        "  z-index:7;\n",
        "}\n",
        "\n",
        "/* --------------------------------------------------------- */\n",
        "/* Back-to-top button                                        */\n",
        "/* --------------------------------------------------------- */\n",
        "\n",
        ".back-to-top {\n",
        "  position:fixed;\n",
        "  right:16px;\n",
        "  bottom:16px;\n",
        "  padding:6px 10px;\n",
        "  border:1px solid #3e5a97;\n",
        "  background:var(--brand-blue);\n",
        "  color:#ffffff;\n",
        "  cursor:pointer;\n",
        "  border-radius:6px;\n",
        "  display:none;\n",
        "  z-index:9999;\n",
        "}\n",
        "\n",
        ".back-to-top:hover {\n",
        "  background:var(--brand-blue-dark);\n",
        "}\n",
        "\n",
        "/* --------------------------------------------------------- */\n",
        "/* Controls (search, selection menu, etc.)                   */\n",
        "/* --------------------------------------------------------- */\n",
        "\n",
        ".controls {\n",
        "  text-align:center;\n",
        "}\n",
        "\n",
        ".controls-spaced {\n",
        "  margin:6px 0 10px 0;\n",
        "}\n",
        "\n",
        ".search {\n",
        "  font-size: 14px;\n",
        "  padding:5px 8px;\n",
        "}\n",
        "\n",
        ".selection-menu {\n",
        "  margin:6px 0 10px 0;\n",
        "  font-size: 14px;\n",
        "}\n",
        "\n",
        ".selection-menu a {\n",
        "  text-decoration:none;\n",
        "}\n",
        "\n",
        "/* --------------------------------------------------------- */\n",
        "/* Old-school blue nav menu                                  */\n",
        "/* --------------------------------------------------------- */\n",
        "\n",
        ".oldnav {\n",
        "  margin:8px auto 6px auto;\n",
        "  padding:0;\n",
        "  background:var(--brand-blue);\n",
        "  border-radius:6px;\n",
        "  overflow:hidden;\n",
        "  max-width: var(--table-width-px);\n",
        "}\n",
        "\n",
        ".oldnav ul {\n",
        "  list-style:none;\n",
        "  margin:0;\n",
        "  padding:0;\n",
        "  display:flex;\n",
        "  flex-wrap:wrap;\n",
        "}\n",
        "\n",
        ".oldnav li {\n",
        "  margin:0;\n",
        "  padding:0;\n",
        "}\n",
        "\n",
        ".oldnav a,\n",
        ".oldnav a:link,\n",
        ".oldnav a:visited,\n",
        ".oldnav a:active {\n",
        "  color:#ffffff !important;\n",
        "}\n",
        "\n",
        ".oldnav a {\n",
        "  display:block;\n",
        "  padding:8px 12px;\n",
        "  text-decoration:none;\n",
        "  white-space:nowrap;\n",
        "  border-right:1px solid #ffffff;\n",
        "  font-weight:600;\n",
        "}\n",
        "\n",
        ".oldnav li:last-child a {\n",
        "  border-right:none;\n",
        "}\n",
        "\n",
        ".oldnav a:hover {\n",
        "  background:#4668aa;\n",
        "  color:#ffffff !important;\n",
        "}\n",
        "\n",
        "/* --------------------------------------------------------- */\n",
        "/* Responsive tweaks                                         */\n",
        "/* --------------------------------------------------------- */\n",
        "\n",
        "@media screen and (min-width: 1200px) {\n",
        "  .wrap {\n",
        "    max-width: var(--table-width-px);\n",
        "  }\n",
        "}\n",
        "\n",
        "@media screen and (max-width: 1199px) {\n",
        "  .oldnav {\n",
        "    border-radius:0;\n",
        "  }\n",
        "}\n",
        "\n",
        "@media screen and (max-width: 700px) {\n",
        "  table.sortable th,\n",
        "  table.sortable td {\n",
        "    padding:5px 6px;\n",
        "  }\n",
        "}\n",
        "\n",
        "/* --------------------------------------------------------- */\n",
        "/* Selection highlighting (robust, across all DNA pages)     */\n",
        "/* --------------------------------------------------------- */\n",
        "\n",
        "/* Baseline: any row that JS has tagged as selected */\n",
        "tr[data-selected=\"1\"],\n",
        "tr.sel-row {\n",
        "  background-color: #fff8b3 !important;   /* soft yellow */\n",
        "  font-weight: 600;                        /* bold text */\n",
        "}\n",
        "\n",
        "/* Add a left border anchor so selection is obvious even if\n",
        "   background rendering is odd in some browsers/contexts. */\n",
        ".table-scroll table tr[data-selected=\"1\"],\n",
        "#ref-table tr[data-selected=\"1\"],\n",
        "#match-table tr[data-selected=\"1\"],\n",
        "#lineage-table tr[data-selected=\"1\"],\n",
        "#refactor-table tr[data-selected=\"1\"],\n",
        "#reg-list tr[data-selected=\"1\"],\n",
        ".table-scroll table tr.sel-row,\n",
        "#ref-table tr.sel-row,\n",
        "#match-table tr.sel-row,\n",
        "#lineage-table tr.sel-row,\n",
        "#refactor-table tr.sel-row,\n",
        "#reg-list tr.sel-row {\n",
        "  border-left: 4px solid #d4a300 !important;\n",
        "}\n",
        "\n",
        "/* Legacy rule from earlier versions (kept for safety) */\n",
        "#match-table tr.sel-row,\n",
        "#lineage-table tr.sel-row,\n",
        "#refactor-table tr.sel-row,\n",
        ".table-scroll table tr.sel-row {\n",
        "  background-color: #ffffcc !important;\n",
        "}\n",
        "\n",
        "/* --------------------------------------------------------- */\n",
        "/* Print overrides (cousin list and other print views)       */\n",
        "/* --------------------------------------------------------- */\n",
        "\n",
        "@media print {\n",
        "\n",
        "  /* Let scroll containers expand and show all rows */\n",
        "  .table-scroll,\n",
        "  .table-scroll-wrapper,\n",
        "  .scroll-sync-top {\n",
        "    max-height: none !important;\n",
        "    overflow: visible !important;\n",
        "    border:none !important;\n",
        "  }\n",
        "\n",
        "  /* Hide non-essential chrome on printout */\n",
        "  nav.oldnav,\n",
        "  .oldnav,\n",
        "  .updated,\n",
        "  .downloads,\n",
        "  .selection-menu,\n",
        "  .back-to-top {\n",
        "    display: none !important;\n",
        "  }\n",
        "\n",
        "  /* Ensure tables themselves are visible */\n",
        "  #refactor-table,\n",
        "  #ref-table,\n",
        "  #match-table,\n",
        "  #lineage-table,\n",
        "  #reg-list,\n",
        "  .table-scroll table {\n",
        "    display: table !important;\n",
        "  }\n",
        "\n",
        "  /* Slightly nicer print layout */\n",
        "  body {\n",
        "    margin: 10mm;\n",
        "    font-size: 11pt;\n",
        "  }\n",
        "\n",
        "  /* Keep selected rows visible in print as well */\n",
        "  tr[data-selected=\"1\"],\n",
        "  tr.sel-row {\n",
        "    background-color:#fff8b3 !important;\n",
        "    font-weight:600;\n",
        "  }\n",
        "}\n",
        "\n",
        "/* -------------------------- END unified stylesheet ------------------------ */\n",
        "\"\"\" % (\n",
        "    CSS_VERSION,\n",
        "    TABLE_TOTAL_WIDTH_PX,\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# HTML templates for full page + table\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "HTML_TEMPLATE = Template(r\"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "<title>ONS Yates Study Autosomal DNA Register</title>\n",
        "%s\n",
        "</head>\n",
        "<body id=\"top\">\n",
        "<div class=\"wrap\">\n",
        "  <h1 class=\"centerline\">ONS Yates Study Autosomal DNA Register</h1>\n",
        "  <p class=\"downloads centerline\">Download: <a href=\"/partials/yates_ancestor_register.csv\">CSV</a> | <a href=\"/partials/yates_ancestor_register.xlsx\">Excel</a></p>\n",
        "  <div class=\"updated centerline\">Last updated: <span id=\"last-updated\"></span> &nbsp;|&nbsp; <a href=\"#refactor-table\">Jump to register</a></div>\n",
        "\n",
        "  <!--#include virtual=\"/partials/nav_block.shtml\" -->\n",
        "\n",
        "  <div class=\"controls controls-spaced\">\n",
        "    <input type=\"text\" id=\"search-box\" class=\"search\" placeholder=\"Quick filter by name, kit, line, etc.\" />\n",
        "  </div>\n",
        "\n",
        "  <div class=\"table-scroll-wrapper\">\n",
        "    <div class=\"scroll-sync-top\">\n",
        "      <div class=\"scroll-sync-top-inner\" id=\"scroll-sync-top-inner\"></div>\n",
        "    </div>\n",
        "    <div class=\"table-scroll\" id=\"table-scroll\">\n",
        "      $TABLE_HTML\n",
        "    </div>\n",
        "  </div>\n",
        "\n",
        "  <div class=\"back-to-top\" id=\"back-to-top\">Back to top</div>\n",
        "</div>\n",
        "\n",
        "<script type=\"text/javascript\">\n",
        "// simple text helper\n",
        "function _txt(node){\n",
        "  return (node && node.textContent) ? node.textContent.replace(/\\\\s+/g,\" \").trim() : \"\";\n",
        "}\n",
        "\n",
        "// sync the top scrollbar\n",
        "(function(){\n",
        "  var topOuter = document.querySelector('.scroll-sync-top');\n",
        "  var topInner = document.getElementById('scroll-sync-top-inner');\n",
        "  var scroll   = document.getElementById('table-scroll');\n",
        "\n",
        "  if(!topOuter || !topInner || !scroll) return;\n",
        "\n",
        "  function syncWidth(){\n",
        "    if(!scroll || !scroll.firstElementChild) return;\n",
        "    var w = scroll.firstElementChild.scrollWidth || scroll.scrollWidth || 0;\n",
        "    topInner.style.width = w + 'px';\n",
        "  }\n",
        "\n",
        "  syncWidth();\n",
        "  window.addEventListener('resize', syncWidth);\n",
        "\n",
        "  topOuter.addEventListener('scroll', function(){\n",
        "    scroll.scrollLeft = topOuter.scrollLeft;\n",
        "  });\n",
        "  scroll.addEventListener('scroll', function(){\n",
        "    topOuter.scrollLeft = scroll.scrollLeft;\n",
        "  });\n",
        "})();\n",
        "\n",
        "// simple in-page filter\n",
        "(function(){\n",
        "  var box = document.getElementById('search-box');\n",
        "  var tbl = document.getElementById('refactor-table');\n",
        "  if(!box || !tbl || !tbl.tBodies.length) return;\n",
        "\n",
        "  var tb = tbl.tBodies[0];\n",
        "\n",
        "  function textOfRow(tr){\n",
        "    var txt = '';\n",
        "    for(var i=0;i<tr.cells.length;i++){\n",
        "      txt += ' ' + _txt(tr.cells[i]);\n",
        "    }\n",
        "    return txt.toLowerCase();\n",
        "  }\n",
        "\n",
        "  var cache = [];\n",
        "  (function buildCache(){\n",
        "    var rows = tb.rows || [];\n",
        "    for(var i=0;i<rows.length;i++){\n",
        "      cache.push({\n",
        "        row: rows[i],\n",
        "        text: textOfRow(rows[i])\n",
        "      });\n",
        "    }\n",
        "  })();\n",
        "\n",
        "  box.addEventListener('input', function(){\n",
        "    var q = (box.value || '').toLowerCase();\n",
        "    for(var i=0;i<cache.length;i++){\n",
        "      var c = cache[i];\n",
        "      if(!q){\n",
        "        c.row.style.display = '';\n",
        "      } else {\n",
        "        c.row.style.display = (c.text.indexOf(q) !== -1) ? '' : 'none';\n",
        "      }\n",
        "    }\n",
        "  });\n",
        "})();\n",
        "\n",
        "// sortable headers\n",
        "(function(){\n",
        "  function textOf(cell){\n",
        "    return _txt(cell).toLowerCase();\n",
        "  }\n",
        "\n",
        "  function sortTable(tbl, colIndex, dir){\n",
        "    var tb = tbl && tbl.tBodies ? tbl.tBodies[0] : null;\n",
        "    if(!tb) return;\n",
        "    var rows = Array.prototype.slice.call(tb.rows || []);\n",
        "    var asc  = (dir === 'asc');\n",
        "\n",
        "    rows.sort(function(a,b){\n",
        "      var A = textOf(a.cells[colIndex]),\n",
        "          B = textOf(b.cells[colIndex]);\n",
        "\n",
        "      var nA = parseFloat(A.replace(/[^0-9.\\\\-]/g,'')),\n",
        "          nB = parseFloat(B.replace(/[^0-9.\\\\-]/g,''));\n",
        "\n",
        "      if(!isNaN(nA) && !isNaN(nB) && (A === String(nA)) && (B === String(nB))){\n",
        "        return asc ? (nA - nB) : (nB - nA);\n",
        "      }\n",
        "\n",
        "      if(A < B) return asc ? -1 : 1;\n",
        "      if(A > B) return asc ?  1 : -1;\n",
        "      return 0;\n",
        "    });\n",
        "\n",
        "    var frag = document.createDocumentFragment();\n",
        "    for(var i=0;i<rows.length;i++){\n",
        "      frag.appendChild(rows[i]);\n",
        "    }\n",
        "    tb.appendChild(frag);\n",
        "  }\n",
        "\n",
        "  function bindHeaderSort(){\n",
        "    var tbl = document.getElementById('refactor-table');\n",
        "    if(!(tbl && tbl.tHead && tbl.tHead.rows.length)) return;\n",
        "\n",
        "    var ths = tbl.tHead.rows[0].cells;\n",
        "    if(!ths) return;\n",
        "\n",
        "    for(var i=0;i<ths.length;i++){\n",
        "      (function(idx){\n",
        "        var th  = ths[idx];\n",
        "        var dir = 'asc';\n",
        "        th.addEventListener('click', function(){\n",
        "          sortTable(tbl, idx, dir);\n",
        "          dir = (dir === 'asc') ? 'desc' : 'asc';\n",
        "        });\n",
        "      })(i);\n",
        "    }\n",
        "  }\n",
        "\n",
        "  if(document.readyState === 'loading'){\n",
        "    document.addEventListener('DOMContentLoaded', bindHeaderSort);\n",
        "  } else {\n",
        "    bindHeaderSort();\n",
        "  }\n",
        "})();\n",
        "\n",
        "// back-to-top button\n",
        "(function(){\n",
        "  var btn = document.getElementById('back-to-top');\n",
        "  if(!btn) return;\n",
        "\n",
        "  window.addEventListener('scroll', function(){\n",
        "    var y = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop || 0;\n",
        "    btn.style.display = (y > 400) ? 'block' : 'none';\n",
        "  });\n",
        "\n",
        "  btn.addEventListener('click', function(e){\n",
        "    e.preventDefault();\n",
        "    if(window.scrollTo){\n",
        "      window.scrollTo({ top: 0, behavior: 'smooth' });\n",
        "    } else {\n",
        "      window.scrollTo(0,0);\n",
        "    }\n",
        "  });\n",
        "})();\n",
        "\n",
        "// last-updated stamp (uses document.lastModified)\n",
        "(function(){\n",
        "  var span = document.getElementById('last-updated');\n",
        "  if(!span) return;\n",
        "  var lm = document.lastModified || '';\n",
        "  span.textContent = lm;\n",
        "})();\n",
        "</script>\n",
        "\n",
        "</body>\n",
        "</html>\n",
        "\"\"\" % HEAD_LINK)\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Utility: basic FTP/FTPS upload with TLS\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def ftps_upload(local_path, remote_path):\n",
        "  \"\"\"\n",
        "  Upload a local file to the FTPS server using explicit TLS.\n",
        "  \"\"\"\n",
        "  if not (FTP_HOST and FTP_USER and FTP_PASS):\n",
        "    print(\"[WARN] FTP credentials not fully set; skipping upload for\", remote_path)\n",
        "    return\n",
        "\n",
        "  print(\"[FTPS] Connecting to %s:%d...\" % (FTP_HOST, FTP_PORT))\n",
        "  ftps = FTP_TLS()\n",
        "  ftps.connect(FTP_HOST, FTP_PORT, timeout=FTP_TIMEOUT)\n",
        "  ftps.auth()\n",
        "  ftps.prot_p()\n",
        "  ftps.login(FTP_USER, FTP_PASS)\n",
        "\n",
        "  # Ensure we are at root, then navigate path\n",
        "  dirname, basename = posixpath.split(remote_path)\n",
        "  if dirname:\n",
        "    parts = [p for p in dirname.split(\"/\") if p]\n",
        "    for p in parts:\n",
        "      try:\n",
        "        ftps.cwd(p)\n",
        "      except Exception:\n",
        "        try:\n",
        "          ftps.mkd(p)\n",
        "          ftps.cwd(p)\n",
        "        except Exception as e:\n",
        "          print(\"[FTPS] Error ensuring directory %r: %s\" % (p, e))\n",
        "          raise\n",
        "\n",
        "  with open(local_path, \"rb\") as f:\n",
        "    print(\"[FTPS] STOR %s\" % basename)\n",
        "    ftps.storbinary(\"STOR \" + basename, f)\n",
        "\n",
        "  ftps.quit()\n",
        "  print(\"[FTPS] Upload complete for\", remote_path)\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Load data, write CSV/XLSX and HTML\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "try:\n",
        "  # Load main register CSV\n",
        "  print(\"[INFO] Loading input register CSV:\", INPUT_CSV_LOCAL)\n",
        "  df = pd.read_csv(INPUT_CSV_LOCAL, dtype=str).fillna(\"\")\n",
        "\n",
        "  # Persist working CSV/XLSX for downloads\n",
        "  print(\"[INFO] Writing CSV to:\", REGISTER_CSV_LOCAL)\n",
        "  df.to_csv(REGISTER_CSV_LOCAL, index=False, encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\")\n",
        "\n",
        "  print(\"[INFO] Writing XLSX to:\", REGISTER_XLSX_LOCAL)\n",
        "  df.to_excel(REGISTER_XLSX_LOCAL, index=False)\n",
        "\n",
        "  # Build HTML table\n",
        "  print(\"[INFO] Building HTML table for register...\")\n",
        "  table_html = df.to_html(\n",
        "      index=False,\n",
        "      classes=[\"dataframe\", \"sortable\", \"dna-register-table\"],\n",
        "      table_id=\"refactor-table\",\n",
        "      escape=False,\n",
        "      border=0\n",
        "  )\n",
        "\n",
        "  # Plug into full HTML template\n",
        "  full_html = HTML_TEMPLATE.substitute(TABLE_HTML=table_html)\n",
        "\n",
        "  # Ensure partials dir exists\n",
        "  os.makedirs(os.path.dirname(REGISTER_HTML_LOCAL), exist_ok=True)\n",
        "\n",
        "  print(\"[INFO] Writing HTML register to:\", REGISTER_HTML_LOCAL)\n",
        "  with _safe_open(REGISTER_HTML_LOCAL, \"w\") as f:\n",
        "    f.write(full_html)\n",
        "\n",
        "  # Write unified stylesheet\n",
        "  print(\"[INFO] Writing unified stylesheet to:\", STYLESHEET_LOCAL)\n",
        "  with _safe_open(STYLESHEET_LOCAL, \"w\") as f_css:\n",
        "    f_css.write(CSS_TEXT)\n",
        "\n",
        "  # Upload assets via FTPS\n",
        "  print(\"[INFO] Starting FTPS uploads...\")\n",
        "  ftps_upload(REGISTER_HTML_LOCAL,  REGISTER_HTML_REMOTE)\n",
        "  ftps_upload(REGISTER_CSV_LOCAL,   REGISTER_CSV_REMOTE)\n",
        "  ftps_upload(REGISTER_XLSX_LOCAL,  REGISTER_XLSX_REMOTE)\n",
        "  ftps_upload(STYLESHEET_LOCAL,     STYLESHEET_REMOTE)\n",
        "\n",
        "  print(\"[DONE] Cell 2 completed successfully.\")\n",
        "\n",
        "except Exception as e:\n",
        "  print(\"[ERROR] Cell 2 failed:\", e)\n",
        "  traceback.print_exc()\n",
        "\n",
        "# ====== CUT END [1/1] CELL 2 - Build + Publish DNA Register (All styling via stylesheet) ======\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27pn7wvz1cZC",
        "outputId": "ac3699c5-374e-4a55-88cc-23f1c8ffce6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CONFIRM] Golden Rules active | Cell=Cell2_AllStyles_ExternalCSS | Version=2025.11.21-G3 | Encoding=ISO-8859-15\n",
            "[INFO] Loading input register CSV: /content/yates_ancestor_register.csv\n",
            "[ERROR] Cell 2 failed: 'utf-8' codec can't decode byte 0xef in position 238263: invalid continuation byte\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-3775920501.py\", line 725, in <cell line: 0>\n",
            "    df = pd.read_csv(INPUT_CSV_LOCAL, dtype=str).fillna(\"\")\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
            "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
            "    self._engine = self._make_engine(f, self.engine)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\", line 1898, in _make_engine\n",
            "    return mapping[engine](f, **self.options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/c_parser_wrapper.py\", line 93, in __init__\n",
            "    self._reader = parsers.TextReader(src, **kwds)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"parsers.pyx\", line 574, in pandas._libs.parsers.TextReader.__cinit__\n",
            "  File \"parsers.pyx\", line 663, in pandas._libs.parsers.TextReader._get_header\n",
            "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
            "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
            "  File \"parsers.pyx\", line 2053, in pandas._libs.parsers.raise_parser_error\n",
            "  File \"<frozen codecs>\", line 322, in decode\n",
            "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xef in position 238263: invalid continuation byte\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Cell 2"
      ],
      "metadata": {
        "id": "RaCwZHY-4F-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] CELL 2 — Build + Publish DNA Register (All styling via stylesheet) ======\n",
        "# RON GOLDEN RULES — CLIFF NOTES (v2025.11.25-G1)\n",
        "# - Complete and runnable Colab cell, one contiguous block.\n",
        "# - Source ASCII-only; outputs written with encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\".\n",
        "# - XHTML 1.0 Transitional; typography/layout via /partials/dna_tree_styles.css (this cell writes it).\n",
        "# - Deterministic audit:\n",
        "#   [CONFIRM] Golden Rules active | Cell=Cell2_AllStyles_ExternalCSS | Version=2025.11.25-G1 | Encoding=ISO-8859-15\n",
        "# - Enforce ISO-8859-15 printable chars on writes.\n",
        "\n",
        "print(\"[CONFIRM] Golden Rules active | Cell=Cell2_AllStyles_ExternalCSS | Version=2025.11.25-G1 | Encoding=ISO-8859-15\")\n",
        "\n",
        "import os, re, posixpath, socket, traceback, urllib.parse as _u\n",
        "from ftplib import FTP_TLS\n",
        "import pandas as pd\n",
        "import html as _html\n",
        "from string import Template\n",
        "\n",
        "# ---------- A) LAYOUT CONTROL BLOCK (ONE PLACE TO TUNE WIDTHS) ----------\n",
        "# Logical columns:\n",
        "#   Col 1 = Match to\n",
        "#   Col 2 = Name\n",
        "#   Col 3 = cM\n",
        "#   Col 4 = Match Summary\n",
        "#   Col 5 = Website\n",
        "#   Col 6 = Yates DNA Ancestral Lines\n",
        "#\n",
        "# For HTML display we currently RENDER ONLY columns 1, 4, and 6.\n",
        "# Columns 2, 3, and 5 remain in the CSV/XLSX exports but are not shown in the HTML table.\n",
        "\n",
        "COL_1_PX = 80\n",
        "COL_2_PX = 220\n",
        "COL_3_PX = 60\n",
        "COL_4_PX = 1200\n",
        "COL_5_PX = 120\n",
        "COL_6_PX = 1800\n",
        "\n",
        "COL_WIDTHS = [COL_1_PX, COL_2_PX, COL_3_PX, COL_4_PX, COL_5_PX, COL_6_PX]\n",
        "\n",
        "# Indices of columns we render in the HTML table: 0=Match to, 3=Match Summary, 5=Lineage\n",
        "VISIBLE_COL_INDEXES = [0, 3, 5]\n",
        "\n",
        "TABLE_TOTAL_WIDTH_PX = sum(COL_WIDTHS[i] for i in VISIBLE_COL_INDEXES)\n",
        "\n",
        "print(\"[LAYOUT] TABLE_TOTAL_WIDTH_PX=%d\" % TABLE_TOTAL_WIDTH_PX)\n",
        "print(\"[LAYOUT] Column widths (px): 1=%d 2=%d 3=%d 4=%d 5=%d 6=%d\" %\n",
        "      (COL_1_PX, COL_2_PX, COL_3_PX, COL_4_PX, COL_5_PX, COL_6_PX))\n",
        "print(\"[LAYOUT] Visible HTML columns (0-based indexes): %s\" % VISIBLE_COL_INDEXES)\n",
        "\n",
        "# ---------- 0) Secrets ----------\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ[\"FTP_HOST\"] = userdata.get(\"FTP_HOST\")\n",
        "    os.environ[\"FTP_USER\"] = userdata.get(\"FTP_USER\")\n",
        "    os.environ[\"FTP_PASS\"] = userdata.get(\"FTP_PASS\")\n",
        "    try:\n",
        "        os.environ[\"FTP_DIR\"] = userdata.get(\"FTP_DIR\")\n",
        "    except Exception:\n",
        "        os.environ.setdefault(\"FTP_DIR\", \"\")\n",
        "    try:\n",
        "        os.environ[\"FTP_PORT\"] = userdata.get(\"FTP_PORT\")\n",
        "    except Exception:\n",
        "        os.environ.setdefault(\"FTP_PORT\", \"21\")\n",
        "except Exception:\n",
        "    os.environ.setdefault(\"FTP_HOST\", \"\")\n",
        "    os.environ.setdefault(\"FTP_USER\", \"\")\n",
        "    os.environ.setdefault(\"FTP_PASS\", \"\")\n",
        "    os.environ.setdefault(\"FTP_DIR\", \"\")\n",
        "    os.environ.setdefault(\"FTP_PORT\", \"21\")\n",
        "\n",
        "# ---------- 1) Config ----------\n",
        "CSV_IN = \"final_combined_df_with_value_labels.csv\"\n",
        "\n",
        "# NOTE: main register pages now .shtml (SSI pages only)\n",
        "LOCAL_HTML        = \"yates_ancestor_register.shtml\"\n",
        "REMOTE_HTML_CANON = posixpath.join(\"partials\", \"yates_ancestor_register.shtml\")\n",
        "REMOTE_HTML_LEG   = posixpath.join(\"partials\", \"ons_yates_dna_register.shtml\")\n",
        "\n",
        "DNA_REGISTER_ABS = \"https://yates.one-name.net/partials/ons_yates_dna_register.shtml\"\n",
        "TREES_ABS        = \"https://yates.one-name.net/partials/just-trees.htm\"\n",
        "\n",
        "EXPORT_BASENAME = \"yates_ancestor_register\"\n",
        "LOCAL_CSV  = \"%s.csv\"  % EXPORT_BASENAME\n",
        "LOCAL_XLSX = \"%s.xlsx\" % EXPORT_BASENAME\n",
        "REMOTE_CSV  = posixpath.join(\"partials\", os.path.basename(LOCAL_CSV))\n",
        "REMOTE_XLSX = posixpath.join(\"partials\", os.path.basename(LOCAL_XLSX))\n",
        "\n",
        "FTP_DIR  = (os.environ.get(\"FTP_DIR\", \"\") or \"\").strip()\n",
        "TNG_BASE = \"https://yates.one-name.net/tng\"\n",
        "TNG_TREE = \"tree1\"\n",
        "\n",
        "# Name-page now .shtml as well\n",
        "HOME_URL = \"https://yates.one-name.net/partials/yates_ancestor_register.shtml\"\n",
        "REMOTE_NAME_ABS = HOME_URL\n",
        "\n",
        "ARROW_ENTITY         = \"&rarr;\"\n",
        "REMOVE_PERIOD_AT_END = True\n",
        "\n",
        "SERVER_PARTIALS_DIR        = \"partials\"\n",
        "SERVER_MAPPING_BASENAME    = \"match_to_unmasked.csv\"\n",
        "SERVER_MAPPING_REMOTE      = posixpath.join(SERVER_PARTIALS_DIR, SERVER_MAPPING_BASENAME)\n",
        "SERVER_MAPPING_LOCAL_CACHE = \"match_to_unmasked.server.csv\"\n",
        "\n",
        "# Stylesheet\n",
        "STYLESHEET_BASENAME = \"dna_tree_styles.css\"\n",
        "STYLESHEET_LOCAL    = os.path.join(\"partials\", STYLESHEET_BASENAME)\n",
        "STYLESHEET_REMOTE   = posixpath.join(\"partials\", STYLESHEET_BASENAME)\n",
        "CSS_VERSION         = \"v2025-11-25-g1\"\n",
        "STYLESHEET_HREF     = \"/partials/%s?%s\" % (STYLESHEET_BASENAME, CSS_VERSION)\n",
        "HEAD_LINK           = '<link rel=\"stylesheet\" type=\"text/css\" href=\"%s\" />' % STYLESHEET_HREF\n",
        "\n",
        "# Path for vitals from Cell 1\n",
        "VITALS_CSV = \"dna_vitals.csv\"\n",
        "\n",
        "# ---------- 2) FTP ----------\n",
        "FTP_TIMEOUT = int(os.environ.get(\"FTP_TIMEOUT\", \"30\"))\n",
        "FTP_PASSIVE = True\n",
        "\n",
        "def ftp_connect() -> FTP_TLS:\n",
        "    ftps = FTP_TLS(timeout=FTP_TIMEOUT)\n",
        "    socket.setdefaulttimeout(FTP_TIMEOUT)\n",
        "    ftps.connect(os.environ.get(\"FTP_HOST\", \"\"), int(os.environ.get(\"FTP_PORT\", 21)))\n",
        "    ftps.login(os.environ.get(\"FTP_USER\", \"\"), os.environ.get(\"FTP_PASS\", \"\"))\n",
        "    try:\n",
        "        ftps.prot_p()\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        ftps.set_pasv(FTP_PASSIVE)\n",
        "    except Exception:\n",
        "        pass\n",
        "    if FTP_DIR:\n",
        "        for p in [p for p in FTP_DIR.split(\"/\") if p]:\n",
        "            try:\n",
        "                ftps.mkd(p)\n",
        "            except Exception:\n",
        "                pass\n",
        "            ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "def _remote_path(name: str) -> str:\n",
        "    return posixpath.join(FTP_DIR, name) if FTP_DIR else name\n",
        "\n",
        "def ensure_remote_dirs(ftps, remote_path):\n",
        "    if \"/\" not in remote_path:\n",
        "        return\n",
        "    pwd0 = ftps.pwd()\n",
        "    for seg in [p for p in remote_path.split(\"/\")[:-1] if p and p != \".\"]:\n",
        "        try:\n",
        "            ftps.cwd(seg)\n",
        "        except Exception:\n",
        "            try:\n",
        "                ftps.mkd(seg)\n",
        "            except Exception:\n",
        "                pass\n",
        "            ftps.cwd(seg)\n",
        "    ftps.cwd(pwd0)\n",
        "\n",
        "def ftp_download_if_exists(ftps, remote_name, local_name) -> bool:\n",
        "    try:\n",
        "        with open(local_name, \"wb\") as f:\n",
        "            ftps.retrbinary(\"RETR %s\" % remote_name, f.write)\n",
        "        print(\"[PULL] %s -> %s\" % (remote_name, os.path.abspath(local_name)))\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            if os.path.exists(local_name):\n",
        "                os.remove(local_name)\n",
        "        except Exception:\n",
        "            pass\n",
        "        print(\"[MISS] %s (%s)\" % (remote_name, e))\n",
        "        return False\n",
        "\n",
        "def ftp_upload_overwrite(ftps, local_path, remote_name):\n",
        "    ensure_remote_dirs(ftps, remote_name)\n",
        "    with open(local_path, \"rb\") as fh:\n",
        "        ftps.storbinary(\"STOR %s\" % remote_name, fh)\n",
        "    print(\"[PUT] %s -> %s\" % (local_path, remote_name))\n",
        "\n",
        "def ftp_size(ftps, remote_name):\n",
        "    try:\n",
        "        sz = ftps.size(remote_name)\n",
        "        return int(sz) if sz is not None else None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# ---------- 3) Resolver ----------\n",
        "def _read_mapping_csv(path: str) -> pd.DataFrame:\n",
        "    encs = (\"iso-8859-15\", \"utf-8-sig\", \"utf-8\", \"cp1252\", \"latin1\")\n",
        "    last = None\n",
        "    df = None\n",
        "    for enc in encs:\n",
        "        try:\n",
        "            df = pd.read_csv(path, encoding=enc, dtype=str, keep_default_na=False)\n",
        "            break\n",
        "        except Exception as e:\n",
        "            last = e\n",
        "            df = None\n",
        "    if df is None:\n",
        "        raise RuntimeError(\"Unable to read mapping CSV %s: %s\" % (path, last))\n",
        "    if df.shape[1] < 2:\n",
        "        raise RuntimeError(\"Mapping CSV must have at least two columns: code, unmasked\")\n",
        "    df = df.iloc[:, :2].copy()\n",
        "    df.columns = [\"code\", \"unmasked\"]\n",
        "    df[\"code\"]     = df[\"code\"].astype(str).str.strip().str.lower()\n",
        "    df[\"unmasked\"] = df[\"unmasked\"].astype(str).str.strip()\n",
        "    df = df[df[\"code\"] != \"\"].drop_duplicates(subset=[\"code\"], keep=\"first\")\n",
        "    if df.empty:\n",
        "        raise RuntimeError(\"Mapping CSV empty after normalization.\")\n",
        "    return df\n",
        "\n",
        "def load_resolver_from_server() -> dict:\n",
        "    with ftp_connect() as ftps:\n",
        "        try:\n",
        "            ftps.cwd(SERVER_PARTIALS_DIR)\n",
        "        except Exception:\n",
        "            pass\n",
        "        ok = ftp_download_if_exists(ftps, SERVER_MAPPING_BASENAME, SERVER_MAPPING_LOCAL_CACHE)\n",
        "        try:\n",
        "            ftps.quit()\n",
        "        except Exception:\n",
        "            pass\n",
        "    if not ok:\n",
        "        raise RuntimeError(\n",
        "            \"Resolver not found on server: /%s. Upload match_to_unmasked.csv into /partials/ and re-run.\"\n",
        "            % _remote_path(SERVER_MAPPING_REMOTE)\n",
        "        )\n",
        "    df_map = _read_mapping_csv(SERVER_MAPPING_LOCAL_CACHE)\n",
        "    print(\"[OK] Resolver loaded: %d codes\" % len(df_map))\n",
        "    return dict(zip(df_map[\"code\"], df_map[\"unmasked\"]))\n",
        "\n",
        "MATCH_TO_UNMASKED = {}\n",
        "\n",
        "def _setup_resolver():\n",
        "    global MATCH_TO_UNMASKED\n",
        "    if not MATCH_TO_UNMASKED:\n",
        "        MATCH_TO_UNMASKED = load_resolver_from_server()\n",
        "\n",
        "def resolve_match_to(code: str) -> str:\n",
        "    if not isinstance(code, str):\n",
        "        return \"\"\n",
        "    return MATCH_TO_UNMASKED.get(code.strip().lower(), code)\n",
        "\n",
        "# ---------- 4) Name/text utils ----------\n",
        "SEP_RE = re.compile(r\"\\s*(?:\\u2192|&rarr;|;|>|,|~{2,}|/{2,}|\\|{2,})\\s*\")\n",
        "\n",
        "def split_tokens(s):\n",
        "    if pd.isna(s):\n",
        "        return []\n",
        "    if not isinstance(s, str):\n",
        "        s = str(s)\n",
        "    return [p.strip() for p in SEP_RE.split(s) if str(p).strip()]\n",
        "\n",
        "def _clean_piece(text: str) -> str:\n",
        "    t = re.sub(r\"~+\", \" \", str(text))\n",
        "    t = re.sub(r\"\\s+\", \" \", t)\n",
        "    return t.strip()\n",
        "\n",
        "_PARTICLES = {\n",
        "    \"de\", \"del\", \"della\", \"der\", \"van\", \"von\", \"da\", \"dos\", \"das\", \"di\", \"la\", \"le\", \"du\", \"of\"\n",
        "}\n",
        "\n",
        "def _smart_title(token: str) -> str:\n",
        "    if not token:\n",
        "        return token\n",
        "    token = re.sub(\n",
        "        r\"(^|\\b)([a-z])(['’])([a-z])\",\n",
        "        lambda m: m.group(1) + m.group(2).upper() + m.group(3) + m.group(4).upper(),\n",
        "        token.lower(),\n",
        "    )\n",
        "    token = \"-\".join([w.capitalize() for w in token.split(\"-\")])\n",
        "    token = re.sub(r\"\\bmc([a-z])\",  lambda m: \"Mc\"  + m.group(1).upper(), token)\n",
        "    token = re.sub(r\"\\bmac([a-z])\", lambda m: \"Mac\" + m.group(1).upper(), token)\n",
        "    return token\n",
        "\n",
        "def smart_titlecase(name: str) -> str:\n",
        "    name = _clean_piece(name)\n",
        "    if not name:\n",
        "        return name\n",
        "    if \",\" in name:\n",
        "        last, first = [p.strip() for p in name.split(\",\", 1)]\n",
        "        pieces = (first + \" \" + last).split()\n",
        "    else:\n",
        "        pieces = name.split()\n",
        "    out = []\n",
        "    for i, w in enumerate(pieces):\n",
        "        if i > 0 and w.lower() in _PARTICLES:\n",
        "            out.append(w.lower())\n",
        "        else:\n",
        "            out.append(_smart_title(w))\n",
        "    return \" \".join(out)\n",
        "\n",
        "def surname_given_from_token(token):\n",
        "    token = token.strip()\n",
        "    idx = None\n",
        "    for i in range(1, len(token)):\n",
        "        if token[i-1].islower() and token[i].isupper():\n",
        "            idx = i\n",
        "            break\n",
        "    if idx is None:\n",
        "        for i in range(1, len(token)):\n",
        "            if token[i].isupper():\n",
        "                idx = i\n",
        "                break\n",
        "    if idx is None:\n",
        "        return (token,)\n",
        "    surname      = token[:idx]\n",
        "    given        = token[idx:]\n",
        "    given_spaced = re.sub(r\"(?<!^)([A-Z])\", r\" \\1\", given)\n",
        "    return (\"%s %s\" % (given_spaced.strip(), surname.strip()),)\n",
        "\n",
        "def normalize_person_name(s: str) -> str:\n",
        "    if pd.isna(s):\n",
        "        return \"\"\n",
        "    s = _clean_piece(str(s))\n",
        "    if \",\" in s:\n",
        "        last, first = [p.strip() for p in s.split(\",\", 1)]\n",
        "        s = \"%s %s\" % (first, last)\n",
        "    if \" \" not in s and s.isalpha():\n",
        "        return smart_titlecase(surname_given_from_token(s)[0])\n",
        "    return smart_titlecase(s)\n",
        "\n",
        "_CAMEL_WORDS = re.compile(r\"[A-Z][a-z]*|[A-Z]+(?![a-z])|[a-z]+\")\n",
        "\n",
        "def norm_matchee_name(raw: str) -> str:\n",
        "    raw = str(raw or \"\").strip()\n",
        "    if not raw:\n",
        "        return \"\"\n",
        "    if \" \" in raw or \",\" in raw:\n",
        "        nm    = smart_titlecase(raw)\n",
        "        parts = nm.split()\n",
        "        if len(parts) == 1:\n",
        "            return nm\n",
        "        return (\"%s %s\" % (parts[0], parts[-1])).strip()\n",
        "    words = _CAMEL_WORDS.findall(raw)\n",
        "    while words and len(words[0]) == 1:\n",
        "        words.pop(0)\n",
        "    if not words:\n",
        "        nm = smart_titlecase(surname_given_from_token(raw)[0])\n",
        "        ps = nm.split()\n",
        "        if len(ps) == 1:\n",
        "            return nm\n",
        "        return (\"%s %s\" % (ps[0], ps[-1])).strip()\n",
        "    surname          = smart_titlecase(words[0])\n",
        "    given_candidates = [w for w in words[1:] if w.lower() != surname.lower()]\n",
        "    if not given_candidates:\n",
        "        return surname\n",
        "    return (\"%s %s\" % (smart_titlecase(given_candidates[0]), surname)).strip()\n",
        "\n",
        "def derive_common_from_first_token(tokens):\n",
        "    if not tokens:\n",
        "        return (\"\", \"\")\n",
        "    first = _clean_piece(tokens[0])\n",
        "    parts = re.split(r\"\\s*(?:&| and )\\s*\", first, maxsplit=1, flags=re.I)\n",
        "    if len(parts) != 2:\n",
        "        return (\"\", \"\")\n",
        "    def _norm(s):\n",
        "        if \" \" in s:\n",
        "            return smart_titlecase(s)\n",
        "        return smart_titlecase(surname_given_from_token(s)[0])\n",
        "    return (_norm(parts[0]), _norm(parts[1]))\n",
        "\n",
        "def degree_label_from_generations(g):\n",
        "    if g <= 1:\n",
        "        return \"parents\" if g == 1 else \"self\"\n",
        "    if g == 2:\n",
        "        return \"grandparents\"\n",
        "    greats = g - 2\n",
        "    if greats == 1:\n",
        "        return \"great-grandparents\"\n",
        "    return \"%dx-great-grandparents\" % greats\n",
        "\n",
        "def build_header(subject_name_html, cm_val, matchee_name_html, gens, husband, wife):\n",
        "    try:\n",
        "        cm_str = \"%d\" % int(round(float(cm_val)))\n",
        "    except Exception:\n",
        "        cm_str = (str(cm_val).strip() or \"0\")\n",
        "    degree_label = degree_label_from_generations(gens)\n",
        "    parts = [\n",
        "        \"%s is a %s cM cousin match to %s, whose\" % (subject_name_html, cm_str, matchee_name_html),\n",
        "        \"%s (back %d Gens)\" % (degree_label, gens),\n",
        "        \"are\",\n",
        "        \"%s & %s.\" % (husband, wife),\n",
        "    ]\n",
        "    s = \" \".join(parts)\n",
        "    if REMOVE_PERIOD_AT_END:\n",
        "        s = re.sub(r\"\\.\\s*$\", \"\", s)\n",
        "    return s\n",
        "\n",
        "ID_PAT = re.compile(r\"\\bI\\d+\\b\", re.I)\n",
        "\n",
        "def extract_person_id(s: str) -> str:\n",
        "    m = ID_PAT.search(str(s or \"\"))\n",
        "    return m.group(0).upper() if m else \"\"\n",
        "\n",
        "# ---------- 5) Read CSV ----------\n",
        "def find_col(df, patterns, prefer_exact=None):\n",
        "    cols   = list(df.columns)\n",
        "    lowmap = {c.lower(): c for c in cols}\n",
        "    if prefer_exact:\n",
        "        for name in prefer_exact:\n",
        "            if name in df.columns:\n",
        "                return name\n",
        "            if name and name.lower() in lowmap:\n",
        "                return lowmap[name.lower()]\n",
        "    for pat in patterns:\n",
        "        rx = re.compile(pat, re.I)\n",
        "        for c in cols:\n",
        "            if rx.search(c):\n",
        "                return c\n",
        "    return None\n",
        "\n",
        "_encs     = (\"utf-8-sig\", \"utf-8\", \"cp1252\", \"iso-8859-15\", \"latin1\")\n",
        "_last_err = None\n",
        "df        = None\n",
        "for _e in _encs:\n",
        "    try:\n",
        "        df = pd.read_csv(CSV_IN, encoding=_e, dtype=str, keep_default_na=False)\n",
        "        break\n",
        "    except Exception as _ex:\n",
        "        _last_err = _ex\n",
        "        df        = None\n",
        "if df is None:\n",
        "    raise RuntimeError(\"Unable to read CSV: %s (%s)\" % (CSV_IN, _last_err))\n",
        "print(\"[OK] Loaded CSV: %d rows, %d cols\" % (len(df), len(df.columns)))\n",
        "\n",
        "id_col    = find_col(df, [r\"^(id#|personid)$\"], [\"ID#\", \"ID\", \"PersonID\", \"personID\"])\n",
        "match_col = find_col(df, [r\"^match\\s*to$\"], [\"Match to\", \"Match\", \"match_to\", \"Match_to\"])\n",
        "name_col  = find_col(df, [r\"^name$\"], [\"Name\"])\n",
        "cm_col    = find_col(df, [r\"^(c\\s*:?m|cm)$\", r\"centi.?morgan\"], [\"cM\", \"cm\"])\n",
        "path_col  = find_col(\n",
        "    df,\n",
        "    [r\"(yates\\s*dna\\s*ancestral\\s*line|ancestral\\s*line|lineage)\"],\n",
        "    [\"Yates DNA Ancestral Line\", \"Ancestral Line\", \"Lineage\"],\n",
        ")\n",
        "\n",
        "if not id_col:\n",
        "    raise ValueError(\"CSV missing an ID#/PersonID column.\")\n",
        "if not match_col:\n",
        "    raise ValueError(\"CSV missing 'Match to' column (try headings like 'Match to' or 'Match').\")\n",
        "if not name_col:\n",
        "    raise ValueError(\"CSV missing 'Name' column.\")\n",
        "if not cm_col:\n",
        "    raise ValueError(\"CSV missing 'cM' column.\")\n",
        "if not path_col:\n",
        "    raise ValueError(\"CSV missing lineage/path column.\")\n",
        "\n",
        "# ---------- 5.1) Read vitals from dna_vitals.csv ----------\n",
        "AUTOSOMAL_MATCHES = \"\"\n",
        "SHOWING_STATIC    = \"\"\n",
        "\n",
        "def _load_vitals(path):\n",
        "    global AUTOSOMAL_MATCHES, SHOWING_STATIC\n",
        "    if not os.path.exists(path):\n",
        "        print(\"[INFO] dna_vitals.csv not found; header will omit counts.\")\n",
        "        return\n",
        "    try:\n",
        "        vdf = pd.read_csv(path, dtype=str, encoding=\"iso-8859-15\", keep_default_na=False)\n",
        "    except Exception:\n",
        "        encs = (\"utf-8-sig\", \"utf-8\", \"cp1252\", \"latin1\")\n",
        "        last = None\n",
        "        vdf  = None\n",
        "        for enc in encs:\n",
        "            try:\n",
        "                vdf = pd.read_csv(path, dtype=str, encoding=enc, keep_default_na=False)\n",
        "                break\n",
        "            except Exception as e:\n",
        "                last = e\n",
        "        if vdf is None:\n",
        "            print(\"[WARN] Unable to read dna_vitals.csv: %s\" % last)\n",
        "            return\n",
        "\n",
        "    flat = []\n",
        "    for row in vdf.astype(str).values.tolist():\n",
        "        for cell in row:\n",
        "            flat.append(str(cell))\n",
        "\n",
        "    autosomal = None\n",
        "    showing   = None\n",
        "\n",
        "    for cell in flat:\n",
        "        s = str(cell)\n",
        "        if \"Records tagged and filtered by NPFX\" in s and autosomal is None:\n",
        "            m = re.search(r\"(\\d+)\", s)\n",
        "            if m:\n",
        "                autosomal = m.group(1)\n",
        "        if \"After manual filter, total records\" in s and showing is None:\n",
        "            m = re.search(r\"(\\d+)\", s)\n",
        "            if m:\n",
        "                showing = m.group(1)\n",
        "\n",
        "    if autosomal is None or showing is None:\n",
        "        all_text = \" \".join(flat)\n",
        "        nums = re.findall(r\"\\d+\", all_text)\n",
        "        if autosomal is None and len(nums) >= 1:\n",
        "            autosomal = nums[0]\n",
        "        if showing is None and len(nums) >= 2:\n",
        "            showing = nums[1]\n",
        "\n",
        "    AUTOSOMAL_MATCHES = autosomal or \"\"\n",
        "    SHOWING_STATIC    = showing   or \"\"\n",
        "\n",
        "    print(\"[OK] Loaded vitals from %s -> autosomal=%s, showing=%s\"\n",
        "          % (path, AUTOSOMAL_MATCHES or \"?\", SHOWING_STATIC or \"?\"))\n",
        "\n",
        "_load_vitals(VITALS_CSV)\n",
        "\n",
        "if SHOWING_STATIC:\n",
        "    try:\n",
        "        if int(SHOWING_STATIC) != len(df):\n",
        "            print(\"[WARN] dna_vitals showing (%s) != CSV rows (%d)\" %\n",
        "                  (SHOWING_STATIC, len(df)))\n",
        "    except Exception as _e:\n",
        "        print(\"[WARN] Unable to compare showing from dna_vitals.csv to CSV rows: %s\" % _e)\n",
        "\n",
        "# ---------- 6) Transform ----------\n",
        "_setup_resolver()\n",
        "\n",
        "headers          = []\n",
        "lineages         = []\n",
        "subjects         = []\n",
        "first_ancestors  = []\n",
        "display_match_to = []  # normalized \"Match to\"\n",
        "display_name     = []  # normalized Name (with link to TNG if available)\n",
        "\n",
        "LINEAGE_HEADER_SAFE = \"Yates DNA Ancestral Lines\"\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    subject_raw    = row.get(match_col, \"\")\n",
        "    subject_name   = normalize_person_name(resolve_match_to(subject_raw))\n",
        "    subject_name_b = \"<strong>%s</strong>\" % subject_name if subject_name else subject_name\n",
        "\n",
        "    pid          = extract_person_id(row.get(id_col, \"\"))\n",
        "    matchee_raw  = row.get(name_col, \"\")\n",
        "    matchee_name = norm_matchee_name(matchee_raw) or subject_name\n",
        "\n",
        "    if pid:\n",
        "        matchee_url = (\n",
        "            \"%s/verticalchart.php?personID=%s&tree=%s&parentset=0&display=vertical&generations=15\"\n",
        "            % (TNG_BASE, pid, TNG_TREE)\n",
        "        )\n",
        "        matchee_name_html = '<a href=\"%s\" target=\"_blank\" rel=\"noopener\">%s</a>' % (matchee_url, matchee_name)\n",
        "    else:\n",
        "        matchee_name_html = matchee_name\n",
        "\n",
        "    cm_val      = row.get(cm_col, \"0\")\n",
        "    tokens      = split_tokens(row.get(path_col, \"\"))\n",
        "    gens_total  = len(tokens)\n",
        "    tokens_disp = tokens[:7]\n",
        "\n",
        "    if \"common_husband\" in df.columns and \"common_wife\" in df.columns:\n",
        "        husband_raw = str(row.get(\"common_husband\", \"\")).strip()\n",
        "        wife_raw    = str(row.get(\"common_wife\", \"\")).strip()\n",
        "        if not husband_raw and not wife_raw:\n",
        "            husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "    else:\n",
        "        husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "\n",
        "    header_html = build_header(subject_name_b or subject_name, cm_val, matchee_name_html, gens_total, husband_raw, wife_raw)\n",
        "    if tokens_disp:\n",
        "        tokens_disp[0] = \"<strong>%s</strong>\" % tokens_disp[0]\n",
        "    sep          = \" %s \" % ARROW_ENTITY\n",
        "    lineage_text = sep.join(tokens_disp) if tokens_disp else \"\"\n",
        "\n",
        "    headers.append(header_html)\n",
        "    lineages.append(lineage_text)\n",
        "    subjects.append(subject_name)\n",
        "    first_ancestors.append(tokens[0] if tokens else \"\")\n",
        "\n",
        "    display_match_to.append(subject_name)\n",
        "    display_name.append(matchee_name_html)\n",
        "\n",
        "df[\"Match Summary\"]      = headers\n",
        "df[LINEAGE_HEADER_SAFE]  = lineages\n",
        "df[\"Subject\"]            = subjects\n",
        "df[\"First Ancestor\"]     = [_clean_piece(x) for x in first_ancestors]\n",
        "\n",
        "# ---------- 6.1) Clean exports ----------\n",
        "TAG_RE = re.compile(r\"<[^>]+>\")\n",
        "\n",
        "def _html_to_text(s: str) -> str:\n",
        "    t = TAG_RE.sub(\"\", str(s or \"\"))\n",
        "    t = _html.unescape(t)\n",
        "    t = t.replace(\"\\u2192\", \"->\")\n",
        "    t = re.sub(r\"\\s+\", \" \", t)\n",
        "    return t.strip()\n",
        "\n",
        "def _extract_find_url(subject_name: str) -> str:\n",
        "    if not subject_name:\n",
        "        return \"\"\n",
        "    q = _u.quote(subject_name)\n",
        "    return \"%s?q=%s\" % (REMOTE_NAME_ABS, q)\n",
        "\n",
        "website_urls = [_extract_find_url(subj) for subj in df[\"Subject\"].tolist()]\n",
        "\n",
        "export_df = pd.DataFrame({\n",
        "    \"Match to\"      : df[match_col].tolist(),\n",
        "    \"Name\"          : df[name_col].tolist(),\n",
        "    \"cM\"            : df[cm_col].tolist(),\n",
        "    \"Match Summary\" : [_html_to_text(v) for v in df[\"Match Summary\"].tolist()],\n",
        "    \"Website URL\"   : website_urls,\n",
        "    \"Lineage\"       : [_html_to_text(v) for v in df[LINEAGE_HEADER_SAFE].tolist()],\n",
        "})\n",
        "\n",
        "export_df.to_csv(LOCAL_CSV, index=False, encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\")\n",
        "try:\n",
        "    export_df.to_excel(LOCAL_XLSX, index=False)\n",
        "except Exception:\n",
        "    with pd.ExcelWriter(LOCAL_XLSX) as _writer:\n",
        "        export_df.to_excel(_writer, index=False)\n",
        "print(\"[OK] Wrote exports: %s and %s\" % (os.path.abspath(LOCAL_CSV), os.path.abspath(LOCAL_XLSX)))\n",
        "\n",
        "# ---------- 7) Stylesheet content (with mobile single-scroll behavior) ----------\n",
        "CSS_TEXT = \"\"\"/* yates.one-name.net - DNA pages (unified stylesheet)\n",
        "   Version: %s\n",
        "   Note: Typography, layout, colors, borders - centralized here. */\n",
        "\n",
        ":root {\n",
        "  --table-width-px: %dpx;\n",
        "  --brand-blue: #5b79b8;\n",
        "  --brand-blue-dark: #4668aa;\n",
        "  --line: #dddddd;\n",
        "  --line-strong: #999999;\n",
        "}\n",
        "\n",
        "html, body {\n",
        "  margin:0; padding:0;\n",
        "  font-family: \"Times New Roman\", Times, serif;\n",
        "  font-size: 16px; line-height: 1.35;\n",
        "  color:#111111; background:#ffffff;\n",
        "}\n",
        "\n",
        ".wrap {\n",
        "  max-width:100%%;\n",
        "  margin:0 auto;\n",
        "  background:#ffffff;\n",
        "  padding:16px;\n",
        "  padding-bottom:48px;\n",
        "}\n",
        ".centerline { text-align:center; }\n",
        "\n",
        ".downloads { text-align:center; margin:4px 0 10px 0; font-size: 13px; }\n",
        ".updated   { font-size: 12px; color:#555555; text-align:center; margin:2px 0 10px 0; }\n",
        "\n",
        ".left-align { text-align:left; }\n",
        "\n",
        "/* Simple header alignment helpers */\n",
        "th.center-header { text-align:center; }\n",
        "th.left-header   { text-align:left; }\n",
        "\n",
        "/* Wrapper for top and bottom scroll sync */\n",
        ".table-scroll-wrapper {\n",
        "  width:100%%;\n",
        "  max-width:100%%;\n",
        "  margin:0 auto;\n",
        "}\n",
        "\n",
        "/* Top visible horizontal scrollbar (desktop / large screens) */\n",
        ".scroll-sync-top {\n",
        "  width:100%%;\n",
        "  max-width:100%%;\n",
        "  overflow-x:auto;\n",
        "  overflow-y:hidden;\n",
        "  border:1px solid var(--line);\n",
        "  border-bottom:none;\n",
        "  height:18px;\n",
        "  -webkit-overflow-scrolling:touch;\n",
        "}\n",
        ".scroll-sync-top-inner {\n",
        "  height:1px;\n",
        "}\n",
        "\n",
        "/* Bottom scroll container: real scroll, scrollbar hidden visually by default */\n",
        ".table-scroll {\n",
        "  width:100%%;\n",
        "  max-width:100%%;\n",
        "  max-height:80vh;\n",
        "  overflow-x:auto;\n",
        "  overflow-y:auto;\n",
        "  border:1px solid var(--line);\n",
        "  border-top:none;\n",
        "  position:relative;\n",
        "  -webkit-overflow-scrolling:touch;\n",
        "  scrollbar-width:none;          /* Firefox */\n",
        "  -ms-overflow-style:none;       /* IE/Edge legacy */\n",
        "}\n",
        ".table-scroll::-webkit-scrollbar {\n",
        "  display:none;                  /* WebKit / Blink */\n",
        "}\n",
        "\n",
        "/* Table: let widths and content drive horizontal size */\n",
        "table.sortable {\n",
        "  border-collapse:separate;\n",
        "  border-spacing:0;\n",
        "}\n",
        "\n",
        "table.sortable th,\n",
        "table.sortable td {\n",
        "  border:1px solid var(--line);\n",
        "  padding:6px 8px;\n",
        "  vertical-align:top;\n",
        "  white-space:nowrap;\n",
        "}\n",
        "\n",
        "/* Sticky header row (desktop and iOS) */\n",
        "table.sortable th {\n",
        "  background:#e3eaf8;\n",
        "  position:-webkit-sticky;   /* iOS Safari */\n",
        "  position:sticky;\n",
        "  top:0;\n",
        "  z-index:5;\n",
        "  box-shadow:0 1px 0 #cccccc;\n",
        "  cursor:pointer;\n",
        "}\n",
        "\n",
        "/* Sticky first column (Match to) for DNA Register table */\n",
        "table.dna-register-table th:nth-child(1),\n",
        "table.dna-register-table td:nth-child(1) {\n",
        "  position:-webkit-sticky;   /* iOS Safari */\n",
        "  position:sticky;\n",
        "  left:0;\n",
        "  z-index:6;\n",
        "  background:#ffffff;\n",
        "}\n",
        "table.dna-register-table th:nth-child(1) {\n",
        "  z-index:7;\n",
        "}\n",
        "\n",
        "/* First data row marker */\n",
        "#first-row td { border-top:2px solid var(--line-strong); }\n",
        "\n",
        "/* Back-to-top button */\n",
        ".back-to-top {\n",
        "  position:fixed; right:16px; bottom:16px; padding:6px 10px;\n",
        "  border:1px solid #3e5a97; background:var(--brand-blue);\n",
        "  color:#ffffff; cursor:pointer; border-radius:6px; display:none; z-index:9999;\n",
        "}\n",
        ".back-to-top:hover { background:var(--brand-blue-dark); }\n",
        "\n",
        "/* Controls */\n",
        ".controls { text-align:center; }\n",
        ".controls-spaced { margin:6px 0 10px 0; }\n",
        ".search { font-size: 14px; padding:5px 8px; }\n",
        "\n",
        "/* Old-school blue nav menu */\n",
        ".oldnav {\n",
        "  margin:8px auto 6px auto; padding:0; background:var(--brand-blue);\n",
        "  border-radius:6px; overflow:hidden; max-width: var(--table-width-px);\n",
        "}\n",
        ".oldnav ul { list-style:none; margin:0; padding:0; display:flex; flex-wrap:wrap; }\n",
        ".oldnav li { margin:0; padding:0; }\n",
        ".oldnav a, .oldnav a:link, .oldnav a:visited, .oldnav a:active { color:#ffffff !important; }\n",
        ".oldnav a {\n",
        "  display:block;\n",
        "  padding:8px 12px;\n",
        "  text-decoration:none;\n",
        "  white-space:nowrap;\n",
        "  border-right:1px solid #ffffff;\n",
        "  font-weight:600;\n",
        "}\n",
        ".oldnav li:last-child a { border-right:none; }\n",
        ".oldnav a:hover { background:var(--brand-blue-dark); color:#ffffff !important; }\n",
        "\n",
        "/* Responsive tweaks */\n",
        "@media screen and (min-width: 1200px) {\n",
        "  .wrap { max-width: var(--table-width-px); }\n",
        "}\n",
        "@media screen and (max-width: 1199px) {\n",
        "  .oldnav { border-radius:0; }\n",
        "}\n",
        "@media screen and (max-width: 700px) {\n",
        "  table.sortable th, table.sortable td { padding:5px 6px; }\n",
        "}\n",
        "\n",
        "/* Mobile single-scroll optimization (iPhone/iPad and small screens):\n",
        "   - Hide the fake top scrollbar\n",
        "   - Use the native horizontal scrollbar on the bottom container\n",
        "   - Keep sticky header and sticky first column */\n",
        "@media screen and (max-width: 1024px) {\n",
        "  .scroll-sync-top {\n",
        "    display:none;\n",
        "  }\n",
        "  .table-scroll {\n",
        "    -webkit-overflow-scrolling:touch;\n",
        "    scrollbar-width:auto;\n",
        "  }\n",
        "  .table-scroll::-webkit-scrollbar {\n",
        "    display:block;\n",
        "  }\n",
        "}\n",
        "\"\"\" % (\n",
        "    CSS_VERSION,\n",
        "    TABLE_TOTAL_WIDTH_PX,\n",
        ")\n",
        "\n",
        "os.makedirs(\"partials\", exist_ok=True)\n",
        "with open(STYLESHEET_LOCAL, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as _css:\n",
        "    _css.write(CSS_TEXT)\n",
        "print(\"[OK] Wrote stylesheet: %s\" % os.path.abspath(STYLESHEET_LOCAL))\n",
        "\n",
        "# ---------- 8) Main HTML ----------\n",
        "page_tpl = Template(\"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "<title>ONS Yates Study Autosomal DNA Register</title>\n",
        "$HEAD_LINK\n",
        "</head>\n",
        "<body id=\"top\">\n",
        "<div class=\"wrap\">\n",
        "  <h1 class=\"centerline\">ONS Yates Study Autosomal DNA Register</h1>\n",
        "  $DOWNLOADS_BLOCK\n",
        "  $UPDATED_BLOCK\n",
        "  $NAV_BLOCK\n",
        "  $CONTROLS_BLOCK\n",
        "  $SCROLL_WRAPPER\n",
        "</div>\n",
        "<button id=\"back-to-top\" class=\"back-to-top\">&#9650; Top</button>\n",
        "<script type=\"text/javascript\">\n",
        "//<![CDATA[\n",
        "(function(){\n",
        "  function textOf(cell){\n",
        "    return (cell && (cell.textContent || cell.innerText) || '')\n",
        "      .replace(/\\\\s+/g,' ')\n",
        "      .trim()\n",
        "      .toLowerCase();\n",
        "  }\n",
        "\n",
        "  function sortTable(tbl, colIndex, dir){\n",
        "    var tb = tbl && tbl.tBodies ? tbl.tBodies[0] : null;\n",
        "    if(!tb) return;\n",
        "    var rows = Array.prototype.slice.call(tb.rows || []);\n",
        "    var asc  = (dir === 'asc');\n",
        "\n",
        "    rows.sort(function(a,b){\n",
        "      var A = textOf(a.cells[colIndex]),\n",
        "          B = textOf(b.cells[colIndex]);\n",
        "\n",
        "      var nA = parseFloat(A.replace(/[^0-9.\\\\-]/g,'')),\n",
        "          nB = parseFloat(B.replace(/[^0-9.\\\\-]/g,''));\n",
        "\n",
        "      if(!isNaN(nA) && !isNaN(nB)){\n",
        "        return asc ? (nA - nB) : (nB - nA);\n",
        "      }\n",
        "      if (A < B) return asc ? -1 : 1;\n",
        "      if (A > B) return asc ?  1 : -1;\n",
        "      return 0;\n",
        "    });\n",
        "\n",
        "    var frag = document.createDocumentFragment();\n",
        "    for(var i=0;i<rows.length;i++){\n",
        "      frag.appendChild(rows[i]);\n",
        "    }\n",
        "    tb.appendChild(frag);\n",
        "  }\n",
        "\n",
        "  function bindHeaderSort(){\n",
        "    var tbl = document.getElementById('refactor-table');\n",
        "    if(!(tbl && tbl.tHead && tbl.tHead.rows.length)) return;\n",
        "\n",
        "    var ths = tbl.tHead.rows[0].cells;\n",
        "    if(!ths) return;\n",
        "\n",
        "    for(var i=0;i<ths.length;i++){\n",
        "      (function(idx){\n",
        "        var th  = ths[idx];\n",
        "        var dir = 'asc';\n",
        "        th.addEventListener('click', function(){\n",
        "          dir = (dir === 'asc') ? 'desc' : 'asc';\n",
        "\n",
        "          for (var j = 0; j < ths.length; j++){\n",
        "            ths[j].innerHTML = ths[j].innerHTML.replace(/\\\\s+\\\\(asc\\\\)|\\\\s+\\\\(desc\\\\)/,'');\n",
        "          }\n",
        "          th.innerHTML += (dir === 'asc' ? ' (asc)' : ' (desc)');\n",
        "          sortTable(tbl, idx, dir);\n",
        "        }, false);\n",
        "      })(i);\n",
        "    }\n",
        "  }\n",
        "\n",
        "  function getParam(name){\n",
        "    var m = location.search.match(new RegExp('[?&]'+name+'=([^&]+)'));\n",
        "    return m ? decodeURIComponent(m[1].replace(/\\\\+/g,' ')) : '';\n",
        "  }\n",
        "\n",
        "  function bindSearch(){\n",
        "    var box = document.getElementById('search-box');\n",
        "    var tbl = document.getElementById('refactor-table');\n",
        "    if(!(box && tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "\n",
        "    var tb   = tbl.tBodies[0];\n",
        "    var rows = Array.prototype.slice.call(tb.rows || []);\n",
        "\n",
        "    function rowText(tr){\n",
        "      var t = '';\n",
        "      for(var i=0;i<tr.cells.length;i++){\n",
        "        t += ' ' + (tr.cells[i].textContent || tr.cells[i].innerText || '');\n",
        "      }\n",
        "      return t.replace(/\\\\s+/g,' ').toLowerCase();\n",
        "    }\n",
        "\n",
        "    function apply(q){\n",
        "      q = String(q || '').toLowerCase();\n",
        "      for(var i=0;i<rows.length;i++){\n",
        "        var txt  = rowText(rows[i]);\n",
        "        var show = !q || txt.indexOf(q) > -1;\n",
        "        rows[i].style.display = show ? '' : 'none';\n",
        "      }\n",
        "    }\n",
        "\n",
        "    var to = null;\n",
        "    function onInput(){\n",
        "      if(to) clearTimeout(to);\n",
        "      to = setTimeout(function(){ apply(box.value); }, 60);\n",
        "    }\n",
        "\n",
        "    box.addEventListener('input',  onInput, false);\n",
        "    box.addEventListener('search', onInput, false);\n",
        "\n",
        "    var q0 = getParam('q');\n",
        "    if(q0){\n",
        "      box.value = q0;\n",
        "      apply(q0);\n",
        "      try{ history.replaceState(null,'',location.pathname); }catch(e){}\n",
        "    } else {\n",
        "      box.value = '';\n",
        "      apply('');\n",
        "    }\n",
        "  }\n",
        "\n",
        "  function bindBackToTop(){\n",
        "    var btn = document.getElementById('back-to-top');\n",
        "    if(!btn) return;\n",
        "\n",
        "    window.addEventListener('scroll', function(){\n",
        "      btn.style.display = (window.pageYOffset > 200 ? 'block' : 'none');\n",
        "    }, false);\n",
        "\n",
        "    btn.addEventListener('click', function(){\n",
        "      try{\n",
        "        window.scrollTo({top:0, behavior:'smooth'});\n",
        "      } catch(e){\n",
        "        window.scrollTo(0,0);\n",
        "      }\n",
        "    }, false);\n",
        "  }\n",
        "\n",
        "  function bindScrollSync(){\n",
        "    var top    = document.getElementById('top-scroll');\n",
        "    var bottom = document.getElementById('bottom-scroll');\n",
        "    if(!(top && bottom)) return;\n",
        "\n",
        "    var ignore = false;\n",
        "\n",
        "    top.addEventListener('scroll', function(){\n",
        "      if(ignore) return;\n",
        "      ignore = true;\n",
        "      bottom.scrollLeft = top.scrollLeft;\n",
        "      ignore = false;\n",
        "    }, false);\n",
        "\n",
        "    bottom.addEventListener('scroll', function(){\n",
        "      if(ignore) return;\n",
        "      ignore = true;\n",
        "      top.scrollLeft = bottom.scrollLeft;\n",
        "      ignore = false;\n",
        "    }, false);\n",
        "  }\n",
        "\n",
        "  function initLastUpdated(){\n",
        "    var el = document.getElementById('last-updated');\n",
        "    if(!el) return;\n",
        "\n",
        "    var d = new Date(document.lastModified || new Date());\n",
        "    var months = ['January','February','March','April','May','June','July','August','September','October','November','December'];\n",
        "    var day   = d.getDate();\n",
        "    var month = months[d.getMonth()];\n",
        "    var year  = d.getFullYear();\n",
        "    var hour  = d.getHours();\n",
        "    var min   = d.getMinutes();\n",
        "    var ampm  = hour >= 12 ? 'pm' : 'am';\n",
        "\n",
        "    hour = hour % 12;\n",
        "    hour = hour ? hour : 12;\n",
        "    var minStr = min < 10 ? '0' + min : String(min);\n",
        "\n",
        "    el.innerHTML = day + ' ' + month + ', ' + year +\n",
        "                   ' at ' + hour + ':' + minStr + ' ' + ampm;\n",
        "  }\n",
        "\n",
        "  document.addEventListener('DOMContentLoaded', function(){\n",
        "    initLastUpdated();\n",
        "    bindHeaderSort();\n",
        "    bindSearch();\n",
        "    bindBackToTop();\n",
        "    bindScrollSync();\n",
        "  });\n",
        "})();\n",
        "//]]>\n",
        "</script>\n",
        "\n",
        "</body>\n",
        "</html>\n",
        "\"\"\")\n",
        "\n",
        "# ---------- 8.1) Build HTML table manually with inline widths ----------\n",
        "website_links = []\n",
        "for subj in df[\"Subject\"].tolist():\n",
        "    url = _extract_find_url(subj)\n",
        "    if url:\n",
        "        website_links.append('<a href=\"%s\" target=\"_blank\" rel=\"noopener\">Website</a>' % _html.escape(url, quote=True))\n",
        "    else:\n",
        "        website_links.append(\"\")\n",
        "\n",
        "# Full logical headers/data for possible future use\n",
        "col_headers_full = [\n",
        "    (\"Match to\", \"center\"),\n",
        "    (\"Name\", \"center\"),\n",
        "    (\"cM\", \"center\"),\n",
        "    (\"Match Summary\", \"center\"),\n",
        "    (\"Website\", \"center\"),\n",
        "    (\"Yates DNA Ancestral Lines\", \"left\"),\n",
        "]\n",
        "\n",
        "col_data_full = [\n",
        "    display_match_to,\n",
        "    display_name,\n",
        "    df[cm_col].tolist(),\n",
        "    df[\"Match Summary\"].tolist(),\n",
        "    website_links,\n",
        "    df[LINEAGE_HEADER_SAFE].tolist(),\n",
        "]\n",
        "\n",
        "# Restrict HTML table to visible columns only (1, 4, 6 -> indexes 0, 3, 5)\n",
        "col_headers = [col_headers_full[i] for i in VISIBLE_COL_INDEXES]\n",
        "col_data    = [col_data_full[i]    for i in VISIBLE_COL_INDEXES]\n",
        "\n",
        "thead_cells = []\n",
        "for (idx, (hdr, align)) in enumerate(col_headers):\n",
        "    src_idx = VISIBLE_COL_INDEXES[idx]\n",
        "    wpx     = COL_WIDTHS[src_idx]\n",
        "    if align == \"center\":\n",
        "        cell_html = '<th class=\"center-header\" style=\"width:%dpx;\">%s</th>' % (wpx, hdr)\n",
        "    else:\n",
        "        cell_html = '<th class=\"left-header\" style=\"width:%dpx;\">%s</th>' % (wpx, hdr)\n",
        "    thead_cells.append(cell_html)\n",
        "thead_html = \"<thead>\\n  <tr>\" + \"\".join(thead_cells) + \"</tr>\\n</thead>\"\n",
        "\n",
        "nrows = len(df)\n",
        "tbody_lines = [\"<tbody>\"]\n",
        "for r in range(nrows):\n",
        "    tr_open = '  <tr id=\"first-row\">' if r == 0 else '  <tr>'\n",
        "    cells = []\n",
        "    for idx in range(len(col_headers)):\n",
        "        src_idx = VISIBLE_COL_INDEXES[idx]\n",
        "        wpx     = COL_WIDTHS[src_idx]\n",
        "        val     = col_data[idx][r]\n",
        "        val_str = \"\" if val is None else str(val)\n",
        "        cells.append('<td style=\"width:%dpx;\">%s</td>' % (wpx, val_str))\n",
        "    tbody_lines.append(tr_open + \"\".join(cells) + \"</tr>\")\n",
        "tbody_lines.append(\"</tbody>\")\n",
        "tbody_html = \"\\n\".join(tbody_lines)\n",
        "\n",
        "html_table = (\n",
        "    '<table border=\"1\" class=\"dataframe sortable dna-register-table\" id=\"refactor-table\">'\n",
        "    + thead_html +\n",
        "    \"\\n\" +\n",
        "    tbody_html +\n",
        "    \"</table>\"\n",
        ")\n",
        "\n",
        "# Scroll wrapper: top visible bar (desktop) and bottom real scroll\n",
        "SCROLL_WRAPPER = (\n",
        "    '<div class=\"table-scroll-wrapper\">'\n",
        "    '<div id=\"top-scroll\" class=\"scroll-sync-top\">'\n",
        "    '<div class=\"scroll-sync-top-inner\" style=\"width:%dpx;\"></div>'\n",
        "    '</div>'\n",
        "    '<div class=\"table-scroll\" id=\"bottom-scroll\">%s</div>'\n",
        "    '</div>'\n",
        ") % (TABLE_TOTAL_WIDTH_PX, html_table)\n",
        "\n",
        "# ---------- 8.2) Page assembly ----------\n",
        "_updated_parts = [\n",
        "    'Last updated: <span id=\"last-updated\"></span>'\n",
        "]\n",
        "if AUTOSOMAL_MATCHES:\n",
        "    _updated_parts.append('Autosomal matches: %s' % _html.escape(AUTOSOMAL_MATCHES))\n",
        "if SHOWING_STATIC:\n",
        "    _updated_parts.append('Showing: %s' % _html.escape(SHOWING_STATIC))\n",
        "\n",
        "UPDATED_BLOCK = (\n",
        "    '<div class=\"updated centerline\">' +\n",
        "    ' &nbsp;|&nbsp; '.join(_updated_parts) +\n",
        "    '</div>'\n",
        ")\n",
        "\n",
        "DOWNLOADS_BLOCK = \"\"  # no Download: CSV | Excel paragraph on the page\n",
        "\n",
        "NAV_BLOCK = '<!--#include virtual=\"/partials/nav_block.shtml\" -->'\n",
        "\n",
        "CONTROLS_BLOCK = (\n",
        "  '<div class=\"controls controls-spaced centerline\">'\n",
        "  '<input type=\"text\" id=\"search-box\" class=\"search\" size=\"28\" value=\"\" placeholder=\"Search&amp;hellip;\" />'\n",
        "  '</div>'\n",
        ")\n",
        "\n",
        "final_html = page_tpl.safe_substitute(\n",
        "    HEAD_LINK       = HEAD_LINK,\n",
        "    UPDATED_BLOCK   = UPDATED_BLOCK,\n",
        "    NAV_BLOCK       = NAV_BLOCK,\n",
        "    CONTROLS_BLOCK  = CONTROLS_BLOCK,\n",
        "    DOWNLOADS_BLOCK = DOWNLOADS_BLOCK,\n",
        "    SCROLL_WRAPPER  = SCROLL_WRAPPER,\n",
        ")\n",
        "\n",
        "with open(LOCAL_HTML, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(final_html)\n",
        "print(\"[OK] Saved canonical render: %s\" % os.path.abspath(LOCAL_HTML))\n",
        "\n",
        "# ---------- 9) Upload ----------\n",
        "def save_and_upload_all():\n",
        "    if not all(os.environ.get(k) for k in [\"FTP_HOST\", \"FTP_USER\", \"FTP_PASS\"]):\n",
        "        print(\"[SKIP] Missing FTP creds; uploads skipped.\")\n",
        "        return\n",
        "    try:\n",
        "        ftps = ftp_connect()\n",
        "\n",
        "        try:\n",
        "            ftp_upload_overwrite(ftps, STYLESHEET_LOCAL, _remote_path(STYLESHEET_REMOTE))\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload stylesheet failed: %s\" % e)\n",
        "\n",
        "        try:\n",
        "            ftp_upload_overwrite(ftps, LOCAL_HTML, _remote_path(REMOTE_HTML_CANON))\n",
        "            ftp_upload_overwrite(ftps, LOCAL_HTML, _remote_path(REMOTE_HTML_LEG))\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload main HTML failed: %s\" % e)\n",
        "\n",
        "        try:\n",
        "            if os.path.exists(LOCAL_CSV):\n",
        "                ftp_upload_overwrite(ftps, LOCAL_CSV, _remote_path(REMOTE_CSV))\n",
        "            if os.path.exists(LOCAL_XLSX):\n",
        "                ftp_upload_overwrite(ftps, LOCAL_XLSX, _remote_path(REMOTE_XLSX))\n",
        "            print(\"[OK] Uploaded CSV/XLSX -> /partials/\")\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload CSV/XLSX failed: %s\" % e)\n",
        "\n",
        "        print(\"\\n--- SIZE Verification (if supported) ---\")\n",
        "        for p in [\n",
        "            _remote_path(REMOTE_HTML_CANON),\n",
        "            _remote_path(REMOTE_HTML_LEG),\n",
        "            _remote_path(REMOTE_CSV),\n",
        "            _remote_path(REMOTE_XLSX),\n",
        "            _remote_path(STYLESHEET_REMOTE),\n",
        "        ]:\n",
        "            sz = ftp_size(ftps, p)\n",
        "            print(\"%s : %s\" % (p, sz if sz is not None else \"(SIZE unsupported)\"))\n",
        "\n",
        "        try:\n",
        "            ftps.quit()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        print(\"\\n--- Open URLs ---\")\n",
        "        print(\"Canonical:        https://yates.one-name.net/partials/yates_ancestor_register.shtml\")\n",
        "        print(\"Legacy (ons_):    https://yates.one-name.net/partials/ons_yates_dna_register.shtml\")\n",
        "        print(\"Match Count:      https://yates.one-name.net/partials/match_count.shtml\")\n",
        "        print(\"Lineage Count:    https://yates.one-name.net/partials/lineage_count.shtml\")\n",
        "        print(\"Cousin Printable: https://yates.one-name.net/partials/cousin_list_print.htm\")\n",
        "        print(\"Trees (Cell 3):   https://yates.one-name.net/partials/just-trees.htm\")\n",
        "        print(\"Stylesheet:       https://yates.one-name.net/partials/dna_tree_styles.css\")\n",
        "        print(\"\\nBust cache once if needed by appending ?v=%s to the URL.\" % CSS_VERSION)\n",
        "    except Exception as e:\n",
        "        print(\"[FAIL] FTP session: %s\" % e)\n",
        "        traceback.print_exc()\n",
        "\n",
        "save_and_upload_all()\n",
        "# ====== CUT STOP [1/1] CELL 2 ==================================================================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW6BzXnD1Mqy",
        "outputId": "22dcde4f-693a-41de-f223-31d01702b211"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CONFIRM] Golden Rules active | Cell=Cell2_AllStyles_ExternalCSS | Version=2025.11.25-G1 | Encoding=ISO-8859-15\n",
            "[LAYOUT] TABLE_TOTAL_WIDTH_PX=3080\n",
            "[LAYOUT] Column widths (px): 1=80 2=220 3=60 4=1200 5=120 6=1800\n",
            "[LAYOUT] Visible HTML columns (0-based indexes): [0, 3, 5]\n",
            "[OK] Loaded CSV: 1596 rows, 6 cols\n",
            "[OK] Loaded vitals from dna_vitals.csv -> autosomal=1596, showing=1596\n",
            "[PULL] match_to_unmasked.csv -> /content/match_to_unmasked.server.csv\n",
            "[OK] Resolver loaded: 83 codes\n",
            "[OK] Wrote exports: /content/yates_ancestor_register.csv and /content/yates_ancestor_register.xlsx\n",
            "[OK] Wrote stylesheet: /content/partials/dna_tree_styles.css\n",
            "[OK] Saved canonical render: /content/yates_ancestor_register.shtml\n",
            "[PUT] partials/dna_tree_styles.css -> partials/dna_tree_styles.css\n",
            "[PUT] yates_ancestor_register.shtml -> partials/yates_ancestor_register.shtml\n",
            "[PUT] yates_ancestor_register.shtml -> partials/ons_yates_dna_register.shtml\n",
            "[PUT] yates_ancestor_register.csv -> partials/yates_ancestor_register.csv\n",
            "[PUT] yates_ancestor_register.xlsx -> partials/yates_ancestor_register.xlsx\n",
            "[OK] Uploaded CSV/XLSX -> /partials/\n",
            "\n",
            "--- SIZE Verification (if supported) ---\n",
            "partials/yates_ancestor_register.shtml : 1067633\n",
            "partials/ons_yates_dna_register.shtml : 1067633\n",
            "partials/yates_ancestor_register.csv : 709879\n",
            "partials/yates_ancestor_register.xlsx : 156154\n",
            "partials/dna_tree_styles.css : 4558\n",
            "\n",
            "--- Open URLs ---\n",
            "Canonical:        https://yates.one-name.net/partials/yates_ancestor_register.shtml\n",
            "Legacy (ons_):    https://yates.one-name.net/partials/ons_yates_dna_register.shtml\n",
            "Match Count:      https://yates.one-name.net/partials/match_count.shtml\n",
            "Lineage Count:    https://yates.one-name.net/partials/lineage_count.shtml\n",
            "Cousin Printable: https://yates.one-name.net/partials/cousin_list_print.htm\n",
            "Trees (Cell 3):   https://yates.one-name.net/partials/just-trees.htm\n",
            "Stylesheet:       https://yates.one-name.net/partials/dna_tree_styles.css\n",
            "\n",
            "Bust cache once if needed by appending ?v=v2025-11-25-g1 to the URL.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEST-Cell 2b-Counts"
      ],
      "metadata": {
        "id": "E63jQKAg2vwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] CELL 2b — Build + Upload Match/Lineage Count Partials (Counts only) ======\n",
        "# RON GOLDEN RULES -- CLIFF NOTES (v2025.11.21-G2)\n",
        "# • Complete & runnable Colab cell — one contiguous block.\n",
        "# • Source ASCII-only; outputs written with encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\".\n",
        "# • XHTML 1.0 Transitional; ALL typography/layout via /partials/dna_tree_styles.css (linked only).\n",
        "# • Deterministic audit:\n",
        "#   [CONFIRM] Golden Rules active | Cell=Cell2b_Counts | Version=2025.11.21-G2 | Encoding=ISO-8859-15\n",
        "# • Enforce ISO-8859-15 printable chars on writes;\n",
        "\n",
        "print(\"[CONFIRM] Golden Rules active | Cell=Cell2b_Counts | Version=2025.11.21-G2 | Encoding=ISO-8859-15\")\n",
        "\n",
        "DOWNLOADS_BLOCK = \"\"  # moved into nav_block.shtml\n",
        "\n",
        "import os, re, posixpath, socket, traceback\n",
        "from ftplib import FTP_TLS\n",
        "import pandas as pd\n",
        "import html as _html\n",
        "\n",
        "# ---------- 0) Secrets ----------\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ[\"FTP_HOST\"] = userdata.get(\"FTP_HOST\")\n",
        "    os.environ[\"FTP_USER\"] = userdata.get(\"FTP_USER\")\n",
        "    os.environ[\"FTP_PASS\"] = userdata.get(\"FTP_PASS\")\n",
        "    try:\n",
        "        os.environ[\"FTP_DIR\"] = userdata.get(\"FTP_DIR\")\n",
        "    except Exception:\n",
        "        os.environ.setdefault(\"FTP_DIR\", \"\")\n",
        "    try:\n",
        "        os.environ[\"FTP_PORT\"] = userdata.get(\"FTP_PORT\")\n",
        "    except Exception:\n",
        "        os.environ.setdefault(\"FTP_PORT\", \"21\")\n",
        "except Exception:\n",
        "    os.environ.setdefault(\"FTP_HOST\", \"\")\n",
        "    os.environ.setdefault(\"FTP_USER\", \"\")\n",
        "    os.environ.setdefault(\"FTP_PASS\", \"\")\n",
        "    os.environ.setdefault(\"FTP_DIR\", \"\")\n",
        "    os.environ.setdefault(\"FTP_PORT\", \"21\")\n",
        "\n",
        "# ---------- 1) Config ----------\n",
        "CSV_IN = \"final_combined_df_with_value_labels.csv\"\n",
        "\n",
        "SERVER_PARTIALS_DIR = \"partials\"\n",
        "SERVER_MAPPING_BASENAME = \"match_to_unmasked.csv\"\n",
        "SERVER_MAPPING_REMOTE = posixpath.join(SERVER_PARTIALS_DIR, SERVER_MAPPING_BASENAME)\n",
        "SERVER_MAPPING_LOCAL_CACHE = \"match_to_unmasked.server.csv\"\n",
        "\n",
        "FTP_DIR = (os.environ.get(\"FTP_DIR\", \"\") or \"\").strip()\n",
        "\n",
        "# Shared stylesheet link (must already be present on server from Cell 2)\n",
        "STYLESHEET_BASENAME = \"dna_tree_styles.css\"\n",
        "# Use same cache-buster as main DNA register stylesheet:\n",
        "CSS_VERSION = \"v2025-11-14-g6\"\n",
        "STYLESHEET_HREF = \"/partials/%s?%s\" % (STYLESHEET_BASENAME, CSS_VERSION)\n",
        "HEAD_LINK = '<link rel=\"stylesheet\" type=\"text/css\" href=\"%s\" />' % STYLESHEET_HREF\n",
        "\n",
        "# Shared nav include (SSI)\n",
        "NAV_BLOCK = '<!--#include virtual=\"/partials/nav_block.shtml\" -->'\n",
        "\n",
        "# Count file URL for JS in partials\n",
        "REMOTE_COUNT_NAME = \"autosomal_count.txt\"\n",
        "if FTP_DIR:\n",
        "    COUNT_PUBLIC_URL = \"/%s/%s\" % (FTP_DIR, REMOTE_COUNT_NAME)\n",
        "else:\n",
        "    COUNT_PUBLIC_URL = \"/%s\" % REMOTE_COUNT_NAME\n",
        "\n",
        "# TNG settings for cousin links (match vertical chart behavior in main register)\n",
        "TNG_BASE = \"https://yates.one-name.net/tng\"\n",
        "TNG_TREE = \"tree1\"\n",
        "\n",
        "# Local partial paths\n",
        "MATCH_COUNT_LOCAL   = os.path.join(\"partials\", \"match_count.shtml\")\n",
        "LINEAGE_COUNT_LOCAL = os.path.join(\"partials\", \"lineage_count.shtml\")\n",
        "COUSIN_PRINT_LOCAL  = os.path.join(\"partials\", \"cousin_list_print.htm\")\n",
        "\n",
        "# Remote partial paths (server-side)\n",
        "MATCH_COUNT_REMOTE   = posixpath.join(\"partials\", \"match_count.shtml\")\n",
        "LINEAGE_COUNT_REMOTE = posixpath.join(\"partials\", \"lineage_count.shtml\")\n",
        "COUSIN_PRINT_REMOTE  = posixpath.join(\"partials\", \"cousin_list_print.htm\")\n",
        "\n",
        "# ---------- 2) FTP helpers ----------\n",
        "FTP_TIMEOUT = int(os.environ.get(\"FTP_TIMEOUT\", \"30\"))\n",
        "FTP_PASSIVE = True\n",
        "\n",
        "\n",
        "def ftp_connect() -> FTP_TLS:\n",
        "    ftps = FTP_TLS(timeout=FTP_TIMEOUT)\n",
        "    socket.setdefaulttimeout(FTP_TIMEOUT)\n",
        "    ftps.connect(os.environ.get(\"FTP_HOST\", \"\"), int(os.environ.get(\"FTP_PORT\", 21)))\n",
        "    ftps.login(os.environ.get(\"FTP_USER\", \"\"), os.environ.get(\"FTP_PASS\", \"\"))\n",
        "    try:\n",
        "        ftps.prot_p()\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        ftps.set_pasv(FTP_PASSIVE)\n",
        "    except Exception:\n",
        "        pass\n",
        "    if FTP_DIR:\n",
        "        for p in [p for p in FTP_DIR.split(\"/\") if p]:\n",
        "            try:\n",
        "                ftps.mkd(p)\n",
        "            except Exception:\n",
        "                pass\n",
        "            ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "\n",
        "def _remote_path(name: str) -> str:\n",
        "    return posixpath.join(FTP_DIR, name) if FTP_DIR else name\n",
        "\n",
        "\n",
        "def ensure_remote_dirs(ftps, remote_path):\n",
        "    if \"/\" not in remote_path:\n",
        "        return\n",
        "    pwd0 = ftps.pwd()\n",
        "    parts = [p for p in remote_path.split(\"/\")[:-1] if p and p != \".\"]\n",
        "    for seg in parts:\n",
        "        try:\n",
        "            ftps.cwd(seg)\n",
        "        except Exception:\n",
        "            try:\n",
        "                ftps.mkd(seg)\n",
        "            except Exception:\n",
        "                pass\n",
        "            ftps.cwd(seg)\n",
        "    ftps.cwd(pwd0)\n",
        "\n",
        "\n",
        "def ftp_download_if_exists(ftps, remote_name, local_name) -> bool:\n",
        "    try:\n",
        "        with open(local_name, \"wb\") as f:\n",
        "            ftps.retrbinary(\"RETR %s\" % remote_name, f.write)\n",
        "        print(\"[PULL] %s -> %s\" % (remote_name, os.path.abspath(local_name)))\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            if os.path.exists(local_name):\n",
        "                os.remove(local_name)\n",
        "        except Exception:\n",
        "            pass\n",
        "        print(\"[MISS] %s (%s)\" % (remote_name, e))\n",
        "        return False\n",
        "\n",
        "\n",
        "def ftp_upload_overwrite(ftps, local_path, remote_name):\n",
        "    ensure_remote_dirs(ftps, remote_name)\n",
        "    with open(local_path, \"rb\") as fh:\n",
        "        ftps.storbinary(\"STOR %s\" % remote_name, fh)\n",
        "    print(\"[PUT] %s -> %s\" % (local_path, remote_name))\n",
        "\n",
        "\n",
        "def ftp_size(ftps, remote_name):\n",
        "    try:\n",
        "        sz = ftps.size(remote_name)\n",
        "        return int(sz) if sz is not None else None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "# ---------- 3) Resolver (match_to_unmasked.csv on server) ----------\n",
        "def _read_mapping_csv(path: str) -> pd.DataFrame:\n",
        "    encs = (\"iso-8859-15\", \"utf-8-sig\", \"utf-8\", \"cp1252\", \"latin1\")\n",
        "    last = None\n",
        "    df = None\n",
        "    for enc in encs:\n",
        "        try:\n",
        "            df = pd.read_csv(path, encoding=enc, dtype=str, keep_default_na=False)\n",
        "            break\n",
        "        except Exception as e:\n",
        "            last = e\n",
        "            df = None\n",
        "    if df is None:\n",
        "        raise RuntimeError(\"Unable to read mapping CSV %s: %s\" % (path, last))\n",
        "    if df.shape[1] < 2:\n",
        "        raise RuntimeError(\"Mapping CSV must have at least two columns: code, unmasked\")\n",
        "    df = df.iloc[:, :2].copy()\n",
        "    df.columns = [\"code\", \"unmasked\"]\n",
        "    df[\"code\"] = df[\"code\"].astype(str).str.strip().str.lower()\n",
        "    df[\"unmasked\"] = df[\"unmasked\"].astype(str).str.strip()\n",
        "    df = df[df[\"code\"] != \"\"].drop_duplicates(subset=[\"code\"], keep=\"first\")\n",
        "    if df.empty:\n",
        "        raise RuntimeError(\"Mapping CSV empty after normalization.\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def load_resolver_from_server() -> dict:\n",
        "    with ftp_connect() as ftps:\n",
        "        try:\n",
        "            ftps.cwd(SERVER_PARTIALS_DIR)\n",
        "        except Exception:\n",
        "            pass\n",
        "        ok = ftp_download_if_exists(ftps, SERVER_MAPPING_BASENAME, SERVER_MAPPING_LOCAL_CACHE)\n",
        "        try:\n",
        "            ftps.quit()\n",
        "        except Exception:\n",
        "            pass\n",
        "    if not ok:\n",
        "        raise RuntimeError(\n",
        "            \"Resolver not found on server: /%s. Upload match_to_unmasked.csv into /partials/ and re-run.\"\n",
        "            % _remote_path(SERVER_MAPPING_REMOTE)\n",
        "        )\n",
        "    df_map = _read_mapping_csv(SERVER_MAPPING_LOCAL_CACHE)\n",
        "    print(\"[OK] Resolver loaded: %d codes\" % len(df_map))\n",
        "    return dict(zip(df_map[\"code\"], df_map[\"unmasked\"]))\n",
        "\n",
        "\n",
        "MATCH_TO_UNMASKED = {}\n",
        "\n",
        "\n",
        "def _setup_resolver():\n",
        "    global MATCH_TO_UNMASKED\n",
        "    if not MATCH_TO_UNMASKED:\n",
        "        MATCH_TO_UNMASKED = load_resolver_from_server()\n",
        "\n",
        "\n",
        "# ---------- 4) CSV + name helpers ----------\n",
        "def find_col(df, patterns, prefer_exact=None):\n",
        "    cols = list(df.columns)\n",
        "    lowmap = {c.lower(): c for c in cols}\n",
        "    if prefer_exact:\n",
        "        for name in prefer_exact:\n",
        "            if name in df.columns:\n",
        "                return name\n",
        "            if name and name.lower() in lowmap:\n",
        "                return lowmap[name.lower()]\n",
        "    for pat in patterns:\n",
        "        rx = re.compile(pat, re.I)\n",
        "        for c in cols:\n",
        "            if rx.search(c):\n",
        "                return c\n",
        "    return None\n",
        "\n",
        "\n",
        "SEP_RE = re.compile(r\"\\s*(?:\\u2192|&rarr;|;|>|,|~{2,}|/{2,}|\\|{2,})\\s*\")\n",
        "\n",
        "\n",
        "def split_tokens(s):\n",
        "    if pd.isna(s):\n",
        "        return []\n",
        "    if not isinstance(s, str):\n",
        "        s = str(s)\n",
        "    return [p.strip() for p in SEP_RE.split(s) if str(p).strip()]\n",
        "\n",
        "\n",
        "def _clean_piece(text: str) -> str:\n",
        "    t = re.sub(r\"~+\", \" \", str(text))\n",
        "    t = re.sub(r\"\\s+\", \" \", t)\n",
        "    return t.strip()\n",
        "\n",
        "\n",
        "_PARTICLES = {\n",
        "    \"de\",\n",
        "    \"del\",\n",
        "    \"della\",\n",
        "    \"der\",\n",
        "    \"van\",\n",
        "    \"von\",\n",
        "    \"da\",\n",
        "    \"dos\",\n",
        "    \"das\",\n",
        "    \"di\",\n",
        "    \"la\",\n",
        "    \"le\",\n",
        "    \"du\",\n",
        "    \"of\",\n",
        "}\n",
        "\n",
        "\n",
        "def _smart_title(token: str) -> str:\n",
        "    if not token:\n",
        "        return token\n",
        "    token = re.sub(\n",
        "        r\"(^|\\b)([a-z])(['’])([a-z])\",\n",
        "        lambda m: m.group(1) + m.group(2).upper() + m.group(3) + m.group(4).upper(),\n",
        "        token.lower(),\n",
        "    )\n",
        "    token = \"-\".join([w.capitalize() for w in token.split(\"-\")])\n",
        "    token = re.sub(r\"\\bmc([a-z])\", lambda m: \"Mc\" + m.group(1).upper(), token)\n",
        "    token = re.sub(r\"\\bmac([a-z])\", lambda m: \"Mac\" + m.group(1).upper(), token)\n",
        "    return token\n",
        "\n",
        "\n",
        "def smart_titlecase(name: str) -> str:\n",
        "    name = _clean_piece(name)\n",
        "    if not name:\n",
        "        return name\n",
        "    if \",\" in name:\n",
        "        last, first = [p.strip() for p in name.split(\",\", 1)]\n",
        "        pieces = (first + \" \" + last).split()\n",
        "    else:\n",
        "        pieces = name.split()\n",
        "    out = []\n",
        "    for i, w in enumerate(pieces):\n",
        "        out.append(w.lower() if (i > 0 and w.lower() in _PARTICLES) else _smart_title(w))\n",
        "    return \" \".join(out)\n",
        "\n",
        "\n",
        "def surname_given_from_token(token):\n",
        "    token = token.strip()\n",
        "    idx = None\n",
        "    for i in range(1, len(token)):\n",
        "        if token[i - 1].islower() and token[i].isupper():\n",
        "            idx = i\n",
        "            break\n",
        "    if idx is None:\n",
        "        for i in range(1, len(token)):\n",
        "            if token[i].isupper():\n",
        "                idx = i\n",
        "                break\n",
        "    if idx is None:\n",
        "        return (token,)\n",
        "    surname = token[:idx]\n",
        "    given = token[idx:]\n",
        "    given_spaced = re.sub(r\"(?<!^)([A-Z])\", r\" \\1\", given)\n",
        "    return (\"%s %s\" % (given_spaced.strip(), surname.strip()),)\n",
        "\n",
        "\n",
        "_CAMEL_WORDS = re.compile(r\"[A-Z][a-z]*|[A-Z]+(?![a-z])|[a-z]+\")\n",
        "\n",
        "\n",
        "def norm_matchee_name(raw: str) -> str:\n",
        "    raw = str(raw or \"\").strip()\n",
        "    if not raw:\n",
        "        return \"\"\n",
        "    if \" \" in raw or \",\" in raw:\n",
        "        nm = smart_titlecase(raw)\n",
        "        parts = nm.split()\n",
        "        if len(parts) == 1:\n",
        "            return nm\n",
        "        return (\"%s %s\" % (parts[0], parts[-1])).strip()\n",
        "    words = _CAMEL_WORDS.findall(raw)\n",
        "    while words and len(words[0]) == 1:\n",
        "        words.pop(0)\n",
        "    if not words:\n",
        "        nm = smart_titlecase(surname_given_from_token(raw)[0])\n",
        "        ps = nm.split()\n",
        "        if len(ps) == 1:\n",
        "            return nm\n",
        "        return (\"%s %s\" % (ps[0], ps[-1])).strip()\n",
        "    surname = smart_titlecase(words[0])\n",
        "    given_candidates = [w for w in words[1:] if w.lower() != surname.lower()]\n",
        "    if not given_candidates:\n",
        "        return surname\n",
        "    return (\"%s %s\" % (smart_titlecase(given_candidates[0]), surname)).strip()\n",
        "\n",
        "\n",
        "def normalize_person_name(s: str) -> str:\n",
        "    if pd.isna(s):\n",
        "        return \"\"\n",
        "    s = _clean_piece(str(s))\n",
        "    if \",\" in s:\n",
        "        last, first = [p.strip() for p in s.split(\",\", 1)]\n",
        "        s = \"%s %s\" % (first, last)\n",
        "    if \" \" not in s and s.isalpha():\n",
        "        return smart_titlecase(surname_given_from_token(s)[0])\n",
        "    return smart_titlecase(s)\n",
        "\n",
        "\n",
        "ID_PAT = re.compile(r\"\\bI\\d+\\b\", re.I)\n",
        "\n",
        "\n",
        "def extract_person_id(s: str) -> str:\n",
        "    m = ID_PAT.search(str(s or \"\"))\n",
        "    return m.group(0).upper() if m else \"\"\n",
        "\n",
        "\n",
        "def derive_common_from_first_token(tokens):\n",
        "    if not tokens:\n",
        "        return (\"\", \"\")\n",
        "    first = _clean_piece(tokens[0])\n",
        "    parts = re.split(r\"\\s*(?:&| and )\\s*\", first, maxsplit=1, flags=re.I)\n",
        "    if len(parts) != 2:\n",
        "        return (\"\", \"\")\n",
        "\n",
        "    def _norm(s):\n",
        "        return smart_titlecase(s) if \" \" in s else smart_titlecase(surname_given_from_token(s)[0])\n",
        "\n",
        "    return (_norm(parts[0]), _norm(parts[1]))\n",
        "\n",
        "\n",
        "def degree_label_from_generations(g):\n",
        "    if g <= 1:\n",
        "        return \"parents\" if g == 1 else \"self\"\n",
        "    if g == 2:\n",
        "        return \"grandparents\"\n",
        "    greats = g - 2\n",
        "    if greats == 1:\n",
        "        return \"great-grandparents\"\n",
        "    return \"%dx-great-grandparents\" % greats\n",
        "\n",
        "\n",
        "def build_header(subject_name_html, cm_val, matchee_name_html, gens, husband, wife):\n",
        "    try:\n",
        "        cm_str = \"%d\" % int(round(float(cm_val)))\n",
        "    except Exception:\n",
        "        cm_str = (str(cm_val).strip() or \"0\")\n",
        "    degree_label = degree_label_from_generations(gens)\n",
        "    parts = [\n",
        "        \"%s is a %s cM cousin match to %s, whose\" % (subject_name_html, cm_str, matchee_name_html),\n",
        "        \"%s (back %d Gens)\" % (degree_label, gens),\n",
        "        \"are\",\n",
        "        \"%s & %s.\" % (husband, wife),\n",
        "    ]\n",
        "    s = \" \".join(parts)\n",
        "    s = re.sub(r\"\\.\\s*$\", \"\", s)\n",
        "    return s\n",
        "\n",
        "# ---------- 5) Count helpers + partial HTML shells ----------\n",
        "def _norm_code_for_count(s):\n",
        "    t = str(s or \"\").strip()\n",
        "    if (t.startswith('\"') and t.endswith('\"')) or (t.startswith(\"'\") and t.endswith(\"'\")):\n",
        "        t = t[1:-1]\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n",
        "    return t\n",
        "\n",
        "\n",
        "def _partial_head(title):\n",
        "    return (\n",
        "        \"<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Transitional//EN\\\"\\n\"\n",
        "        \" \\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\\\">\\n\"\n",
        "        \"<html xmlns=\\\"http://www.w3.org/1999/xhtml\\\" lang=\\\"en\\\">\\n<head>\\n\"\n",
        "        \"%s\\n\" % HEAD_LINK\n",
        "        + \"<meta http-equiv=\\\"Content-Type\\\" content=\\\"text/html; charset=iso-8859-15\\\" />\\n\"\n",
        "        + \"<title>%s</title>\\n\" % _html.escape(title)\n",
        "        + \"</head>\\n<body>\\n<div class=\\\"wrap\\\">\\n\"\n",
        "        + \"<h1 class=\\\"centerline\\\">%s</h1>\\n\" % _html.escape(title)\n",
        "        + \"<div class=\\\"updated centerline\\\">Last updated: \"\n",
        "          \"<span id=\\\"last-updated\\\"></span> &nbsp;|&nbsp; \"\n",
        "          \"Autosomal matches: <span id=\\\"auto-count\\\">&mdash;</span></div>\\n\"\n",
        "        + NAV_BLOCK + \"\\n\"\n",
        "        + \"<div class=\\\"selection-menu centerline\\\">\"\n",
        "          \"<a href=\\\"#\\\" onclick=\\\"return ySelShowSelected('ref-tb');\\\">Show selected</a> &nbsp;|&nbsp; \"\n",
        "          \"<a href=\\\"#\\\" onclick=\\\"return ySelShowAll('ref-tb');\\\">Show all</a> &nbsp;|&nbsp; \"\n",
        "          \"<a href=\\\"#\\\" onclick=\\\"return ySelReset('ref-tb');\\\">Reset</a>\"\n",
        "          \"</div>\\n\"\n",
        "        + \"<div class=\\\"table-scroll\\\">\\n\"\n",
        "    )\n",
        "\n",
        "\n",
        "def _partial_tail():\n",
        "    safe_count = COUNT_PUBLIC_URL.replace(\"'\", \"%27\")\n",
        "    return (\n",
        "        \"</div>\\n</div>\\n\"\n",
        "        \"<script type=\\\"text/javascript\\\">\\n//<![CDATA[\\n\"\n",
        "        \"(function(){\"\n",
        "        \"function stamp(){var el=document.getElementById('last-updated');\"\n",
        "        \" if(!el) return; var d=new Date(document.lastModified||new Date());\"\n",
        "        \" var months=['January','February','March','April','May','June','July','August','September','October','November','December'];\"\n",
        "        \" var day=d.getDate(); var month=months[d.getMonth()]; var year=d.getFullYear();\"\n",
        "        \" var hour=d.getHours(); var min=d.getMinutes(); var ampm = hour >= 12 ? 'pm' : 'am';\"\n",
        "        \" hour = hour % 12; hour = hour ? hour : 12;\"\n",
        "        \" var minStr = min < 10 ? '0' + min : min;\"\n",
        "        \" el.innerHTML = day + ' ' + month + ', ' + year + ' at ' + hour + ':' + minStr + ' ' + ampm;}\"\n",
        "        \"function load(){var el=document.getElementById('auto-count'); if(!el) return;\"\n",
        "        \" var URL='\" + safe_count + \"';\"\n",
        "        \" try{var xhr=new XMLHttpRequest();\"\n",
        "        \" xhr.open('GET', URL+(URL.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true);\"\n",
        "        \" xhr.onreadystatechange=function(){if(xhr.readyState===4){\"\n",
        "        \" if(xhr.status>=200&&xhr.status<300){var m=(xhr.responseText||'').match(/(\\\\d+)/);\"\n",
        "        \" el.textContent=(m?m[1]:'');}\"\n",
        "        \" else {el.textContent='(unavailable)';}}}; xhr.send(null);}catch(e){el.textContent='(unavailable)';}}\"\n",
        "        \"function ySelEachRow(tb, cb){\"\n",
        "        \" if(!tb) return;\"\n",
        "        \" var rows=tb.getElementsByTagName('tr');\"\n",
        "        \" for(var i=0;i<rows.length;i++){cb(rows[i]);}\"\n",
        "        \"}\"\n",
        "        \"function ySelClear(tr){\"\n",
        "        \" if(!tr) return;\"\n",
        "        \" tr.removeAttribute('data-selected');\"\n",
        "        \" var cls=tr.className||'';\"\n",
        "        \" cls=cls.replace(/\\\\bsel-row\\\\b/g,'').replace(/\\\\s{2,}/g,' ').replace(/^\\\\s+|\\\\s+$/g,'');\"\n",
        "        \" tr.className=cls;\"\n",
        "        \"}\"\n",
        "        \"function ySelToggle(a){\"\n",
        "        \" var tr=a;\"\n",
        "        \" while(tr&&tr.tagName&&tr.tagName.toLowerCase()!=='tr'){tr=tr.parentNode;}\"\n",
        "        \" if(!tr) return false;\"\n",
        "        \" var sel=tr.getAttribute('data-selected')==='1';\"\n",
        "        \" if(sel){\"\n",
        "        \"  ySelClear(tr);\"\n",
        "        \" }else{\"\n",
        "        \"  tr.setAttribute('data-selected','1');\"\n",
        "        \"  var cls=tr.className||'';\"\n",
        "        \"  if(cls.indexOf('sel-row')===-1){tr.className=(cls?(cls+' '):'')+'sel-row';}\"\n",
        "        \" }\"\n",
        "        \" return false;\"\n",
        "        \"}\"\n",
        "        \"function ySelGetTBody(tbodyId){\"\n",
        "        \" var tb=document.getElementById(tbodyId);\"\n",
        "        \" if(tb) return tb;\"\n",
        "        \" var t=document.getElementById('ref-table');\"\n",
        "        \" if(!t) return null;\"\n",
        "        \" if(t.tBodies&&t.tBodies.length){return t.tBodies[0];}\"\n",
        "        \" return t;\"\n",
        "        \"}\"\n",
        "        \"function ySelShowSelected(tbodyId){\"\n",
        "        \" var tb=ySelGetTBody(tbodyId);\"\n",
        "        \" if(!tb) return false;\"\n",
        "        \" ySelEachRow(tb,function(tr){\"\n",
        "        \"  var sel=tr.getAttribute('data-selected')==='1';\"\n",
        "        \"  tr.style.display=sel?'':'none';\"\n",
        "        \" });\"\n",
        "        \" var rl=document.getElementById('reg-list');\"\n",
        "        \" if(rl){\"\n",
        "        \"  var selVals=[];\"\n",
        "        \"  ySelEachRow(tb,function(tr){\"\n",
        "        \"    if(tr.getAttribute('data-selected')==='1'){\"\n",
        "        \"      var v=tr.getAttribute('data-filter')\"\n",
        "        \"        || tr.getAttribute('data-lineage')\"\n",
        "        \"        || tr.getAttribute('data-code')\"\n",
        "        \"        || tr.getAttribute('data-q')\"\n",
        "        \"        || '';\"\n",
        "        \"      if(v){selVals.push(v);}\"\n",
        "        \"    }\"\n",
        "        \"  });\"\n",
        "        \"  if(selVals.length===0){\"\n",
        "        \"    return false;\"\n",
        "        \"  }\"\n",
        "        \"  var rows=rl.getElementsByTagName('tr');\"\n",
        "        \"  for(var i=0;i<rows.length;i++){\"\n",
        "        \"    var r=rows[i];\"\n",
        "        \"    var lv=r.getAttribute('data-filter')\"\n",
        "        \"      || r.getAttribute('data-lineage')\"\n",
        "        \"      || r.getAttribute('data-code')\"\n",
        "        \"      || '';\"\n",
        "        \"    var show=false;\"\n",
        "        \"    for(var j=0;j<selVals.length;j++){\"\n",
        "        \"      if(lv===selVals[j]){show=true; break;}\"\n",
        "        \"    }\"\n",
        "        \"    r.style.display=show?'':'none';\"\n",
        "        \"  }\"\n",
        "        \" }\"\n",
        "        \" return false;\"\n",
        "        \"}\"\n",
        "        \"function ySelShowAll(tbodyId){\"\n",
        "        \" var tb=ySelGetTBody(tbodyId);\"\n",
        "        \" if(!tb) return false;\"\n",
        "        \" ySelEachRow(tb,function(tr){tr.style.display='';});\"\n",
        "        \" var rl=document.getElementById('reg-list');\"\n",
        "        \" if(rl){\"\n",
        "        \"  var rows=rl.getElementsByTagName('tr');\"\n",
        "        \"  for(var i=0;i<rows.length;i++){rows[i].style.display='';}\"\n",
        "        \" }\"\n",
        "        \" return false;\"\n",
        "        \"}\"\n",
        "        \"function ySelReset(tbodyId){\"\n",
        "        \" var tb=ySelGetTBody(tbodyId);\"\n",
        "        \" if(!tb) return false;\"\n",
        "        \" ySelEachRow(tb,function(tr){tr.style.display=''; ySelClear(tr);});\"\n",
        "        \" var rl=document.getElementById('reg-list');\"\n",
        "        \" if(rl){\"\n",
        "        \"  var rows=rl.getElementsByTagName('tr');\"\n",
        "        \"  for(var i=0;i<rows.length;i++){rows[i].style.display='';}\"\n",
        "        \" }\"\n",
        "        \" return false;\"\n",
        "        \"}\"\n",
        "        \"window.ySelToggle=ySelToggle;\"\n",
        "        \"window.ySelShowSelected=ySelShowSelected;\"\n",
        "        \"window.ySelShowAll=ySelShowAll;\"\n",
        "        \"window.ySelReset=ySelReset;\"\n",
        "        \"document.addEventListener('DOMContentLoaded', function(){ stamp(); load(); }, false);\"\n",
        "        \"})();\\n//]]>\\n</script>\\n</body>\\n</html>\"\n",
        "    )\n",
        "\n",
        "# ---------- 6) DNA-register-style row builder ----------\n",
        "def build_register_row(\n",
        "    row,\n",
        "    id_col: str,\n",
        "    match_col: str,\n",
        "    name_col: str,\n",
        "    cm_col: str,\n",
        "    path_col: str,\n",
        "):\n",
        "    subject_raw = row.get(match_col, \"\")\n",
        "    # Unmask subject if possible, then normalize to same style as main register\n",
        "    key = str(subject_raw).strip().lower()\n",
        "    subject_unmasked = MATCH_TO_UNMASKED.get(key, subject_raw)\n",
        "    subject_name = normalize_person_name(subject_unmasked)\n",
        "    subject_name_html = _html.escape(subject_name or \"\")\n",
        "\n",
        "    pid = extract_person_id(row.get(id_col, \"\"))\n",
        "\n",
        "    matchee_name = norm_matchee_name(row.get(name_col, \"\")) or subject_name\n",
        "    if pid:\n",
        "        name_html = (\n",
        "            '<a href=\"%s/verticalchart.php?personID=%s&tree=%s&parentset=0&display=vertical&generations=15\" '\n",
        "            'target=\"_blank\" rel=\"noopener\">%s</a>'\n",
        "            % (TNG_BASE, pid, TNG_TREE, _html.escape(matchee_name or \"\", quote=False))\n",
        "        )\n",
        "    else:\n",
        "        name_html = _html.escape(matchee_name or \"\", quote=False)\n",
        "\n",
        "    cm_val = row.get(cm_col, \"0\")\n",
        "    tokens = split_tokens(row.get(path_col, \"\"))\n",
        "    gens_total = len(tokens)\n",
        "\n",
        "    if \"common_husband\" in row.index and \"common_wife\" in row.index:\n",
        "        husband_raw = str(row.get(\"common_husband\", \"\")).strip()\n",
        "        wife_raw = str(row.get(\"common_wife\", \"\")).strip()\n",
        "        if not husband_raw and not wife_raw:\n",
        "            husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "    else:\n",
        "        husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "\n",
        "    header_html = build_header(\n",
        "        subject_name_html or subject_name,\n",
        "        cm_val,\n",
        "        name_html,\n",
        "        gens_total,\n",
        "        husband_raw,\n",
        "        wife_raw,\n",
        "    )\n",
        "\n",
        "    return subject_name_html, name_html, _html.escape(str(cm_val).strip()), header_html\n",
        "\n",
        "# ---------- 7) Match Count partial ----------\n",
        "def build_match_count_partial(\n",
        "    main_df: pd.DataFrame,\n",
        "    id_col: str,\n",
        "    match_col: str,\n",
        "    name_col: str,\n",
        "    cm_col: str,\n",
        "    path_col: str,\n",
        ") -> str:\n",
        "    codes_raw = main_df[match_col].astype(str).map(lambda x: x.strip())\n",
        "    keys_norm = codes_raw.map(_norm_code_for_count)\n",
        "\n",
        "    counts_series = keys_norm.value_counts(dropna=False)\n",
        "    counts = counts_series.reset_index()\n",
        "    if counts.shape[1] >= 2:\n",
        "        counts.columns = [\"norm_key\", \"Count\"]\n",
        "    else:\n",
        "        counts[\"norm_key\"] = counts.index.astype(str)\n",
        "        counts[\"Count\"] = counts_series.values\n",
        "        counts = counts[[\"norm_key\", \"Count\"]]\n",
        "\n",
        "    first_display = {}\n",
        "    raw_list = codes_raw.tolist()\n",
        "    norm_list = keys_norm.tolist()\n",
        "    for code_disp, k in zip(raw_list, norm_list):\n",
        "        if k not in first_display and str(k) != \"\":\n",
        "            first_display[k] = code_disp\n",
        "\n",
        "    counts[\"Code\"] = counts[\"norm_key\"].map(lambda k: first_display.get(k, k))\n",
        "    counts[\"Unmasked\"] = counts[\"norm_key\"].map(lambda k: MATCH_TO_UNMASKED.get(k, \"\"))\n",
        "\n",
        "    counts = counts.sort_values(\n",
        "        by=[\"Code\", \"Count\"],\n",
        "        ascending=[True, False],\n",
        "        kind=\"mergesort\",\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    html = []\n",
        "    html.append(_partial_head(\"Match Count\"))\n",
        "    html.append('<table id=\"ref-table\" class=\"sortable\" border=\"1\"><thead><tr>')\n",
        "    html.append(\n",
        "        '<th style=\"width:35%\">Code</th>'\n",
        "        '<th style=\"width:35%\">Unmasked</th>'\n",
        "        '<th style=\"width:30%\">Count</th>'\n",
        "    )\n",
        "    html.append(\"</tr></thead><tbody id=\\\"ref-tb\\\">\")\n",
        "\n",
        "    for _, r in counts.iterrows():\n",
        "        code = r.get(\"Code\", \"\")\n",
        "        unm = r.get(\"Unmasked\", \"\")\n",
        "        cnt = int(str(r.get(\"Count\", \"0\")).strip() or \"0\")\n",
        "        norm_key = _norm_code_for_count(code)\n",
        "        label = (unm or code).strip()\n",
        "        tr = (\n",
        "            \"<tr data-q=\\\"%s\\\" data-count=\\\"%d\\\" data-code=\\\"%s\\\" data-filter=\\\"%s\\\">\"\n",
        "            \"<td>%s</td><td>%s</td>\"\n",
        "            \"<td class=\\\"count\\\">\"\n",
        "            \"<a href=\\\"#\\\" class=\\\"count-pick\\\" onclick=\\\"return ySelToggle(this);\\\" title=\\\"Toggle select\\\">%d</a>\"\n",
        "            \"</td></tr>\"\n",
        "            % (\n",
        "                _html.escape(label, quote=True),\n",
        "                cnt,\n",
        "                _html.escape(norm_key, quote=True),\n",
        "                _html.escape(norm_key, quote=True),\n",
        "                _html.escape(code),\n",
        "                _html.escape(unm),\n",
        "                cnt,\n",
        "            )\n",
        "        )\n",
        "    ...\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-Fg8NSY0LSF",
        "outputId": "5d39f37c-9990-482e-84b8-289f914d7c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CONFIRM] Golden Rules active | Cell=Cell2b_Counts | Version=2025.11.21-G2 | Encoding=ISO-8859-15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEST Cell 3"
      ],
      "metadata": {
        "id": "ZST5Z7Gxnene"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] CELL 3 — Ancestor Register (Old-school Blue Menu; WHITE menu text; .shtml + SSI) ======\n",
        "# RON GOLDEN RULES -- CLIFF NOTES (v2025.11.15)\n",
        "# • Complete & runnable Colab cell -- one contiguous block.\n",
        "# • Source ASCII-only; outputs written with encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\".\n",
        "# • XHTML 1.0 Transitional; typography comes ONLY from /partials/dna_tree_styles.css.\n",
        "# • Deterministic audit:\n",
        "#   [CONFIRM] Golden Rules active | Cell=Cell3_OldSchoolMenu_WhiteText | Version=2025.11.15 | Encoding=ISO-8859-15\n",
        "# • Enforce ISO-8859-15 printable chars on writes\n",
        "print(\"[CONFIRM] Golden Rules active | Cell=Cell3_OldSchoolMenu_WhiteText | Version=2025.11.15 | Encoding=ISO-8859-15\")\n",
        "\n",
        "# ---------- Imports ----------\n",
        "import os, re, socket, posixpath, traceback\n",
        "import pandas as pd\n",
        "import html as _html\n",
        "from ftplib import FTP_TLS\n",
        "from string import Template as _T\n",
        "\n",
        "# Downloads paragraph is now suppressed (links live in nav_block.shtml)\n",
        "DOWNLOADS_BLOCK = \"\"\n",
        "\n",
        "# ---------- Secrets ----------\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ[\"FTP_HOST\"] = userdata.get(\"FTP_HOST\")\n",
        "    os.environ[\"FTP_USER\"] = userdata.get(\"FTP_USER\")\n",
        "    os.environ[\"FTP_PASS\"] = userdata.get(\"FTP_PASS\")\n",
        "    try:\n",
        "        os.environ[\"FTP_PORT\"] = userdata.get(\"FTP_PORT\")\n",
        "    except Exception:\n",
        "        os.environ.setdefault(\"FTP_PORT\", \"21\")\n",
        "    try:\n",
        "        os.environ[\"FTP_DIR\"] = userdata.get(\"FTP_DIR\")\n",
        "    except Exception:\n",
        "        os.environ.setdefault(\"FTP_DIR\", \"\")\n",
        "except Exception:\n",
        "    os.environ.setdefault(\"FTP_HOST\", \"\")\n",
        "    os.environ.setdefault(\"FTP_USER\", \"\")\n",
        "    os.environ.setdefault(\"FTP_PASS\", \"\")\n",
        "    os.environ.setdefault(\"FTP_PORT\", \"21\")\n",
        "    os.environ.setdefault(\"FTP_DIR\", \"\")\n",
        "\n",
        "FTP_DIR = os.environ.get(\"FTP_DIR\", \"\").strip().strip(\"/\")\n",
        "COUNT_PUBLIC_URL = (\"/%s/%s\" % (FTP_DIR, \"autosomal_count.txt\")) if FTP_DIR else \"/autosomal_count.txt\"\n",
        "\n",
        "# ---------- Config / Paths ----------\n",
        "INPUT_CSV = \"final_combined_df_with_value_labels.csv\"\n",
        "\n",
        "EXPORT_BASENAME = \"yates_ancestor_register\"\n",
        "LOCAL_CSV   = EXPORT_BASENAME + \".csv\"\n",
        "LOCAL_XLSX  = EXPORT_BASENAME + \".xlsx\"\n",
        "REMOTE_CSV  = posixpath.join(\"partials\", LOCAL_CSV)\n",
        "REMOTE_XLSX = posixpath.join(\"partials\", LOCAL_XLSX)\n",
        "\n",
        "# This page is now .shtml so Apache will parse SSI\n",
        "OUTPUT_NAME = \"just-trees.shtml\"\n",
        "REMOTE_HTML = posixpath.join(\"partials\", OUTPUT_NAME)\n",
        "\n",
        "# Stylesheet + cache buster (shared with Cell 2)\n",
        "STYLESHEET_HREF = \"/partials/dna_tree_styles.css\"\n",
        "CSS_VERSION     = \"v2025-11-14-g6\"\n",
        "HEAD_LINK = '<link rel=\"stylesheet\" type=\"text/css\" href=\"%s?%s\" />' % (STYLESHEET_HREF, CSS_VERSION)\n",
        "\n",
        "# Layout knob (used for top-scroll inner width)\n",
        "TABLE_WIDTH_PX = 5550\n",
        "\n",
        "# ---------- Load CSV (robust) ----------\n",
        "df = None\n",
        "_last_err = None\n",
        "for enc in (\"utf-8-sig\", \"utf-8\", \"cp1252\", \"iso-8859-15\", \"latin1\"):\n",
        "    try:\n",
        "        df = pd.read_csv(INPUT_CSV, dtype=str, keep_default_na=False, encoding=enc)\n",
        "        break\n",
        "    except Exception as e:\n",
        "        _last_err = e\n",
        "        df = None\n",
        "if df is None:\n",
        "    raise SystemExit(\"[ERROR] Unable to read CSV: %s (%r)\" % (INPUT_CSV, _last_err))\n",
        "print(\"[OK] Loaded CSV: %s rows=%d, cols=%d\" % (INPUT_CSV, len(df), len(df.columns)))\n",
        "\n",
        "# Ensure haplogroup present (harmless for this view)\n",
        "if \"haplogroup\" not in df.columns:\n",
        "    df[\"haplogroup\"] = \"\"\n",
        "else:\n",
        "    df[\"haplogroup\"] = df[\"haplogroup\"].fillna(\"\")\n",
        "\n",
        "# ---------- Resolver: Column B (masked) -> Column C (unmasked) ----------\n",
        "A_IDX = 0\n",
        "B_IDX = 1\n",
        "C_IDX = 2\n",
        "\n",
        "def _norm_code(s):\n",
        "    t = str(s or \"\").strip()\n",
        "    if (t.startswith('\"') and t.endswith('\"')) or (t.startswith(\"'\") and t.endswith(\"'\")):\n",
        "        t = t[1:-1]\n",
        "    t = t.replace(\"\\u00a0\", \" \")\n",
        "    t = re.sub(r\"\\s{2,}\", \" \", t)\n",
        "    return t.lower()\n",
        "\n",
        "# Prefer local-first resolver cached by Cell 1; fall back to server\n",
        "LOCAL_RESOLVER = \"match_to_unmasked.csv\"\n",
        "if not os.path.exists(LOCAL_RESOLVER) and os.path.exists(\"/content/partials/match_to_unmasked.csv\"):\n",
        "    LOCAL_RESOLVER = \"/content/partials/match_to_unmasked.csv\"\n",
        "\n",
        "def _pull_resolver_if_needed(local_path):\n",
        "    if os.path.exists(local_path):\n",
        "        print(\"Using resolver:\", os.path.abspath(local_path))\n",
        "        return local_path\n",
        "    print(\"Resolver not found locally; attempting server pull ...\")\n",
        "    try:\n",
        "        with FTP_TLS(timeout=30) as ftps:\n",
        "            ftps.connect(os.environ.get(\"FTP_HOST\", \"\"), int(os.environ.get(\"FTP_PORT\", \"21\")))\n",
        "            ftps.login(os.environ.get(\"FTP_USER\", \"\"), os.environ.get(\"FTP_PASS\", \"\"))\n",
        "            try:\n",
        "                ftps.prot_p()\n",
        "            except Exception:\n",
        "                pass\n",
        "            try:\n",
        "                ftps.set_pasv(True)\n",
        "            except Exception:\n",
        "                pass\n",
        "            if FTP_DIR:\n",
        "                for p in [p for p in FTP_DIR.split(\"/\") if p]:\n",
        "                    try:\n",
        "                        ftps.cwd(p)\n",
        "                    except Exception:\n",
        "                        try:\n",
        "                            ftps.mkd(p)\n",
        "                        except Exception:\n",
        "                            pass\n",
        "                        ftps.cwd(p)\n",
        "            try:\n",
        "                ftps.cwd(\"partials\")\n",
        "            except Exception:\n",
        "                pass\n",
        "            with open(\"match_to_unmasked.csv\", \"wb\") as f:\n",
        "                ftps.retrbinary(\"RETR match_to_unmasked.csv\", f.write)\n",
        "        print(\"[OK] Pulled resolver from server -> match_to_unmasked.csv\")\n",
        "        return \"match_to_unmasked.csv\"\n",
        "    except Exception as e:\n",
        "        print(\"[WARN] Could not pull resolver from server:\", e)\n",
        "        return local_path\n",
        "\n",
        "LOCAL_RESOLVER = _pull_resolver_if_needed(LOCAL_RESOLVER)\n",
        "\n",
        "def _load_resolver_to_map(path):\n",
        "    last = None\n",
        "    m = None\n",
        "    for enc in (\"utf-8-sig\", \"iso-8859-15\", \"utf-8\", \"cp1252\", \"latin1\"):\n",
        "        try:\n",
        "            m = pd.read_csv(path, dtype=str, keep_default_na=False, encoding=enc)\n",
        "            break\n",
        "        except Exception as e:\n",
        "            last = e\n",
        "            m = None\n",
        "    if m is None:\n",
        "        print(\"[WARN] Resolver not loaded:\", last)\n",
        "        return {}\n",
        "    cols = {c.lower(): c for c in m.columns}\n",
        "    if \"code\" not in cols or \"unmasked\" not in cols:\n",
        "        print(\"[WARN] Resolver missing 'code'/'unmasked' cols; skipping map.\")\n",
        "        return {}\n",
        "    m = m[[cols[\"code\"], cols[\"unmasked\"]]].copy()\n",
        "    m[\"__key__\"] = m[cols[\"code\"]].map(_norm_code)\n",
        "    m[\"__val__\"] = m[cols[\"unmasked\"]].astype(str)\n",
        "    m = m.drop_duplicates(subset=\"__key__\", keep=\"first\")\n",
        "    return dict(zip(m[\"__key__\"], m[\"__val__\"]))\n",
        "\n",
        "resolver_map = _load_resolver_to_map(LOCAL_RESOLVER) if os.path.exists(LOCAL_RESOLVER) else {}\n",
        "\n",
        "if df.shape[1] < 3:\n",
        "    raise ValueError(\"Main df must have at least 3 columns: A(ID#), B(match to), C(unmasked).\")\n",
        "\n",
        "masked_raw = df.iloc[:, B_IDX].astype(str)\n",
        "masked_key = masked_raw.map(_norm_code)\n",
        "resolved   = masked_key.map(resolver_map)\n",
        "df.iloc[:, C_IDX] = resolved.fillna(\"\")\n",
        "\n",
        "print(\n",
        "    \"[OK] Column B -> C mapping: %d / %d  unmatched: %d\"\n",
        "    % (int(resolved.notna().sum()), len(df), len(df) - int(resolved.notna().sum()))\n",
        ")\n",
        "\n",
        "# ---------- Blocks (updated, nav via SSI, controls) ----------\n",
        "UPDATED_BLOCK = (\n",
        "    '<div class=\"updated centerline\">'\n",
        "    'Last updated: <span id=\"last-updated\"></span>'\n",
        "    ' &nbsp;|&nbsp; Autosomal matches: <span id=\"auto-count\" class=\"js-count\"></span>'\n",
        "    ' &nbsp;|&nbsp; Showing: <span id=\"showing-count\"></span>'\n",
        "    \"</div>\"\n",
        ")\n",
        "\n",
        "# Shared nav now comes from SSI include on a .shtml page\n",
        "NAV_BLOCK = '<!--#include virtual=\"/partials/nav_block.shtml\" -->'\n",
        "\n",
        "CONTROLS_BLOCK = (\n",
        "    '<div class=\"controls centerline\" style=\"margin:6px 0 10px 0;\">'\n",
        "    '<input type=\"text\" id=\"search-box\" class=\"search\" size=\"28\" value=\"\" '\n",
        "    'placeholder=\"Search&amp;hellip;\" />'\n",
        "    \"</div>\"\n",
        ")\n",
        "\n",
        "# ---------- HTML table (all current Cell 3 columns, including full lineage) ----------\n",
        "visible_cols = [c for c in df.columns if c]\n",
        "\n",
        "table_html = df.to_html(\n",
        "    index=False,\n",
        "    columns=visible_cols,\n",
        "    escape=False,\n",
        "    border=1,\n",
        "    classes=\"dataframe sortable\"\n",
        ")\n",
        "\n",
        "# Robustly inject id=\"refactor-table\" on the first <table> tag, regardless of attribute order\n",
        "if 'id=\"refactor-table\"' not in table_html:\n",
        "    table_html = re.sub(r\"<table([^>]*)>\", r'<table\\1 id=\"refactor-table\">', table_html, count=1)\n",
        "\n",
        "# Ensure the table has the \"sortable\" class (defensive, in case Pandas changes class output)\n",
        "if 'class=\"dataframe sortable\"' not in table_html and \"sortable\" not in table_html:\n",
        "    table_html = table_html.replace('class=\"dataframe\"', 'class=\"dataframe sortable\"', 1)\n",
        "\n",
        "# Optional: mark first data row\n",
        "table_html = table_html.replace(\"<tbody>\\n<tr>\", \"<tbody>\\n<tr id=\\\"first-row\\\">\", 1)\n",
        "\n",
        "# ---------- Build scroll wrapper (top visible, bottom real) ----------\n",
        "SCROLL_WRAPPER = (\n",
        "    '<div class=\"table-scroll-wrapper\">'\n",
        "    '<div id=\"top-scroll\" class=\"scroll-sync-top\">'\n",
        "    '<div class=\"scroll-sync-top-inner\" style=\"width:%dpx;\"></div>'\n",
        "    '</div>'\n",
        "    '<div id=\"bottom-scroll\" class=\"table-scroll\">%s</div>'\n",
        "    '</div>'\n",
        ") % (TABLE_WIDTH_PX, table_html)\n",
        "\n",
        "# ---------- XHTML page template (top+bottom scrollbars, sticky column 2) ----------\n",
        "page_tpl = _T(\"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "<title>Ancestor Register (Trees View)</title>\n",
        "$HEAD_LINK\n",
        "<style type=\"text/css\">\n",
        "/* Sticky second column (index 2) for Trees table */\n",
        "#refactor-table th:nth-child(2),\n",
        "#refactor-table td:nth-child(2){\n",
        "  position:sticky;\n",
        "  left:0;\n",
        "  z-index:6;\n",
        "  background:#ffffff;\n",
        "}\n",
        "#refactor-table th:nth-child(2){\n",
        "  z-index:7;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body id=\"top\">\n",
        "<div class=\"wrap\">\n",
        "  <h1 class=\"centerline\">Ancestor Register (Trees View)</h1>\n",
        "  $DOWNLOADS_BLOCK\n",
        "  $UPDATED_BLOCK\n",
        "  $NAV_BLOCK\n",
        "  $CONTROLS_BLOCK\n",
        "  $SCROLL_WRAPPER\n",
        "</div>\n",
        "<button id=\"back-to-top\" class=\"back-to-top\">&#9650; Top</button>\n",
        "<script type=\"text/javascript\">\n",
        "//<![CDATA[\n",
        "(function(){\n",
        "  function textOf(cell){\n",
        "    return (cell && (cell.textContent || cell.innerText) || '').replace(/\\\\s+/g,' ').trim().toLowerCase();\n",
        "  }\n",
        "  function sortTable(tbl, colIndex, dir){\n",
        "    var tb = tbl && tbl.tBodies ? tbl.tBodies[0] : null;\n",
        "    if(!tb) return;\n",
        "    var rows = [].slice.call(tb.rows || []);\n",
        "    var asc  = (dir === 'asc');\n",
        "    rows.sort(function(a,b){\n",
        "      var A = textOf(a.cells[colIndex]), B = textOf(b.cells[colIndex]);\n",
        "      var nA = parseFloat(A.replace(/[^0-9.\\\\-]/g,'')),\n",
        "          nB = parseFloat(B.replace(/[^0-9.\\\\-]/g,''));\n",
        "      if(!isNaN(nA) && !isNaN(nB)){ return asc ? (nA-nB) : (nB-nA); }\n",
        "      if (A < B) return asc ? -1 : 1;\n",
        "      if (A > B) return asc ?  1 : -1;\n",
        "      return 0;\n",
        "    });\n",
        "    var frag = document.createDocumentFragment();\n",
        "    for(var i=0;i<rows.length;i++) frag.appendChild(rows[i]);\n",
        "    tb.appendChild(frag);\n",
        "    updateShowing();\n",
        "  }\n",
        "  function bindHeaderSort(){\n",
        "    var tbl = document.getElementById('refactor-table');\n",
        "    if(!(tbl && tbl.tHead && tbl.tHead.rows.length)) return;\n",
        "    var ths = tbl.tHead.rows[0].cells;\n",
        "    if(!ths) return;\n",
        "    for(var i=0;i<ths.length;i++)(function(idx){\n",
        "      var th = ths[idx];\n",
        "      var dir = 'asc';\n",
        "      th.addEventListener('click', function(){\n",
        "        dir = (dir === 'asc') ? 'desc' : 'asc';\n",
        "        for (var j = 0; j < ths.length; j++){\n",
        "          ths[j].innerHTML = ths[j].innerHTML.replace(/\\\\s+\\\\(asc\\\\)|\\\\s+\\\\(desc\\\\)/,'');\n",
        "        }\n",
        "        th.innerHTML += (dir === 'asc' ? ' (asc)' : ' (desc)');\n",
        "        sortTable(tbl, idx, dir);\n",
        "      }, false);\n",
        "    })(i);\n",
        "  }\n",
        "  function formatWithCommas(n){\n",
        "    try{\n",
        "      var x = parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10);\n",
        "      if(isNaN(x)) return '';\n",
        "      return x.toLocaleString('en-US');\n",
        "    }catch(e){ return String(n||''); }\n",
        "  }\n",
        "  function visibleRowCount(){\n",
        "    var tbl = document.getElementById('refactor-table');\n",
        "    if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return 0;\n",
        "    var rows = tbl.tBodies[0].rows, n = 0;\n",
        "    for(var i=0;i<rows.length;i++){\n",
        "      if(rows[i].style.display !== 'none') n++;\n",
        "    }\n",
        "    return n;\n",
        "  }\n",
        "  function updateShowing(){\n",
        "    var el = document.getElementById('showing-count');\n",
        "    if(!el) return;\n",
        "    el.textContent = formatWithCommas(visibleRowCount());\n",
        "  }\n",
        "  function getParam(name){\n",
        "    var m = location.search.match(new RegExp('[?&]'+name+'=([^&]+)'));\n",
        "    return m ? decodeURIComponent(m[1].replace(/\\\\+/g,' ')) : '';\n",
        "  }\n",
        "  function bindSearch(){\n",
        "    var box = document.getElementById('search-box');\n",
        "    var tbl = document.getElementById('refactor-table');\n",
        "    if(!(box && tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "    var tb = tbl.tBodies[0];\n",
        "    var rows = [].slice.call(tb.rows || []);\n",
        "    function rowText(tr){\n",
        "      var t = '';\n",
        "      for(var i=0;i<tr.cells.length;i++){\n",
        "        t += ' ' + (tr.cells[i].textContent || tr.cells[i].innerText || '');\n",
        "      }\n",
        "      return t.replace(/\\\\s+/g,' ').toLowerCase();\n",
        "    }\n",
        "    function apply(q){\n",
        "      q = String(q || '').toLowerCase();\n",
        "      for(var i=0;i<rows.length;i++){\n",
        "        var txt = rowText(rows[i]);\n",
        "        var show = !q || txt.indexOf(q) > -1;\n",
        "        rows[i].style.display = show ? '' : 'none';\n",
        "      }\n",
        "      updateShowing();\n",
        "    }\n",
        "    var to = null;\n",
        "    function onInput(){\n",
        "      if(to) clearTimeout(to);\n",
        "      to = setTimeout(function(){ apply(box.value); }, 60);\n",
        "    }\n",
        "    box.addEventListener('input', onInput, false);\n",
        "    box.addEventListener('search', onInput, false);\n",
        "    var q0 = getParam('q');\n",
        "    if(q0){\n",
        "      box.value = q0;\n",
        "      apply(q0);\n",
        "      try{ history.replaceState(null,'',location.pathname); }catch(e){}\n",
        "    } else {\n",
        "      box.value = '';\n",
        "      apply('');\n",
        "    }\n",
        "  }\n",
        "  function bindBackToTop(){\n",
        "    var btn = document.getElementById('back-to-top');\n",
        "    if(!btn) return;\n",
        "    function toggle(){ btn.style.display = (window.scrollY > 200 ? 'block' : 'none'); }\n",
        "    toggle();\n",
        "    window.addEventListener('scroll', toggle, {passive:true});\n",
        "    btn.addEventListener('click', function(){\n",
        "      try{\n",
        "        window.scrollTo({top:0, behavior:'smooth'});\n",
        "      } catch(e){\n",
        "        window.scrollTo(0,0);\n",
        "      }\n",
        "    }, false);\n",
        "  }\n",
        "  function stampAndCount(){\n",
        "    var el = document.getElementById('last-updated');\n",
        "    if(el){\n",
        "      var d = new Date(document.lastModified || new Date());\n",
        "      var months = ['January','February','March','April','May','June','July','August','September','October','November','December'];\n",
        "      var day = d.getDate();\n",
        "      var month = months[d.getMonth()];\n",
        "      var year = d.getFullYear();\n",
        "      var hour = d.getHours();\n",
        "      var min  = d.getMinutes();\n",
        "      var ampm = hour >= 12 ? 'pm' : 'am';\n",
        "      hour = hour % 12;\n",
        "      hour = hour ? hour : 12;\n",
        "      var minStr = min < 10 ? '0' + min : String(min);\n",
        "      el.innerHTML = day + ' ' + month + ', ' + year + ' at ' + hour + ':' + minStr + ' ' + ampm;\n",
        "    }\n",
        "    var elc = document.getElementById('auto-count');\n",
        "    if(!elc) return;\n",
        "    var URL = '$JS_COUNT_URL';\n",
        "    try{\n",
        "      var xhr = new XMLHttpRequest();\n",
        "      xhr.open('GET', URL + (URL.indexOf('?') > -1 ? '' : '?v=' + (new Date()).getTime()), true);\n",
        "      xhr.onreadystatechange = function(){\n",
        "        if(xhr.readyState === 4){\n",
        "          if(xhr.status >= 200 && xhr.status < 300){\n",
        "            var m = (xhr.responseText || '').match(/(\\\\d+)/);\n",
        "            elc.textContent = (m ? m[1] : '');\n",
        "          } else {\n",
        "            elc.textContent = '(unavailable)';\n",
        "          }\n",
        "        }\n",
        "      };\n",
        "      xhr.send(null);\n",
        "    } catch(e){\n",
        "      elc.textContent = '(unavailable)';\n",
        "    }\n",
        "  }\n",
        "  function bindSyncedScrollbars(){\n",
        "    var topScroll    = document.getElementById('top-scroll');\n",
        "    var bottomScroll = document.getElementById('bottom-scroll');\n",
        "    if(!(topScroll && bottomScroll)) return;\n",
        "    var syncing = false;\n",
        "    topScroll.addEventListener('scroll', function(){\n",
        "      if(syncing) return;\n",
        "      syncing = true;\n",
        "      bottomScroll.scrollLeft = topScroll.scrollLeft;\n",
        "      syncing = false;\n",
        "    }, false);\n",
        "    bottomScroll.addEventListener('scroll', function(){\n",
        "      if(syncing) return;\n",
        "      syncing = true;\n",
        "      topScroll.scrollLeft = bottomScroll.scrollLeft;\n",
        "      syncing = false;\n",
        "    }, false);\n",
        "  }\n",
        "  document.addEventListener('DOMContentLoaded', function(){\n",
        "    bindHeaderSort();\n",
        "    bindBackToTop();\n",
        "    bindSearch();\n",
        "    bindSyncedScrollbars();\n",
        "    stampAndCount();\n",
        "    updateShowing();\n",
        "  });\n",
        "})();\n",
        "//]]>\n",
        "</script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\")\n",
        "\n",
        "final_html = page_tpl.safe_substitute(\n",
        "    HEAD_LINK=HEAD_LINK,\n",
        "    DOWNLOADS_BLOCK=DOWNLOADS_BLOCK,\n",
        "    UPDATED_BLOCK=UPDATED_BLOCK,\n",
        "    NAV_BLOCK=NAV_BLOCK,\n",
        "    CONTROLS_BLOCK=CONTROLS_BLOCK,\n",
        "    SCROLL_WRAPPER=SCROLL_WRAPPER,\n",
        "    JS_COUNT_URL=COUNT_PUBLIC_URL\n",
        ")\n",
        "\n",
        "# ---------- Exports ----------\n",
        "export_df = df.copy()\n",
        "export_df.to_csv(LOCAL_CSV, index=False, encoding=\"iso-8859-15\")\n",
        "try:\n",
        "    export_df.to_excel(LOCAL_XLSX, index=False)\n",
        "except Exception:\n",
        "    from pandas import ExcelWriter\n",
        "    with ExcelWriter(LOCAL_XLSX) as _w:\n",
        "        export_df.to_excel(_w, index=False)\n",
        "print(\"[OK] Wrote exports:\", os.path.abspath(LOCAL_CSV), \"and\", os.path.abspath(LOCAL_XLSX))\n",
        "\n",
        "# ---------- Save page locally ----------\n",
        "try:\n",
        "    with open(OUTPUT_NAME, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(final_html)\n",
        "    print(\"[OK] Saved locally:\", os.path.abspath(OUTPUT_NAME))\n",
        "except Exception as e:\n",
        "    print(\"[ERROR] Save failed:\", e)\n",
        "    traceback.print_exc()\n",
        "\n",
        "# ---------- Upload to /partials ----------\n",
        "def _ftps_ensure_dir(ftps, path):\n",
        "    if not path:\n",
        "        return\n",
        "    for seg in [p for p in path.split(\"/\") if p]:\n",
        "        try:\n",
        "            ftps.cwd(seg)\n",
        "        except Exception:\n",
        "            try:\n",
        "                ftps.mkd(seg)\n",
        "            except Exception:\n",
        "                pass\n",
        "            ftps.cwd(seg)\n",
        "\n",
        "ftp_host = os.environ.get(\"FTP_HOST\")\n",
        "ftp_user = os.environ.get(\"FTP_USER\")\n",
        "ftp_pass = os.environ.get(\"FTP_PASS\")\n",
        "ftp_port = int(os.environ.get(\"FTP_PORT\", \"21\") or \"21\")\n",
        "\n",
        "if ftp_host and ftp_user and ftp_pass:\n",
        "    print(\"[INFO] Attempting FTP upload ...\")\n",
        "    try:\n",
        "        socket.setdefaulttimeout(30)\n",
        "        with FTP_TLS(timeout=30) as ftps:\n",
        "            ftps.connect(ftp_host, ftp_port)\n",
        "            ftps.login(ftp_user, ftp_pass)\n",
        "            try:\n",
        "                ftps.prot_p()\n",
        "            except Exception:\n",
        "                pass\n",
        "            try:\n",
        "                ftps.set_pasv(True)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "            _ftps_ensure_dir(ftps, FTP_DIR)\n",
        "            _ftps_ensure_dir(ftps, \"partials\")\n",
        "\n",
        "            # Upload HTML (.shtml for SSI)\n",
        "            with open(OUTPUT_NAME, \"rb\") as fh:\n",
        "                ftps.storbinary(\"STOR \" + os.path.basename(REMOTE_HTML), fh)\n",
        "            print(\"[OK] Uploaded HTML -> /partials/%s\" % os.path.basename(REMOTE_HTML))\n",
        "\n",
        "            # Upload CSV/XLSX\n",
        "            with open(LOCAL_CSV, \"rb\") as fh:\n",
        "                ftps.storbinary(\"STOR \" + os.path.basename(REMOTE_CSV), fh)\n",
        "            with open(LOCAL_XLSX, \"rb\") as fh:\n",
        "                ftps.storbinary(\"STOR \" + os.path.basename(REMOTE_XLSX), fh)\n",
        "            print(\"[OK] Uploaded exports -> /partials/ (%s, %s)\" % (LOCAL_CSV, LOCAL_XLSX))\n",
        "\n",
        "            print(\"\\n--- Open URLs ---\")\n",
        "            print(\"Trees page:       https://yates.one-name.net/partials/just-trees.shtml\")\n",
        "            print(\"CSV export:       https://yates.one-name.net/partials/%s\" % os.path.basename(LOCAL_CSV))\n",
        "            print(\"Excel export:     https://yates.one-name.net/partials/%s\" % os.path.basename(LOCAL_XLSX))\n",
        "    except Exception as e:\n",
        "        print(\"[ERROR] FTP session failed:\", e)\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"[INFO] Skipping FTP upload (missing credentials).\")\n",
        "\n",
        "print(\"\\n--- Cell 3 Complete (.shtml + SSI nav; TOP visible scroll + hidden bottom; sticky col 2; sortable/searchable with 'Showing' count; exports + upload ready) ---\")\n",
        "# ====== CUT STOP  [1/1] CELL 3 ==================================================================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ir1ZxRhf2xk",
        "outputId": "2239aad4-15eb-4467-8936-7568f4194c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CONFIRM] Golden Rules active | Cell=Cell3_OldSchoolMenu_WhiteText | Version=2025.11.15 | Encoding=ISO-8859-15\n",
            "[OK] Loaded CSV: final_combined_df_with_value_labels.csv rows=7, cols=6\n",
            "Using resolver: /content/match_to_unmasked.csv\n",
            "[OK] Column B -> C mapping: 7 / 7  unmatched: 0\n",
            "[OK] Wrote exports: /content/yates_ancestor_register.csv and /content/yates_ancestor_register.xlsx\n",
            "[OK] Saved locally: /content/just-trees.shtml\n",
            "[INFO] Attempting FTP upload ...\n",
            "[OK] Uploaded HTML -> /partials/just-trees.shtml\n",
            "[OK] Uploaded exports -> /partials/ (yates_ancestor_register.csv, yates_ancestor_register.xlsx)\n",
            "\n",
            "--- Open URLs ---\n",
            "Trees page:       https://yates.one-name.net/partials/just-trees.shtml\n",
            "CSV export:       https://yates.one-name.net/partials/yates_ancestor_register.csv\n",
            "Excel export:     https://yates.one-name.net/partials/yates_ancestor_register.xlsx\n",
            "\n",
            "--- Cell 3 Complete (.shtml + SSI nav; TOP visible scroll + hidden bottom; sticky col 2; sortable/searchable with 'Showing' count; exports + upload ready) ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# debug"
      ],
      "metadata": {
        "id": "9G7Y0HwjtZIt"
      }
    }
  ]
}