{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyME3lY45G+SM29KzhxBLvoW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronyates47/Gedcom-Utils/blob/main/Gold__1_%26_2_%26_3_20251108_1200.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PIP"
      ],
      "metadata": {
        "id": "XtvXRl-lcavJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT5s4n9S5ZpZ",
        "outputId": "a8dd2836-a3df-4796-d72b-598e05cc79d8",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting python-gedcom\n",
            "  Downloading python_gedcom-1.0.0-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Downloading python_gedcom-1.0.0-py2.py3-none-any.whl (35 kB)\n",
            "Installing collected packages: python-gedcom\n",
            "Successfully installed python-gedcom-1.0.0\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Collecting xlsxwriter\n",
            "  Downloading xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\n",
            "Downloading xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.9\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.12/dist-packages (0.23.4)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (1.16.3)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (1.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from mlxtend) (1.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.1->mlxtend) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.17.0)\n",
            "ERROR: unknown command \"caas_jupyter_tools\"\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install python-gedcom\n",
        "!pip install openpyxl\n",
        "!pip install xlsxwriter\n",
        "!pip install mlxtend\n",
        "!pip caas_jupyter_tools"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ron Rules-QUICK CODE CARD (v2025.10.27-Refined)\n",
        "# - Complete & runnable in Colab; ISO-8859-15 (ASCII-only in source).\n",
        "# - Punctuation in strings use HTML entities (&rsquo; &ldquo; &rdquo; &mdash; &rarr;).\n",
        "# - Deliver Python code (inline, executable, CUT-ready section)\n",
        "# - XHTML 1.0 Transitional; old-school friendly; Times New Roman body.\n",
        "# - Use CUT markers; five # spacer lines follow the STOP marker."
      ],
      "metadata": {
        "id": "g3hSp6RQHgPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Style Sheet"
      ],
      "metadata": {
        "id": "hqUDdX5zb3Eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] UPDATE /partials/dna_tree_styles.css — SITE-WIDE SANS ==================\n",
        "# RON RULES — QUICK CODE CARD (v2025.11.06-SharedCSS-SiteWideSans)\n",
        "# - Complete & runnable in Colab; ISO-8859-15 (ASCII-only in source).\n",
        "# - Purpose: Switch site-wide body typeface to a sans stack in /partials/dna_tree_styles.css\n",
        "# - Creates a timestamped .bak on the server before overwrite.\n",
        "\n",
        "import os, re, socket, time, traceback\n",
        "from ftplib import FTP_TLS\n",
        "\n",
        "# ---------- Secrets ----------\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ['FTP_HOST'] = userdata.get('FTP_HOST')\n",
        "    os.environ['FTP_USER'] = userdata.get('FTP_USER')\n",
        "    os.environ['FTP_PASS'] = userdata.get('FTP_PASS')\n",
        "    try:  os.environ['FTP_PORT'] = userdata.get('FTP_PORT')\n",
        "    except Exception: os.environ.setdefault('FTP_PORT', '21')\n",
        "    try:  os.environ['FTP_DIR']  = userdata.get('FTP_DIR')\n",
        "    except Exception: os.environ.setdefault('FTP_DIR', '')\n",
        "except Exception:\n",
        "    os.environ.setdefault('FTP_HOST', '')\n",
        "    os.environ.setdefault('FTP_USER', '')\n",
        "    os.environ.setdefault('FTP_PASS', '')\n",
        "    os.environ.setdefault('FTP_PORT', '21')\n",
        "    os.environ.setdefault('FTP_DIR', '')\n",
        "\n",
        "FTP_HOST = os.environ.get('FTP_HOST','')\n",
        "FTP_USER = os.environ.get('FTP_USER','')\n",
        "FTP_PASS = os.environ.get('FTP_PASS','')\n",
        "FTP_PORT = int(os.environ.get('FTP_PORT','21'))\n",
        "FTP_DIR  = (os.environ.get('FTP_DIR','') or '').strip('/')\n",
        "\n",
        "TARGET_DIR  = 'partials'\n",
        "TARGET_NAME = 'dna_tree_styles.css'\n",
        "LOCAL_ORIG  = 'dna_tree_styles.orig.css'\n",
        "LOCAL_NEW   = 'dna_tree_styles.css'\n",
        "\n",
        "if not all([FTP_HOST, FTP_USER, FTP_PASS]):\n",
        "    raise SystemExit(\"[EXIT] Missing FTP creds in Colab userdata: FTP_HOST/FTP_USER/FTP_PASS\")\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def _connect():\n",
        "    socket.setdefaulttimeout(30)\n",
        "    ftps = FTP_TLS(timeout=30)\n",
        "    ftps.connect(FTP_HOST, FTP_PORT)\n",
        "    ftps.login(FTP_USER, FTP_PASS)\n",
        "    try: ftps.prot_p()\n",
        "    except Exception: pass\n",
        "    try: ftps.set_pasv(True)\n",
        "    except Exception: pass\n",
        "    if FTP_DIR:\n",
        "        for p in [p for p in FTP_DIR.split('/') if p]:\n",
        "            try: ftps.cwd(p)\n",
        "            except Exception:\n",
        "                try: ftps.mkd(p)\n",
        "                except Exception: pass\n",
        "                ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "def _cwd(ftps, path):\n",
        "    for p in [q for q in path.split('/') if q]:\n",
        "        try:\n",
        "            ftps.cwd(p)\n",
        "        except Exception:\n",
        "            try: ftps.mkd(p)\n",
        "            except Exception: pass\n",
        "            ftps.cwd(p)\n",
        "\n",
        "def _download(ftps, remote_name, local_name):\n",
        "    with open(local_name, 'wb') as f:\n",
        "        ftps.retrbinary('RETR ' + remote_name, f.write)\n",
        "    print(\"[OK] Downloaded:\", remote_name, \"->\", os.path.abspath(local_name))\n",
        "\n",
        "def _upload(ftps, local_name, remote_name):\n",
        "    with open(local_name, 'rb') as f:\n",
        "        ftps.storbinary('STOR ' + remote_name, f)\n",
        "    print(\"[OK] Uploaded:\", os.path.abspath(local_name), \"->\", remote_name)\n",
        "\n",
        "def _server_backup(ftps, remote_name):\n",
        "    ts = time.strftime(\"%Y%m%d%H%M\")\n",
        "    bak = remote_name + \".\" + ts + \".bak\"\n",
        "    try:\n",
        "        with open(\"__tmp_bak.css\", \"wb\") as tmp:\n",
        "            ftps.retrbinary('RETR ' + remote_name, tmp.write)\n",
        "        with open(\"__tmp_bak.css\", \"rb\") as tmp:\n",
        "            ftps.storbinary('STOR ' + bak, tmp)\n",
        "        try: os.remove(\"__tmp_bak.css\")\n",
        "        except Exception: pass\n",
        "        print(\"[OK] Server backup created:\", bak)\n",
        "    except Exception as e:\n",
        "        print(\"[WARN] Could not create server backup:\", e)\n",
        "\n",
        "def _set_body_sans(css_text):\n",
        "    # Switch the body stack to sans-serif; add a body rule if missing\n",
        "    if re.search(r'body\\s*\\{[^}]*font-family\\s*:', css_text, flags=re.I|re.S):\n",
        "        return re.sub(\n",
        "            r'(body\\s*\\{[^}]*?)font-family\\s*:\\s*[^;]+;',\n",
        "            r\"\\1font-family: Arial, Helvetica, sans-serif;\",\n",
        "            css_text, flags=re.I|re.S\n",
        "        )\n",
        "    else:\n",
        "        return \"body { font-family: Arial, Helvetica, sans-serif; }\\n\\n\" + css_text\n",
        "\n",
        "# ---------- Main ----------\n",
        "try:\n",
        "    ftps = _connect()\n",
        "    _cwd(ftps, TARGET_DIR)\n",
        "\n",
        "    # 1) Pull current css\n",
        "    _download(ftps, TARGET_NAME, LOCAL_ORIG)\n",
        "\n",
        "    # 2) Transform body font-family to sans stack\n",
        "    with open(LOCAL_ORIG, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "        css = f.read()\n",
        "    new_css = _set_body_sans(css)\n",
        "\n",
        "    # 3) Save ISO-8859-15 safe\n",
        "    with open(LOCAL_NEW, 'w', encoding='iso-8859-15', errors='xmlcharrefreplace') as f:\n",
        "        f.write(new_css)\n",
        "    print(\"[OK] Prepared modified CSS locally:\", os.path.abspath(LOCAL_NEW))\n",
        "\n",
        "    # 4) Server backup + upload\n",
        "    _server_backup(ftps, TARGET_NAME)\n",
        "    _upload(ftps, LOCAL_NEW, TARGET_NAME)\n",
        "\n",
        "    try: ftps.quit()\n",
        "    except Exception: pass\n",
        "\n",
        "    print(\"\\nDONE. Site-wide body font set to Arial, Helvetica, sans-serif.\")\n",
        "    print(\"If a page still shows serif, it likely has later inline <style> forcing Times New Roman.\")\n",
        "    print(\"Add ?v=1 to the page URL or hard-refresh to bust cache.\")\n",
        "except SystemExit as e:\n",
        "    print(str(e))\n",
        "except Exception as e:\n",
        "    print(\"[ERROR] CSS update failed:\", e)\n",
        "    traceback.print_exc()\n",
        "# ====== CUT STOP  [1/1] UPDATE /partials/dna_tree_styles.css — SITE-WIDE SANS ==================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntMaP8X-cDLm",
        "outputId": "f1689f39-f1a1-41b4-febc-18b7888cb5e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Downloaded: dna_tree_styles.css -> /content/dna_tree_styles.orig.css\n",
            "[OK] Prepared modified CSS locally: /content/dna_tree_styles.css\n",
            "[OK] Server backup created: dna_tree_styles.css.202511062314.bak\n",
            "[OK] Uploaded: /content/dna_tree_styles.css -> dna_tree_styles.css\n",
            "\n",
            "DONE. Site-wide body font set to Arial, Helvetica, sans-serif.\n",
            "If a page still shows serif, it likely has later inline <style> forcing Times New Roman.\n",
            "Add ?v=1 to the page URL or hard-refresh to bust cache.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] CENTERLINE FIX — Update shared CSS + Upload =============================\n",
        "# RON RULES — QUICK CODE CARD (v2025.11.06-CSS-Centerline-Fix)\n",
        "# - Complete & runnable in Colab; ISO-8859-15 safe in source.\n",
        "# - Purpose: ensure \"Last updated …\" (meta) is centered site-wide via shared stylesheet.\n",
        "# - Actions: edit/insert CENTERLINE FIX block in dna_tree_styles.css and FTPS-upload to /partials/.\n",
        "\n",
        "import os, re, socket, posixpath, traceback\n",
        "from ftplib import FTP_TLS\n",
        "from datetime import datetime\n",
        "\n",
        "# ---------- 0) Secrets ----------\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ['FTP_HOST'] = userdata.get('FTP_HOST')\n",
        "    os.environ['FTP_USER'] = userdata.get('FTP_USER')\n",
        "    os.environ['FTP_PASS'] = userdata.get('FTP_PASS')\n",
        "    try: os.environ['FTP_DIR']  = userdata.get('FTP_DIR')\n",
        "    except Exception: os.environ.setdefault('FTP_DIR', '')\n",
        "    try: os.environ['FTP_PORT'] = userdata.get('FTP_PORT')\n",
        "    except Exception: os.environ.setdefault('FTP_PORT', '21')\n",
        "except Exception:\n",
        "    os.environ.setdefault('FTP_HOST', '')\n",
        "    os.environ.setdefault('FTP_USER', '')\n",
        "    os.environ.setdefault('FTP_PASS', '')\n",
        "    os.environ.setdefault('FTP_DIR',  '')\n",
        "    os.environ.setdefault('FTP_PORT', '21')\n",
        "\n",
        "FTP_DIR   = (os.environ.get(\"FTP_DIR\",\"\") or \"\").strip()\n",
        "LOCAL_CSS = \"dna_tree_styles.css\"\n",
        "REMOTE_CSS = posixpath.join(\"partials\", \"dna_tree_styles.css\")\n",
        "\n",
        "# ---------- 1) Ensure local css exists (create if missing) ----------\n",
        "if not os.path.exists(LOCAL_CSS):\n",
        "    with open(LOCAL_CSS, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"/* yates.one-name.net shared stylesheet */\\n\")\n",
        "    print(\"[INFO] Created new local stylesheet:\", os.path.abspath(LOCAL_CSS))\n",
        "else:\n",
        "    print(\"[OK] Using existing local stylesheet:\", os.path.abspath(LOCAL_CSS))\n",
        "\n",
        "# ---------- 2) Insert/replace CENTERLINE FIX block ----------\n",
        "with open(LOCAL_CSS, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
        "    css = f.read()\n",
        "\n",
        "start_tag = \"/* === CENTERLINE FIX (do not remove) START === */\"\n",
        "end_tag   = \"/* === CENTERLINE FIX (do not remove) END === */\"\n",
        "block_re  = re.compile(re.escape(start_tag) + r\".*?\" + re.escape(end_tag), flags=re.S)\n",
        "\n",
        "center_block = f\"\"\"{start_tag}\n",
        ":root {{\n",
        "  /* nothing here yet; reserved for future tokens */\n",
        "}}\n",
        "/* Utility: hard center text, wins against generic .meta rules */\n",
        ".centerline {{ text-align: center !important; }}\n",
        "\n",
        "/* Meta display: keep centered across pages, even if other CSS sets .meta {{text-align:left}} */\n",
        ".wrap .meta, .intro .meta, .updated, .updated.centerline {{\n",
        "  text-align: center !important;\n",
        "}}\n",
        "\n",
        "/* Table meta stamping alignment on partials and main pages */\n",
        "#last-updated, #auto-count, #showing-count {{ /* inline metrics */ }}\n",
        "{end_tag}\n",
        "\"\"\"\n",
        "\n",
        "if block_re.search(css):\n",
        "    css = block_re.sub(center_block, css)\n",
        "    action = \"[OK] Replaced existing CENTERLINE FIX block.\"\n",
        "else:\n",
        "    # Append with a divider so it overrides earlier rules\n",
        "    css += \"\\n\\n/* ------------------------------------------------------------------ */\\n\" + center_block + \"\\n\"\n",
        "    action = \"[OK] Appended CENTERLINE FIX block.\"\n",
        "\n",
        "with open(LOCAL_CSS, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(css)\n",
        "\n",
        "print(action)\n",
        "\n",
        "# ---------- 3) Upload via FTPS ----------\n",
        "def ftp_connect() -> FTP_TLS:\n",
        "    ftps = FTP_TLS(timeout=30)\n",
        "    socket.setdefaulttimeout(30)\n",
        "    ftps.connect(os.environ.get('FTP_HOST',''), int(os.environ.get('FTP_PORT','21')))\n",
        "    ftps.login(os.environ.get('FTP_USER',''), os.environ.get('FTP_PASS',''))\n",
        "    try: ftps.prot_p()\n",
        "    except Exception: pass\n",
        "    try: ftps.set_pasv(True)\n",
        "    except Exception: pass\n",
        "    if FTP_DIR:\n",
        "        for p in [p for p in FTP_DIR.split(\"/\") if p]:\n",
        "            try: ftps.mkd(p)\n",
        "            except Exception: pass\n",
        "            ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "def ensure_remote_dirs(ftps: FTP_TLS, path: str):\n",
        "    parts = [p for p in path.split(\"/\")[:-1] if p]\n",
        "    for seg in parts:\n",
        "        try: ftps.cwd(seg)\n",
        "        except Exception:\n",
        "            try: ftps.mkd(seg)\n",
        "            except Exception: pass\n",
        "            ftps.cwd(seg)\n",
        "\n",
        "if all(os.environ.get(k) for k in (\"FTP_HOST\",\"FTP_USER\",\"FTP_PASS\")):\n",
        "    try:\n",
        "        ftps = ftp_connect()\n",
        "        ensure_remote_dirs(ftps, REMOTE_CSS)\n",
        "        with open(LOCAL_CSS, \"rb\") as fh:\n",
        "            ftps.storbinary(f\"STOR {REMOTE_CSS}\", fh)\n",
        "        try: sz = ftps.size(REMOTE_CSS)\n",
        "        except Exception: sz = None\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "        print(f\"[PUT] {LOCAL_CSS} -> /{REMOTE_CSS}  (size: {sz if sz is not None else 'unknown'})\")\n",
        "        print(\"Cache-bust tip: add ?v=\" + datetime.utcnow().strftime(\"%Y%m%d%H%M%S\") + \" once if needed.\")\n",
        "    except Exception as e:\n",
        "        print(\"[FAIL] FTPS upload:\", e)\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"[SKIP] Missing FTP creds; upload not attempted.\")\n",
        "\n",
        "print(\"\\nNext step:\")\n",
        "print(\"1) In Cell 3 template, ensure the meta block uses class 'centerline':\")\n",
        "print(\"   <div class=\\\"meta centerline\\\">Last updated: <span id=\\\"last-updated\\\"></span> ...</div>\")\n",
        "print(\"   (Cell 2 already uses 'updated centerline'.)\")\n",
        "print(\"2) Re-run Cell 3 to regenerate HTML, or refresh the page with ?v=1.\")\n",
        "# ====== CUT STOP  [1/1] CENTERLINE FIX — Update shared CSS + Upload =============================\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zPfncKCDLVk",
        "outputId": "372acbbe-1c6f-413f-8623-e59bd062a30f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Using existing local stylesheet: /content/dna_tree_styles.css\n",
            "[OK] Appended CENTERLINE FIX block.\n",
            "[FAIL] FTPS upload: 553 Can't open that file: No such file or directory\n",
            "\n",
            "Next step:\n",
            "1) In Cell 3 template, ensure the meta block uses class 'centerline':\n",
            "   <div class=\"meta centerline\">Last updated: <span id=\"last-updated\"></span> ...</div>\n",
            "   (Cell 2 already uses 'updated centerline'.)\n",
            "2) Re-run Cell 3 to regenerate HTML, or refresh the page with ?v=1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-992470288.py\", line 109, in <cell line: 0>\n",
            "    ftps.storbinary(f\"STOR {REMOTE_CSS}\", fh)\n",
            "  File \"/usr/lib/python3.12/ftplib.py\", line 495, in storbinary\n",
            "    with self.transfercmd(cmd, rest) as conn:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/ftplib.py\", line 393, in transfercmd\n",
            "    return self.ntransfercmd(cmd, rest)[0]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/ftplib.py\", line 771, in ntransfercmd\n",
            "    conn, size = super().ntransfercmd(cmd, rest)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/ftplib.py\", line 359, in ntransfercmd\n",
            "    resp = self.sendcmd(cmd)\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/ftplib.py\", line 281, in sendcmd\n",
            "    return self.getresp()\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/ftplib.py\", line 254, in getresp\n",
            "    raise error_perm(resp)\n",
            "ftplib.error_perm: 553 Can't open that file: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] CELL — iOS Font/Spacing CSS Fix + Cache-Busted Reupload =================\n",
        "# RON RULES — QUICK CODE CARD (v2025.11.07-iOS-CSS-Fix)\n",
        "# - Complete & runnable in Colab; ISO-8859-15 (ASCII-only in source).\n",
        "# - No snippets; no fabrication; explicit prints.\n",
        "# - Actions:\n",
        "#   (1) Download /partials/dna_tree_styles.css, append a minimal iOS fix block (safe, idempotent).\n",
        "#   (2) Upload patched css back to /partials/dna_tree_styles.css.\n",
        "#   (3) For selected HTML pages in /partials/, download, inject/refresh '?v=TIMESTAMP' on\n",
        "#       '/partials/dna_tree_styles.css' link, and upload back (cache-bust so iPhone fetches new CSS).\n",
        "# - This cell does NOT change any other content; only the CSS and the cache-buster query on the CSS link.\n",
        "\n",
        "import os, re, io, posixpath, socket, traceback, datetime\n",
        "from ftplib import FTP_TLS\n",
        "\n",
        "# ---------- 0) Secrets ----------\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ['FTP_HOST'] = userdata.get('FTP_HOST')\n",
        "    os.environ['FTP_USER'] = userdata.get('FTP_USER')\n",
        "    os.environ['FTP_PASS'] = userdata.get('FTP_PASS')\n",
        "    try: os.environ['FTP_DIR']  = userdata.get('FTP_DIR')\n",
        "    except Exception: os.environ.setdefault('FTP_DIR', '')\n",
        "    try: os.environ['FTP_PORT'] = userdata.get('FTP_PORT')\n",
        "    except Exception: os.environ.setdefault('FTP_PORT', '21')\n",
        "except Exception:\n",
        "    os.environ.setdefault('FTP_HOST', '')\n",
        "    os.environ.setdefault('FTP_USER', '')\n",
        "    os.environ.setdefault('FTP_PASS', '')\n",
        "    os.environ.setdefault('FTP_DIR',  '')\n",
        "    os.environ.setdefault('FTP_PORT', '21')\n",
        "\n",
        "FTP_DIR     = (os.environ.get(\"FTP_DIR\",\"\") or \"\").strip()\n",
        "FTP_TIMEOUT = int(os.environ.get(\"FTP_TIMEOUT\", \"30\"))\n",
        "FTP_PASSIVE = True\n",
        "\n",
        "def ftp_connect() -> FTP_TLS:\n",
        "    ftps = FTP_TLS(timeout=FTP_TIMEOUT)\n",
        "    socket.setdefaulttimeout(FTP_TIMEOUT)\n",
        "    ftps.connect(os.environ.get('FTP_HOST',''), int(os.environ.get('FTP_PORT', 21)))\n",
        "    ftps.login(os.environ.get('FTP_USER',''), os.environ.get('FTP_PASS',''))\n",
        "    try: ftps.prot_p()\n",
        "    except Exception: pass\n",
        "    try: ftps.set_pasv(FTP_PASSIVE)\n",
        "    except Exception: pass\n",
        "    if FTP_DIR:\n",
        "        parts = [p for p in FTP_DIR.split(\"/\") if p]\n",
        "        for p in parts:\n",
        "            try: ftps.mkd(p)\n",
        "            except Exception: pass\n",
        "            ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "def _remote_path(name: str) -> str:\n",
        "    return posixpath.join(FTP_DIR, name) if FTP_DIR else name\n",
        "\n",
        "def ensure_remote_dirs(ftps: FTP_TLS, remote_path: str):\n",
        "    if \"/\" not in remote_path: return\n",
        "    pwd0 = ftps.pwd()\n",
        "    for seg in [p for p in remote_path.split(\"/\")[:-1] if p and p != \".\"]:\n",
        "        try: ftps.cwd(seg)\n",
        "        except Exception:\n",
        "            try: ftps.mkd(seg)\n",
        "            except Exception: pass\n",
        "            ftps.cwd(seg)\n",
        "    ftps.cwd(pwd0)\n",
        "\n",
        "def ftp_download(ftps: FTP_TLS, remote_name: str) -> bytes:\n",
        "    buf = io.BytesIO()\n",
        "    ftps.retrbinary(f\"RETR {remote_name}\", buf.write)\n",
        "    return buf.getvalue()\n",
        "\n",
        "def ftp_download_if_exists(ftps: FTP_TLS, remote_name: str) -> bytes:\n",
        "    try:\n",
        "        return ftp_download(ftps, remote_name)\n",
        "    except Exception as e:\n",
        "        raise FileNotFoundError(f\"Missing remote file: {remote_name} ({e})\")\n",
        "\n",
        "def ftp_upload_overwrite(ftps: FTP_TLS, content_bytes: bytes, remote_name: str):\n",
        "    ensure_remote_dirs(ftps, remote_name)\n",
        "    bio = io.BytesIO(content_bytes)\n",
        "    ftps.storbinary(f\"STOR {remote_name}\", bio)\n",
        "\n",
        "def ftp_size(ftps: FTP_TLS, remote_name: str):\n",
        "    try:\n",
        "        sz = ftps.size(remote_name)\n",
        "        return int(sz) if sz is not None else None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# ---------- 1) Targets ----------\n",
        "CSS_REMOTE = \"partials/dna_tree_styles.css\"\n",
        "\n",
        "# HTML pages where we refresh the cache-buster on the CSS link.\n",
        "HTML_TARGETS = [\n",
        "    \"partials/yates_ancestor_register.htm\",\n",
        "    \"partials/ons_yates_dna_register.htm\",\n",
        "    \"partials/justdna.htm\",\n",
        "    \"partials/just-trees.htm\",\n",
        "    \"partials/yates_ancestor_register_plus.htm\",\n",
        "    \"partials/work_plus.htm\",\n",
        "    \"partials/match_count.htm\",\n",
        "    \"partials/lineage_count.htm\",\n",
        "    \"partials/cousin_list_print.htm\",\n",
        "]\n",
        "\n",
        "# ---------- 2) Patch builder (idempotent) ----------\n",
        "def patch_css_for_ios(css_text: str) -> str:\n",
        "    # Minimal iOS-friendly adjustments. We wrap in a clearly-marked block; re-running does not duplicate.\n",
        "    # - table.sortable th/td line-height and word-break normalization\n",
        "    # - -webkit-text-size-adjust safeguard\n",
        "    block_header = \"/* --- iOS font/spacing fix (2025-11-07) --- */\"\n",
        "    block_rules  = (\n",
        "        \"html, body { -webkit-text-size-adjust:100%; }\\n\"\n",
        "        \"table.sortable th, table.sortable td { line-height:1.5; word-break:normal; }\\n\"\n",
        "    )\n",
        "    if block_header in css_text:\n",
        "        # Already present; optionally refresh the block content in place to ensure exact rules.\n",
        "        rx = re.compile(r\"/\\*\\s*--- iOS font/spacing fix .*?--- \\*/\\s*[^/]*?(?=$|/\\*)\", re.S)\n",
        "        if rx.search(css_text):\n",
        "            css_text = rx.sub(block_header + \"\\n\" + block_rules, css_text, count=1)\n",
        "        else:\n",
        "            # Edge case: header string present but regex did not match; append once.\n",
        "            css_text = css_text.rstrip() + \"\\n\\n\" + block_header + \"\\n\" + block_rules\n",
        "    else:\n",
        "        css_text = css_text.rstrip() + \"\\n\\n\" + block_header + \"\\n\" + block_rules\n",
        "    return css_text\n",
        "\n",
        "def refresh_css_cache_buster(html_text: str, ts: str) -> str:\n",
        "    # Replace any existing query (?v=...) on /partials/dna_tree_styles.css with the new timestamp.\n",
        "    # Handles single/double-quoted attributes.\n",
        "    def _repl(m):\n",
        "        prefix = m.group(1)  # href=\" or href='\n",
        "        path   = m.group(2)  # /partials/dna_tree_styles.css\n",
        "        return f'{prefix}{path}?v={ts}\"'\n",
        "    # Normalize to double-quote for replacement safety.\n",
        "    html_text = html_text.replace(\"'\", '\"')\n",
        "    pat = re.compile(r'(href=\")(/partials/dna_tree_styles\\.css)(?:\\?[^\"]*)?\"', re.I)\n",
        "    if pat.search(html_text):\n",
        "        html_text = pat.sub(_repl, html_text)\n",
        "    else:\n",
        "        # If a link tag exists without direct match, try to inject one in <head> (rare fallback).\n",
        "        head_pat = re.compile(r\"<head[^>]*>\", re.I)\n",
        "        if head_pat.search(html_text):\n",
        "            link_tag = f'<link rel=\"stylesheet\" type=\"text/css\" href=\"/partials/dna_tree_styles.css?v={ts}\" />'\n",
        "            html_text = head_pat.sub(lambda m: m.group(0) + \"\\n\" + link_tag, html_text, count=1)\n",
        "    return html_text\n",
        "\n",
        "# ---------- 3) Execute patch + uploads ----------\n",
        "def run_fix():\n",
        "    if not all(os.environ.get(k) for k in ['FTP_HOST','FTP_USER','FTP_PASS']):\n",
        "        print(\"[SKIP] Missing FTP creds; uploads skipped.\")\n",
        "        return\n",
        "\n",
        "    ts = datetime.datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "    print(\"[INFO] Cache-buster timestamp:\", ts)\n",
        "\n",
        "    try:\n",
        "        ftps = ftp_connect()\n",
        "\n",
        "        # Patch CSS\n",
        "        print(\"[STEP] Download existing CSS:\", \"/\" + _remote_path(CSS_REMOTE))\n",
        "        css_bytes = ftp_download_if_exists(ftps, _remote_path(CSS_REMOTE))\n",
        "        try:\n",
        "            css_text = css_bytes.decode(\"utf-8\")\n",
        "        except Exception:\n",
        "            css_text = css_bytes.decode(\"iso-8859-15\", errors=\"ignore\")\n",
        "\n",
        "        patched = patch_css_for_ios(css_text)\n",
        "        # Keep CSS ASCII to maintain ISO-8859-15 safety; rules are ASCII-only.\n",
        "        patched_bytes = patched.encode(\"ascii\", errors=\"ignore\")\n",
        "        ftp_upload_overwrite(ftps, patched_bytes, _remote_path(CSS_REMOTE))\n",
        "        print(\"[OK] Uploaded patched CSS -> /\" + _remote_path(CSS_REMOTE))\n",
        "\n",
        "        # Touch each HTML to refresh the cache-buster on the CSS link.\n",
        "        for rel in HTML_TARGETS:\n",
        "            rp = _remote_path(rel)\n",
        "            try:\n",
        "                html_bytes = ftp_download(ftps, rp)\n",
        "            except Exception as e:\n",
        "                print(f\"[MISS] {rp} ({e}); skipping.\")\n",
        "                continue\n",
        "            # Decode as ISO-8859-15 first (your pages are authored that way), fallback to utf-8.\n",
        "            try:\n",
        "                html_text = html_bytes.decode(\"iso-8859-15\")\n",
        "            except Exception:\n",
        "                html_text = html_bytes.decode(\"utf-8\", errors=\"ignore\")\n",
        "\n",
        "            updated = refresh_css_cache_buster(html_text, ts)\n",
        "            # Write back in ISO-8859-15 with entity fallback.\n",
        "            out_bytes = updated.encode(\"iso-8859-15\", errors=\"xmlcharrefreplace\")\n",
        "            ftp_upload_overwrite(ftps, out_bytes, rp)\n",
        "            print(\"[PUT]  cache-busted:\", \"/\" + rp)\n",
        "\n",
        "        # Size check (best-effort)\n",
        "        print(\"\\n--- SIZE Verification (if supported) ---\")\n",
        "        for p in [ _remote_path(CSS_REMOTE) ] + [ _remote_path(h) for h in HTML_TARGETS ]:\n",
        "            try:\n",
        "                sz = ftp_size(ftps, p)\n",
        "                print(f\"/{p} : {sz if sz is not None else '(SIZE unsupported)'}\")\n",
        "            except Exception:\n",
        "                print(f\"/{p} : (check skipped)\")\n",
        "\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "\n",
        "        print(\"\\n--- Open a couple of pages (manual hard-refresh optional) ---\")\n",
        "        print(\"DNA Register:          https://yates.one-name.net/partials/yates_ancestor_register.htm\")\n",
        "        print(\"Register PLUS:         https://yates.one-name.net/partials/yates_ancestor_register_plus.htm\")\n",
        "        print(\"Trees:                 https://yates.one-name.net/partials/just-trees.htm\")\n",
        "        print(\"Shared stylesheet:     https://yates.one-name.net/partials/dna_tree_styles.css\")\n",
        "        print(\"\\nIf an iPhone still shows old spacing, try a hard-refresh (Safari: tap-reload or clear cache).\")\n",
        "    except Exception as e:\n",
        "        print(\"[FAIL] Session:\", e)\n",
        "        traceback.print_exc()\n",
        "\n",
        "run_fix()\n",
        "# ====== CUT STOP  [1/1] CELL ====================================================================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Inck5IHqXqQu",
        "outputId": "be610741-668e-46de-bc45-e384de77478c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3198153314.py:154: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  ts = datetime.datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Cache-buster timestamp: 20251107221012\n",
            "[STEP] Download existing CSS: /partials/dna_tree_styles.css\n",
            "[OK] Uploaded patched CSS -> /partials/dna_tree_styles.css\n",
            "[PUT]  cache-busted: /partials/yates_ancestor_register.htm\n",
            "[PUT]  cache-busted: /partials/ons_yates_dna_register.htm\n",
            "[PUT]  cache-busted: /partials/justdna.htm\n",
            "[PUT]  cache-busted: /partials/just-trees.htm\n",
            "[PUT]  cache-busted: /partials/yates_ancestor_register_plus.htm\n",
            "[PUT]  cache-busted: /partials/work_plus.htm\n",
            "[PUT]  cache-busted: /partials/match_count.htm\n",
            "[PUT]  cache-busted: /partials/lineage_count.htm\n",
            "[PUT]  cache-busted: /partials/cousin_list_print.htm\n",
            "\n",
            "--- SIZE Verification (if supported) ---\n",
            "/partials/dna_tree_styles.css : 3814\n",
            "/partials/yates_ancestor_register.htm : 1267364\n",
            "/partials/ons_yates_dna_register.htm : 1267364\n",
            "/partials/justdna.htm : 1267364\n",
            "/partials/just-trees.htm : 794896\n",
            "/partials/yates_ancestor_register_plus.htm : 1343103\n",
            "/partials/work_plus.htm : 1267364\n",
            "/partials/match_count.htm : 18955\n",
            "/partials/lineage_count.htm : 47782\n",
            "/partials/cousin_list_print.htm : 499776\n",
            "\n",
            "--- Open a couple of pages (manual hard-refresh optional) ---\n",
            "DNA Register:          https://yates.one-name.net/partials/yates_ancestor_register.htm\n",
            "Register PLUS:         https://yates.one-name.net/partials/yates_ancestor_register_plus.htm\n",
            "Trees:                 https://yates.one-name.net/partials/just-trees.htm\n",
            "Shared stylesheet:     https://yates.one-name.net/partials/dna_tree_styles.css\n",
            "\n",
            "If an iPhone still shows old spacing, try a hard-refresh (Safari: tap-reload or clear cache).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 1"
      ],
      "metadata": {
        "id": "JvOlmbj91AGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] CELL 1 — GEDCOM -> final_combined_df_with_value_labels.csv + working HTML ======\n",
        "# RON RULES — QUICK CODE CARD (v2025.11.05-Cell1-NoValueScoring)\n",
        "# - Complete & runnable in Colab; ISO-8859-15 (ASCII-only in source).\n",
        "# - Punctuation in strings use HTML entities (&rsquo; &ldquo; &rdquo; &mdash; &rarr;).\n",
        "# - Python code (inline, executable, full COLAB Cell paste-ready section).\n",
        "# - XHTML 1.0 Transitional; Times New Roman body; absolute links to /partials/.\n",
        "# - Outputs uploaded to /partials/: CSV + HTML; autosomal_count.txt stays local (Cell 2 handles upload).\n",
        "\n",
        "import os, re, glob, logging, functools, socket, posixpath, traceback\n",
        "from datetime import datetime\n",
        "from collections import defaultdict, Counter\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from ftplib import FTP_TLS\n",
        "from IPython.display import display, Javascript\n",
        "from string import Template\n",
        "\n",
        "# ====== LOGGING ======\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ====== SECRETS + CONFIG + FTP HELPERS ======\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ['FTP_HOST'] = userdata.get('FTP_HOST')\n",
        "    os.environ['FTP_USER'] = userdata.get('FTP_USER')\n",
        "    os.environ['FTP_PASS'] = userdata.get('FTP_PASS')\n",
        "    try:  os.environ['FTP_PORT'] = userdata.get('FTP_PORT')\n",
        "    except Exception: os.environ.setdefault('FTP_PORT', '21')\n",
        "    try:  os.environ['FTP_DIR']  = userdata.get('FTP_DIR')\n",
        "    except Exception: os.environ.setdefault('FTP_DIR', '')\n",
        "except Exception:\n",
        "    os.environ.setdefault('FTP_HOST', '')\n",
        "    os.environ.setdefault('FTP_USER', '')\n",
        "    os.environ.setdefault('FTP_PASS', '')\n",
        "    os.environ.setdefault('FTP_PORT', '21')\n",
        "    os.environ.setdefault('FTP_DIR', '')\n",
        "\n",
        "FTP_HOST = os.environ.get('FTP_HOST','')\n",
        "FTP_USER = os.environ.get('FTP_USER','')\n",
        "FTP_PASS = os.environ.get('FTP_PASS','')\n",
        "FTP_PORT = int(os.environ.get('FTP_PORT','21'))\n",
        "FTP_DIR  = os.environ.get('FTP_DIR','').strip().strip('/')\n",
        "\n",
        "def _ftps_connect():\n",
        "    socket.setdefaulttimeout(30)\n",
        "    ftps = FTP_TLS(timeout=30)\n",
        "    ftps.connect(FTP_HOST, FTP_PORT)\n",
        "    ftps.login(FTP_USER, FTP_PASS)\n",
        "    try: ftps.prot_p()\n",
        "    except Exception: pass\n",
        "    try: ftps.set_pasv(True)\n",
        "    except Exception: pass\n",
        "    if FTP_DIR:\n",
        "        for p in [p for p in FTP_DIR.split('/') if p]:\n",
        "            try:\n",
        "                ftps.cwd(p)\n",
        "            except Exception:\n",
        "                try: ftps.mkd(p)\n",
        "                except Exception: pass\n",
        "                ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "def _ftps_ensure_dir(ftps, path):\n",
        "    if not path: return\n",
        "    for p in [p for p in path.split('/') if p]:\n",
        "        try:\n",
        "            ftps.cwd(p)\n",
        "        except Exception:\n",
        "            try: ftps.mkd(p)\n",
        "            except Exception: pass\n",
        "            ftps.cwd(p)\n",
        "\n",
        "def _ftps_upload(ftps, local_path, remote_name):\n",
        "    with open(local_path, 'rb') as fh:\n",
        "        ftps.storbinary(\"STOR \" + remote_name, fh)\n",
        "    print(f\"[OK] Uploaded: {local_path} -> {ftps.pwd().rstrip('/')}/{remote_name}\")\n",
        "\n",
        "# Output names (local + remote inside /partials/)\n",
        "CSV_OUT_LOCAL   = \"final_combined_df_with_value_labels.csv\"  # kept for compatibility with Cell 2\n",
        "HTML_OUT_LOCAL  = \"cell1_work_table.htm\"\n",
        "REMOTE_DIR      = \"partials\"\n",
        "REMOTE_CSV_NAME = os.path.basename(CSV_OUT_LOCAL)\n",
        "REMOTE_HTML_NAME= os.path.basename(HTML_OUT_LOCAL)\n",
        "\n",
        "# Absolute links used inside HTML\n",
        "ABS_CSV_URL  = f\"/{REMOTE_DIR}/{REMOTE_CSV_NAME}\"\n",
        "ABS_HOME_URL = \"/partials/ons_yates_dna_register.htm\"  # main register lives in /partials/\n",
        "\n",
        "# ====== CORE STRUCTURES (dataset, GEDCOM parse) ======\n",
        "anchor_gen1 = None\n",
        "visited_pairs = set()\n",
        "generation_table = []\n",
        "\n",
        "class GedcomDataset:\n",
        "    def __init__(self, gen_person):\n",
        "        self.gen_person = gen_person\n",
        "        self.extractable_detail = {}\n",
        "        self.anchor_gen1 = None\n",
        "    def add_extractable_detail(self, key, value):\n",
        "        self.extractable_detail[key] = value\n",
        "    def get_gen_person(self):\n",
        "        name = self.extractable_detail.get('NAME', '')\n",
        "        parts = name.split('/', 1)\n",
        "        first_name = parts[0].split(' ')[0]\n",
        "        last_name = parts[1].rstrip('/') if len(parts) > 1 else \"\"\n",
        "        self.anchor_gen1 = last_name.replace(\" \", \"\") + first_name.replace(\" \", \"\")\n",
        "        global anchor_gen1\n",
        "        anchor_gen1 = self.anchor_gen1\n",
        "        return self.gen_person.strip('@')\n",
        "    def get_extractable_NPFX(self):\n",
        "        return self.extractable_detail.get('NPFX', '')\n",
        "    def get_extractable_cm(self):\n",
        "        npfx_value = self.extractable_detail.get('NPFX','')\n",
        "        if '&' in npfx_value:\n",
        "            cm_value = npfx_value.split('&')[0].strip()\n",
        "        elif '**' in npfx_value:\n",
        "            cm_value = npfx_value.split('**')[0].strip()\n",
        "        else:\n",
        "            cm_value = npfx_value.strip()\n",
        "        try:\n",
        "            int(cm_value); return cm_value\n",
        "        except ValueError:\n",
        "            return ''\n",
        "    def get_extractable_sort(self):\n",
        "        npfx_value = self.extractable_detail.get('NPFX','')\n",
        "        if '&' in npfx_value:\n",
        "            sort_part = npfx_value.split('&')[1]\n",
        "            sort_value = sort_part.split('**')[0].strip() if '**' in sort_part else sort_part.strip()\n",
        "            return sort_value\n",
        "        return ''\n",
        "    def get_extractable_YDNA(self):\n",
        "        npfx_value = self.extractable_detail.get('NPFX','')\n",
        "        if '**' in npfx_value:\n",
        "            return npfx_value.split('**')[1].strip()\n",
        "        return ''\n",
        "    def get_extractable_FAMC(self):\n",
        "        return self.extractable_detail.get('FAMC','').strip('@')\n",
        "\n",
        "class Gedcom:\n",
        "    def __init__(self, file_name):\n",
        "        self.file_name = file_name\n",
        "        self.gedcom_datasets = []\n",
        "        self.filter_pool = []\n",
        "    def parse_gedcom(self):\n",
        "        with open(self.file_name, 'r', encoding='utf-8-sig') as f:\n",
        "            lines = f.readlines()\n",
        "        current_dataset = None\n",
        "        npfx_count = 0\n",
        "        ydna_count = 0\n",
        "        total_count = 0\n",
        "        for line in lines:\n",
        "            parts = line.strip().split(' ', 2)\n",
        "            level = int(parts[0]); tag = parts[1]; value = parts[2] if len(parts) > 2 else None\n",
        "            if level == 0 and tag.startswith('@') and tag.endswith('@') and value == 'INDI':\n",
        "                total_count += 1\n",
        "                current_dataset = GedcomDataset(tag)\n",
        "                self.gedcom_datasets.append(current_dataset)\n",
        "            elif current_dataset is not None:\n",
        "                if level == 1 and tag in ['NAME','FAMC']:\n",
        "                    current_dataset.add_extractable_detail(tag, value)\n",
        "                elif level == 2 and tag == 'NPFX':\n",
        "                    npfx_count += 1\n",
        "                    current_dataset.add_extractable_detail(tag, value)\n",
        "                    if '**' in value:\n",
        "                        ydna_count += 1\n",
        "        autosomal_count = npfx_count - ydna_count\n",
        "        print(f\"GEDCOM contained {total_count} total records\")\n",
        "        print(f\"Records tagged and filtered by NPFX: {npfx_count}\")\n",
        "        print(f\"Records with YDNA information: {ydna_count}\")\n",
        "        print(f\"Autosomal matches: {autosomal_count}\")\n",
        "        for ds in self.gedcom_datasets:\n",
        "            if ds.get_extractable_NPFX():\n",
        "                self.filter_pool.append(ds)\n",
        "        # Optional manual second-level filter\n",
        "        try:\n",
        "            df_filter = pd.read_excel('filtered_ids.xlsx')\n",
        "            manual_ids = set(df_filter['ID'])\n",
        "            self.filter_pool = [d for d in self.filter_pool if d.get_gen_person() in manual_ids]\n",
        "            print(f\"After manual filter, total records: {len(self.filter_pool)}\")\n",
        "            logger.info(f\"After manual filter, total records: {len(self.filter_pool)}\")\n",
        "        except FileNotFoundError:\n",
        "            logger.warning(\"filtered_ids.xlsx not found. Skipping second-level manual filter.\")\n",
        "        return autosomal_count\n",
        "\n",
        "def chunks(lst, n):\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i+n]\n",
        "\n",
        "def quick_extract_name(full_text):\n",
        "    name_marker = \"\\n1 NAME \"\n",
        "    idx = full_text.find(name_marker)\n",
        "    if idx == -1:\n",
        "        if full_text.startswith(\"1 NAME \"):\n",
        "            idx = 0\n",
        "        else:\n",
        "            return \"UnknownName\"\n",
        "    start = idx + len(name_marker)\n",
        "    end = full_text.find('\\n', start)\n",
        "    if end == -1: end = len(full_text)\n",
        "    name_line = full_text[start:end].strip()\n",
        "    if '/' not in name_line:\n",
        "        return name_line[:10].replace(\" \", \"\")\n",
        "    first_name, last_name = name_line.split('/', 1)\n",
        "    last_name = last_name.replace(\"/\", \"\").strip()\n",
        "    return last_name[:10].replace(\" \", \"\") + first_name[:10].replace(\" \", \"\")\n",
        "\n",
        "def find_parents(individual_id, generation, parents_map):\n",
        "    global visited_pairs, generation_table\n",
        "    if individual_id not in parents_map: return\n",
        "    father_id, mother_id = parents_map[individual_id]\n",
        "    if not father_id and not mother_id: return\n",
        "    pair = (father_id, mother_id)\n",
        "    if pair not in visited_pairs:\n",
        "        visited_pairs.add(pair)\n",
        "        generation_table.append((generation, pair))\n",
        "    if father_id: find_parents(father_id, generation+1, parents_map)\n",
        "    if mother_id: find_parents(mother_id, generation+1, parents_map)\n",
        "\n",
        "def find_distant_ancestors(individual_id, parents_map, path=None):\n",
        "    if path is None: path = []\n",
        "    path.append(individual_id)\n",
        "    if individual_id not in parents_map:\n",
        "        return [path]\n",
        "    father_id, mother_id = parents_map[individual_id]\n",
        "    if not father_id and not mother_id:\n",
        "        return [path]\n",
        "    paths = []\n",
        "    if father_id: paths.extend(find_distant_ancestors(father_id, parents_map, path[:]))\n",
        "    if mother_id: paths.extend(find_distant_ancestors(mother_id, parents_map, path[:]))\n",
        "    return paths if paths else [path]\n",
        "\n",
        "def filter_ancestral_line(winning_path_ids, generation_table_local, names_map):\n",
        "    matching_table = []\n",
        "    for generation, pair in generation_table_local:\n",
        "        id1, id2 = pair\n",
        "        if id1 in winning_path_ids or id2 in winning_path_ids:\n",
        "            matching_table.append((generation, pair))\n",
        "    matching_table.sort(key=lambda x: x[0])\n",
        "    lines = []\n",
        "    for gen, pair in matching_table:\n",
        "        name_pair = [names_map.get(pid, \"UnknownName\") for pid in pair]\n",
        "        lines.append(f\"{name_pair[0]}&{name_pair[1]}\")\n",
        "    lines.reverse()\n",
        "    return \"~~~\".join(lines)\n",
        "\n",
        "def process_record_wrapper(individual_id, gedcom_instance, parents_map, names_map):\n",
        "    global generation_table, visited_pairs, anchor_gen1\n",
        "    generation_table = []; visited_pairs = set()\n",
        "    find_parents(individual_id, 1, parents_map)\n",
        "    distant_paths = find_distant_ancestors(individual_id, parents_map)\n",
        "    best_score, best_path = None, None\n",
        "    for path in distant_paths:\n",
        "        name_path = [names_map.get(pid, \"UnknownName\") for pid in path]\n",
        "        score = sum((idx+1) for idx, nm in enumerate(name_path) if 'Yates' in nm)\n",
        "        if best_score is None or score > best_score:\n",
        "            best_score, best_path = score, path\n",
        "    best_path = best_path or []\n",
        "    best_path_cleaned = [pid for pid in best_path if pid != individual_id]\n",
        "    line_str = filter_ancestral_line(set(best_path_cleaned), generation_table, names_map)\n",
        "    cm_value = ''; sort_value=''; ydna_value=''\n",
        "    for ds in gedcom_instance.filter_pool:\n",
        "        if ds.get_gen_person() == individual_id:\n",
        "            cm_value = ds.get_extractable_cm()\n",
        "            sort_value = ds.get_extractable_sort()\n",
        "            ydna_value = ds.get_extractable_YDNA()\n",
        "            break\n",
        "    short_name = names_map.get(individual_id, \"UnknownName\")\n",
        "    return [individual_id, sort_value, short_name, cm_value, line_str, ydna_value]\n",
        "\n",
        "# ====== MAIN: BUILD DATAFRAME (No Value Scoring) ======\n",
        "def main():\n",
        "    files = glob.glob(\"*.ged\")\n",
        "    if not files:\n",
        "        print(\"No GEDCOM files found.\"); return False\n",
        "    print(\"Automatically selecting the first GEDCOM file.\")\n",
        "    gedcom_file_path = files[0]\n",
        "\n",
        "    ged = Gedcom(gedcom_file_path)\n",
        "    autosomal_count = ged.parse_gedcom()\n",
        "\n",
        "    with open(\"autosomal_count.txt\", \"w\") as f:\n",
        "        f.write(str(autosomal_count))\n",
        "\n",
        "    with open(gedcom_file_path, 'r', encoding='utf-8') as f:\n",
        "        raw_data = f.read()\n",
        "\n",
        "    blocks = raw_data.split('\\n0 ')\n",
        "    all_records = {}\n",
        "    for blk in blocks:\n",
        "        blk = blk.strip()\n",
        "        if not blk: continue\n",
        "        flend = blk.find('\\n'); flend = len(blk) if flend == -1 else flend\n",
        "        first_line = blk[:flend]\n",
        "        if '@' in first_line:\n",
        "            start = first_line.find('@') + 1\n",
        "            end = first_line.find('@', start)\n",
        "            rec_id = first_line[start:end].strip()\n",
        "            all_records[rec_id] = blk\n",
        "\n",
        "    parents_map, names_map, families = {}, {}, {}\n",
        "    for rec_id, txt in all_records.items():\n",
        "        if 'FAM' in txt[:50]:\n",
        "            father_idx = txt.find('1 HUSB @')\n",
        "            husb_id = txt[father_idx+len('1 HUSB @'):txt.find('@', father_idx+len('1 HUSB @'))] if father_idx != -1 else None\n",
        "            wife_idx = txt.find('1 WIFE @')\n",
        "            wife_id = txt[wife_idx+len('1 WIFE @'):txt.find('@', wife_idx+len('1 WIFE @'))] if wife_idx != -1 else None\n",
        "            kids = [ln.split('@')[1] for ln in txt.split('\\n') if ln.strip().startswith('1 CHIL @')]\n",
        "            families[rec_id] = (husb_id, wife_id, kids)\n",
        "    for fam_id, (f_id, m_id, k_list) in families.items():\n",
        "        for kid in k_list:\n",
        "            parents_map[kid] = (f_id, m_id)\n",
        "    for rec_id, txt in all_records.items():\n",
        "        names_map[rec_id] = quick_extract_name(\"\\n\" + txt)\n",
        "\n",
        "    individual_ids = [d.get_gen_person() for d in ged.filter_pool]\n",
        "    print(f\"Processing {len(individual_ids)} individuals with chunk-based parallel...\")\n",
        "\n",
        "    combined_rows = []\n",
        "    chunk_size = 50\n",
        "    max_workers = os.cpu_count() or 4\n",
        "    with ProcessPoolExecutor(max_workers=max_workers) as executor, tqdm(total=len(individual_ids), desc=\"Building Yates Lines (Stage 1)\") as pbar:\n",
        "        for chunk in chunks(individual_ids, chunk_size):\n",
        "            func = functools.partial(process_record_wrapper, gedcom_instance=ged, parents_map=parents_map, names_map=names_map)\n",
        "            results = list(executor.map(func, chunk))\n",
        "            combined_rows.extend(results)\n",
        "            pbar.update(len(chunk))\n",
        "\n",
        "    columns = [\"ID#\", \"Match to\", \"Name\", \"cM\", \"Yates DNA Ancestral Line\", \"haplogroup\"]\n",
        "    df = pd.DataFrame(combined_rows, columns=columns)\n",
        "    df.index += 1\n",
        "\n",
        "    # Trim the historical prefix if present\n",
        "    def remove_specific_prefix(row):\n",
        "        prefix = \"YatesJohn&SearchingStill~~~YatesWilliam&SearchingStill~~~YatesWilliam&SearchingStill~~~YatesEdmund&CornellMargaret~~~YatesRichard&AshendonJoan~~~YatesJohn&HydeAlice~~~YatesThomas&FauconerElizabeth~~~\"\n",
        "        if str(row[\"Yates DNA Ancestral Line\"]).startswith(prefix):\n",
        "            row[\"Yates DNA Ancestral Line\"] = row[\"Yates DNA Ancestral Line\"][len(prefix):]\n",
        "        return row\n",
        "    df = df.apply(remove_specific_prefix, axis=1)\n",
        "\n",
        "    # No Value/Range/Label computation; sort only by lineage for stability\n",
        "    df.sort_values(by=[\"Yates DNA Ancestral Line\"], inplace=True)\n",
        "\n",
        "    # Export CSV (UTF-8-SIG for downstream safety; filename kept for Cell 2 compatibility)\n",
        "    df.to_csv(CSV_OUT_LOCAL, index=False, encoding=\"utf-8-sig\")\n",
        "    logger.info(\"Exported CSV -> %s\", CSV_OUT_LOCAL)\n",
        "\n",
        "    # Simple working HTML (no Value columns)\n",
        "    final_cols = [\"ID#\", \"cM\", \"haplogroup\", \"Match to\", \"Yates DNA Ancestral Line\"]\n",
        "    table_html = df.to_html(index=False, columns=final_cols, escape=False, border=1)\n",
        "\n",
        "    page_tpl = Template(\"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "<title>Cell 1 Working Table</title>\n",
        "<style type=\"text/css\">\n",
        "  html { scroll-behavior: smooth; }\n",
        "  body { font-family: 'Times New Roman', Georgia, serif; background:#ffffff; color:#222; margin:0; padding:20px; }\n",
        "  h1 { margin:0 0 8px 0; font-size:24px; line-height:1.2; text-align:center; }\n",
        "  .meta { text-align:center; font-size:12px; color:#555; margin:2px 0 12px 0; }\n",
        "  .downloads { text-align:center; margin:4px 0 12px 0; font-size:13px; }\n",
        "  a { color:#154b8b; text-decoration:none; } a:hover { text-decoration:underline; }\n",
        "  table { width:100%; border-collapse:collapse; }\n",
        "  th, td { border:1px solid #333; padding: 6px 8px; vertical-align:top; }\n",
        "  th { background:#e3eaf8; text-align:left; }\n",
        "  td:nth-child(5) { text-align:left; white-space:normal; }\n",
        "</style>\n",
        "<script type=\"text/javascript\">\n",
        "//<![CDATA[\n",
        "(function(){ function z(n){return (n<10?'0':'')+n;}\n",
        "document.addEventListener('DOMContentLoaded', function(){\n",
        "  var el = document.getElementById('last-updated');\n",
        "  if(el){ var d=new Date(document.lastModified||new Date());\n",
        "    el.innerHTML = d.getFullYear()+'-'+z(d.getMonth()+1)+'-'+z(d.getDate())+' '+z(d.getHours())+':'+z(d.getMinutes()); }\n",
        "}, false); })();\n",
        "//]]>\n",
        "</script>\n",
        "</head>\n",
        "<body>\n",
        "  <h1>Cell 1 Working Table</h1>\n",
        "  <div class=\"meta\">\n",
        "    <a href=\"$HOME\" target=\"_blank\" rel=\"noopener\">Home</a>\n",
        "    &nbsp;|&nbsp; Last updated: <span id=\"last-updated\"></span>\n",
        "    &nbsp;|&nbsp; Download: <a href=\"$CSV\">$CSV</a>\n",
        "  </div>\n",
        "  <div class=\"downloads\"><a href=\"$CSV\">/partials/$CSV_NAME</a></div>\n",
        "  $TABLE\n",
        "</body>\n",
        "</html>\"\"\")\n",
        "\n",
        "    page = page_tpl.safe_substitute(\n",
        "        HOME=ABS_HOME_URL,\n",
        "        CSV=ABS_CSV_URL,\n",
        "        CSV_NAME=os.path.basename(ABS_CSV_URL),\n",
        "        TABLE=table_html\n",
        "    )\n",
        "\n",
        "    with open(HTML_OUT_LOCAL, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(page)\n",
        "    logger.info(\"Exported HTML -> %s\", HTML_OUT_LOCAL)\n",
        "\n",
        "    return True\n",
        "\n",
        "ok = main()\n",
        "\n",
        "# ====== UPLOAD ALL ARTIFACTS TO /partials/ ======\n",
        "if ok and all([FTP_HOST, FTP_USER, FTP_PASS]):\n",
        "    print(\"[INFO] Uploading artifacts to /partials/ ...\")\n",
        "    try:\n",
        "        ftps = _ftps_connect()\n",
        "        _ftps_ensure_dir(ftps, \"partials\")\n",
        "        try:\n",
        "            _ftps_upload(ftps, CSV_OUT_LOCAL, os.path.basename(CSV_OUT_LOCAL))\n",
        "        except Exception as e:\n",
        "            print(\"[ERROR] CSV upload failed:\", e)\n",
        "        try:\n",
        "            _ftps_upload(ftps, HTML_OUT_LOCAL, os.path.basename(HTML_OUT_LOCAL))\n",
        "        except Exception as e:\n",
        "            print(\"[ERROR] HTML upload failed:\", e)\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "        print(\"[OK] Uploads complete to /partials/\")\n",
        "    except Exception as e:\n",
        "        print(\"[ERROR] FTP session failed:\", e)\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"[INFO] Skipping FTP upload (missing creds or build failed).\")\n",
        "\n",
        "# ====== DONE ======\n",
        "try:\n",
        "    display(Javascript('alert(\"\\\\u2705 Cell 1 build complete (no value scoring): CSV + HTML uploaded to /partials/\");'))\n",
        "except Exception:\n",
        "    pass\n",
        "print(\"\\n--- Cell 1 Complete (no value scoring): artifacts at /partials/ ---\")\n",
        "# ====== CUT STOP [1/1] CELL 1 ===================================================================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "jeCCnPEKfOK1",
        "outputId": "352d3bfe-3769-4553-88a4-73bd07af6624"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically selecting the first GEDCOM file.\n",
            "GEDCOM contained 62312 total records\n",
            "Records tagged and filtered by NPFX: 1572\n",
            "Records with YDNA information: 0\n",
            "Autosomal matches: 1572\n",
            "After manual filter, total records: 7\n",
            "Processing 7 individuals with chunk-based parallel...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Yates Lines (Stage 1): 100%|██████████| 7/7 [00:04<00:00,  1.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Uploading artifacts to /partials/ ...\n",
            "[OK] Uploaded: final_combined_df_with_value_labels.csv -> /partials/final_combined_df_with_value_labels.csv\n",
            "[OK] Uploaded: cell1_work_table.htm -> /partials/cell1_work_table.htm\n",
            "[OK] Uploads complete to /partials/\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "alert(\"\\u2705 Cell 1 build complete (no value scoring): CSV + HTML uploaded to /partials/\");"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Cell 1 Complete (no value scoring): artifacts at /partials/ ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 2"
      ],
      "metadata": {
        "id": "s1Oa3qUz0_Yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] CELL 2 — Build + Publish DNA Register (Unified: Best Display + Correct First-Ancestor) ======\n",
        "# RON RULES — QUICK CODE CARD (v2025.11.08-Cell2-UNIFIED-BEST)\n",
        "# - Complete & runnable in Colab; ASCII-only source (ISO-8859-15 safe outputs).\n",
        "# - XHTML 1.0 Transitional; explicit prints; no fabrication.\n",
        "# - Typography is controlled ONLY by /partials/dna_tree_styles.css (no inline font-family anywhere).\n",
        "# - Row-highlight FIX is limited to PARTIALS ONLY (not the main register page).\n",
        "# - Publishes SAME HTML to:\n",
        "#       /partials/yates_ancestor_register.htm     (canonical, Find target)\n",
        "#       /partials/ons_yates_dna_register.htm     (legacy clone)\n",
        "#       /partials/justdna.htm                     (JUSTDNA alias)\n",
        "# - Also writes PARTIALS (match_count.htm, lineage_count.htm, cousin_list_print.htm) and CSV/XLSX exports.\n",
        "\n",
        "import os, re, io, posixpath, socket, traceback, urllib.parse as _u\n",
        "from ftplib import FTP_TLS\n",
        "import pandas as pd\n",
        "import html as _html\n",
        "from string import Template\n",
        "\n",
        "# ---------- 0) Secrets ----------\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ['FTP_HOST'] = userdata.get('FTP_HOST')\n",
        "    os.environ['FTP_USER'] = userdata.get('FTP_USER')\n",
        "    os.environ['FTP_PASS'] = userdata.get('FTP_PASS')\n",
        "    try: os.environ['FTP_DIR']  = userdata.get('FTP_DIR')\n",
        "    except Exception: os.environ.setdefault('FTP_DIR', '')\n",
        "    try: os.environ['FTP_PORT'] = userdata.get('FTP_PORT')\n",
        "    except Exception: os.environ.setdefault('FTP_PORT', '21')\n",
        "except Exception:\n",
        "    os.environ.setdefault('FTP_HOST', '')\n",
        "    os.environ.setdefault('FTP_USER', '')\n",
        "    os.environ.setdefault('FTP_PASS', '')\n",
        "    os.environ.setdefault('FTP_DIR',  '')\n",
        "    os.environ.setdefault('FTP_PORT', '21')\n",
        "\n",
        "# ---------- 1) Config ----------\n",
        "CSV_IN = \"final_combined_df_with_value_labels.csv\"\n",
        "\n",
        "LOCAL_HTML         = \"yates_ancestor_register.htm\"\n",
        "REMOTE_HTML_CANON  = posixpath.join(\"partials\", \"yates_ancestor_register.htm\")\n",
        "REMOTE_HTML_LEG    = posixpath.join(\"partials\", \"ons_yates_dna_register.htm\")\n",
        "REMOTE_HTML_SIMPLE = posixpath.join(\"partials\", \"justdna.htm\")\n",
        "\n",
        "DNA_REGISTER_ABS = \"https://yates.one-name.net/partials/justdna.htm\"\n",
        "TREES_ABS        = \"https://yates.one-name.net/partials/just-trees.htm\"\n",
        "\n",
        "EXPORT_BASENAME = \"yates_ancestor_register\"\n",
        "LOCAL_CSV       = f\"{EXPORT_BASENAME}.csv\"\n",
        "LOCAL_XLSX      = f\"{EXPORT_BASENAME}.xlsx\"\n",
        "REMOTE_CSV      = posixpath.join(\"partials\", os.path.basename(LOCAL_CSV))\n",
        "REMOTE_XLSX     = posixpath.join(\"partials\", os.path.basename(LOCAL_XLSX))\n",
        "\n",
        "WORK_PLUS_LOCAL  = os.path.join(\"partials\", \"work_plus.htm\")\n",
        "WORK_PLUS_REMOTE = posixpath.join(\"partials\", \"work_plus.htm\")\n",
        "\n",
        "LOCAL_COUNT_FILE  = \"/content/autosomal_count.txt\"\n",
        "REMOTE_COUNT_NAME = \"autosomal_count.txt\"\n",
        "\n",
        "FTP_DIR         = (os.environ.get(\"FTP_DIR\",\"\") or \"\").strip()\n",
        "TNG_BASE        = \"https://yates.one-name.net/tng\"\n",
        "TNG_TREE        = \"tree1\"\n",
        "HOME_URL        = \"https://yates.one-name.net/partials/yates_ancestor_register.htm\"\n",
        "REMOTE_NAME_ABS = HOME_URL\n",
        "COUNT_PUBLIC_URL = (f\"/{FTP_DIR}/{REMOTE_COUNT_NAME}\" if FTP_DIR else f\"/{REMOTE_COUNT_NAME}\")\n",
        "\n",
        "# Layout\n",
        "TABLE_WIDTH_PX = 3150\n",
        "COL_A_PX       = 1100\n",
        "FIND_COL_PX    = 118\n",
        "ARROW_ENTITY   = \"&rarr;\"\n",
        "REMOVE_PERIOD_AT_END = True\n",
        "\n",
        "# Resolver (server mapping for Match-to -> Unmasked)\n",
        "SERVER_PARTIALS_DIR        = \"partials\"\n",
        "SERVER_MAPPING_BASENAME    = \"match_to_unmasked.csv\"\n",
        "SERVER_MAPPING_REMOTE      = posixpath.join(SERVER_PARTIALS_DIR, SERVER_MAPPING_BASENAME)\n",
        "SERVER_MAPPING_LOCAL_CACHE = \"match_to_unmasked.server.csv\"\n",
        "\n",
        "# External stylesheet (controls typography site-wide)\n",
        "STYLESHEET_HREF = \"/partials/dna_tree_styles.css\"\n",
        "CSS_VERSION     = \"v2025-11-06\"  # bump to bust caches when CSS changes\n",
        "HEAD_LINK       = f'<link rel=\"stylesheet\" type=\"text/css\" href=\"{STYLESHEET_HREF}?{CSS_VERSION}\" />'\n",
        "HEAD_LINK_URL   = STYLESHEET_HREF + \"?\" + CSS_VERSION  # used inside JS (print window)\n",
        "\n",
        "# ---------- 2) FTP helpers ----------\n",
        "FTP_TIMEOUT = int(os.environ.get(\"FTP_TIMEOUT\", \"30\"))\n",
        "FTP_PASSIVE = True\n",
        "\n",
        "def ftp_connect() -> FTP_TLS:\n",
        "    ftps = FTP_TLS(timeout=FTP_TIMEOUT)\n",
        "    socket.setdefaulttimeout(FTP_TIMEOUT)\n",
        "    ftps.connect(os.environ.get('FTP_HOST',''), int(os.environ.get('FTP_PORT', 21)))\n",
        "    ftps.login(os.environ.get('FTP_USER',''), os.environ.get('FTP_PASS',''))\n",
        "    try: ftps.prot_p()\n",
        "    except Exception: pass\n",
        "    try: ftps.set_pasv(FTP_PASSIVE)\n",
        "    except Exception: pass\n",
        "    if FTP_DIR:\n",
        "        parts = [p for p in FTP_DIR.split(\"/\") if p]\n",
        "        for p in parts:\n",
        "            try: ftps.mkd(p)\n",
        "            except Exception: pass\n",
        "            ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "def _remote_path(name: str) -> str:\n",
        "    return posixpath.join(FTP_DIR, name) if FTP_DIR else name\n",
        "\n",
        "def ensure_remote_dirs(ftps: FTP_TLS, remote_path: str):\n",
        "    if \"/\" not in remote_path: return\n",
        "    pwd0 = ftps.pwd()\n",
        "    for seg in [p for p in remote_path.split(\"/\")[:-1] if p and p != \".\"]:\n",
        "        try: ftps.cwd(seg)\n",
        "        except Exception:\n",
        "            try: ftps.mkd(seg)\n",
        "            except Exception: pass\n",
        "            ftps.cwd(seg)\n",
        "    ftps.cwd(pwd0)\n",
        "\n",
        "def ftp_download_if_exists(ftps: FTP_TLS, remote_name: str, local_name: str) -> bool:\n",
        "    try:\n",
        "        with open(local_name, \"wb\") as f:\n",
        "            ftps.retrbinary(f\"RETR {remote_name}\", f.write)\n",
        "        print(f\"[PULL] {remote_name} -> {os.path.abspath(local_name)}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            if os.path.exists(local_name): os.remove(local_name)\n",
        "        except Exception: pass\n",
        "        print(f\"[MISS] {remote_name} ({e})\")\n",
        "        return False\n",
        "\n",
        "def ftp_upload_overwrite(ftps: FTP_TLS, local_path: str, remote_name: str):\n",
        "    ensure_remote_dirs(ftps, remote_name)\n",
        "    with open(local_path, \"rb\") as fh:\n",
        "        ftps.storbinary(f\"STOR {remote_name}\", fh)\n",
        "    print(f\"[PUT]  {local_path} -> {remote_name}\")\n",
        "\n",
        "def ftp_size(ftps: FTP_TLS, remote_name: str):\n",
        "    try:\n",
        "        sz = ftps.size(remote_name)\n",
        "        return int(sz) if sz is not None else None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# ---------- 3) Resolver ----------\n",
        "def _read_mapping_csv(path: str) -> pd.DataFrame:\n",
        "    encs = (\"iso-8859-15\",\"utf-8-sig\",\"utf-8\",\"cp1252\",\"latin1\")\n",
        "    last = None; df = None\n",
        "    for enc in encs:\n",
        "        try:\n",
        "            df = pd.read_csv(path, encoding=enc, dtype=str, keep_default_na=False)\n",
        "            break\n",
        "        except Exception as e:\n",
        "            last = e\n",
        "    if df is None:\n",
        "        raise RuntimeError(f\"Unable to read mapping CSV {path}: {last}\")\n",
        "    if df.shape[1] < 2:\n",
        "        raise RuntimeError(\"Mapping CSV must have at least two columns: code, unmasked\")\n",
        "    df = df.iloc[:, :2].copy()\n",
        "    df.columns = [\"code\",\"unmasked\"]\n",
        "    df[\"code\"] = df[\"code\"].astype(str).str.strip().str.lower()\n",
        "    df[\"unmasked\"] = df[\"unmasked\"].astype(str).str.strip()\n",
        "    df = df[df[\"code\"] != \"\"].drop_duplicates(subset=[\"code\"], keep=\"first\")\n",
        "    if df.empty:\n",
        "        raise RuntimeError(\"Mapping CSV empty after normalization.\")\n",
        "    return df\n",
        "\n",
        "def load_resolver_from_server() -> dict:\n",
        "    with ftp_connect() as ftps:\n",
        "        try:\n",
        "            ftps.cwd(SERVER_PARTIALS_DIR)\n",
        "        except Exception:\n",
        "            pass\n",
        "        ok = ftp_download_if_exists(ftps, SERVER_MAPPING_BASENAME, SERVER_MAPPING_LOCAL_CACHE)\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "    if not ok:\n",
        "        raise RuntimeError(\n",
        "            \"Resolver not found on server: /\" + _remote_path(SERVER_MAPPING_REMOTE) +\n",
        "            \". Upload match_to_unmasked.csv into /partials/ and re-run.\"\n",
        "        )\n",
        "    df_map = _read_mapping_csv(SERVER_MAPPING_LOCAL_CACHE)\n",
        "    print(f\"[OK] Resolver loaded: {len(df_map)} codes\")\n",
        "    return dict(zip(df_map[\"code\"], df_map[\"unmasked\"]))\n",
        "\n",
        "MATCH_TO_UNMASKED = {}\n",
        "def _setup_resolver():\n",
        "    global MATCH_TO_UNMASKED\n",
        "    if not MATCH_TO_UNMASKED:\n",
        "        MATCH_TO_UNMASKED = load_resolver_from_server()\n",
        "\n",
        "def resolve_match_to(code: str) -> str:\n",
        "    if not isinstance(code, str): return \"\"\n",
        "    return MATCH_TO_UNMASKED.get(code.strip().lower(), code)\n",
        "\n",
        "# ---------- 4) Name & text utils (UNIFIED: learnings from both versions) ----------\n",
        "SEP_RE = re.compile(r\"\\s*(?:\\u2192|&rarr;|;|>|,|~{2,}|/{2,}|\\|{2,})\\s*\")\n",
        "def split_tokens(s):\n",
        "    if pd.isna(s): return []\n",
        "    if not isinstance(s, str): s = str(s)\n",
        "    return [p.strip() for p in SEP_RE.split(s) if str(p).strip()]\n",
        "\n",
        "def _clean_piece(text: str) -> str:\n",
        "    t = re.sub(r'~+', ' ', str(text)); t = re.sub(r'\\s+', ' ', t)\n",
        "    return t.strip()\n",
        "\n",
        "_PARTICLES = {\"de\",\"del\",\"della\",\"der\",\"van\",\"von\",\"da\",\"dos\",\"das\",\"di\",\"la\",\"le\",\"du\",\"of\"}\n",
        "\n",
        "def _smart_title(token: str) -> str:\n",
        "    if not token: return token\n",
        "    token = re.sub(r\"(^|\\b)([a-z])(['’])([a-z])\", lambda m: m.group(1)+m.group(2).upper()+m.group(3)+m.group(4).upper(), token.lower())\n",
        "    token = \"-\".join([w.capitalize() for w in token.split(\"-\")])\n",
        "    token = re.sub(r\"\\bmc([a-z])\",  lambda m: \"Mc\"+m.group(1).upper(),  token)\n",
        "    token = re.sub(r\"\\bmac([a-z])\", lambda m: \"Mac\"+m.group(1).upper(), token)\n",
        "    return token\n",
        "\n",
        "def smart_titlecase(name: str) -> str:\n",
        "    name = _clean_piece(name)\n",
        "    if not name: return name\n",
        "    if \",\" in name:\n",
        "        last, first = [p.strip() for p in name.split(\",\", 1)]\n",
        "        pieces = (first + \" \" + last).split()\n",
        "    else:\n",
        "        pieces = name.split()\n",
        "    out = []\n",
        "    for i, w in enumerate(pieces):\n",
        "        out.append(w.lower() if (i>0 and w.lower() in _PARTICLES) else _smart_title(w))\n",
        "    return \" \".join(out)\n",
        "\n",
        "# Split CamelCase tokens like \"YatesJohn\" -> (\"Yates\",\"John\") then render \"John Yates\"\n",
        "_CAMEL_WORDS = re.compile(r\"[A-Z][a-z]*|[A-Z]+(?![a-z])|[a-z]+\")\n",
        "def surname_given_from_token(token):\n",
        "    token = token.strip()\n",
        "    if not token: return (token,)\n",
        "    idx = None\n",
        "    for i in range(1, len(token)):\n",
        "        if token[i-1].islower() and token[i].isupper():\n",
        "            idx = i; break\n",
        "    if idx is None:\n",
        "        for i in range(1, len(token)):\n",
        "            if token[i].isupper():\n",
        "                idx = i; break\n",
        "    if idx is None: return (token,)\n",
        "    surname = token[:idx]; given = token[idx:]\n",
        "    given_spaced = re.sub(r'(?<!^)([A-Z])', r' \\1', given)\n",
        "    return (f\"{given_spaced.strip()} {surname.strip()}\",)\n",
        "\n",
        "def normalize_person_name(s: str) -> str:\n",
        "    if pd.isna(s): return \"\"\n",
        "    s = _clean_piece(str(s))\n",
        "    if \",\" in s:\n",
        "        last, first = [p.strip() for p in s.split(\",\", 1)]\n",
        "        s = f\"{first} {last}\"\n",
        "    if \" \" not in s and s.isalpha():\n",
        "        return smart_titlecase(surname_given_from_token(s)[0])\n",
        "    return smart_titlecase(s)\n",
        "\n",
        "def norm_matchee_name(raw: str) -> str:\n",
        "    raw = str(raw or \"\").strip()\n",
        "    if not raw: return \"\"\n",
        "    if \" \" in raw or \",\" in raw:\n",
        "        nm = smart_titlecase(raw)\n",
        "        parts = nm.split()\n",
        "        if len(parts) == 1: return nm\n",
        "        return f\"{parts[0]} {parts[-1]}\".strip()\n",
        "    words = _CAMEL_WORDS.findall(raw)\n",
        "    while words and len(words[0]) == 1:\n",
        "        words.pop(0)\n",
        "    if not words:\n",
        "        nm = smart_titlecase(surname_given_from_token(raw)[0])\n",
        "        ps = nm.split()\n",
        "        if len(ps) == 1: return nm\n",
        "        return f\"{ps[0]} {ps[-1]}\".strip()\n",
        "    surname = smart_titlecase(words[0])\n",
        "    given_candidates = [w for w in words[1:] if w.lower() != surname.lower()]\n",
        "    if not given_candidates: return surname\n",
        "    given = smart_titlecase(given_candidates[0])\n",
        "    return f\"{given} {surname}\".strip()\n",
        "\n",
        "def truncate_first(name: str, n: int = 7) -> str:\n",
        "    name = name.strip()\n",
        "    if not name: return name\n",
        "    parts = name.split()\n",
        "    return parts[0][:n] if len(parts) == 1 else f\"{parts[0][:n]} {parts[-1]}\"\n",
        "\n",
        "def derive_common_from_first_token(tokens):\n",
        "    if not tokens: return (\"\",\"\")\n",
        "    first = _clean_piece(tokens[0])\n",
        "    parts = re.split(r\"\\s*(?:&| and )\\s*\", first, maxsplit=1, flags=re.I)\n",
        "    if len(parts) != 2: return (\"\",\"\")\n",
        "    def _norm(s):\n",
        "        # Accept \"YatesJohn\" and \"Yates, John\" and plain \"John Yates\"\n",
        "        return smart_titlecase(s) if \" \" in s or \",\" in s else smart_titlecase(surname_given_from_token(s)[0])\n",
        "    return (_norm(parts[0]), _norm(parts[1]))\n",
        "\n",
        "def degree_label_from_generations(g):\n",
        "    if g <= 1: return (\"parents\" if g == 1 else \"self\")\n",
        "    if g == 2: return \"grandparents\"\n",
        "    greats = g - 2\n",
        "    if greats == 1: return \"great-grandparents\"\n",
        "    return f\"{greats}x-great-grandparents\"\n",
        "\n",
        "def build_header(subject_name, cm_val, matchee_name_html, gens, husband, wife):\n",
        "    try:\n",
        "        cm_str = f\"{int(round(float(cm_val)))}\"\n",
        "    except Exception:\n",
        "        cm_str = (str(cm_val).strip() or \"0\")\n",
        "    degree_label = degree_label_from_generations(gens)\n",
        "    parts = [\n",
        "        f\"{subject_name} is a {cm_str} cM cousin match to {matchee_name_html}, whose\",\n",
        "        f\"{degree_label} (back {gens} Gens)\",\n",
        "        \"are\",\n",
        "        f\"{husband} & {wife}.\"\n",
        "    ]\n",
        "    s = \" \".join(parts)\n",
        "    if REMOVE_PERIOD_AT_END: s = re.sub(r'\\.\\s*$', '', s)\n",
        "    return s\n",
        "\n",
        "# ---------- 5) Read CSV; detect columns ----------\n",
        "def find_col(df, patterns, prefer_exact=None):\n",
        "    cols = list(df.columns)\n",
        "    lowmap = {c.lower(): c for c in cols}\n",
        "    if prefer_exact:\n",
        "        for name in prefer_exact:\n",
        "            if name in df.columns: return name\n",
        "            if name and name.lower() in lowmap: return lowmap[name.lower()]\n",
        "    for pat in patterns:\n",
        "        rx = re.compile(pat, re.I)\n",
        "        for c in cols:\n",
        "            if rx.search(c): return c\n",
        "    return None\n",
        "\n",
        "_encs = (\"utf-8-sig\",\"utf-8\",\"cp1252\",\"iso-8859-15\",\"latin1\")\n",
        "_last_err = None\n",
        "df = None\n",
        "for _e in _encs:\n",
        "    try:\n",
        "        df = pd.read_csv(CSV_IN, encoding=_e, dtype=str, keep_default_na=False)\n",
        "        break\n",
        "    except Exception as _ex:\n",
        "        _last_err = _ex\n",
        "        df = None\n",
        "if df is None:\n",
        "    raise RuntimeError(f\"Unable to read CSV: {CSV_IN} ({_last_err})\")\n",
        "print(f\"[OK] Loaded CSV: {len(df)} rows, {len(df.columns)} cols\")\n",
        "\n",
        "id_col    = find_col(df, [r'^(id#|personid)$'], [\"ID#\",\"ID\",\"PersonID\",\"personID\"])\n",
        "match_col = find_col(df, [r'^match\\s*to$'], [\"Match to\",\"Match\"])\n",
        "name_col  = find_col(df, [r'^name$'], [\"Name\"])\n",
        "cm_col    = find_col(df, [r'^(c\\s*:?m|cm)$', r'centi.?morgan'], [\"cM\",\"cm\"])\n",
        "path_col  = find_col(df, [r'(yates\\s*dna\\s*ancestral\\s*line|ancestral\\s*line|lineage)'], [\"Yates DNA Ancestral Line\",\"Ancestral Line\",\"Lineage\"])\n",
        "\n",
        "if not id_col:    raise ValueError(\"CSV missing an ID#/PersonID column.\")\n",
        "if not match_col: raise ValueError(\"CSV missing 'Match to' column.\")\n",
        "if not name_col:  raise ValueError(\"CSV missing 'Name' column.\")\n",
        "if not cm_col:    raise ValueError(\"CSV missing 'cM' column.\")\n",
        "if not path_col:  raise ValueError(\"CSV missing lineage/path column.\")\n",
        "\n",
        "# ---------- 6) Transform -> display_df ----------\n",
        "ID_PAT = re.compile(r\"\\bI\\d+\\b\", re.I)\n",
        "def extract_person_id(s: str) -> str:\n",
        "    m = ID_PAT.search(str(s or \"\"))\n",
        "    return m.group(0).upper() if m else \"\"\n",
        "\n",
        "_setup_resolver()\n",
        "\n",
        "headers, lineages, findcol = [], [], []\n",
        "subjects, first_ancestors  = [], []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    subject_raw  = row.get(match_col, \"\")\n",
        "    subject_name = normalize_person_name(resolve_match_to(subject_raw))\n",
        "    subject_name_b = f\"<strong>{subject_name}</strong>\" if subject_name else subject_name\n",
        "\n",
        "    pid = extract_person_id(row.get(id_col, \"\"))\n",
        "    matchee_name = norm_matchee_name(row.get(name_col, \"\")) or subject_name\n",
        "\n",
        "    if pid:\n",
        "        matchee_name_html = (\n",
        "            f'<a href=\"{TNG_BASE}/verticalchart.php?personID={pid}&tree={TNG_TREE}&parentset=0&display=vertical&generations=15\" '\n",
        "            f'target=\"_blank\" rel=\"noopener\">{matchee_name}</a>'\n",
        "        )\n",
        "    else:\n",
        "        matchee_name_html = matchee_name\n",
        "\n",
        "    cm_val = row.get(cm_col, \"0\")\n",
        "    tokens = split_tokens(row.get(path_col, \"\"))\n",
        "    gens_total = len(tokens)\n",
        "    tokens_disp = tokens[:7]\n",
        "\n",
        "    # Prefer explicit husband/wife columns if present, else derive from first token (CamelCase aware)\n",
        "    if \"common_husband\" in df.columns and \"common_wife\" in df.columns:\n",
        "        husband_raw = str(row.get(\"common_husband\",\"\")).strip()\n",
        "        wife_raw    = str(row.get(\"common_wife\",\"\")).strip()\n",
        "        if not husband_raw and not wife_raw:\n",
        "            husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "    else:\n",
        "        husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "\n",
        "    header_html = build_header(\n",
        "        subject_name_b,\n",
        "        cm_val,\n",
        "        matchee_name_html,\n",
        "        gens_total,\n",
        "        husband_raw,\n",
        "        wife_raw\n",
        "    )\n",
        "\n",
        "    if tokens_disp:\n",
        "        tokens_disp[0] = f\"<strong>{tokens_disp[0]}</strong>\"\n",
        "    sep = f\" {ARROW_ENTITY} \"\n",
        "    lineage_text = sep.join(tokens_disp) if tokens_disp else \"\"\n",
        "\n",
        "    q = _u.quote(subject_name)\n",
        "    quick = (\n",
        "        f'<a class=\"find-btn\" href=\"{REMOTE_NAME_ABS}?q={q}\" target=\"_blank\" rel=\"noopener\" '\n",
        "        f'title=\"Open a filtered view for {subject_name}\">Find</a>'\n",
        "    )\n",
        "\n",
        "    headers.append(header_html)\n",
        "    lineages.append(lineage_text)\n",
        "    findcol.append(quick)\n",
        "    subjects.append(subject_name)\n",
        "    first_ancestors.append(tokens[0] if tokens else \"\")\n",
        "\n",
        "LINEAGE_HEADER_SAFE = \"Lineage (Starting with oldest ancestor, the line is:)\"\n",
        "df[\"Match Summary\"]     = headers\n",
        "df[LINEAGE_HEADER_SAFE] = lineages\n",
        "df[\"Find\"]              = findcol\n",
        "df[\"Subject\"]           = subjects\n",
        "df[\"First Ancestor\"]    = [_clean_piece(x) for x in first_ancestors]\n",
        "display_df = df[[\"Find\",\"Match Summary\", LINEAGE_HEADER_SAFE]]\n",
        "\n",
        "# ---------- 6.1) Clean exports (ISO-8859-15 safe; robust) ----------\n",
        "TAG_RE = re.compile(r\"<[^>]+>\")\n",
        "def _html_to_text(s: str) -> str:\n",
        "    t = TAG_RE.sub(\"\", str(s or \"\"))\n",
        "    t = _html.unescape(t)\n",
        "    t = t.replace(\"\\u2192\", \"->\")\n",
        "    return re.sub(r\"\\s+\", \" \", t).strip()\n",
        "\n",
        "def _extract_find_url(cell_html: str) -> str:\n",
        "    m = re.search(r'href=\"([^\"]+)\"', str(cell_html or \"\"))\n",
        "    return _html.unescape(m.group(1)) if m else \"\"\n",
        "\n",
        "export_df = pd.DataFrame({\n",
        "    \"Find URL\":      [ _extract_find_url(v) for v in display_df[\"Find\"].tolist() ],\n",
        "    \"Match Summary\": [ _html_to_text(v)     for v in display_df[\"Match Summary\"].tolist() ],\n",
        "    \"Lineage\":       [ _html_to_text(v)     for v in display_df[LINEAGE_HEADER_SAFE].tolist() ],\n",
        "})\n",
        "\n",
        "# Write CSV with fallback error handler for older pandas/envs\n",
        "try:\n",
        "    export_df.to_csv(LOCAL_CSV, index=False, encoding=\"iso-8859-15\")\n",
        "except TypeError:\n",
        "    # Older pandas may not recognize encoding error args; do manual encode\n",
        "    buf = io.StringIO()\n",
        "    export_df.to_csv(buf, index=False)\n",
        "    with open(LOCAL_CSV, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(buf.getvalue())\n",
        "\n",
        "try:\n",
        "    export_df.to_excel(LOCAL_XLSX, index=False)\n",
        "except Exception:\n",
        "    with pd.ExcelWriter(LOCAL_XLSX) as _writer:\n",
        "        export_df.to_excel(_writer, index=False)\n",
        "print(\"[OK] Wrote exports:\", os.path.abspath(LOCAL_CSV), \"and\", os.path.abspath(LOCAL_XLSX))\n",
        "\n",
        "# ---------- 7) HTML (Register main page; no inline font-family) ----------\n",
        "TABLE_CSS = \"\"\"\n",
        "<style type=\"text/css\">\n",
        "  html { scroll-behavior: smooth; }\n",
        "  body { font-size:100%; background:#ffffff; color:#222; margin:0; padding:0; line-height:1.5; }\n",
        "  .wrap { max-width:3150px; margin:0 auto; background:#ffffff; padding:20px; padding-bottom:48px; }\n",
        "  a { color:#154b8b; text-decoration:none; } a:hover { text-decoration:underline; }\n",
        "  h1 { margin:0 0 4px 0; font-size:26px; line-height:1.2; text-align:center; }\n",
        "  .centerline { text-align:center; }\n",
        "  .downloads { text-align:center; margin:4px 0 10px 0; font-size:13px; }\n",
        "  .updated { font-size:12px; color:#555; text-align:center; margin:2px 0 10px 0; }\n",
        "  .sortbar { margin:6px 0 10px 0; font-size:13px; background:#ffffff; padding:6px 8px; border-radius:6px; display:flex; flex-wrap:wrap; gap:5px; align-items:center; border:1px solid #ddd; justify-content:center; }\n",
        "  .btn { display:inline-block; border:1px solid #5b79b8; background:#5b79b8; color:#fff; padding:4px 9px; text-decoration:none; cursor:pointer; border-radius:5px; line-height:1.2; }\n",
        "  .btn:hover { background:#4668aa; }\n",
        "  input.btn.search { background:#fff; color:#111; border-color:#bbb; }\n",
        "  .find-cell { white-space:nowrap; }\n",
        "  .selbox { margin-right:6px; vertical-align:middle; }\n",
        "  .table-scroll { max-height:70vh; overflow-y:auto; overflow-x:auto; border:1px solid #ddd; }\n",
        "  table.sortable { border-collapse:collapse; width:3150px; table-layout:fixed; }\n",
        "  table.sortable th, table.sortable td { border:1px solid #ddd; padding:6px 8px; vertical-align:top; }\n",
        "  table.sortable th { background:#e3eaf8; text-align:left; position:sticky; top:0; z-index:2; box-shadow:0 1px 0 #ccc; cursor:pointer; }\n",
        "  #first-row td { border-top:2px solid #999; }\n",
        "  .back-to-top { position:fixed; right:16px; bottom:16px; padding:6px 10px; border:1px solid #3e5a97; background:#5b79b8; color:#fff; cursor:pointer; border-radius:6px; font-size:12px; display:none; z-index:9999; }\n",
        "  .back-to-top:hover { background:#4668aa; }\n",
        "  #dynamicContent { margin:10px 0 14px 0; }\n",
        "  @media screen and (max-width: 820px) { .wrap { padding:12px; } h1 { font-size:22px; } }\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "DYNAMIC_BLOCK = (\n",
        "    '<div class=\"sortbar\">'\n",
        "    '<a class=\"btn\" href=\"https://yates.one-name.net/gengen/dna_cousin_surname_study.htm\" target=\"_blank\" rel=\"noopener\">Study Details</a>'\n",
        "    '<a class=\"btn\" href=\"https://yates.one-name.net/gengen/dna_theory_of_the_case.htm\" target=\"_blank\" rel=\"noopener\">Theory in Action</a>'\n",
        "    '<a class=\"btn\" href=\"/gengen/images/cousin-calculator.jpg\" target=\"_blank\" rel=\"noopener\">Cousin Connection</a>'\n",
        "    '<a class=\"btn\" href=\"/gengen/images/Shared_cM_Project_v4.jpg\" target=\"_blank\" rel=\"noopener\">Cousin by DNA</a>'\n",
        "    '<a class=\"btn\" href=\"/partials/match_count.htm\" target=\"_blank\" rel=\"noopener\">Match Count</a>'\n",
        "    '<a class=\"btn\" href=\"/partials/lineage_count.htm\" target=\"_blank\" rel=\"noopener\">Lineage Count</a>'\n",
        "    f'<a class=\"btn\" href=\"{DNA_REGISTER_ABS}\" target=\"_blank\" rel=\"noopener\">DNA Register</a>'\n",
        "    f'<a class=\"btn\" href=\"{TREES_ABS}\" target=\"_blank\" rel=\"noopener\">Trees</a>'\n",
        "    '<span class=\"btn\" id=\"show-selected\" title=\"Show all rows for the checked name(s)\">Show Selected</span>'\n",
        "    '<span class=\"btn\" id=\"show-all\" title=\"Show All\">Show All</span>'\n",
        "    '<span class=\"btn\" id=\"print-cousin-list\" style=\"cursor:pointer;\" title=\"Open a printable list of the *currently visible* rows\">Cousin List (Printable)</span>'\n",
        "    '<span class=\"btn\" id=\"clear-selected\">Reset</span>'\n",
        "    '<input type=\"text\" id=\"search-box\" class=\"btn search\" size=\"24\" value=\"\" placeholder=\"Search&amp;hellip;\" />'\n",
        "    '</div>'\n",
        ")\n",
        "\n",
        "JS_COUNT_URL = COUNT_PUBLIC_URL.replace(\"'\", \"%27\")\n",
        "UPDATED_BLOCK = (\n",
        "    '<div class=\"updated centerline\">'\n",
        "    'Last updated: <span id=\"last-updated\"></span>'\n",
        "    ' &nbsp;|&nbsp; Autosomal matches: <span id=\"auto-count\" class=\"js-count\"></span>'\n",
        "    ' &nbsp;|&nbsp; Showing: <span id=\"showing-count\"></span>'\n",
        "    '</div>'\n",
        ")\n",
        "\n",
        "DOWNLOADS_BLOCK = (\n",
        "    '<p class=\"downloads centerline\">Download: '\n",
        "    f'<a href=\"/partials/{_html.escape(os.path.basename(LOCAL_CSV))}\">CSV</a> | '\n",
        "    f'<a href=\"/partials/{_html.escape(os.path.basename(LOCAL_XLSX))}\">Excel</a></p>'\n",
        ")\n",
        "\n",
        "page_tpl = Template(\"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "<title>ONS Yates Study Autosomal DNA Register</title>\n",
        "$HEAD_LINK\n",
        "$TABLE_CSS\n",
        "<script type=\"text/javascript\">var HEAD_LINK_URL = \"$HEAD_LINK_URL\";</script>\n",
        "</head>\n",
        "<body id=\"top\">\n",
        "<div class=\"wrap\">\n",
        "  <h1 class=\"centerline\">ONS Yates Study Autosomal DNA Register</h1>\n",
        "  $DOWNLOADS_BLOCK\n",
        "  $UPDATED_BLOCK\n",
        "  $DYNAMIC_BLOCK\n",
        "  <div class=\"table-scroll\">\n",
        "    $HTML_TABLE\n",
        "  </div>\n",
        "</div>\n",
        "<button id=\"back-to-top\" class=\"back-to-top\">&#9650; Top</button>\n",
        "<script type=\"text/javascript\">\n",
        "//<![CDATA[\n",
        "(function(){\n",
        "  function textOf(cell){ return (cell && (cell.textContent || cell.innerText) || '').replace(/\\\\s+/g,' ').trim().toLowerCase(); }\n",
        "  function sortTable(tbl, colIndex, dir){\n",
        "    var tb=tbl && tbl.tBodies ? tbl.tBodies[0] : null; if(!tb) return;\n",
        "    var rows=[].slice.call(tb.rows||[]); var asc=(dir==='asc');\n",
        "    rows.sort(function(a,b){var A=textOf(a.cells[colIndex]),B=textOf(b.cells[colIndex]); if(A<B) return asc?-1:1; if(A>B) return asc?1:-1; return 0;});\n",
        "    var frag=document.createDocumentFragment(); for(var i=0;i<rows.length;i++) frag.appendChild(rows[i]); tb.appendChild(frag);\n",
        "    updateShowing();\n",
        "  }\n",
        "  function bindHeaderSort(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tHead && tbl.tHead.rows.length)) return;\n",
        "    var ths=tbl.tHead.rows[0].cells; if(!ths) return;\n",
        "    for(var i=0;i<ths.length;i++){(function(idx){\n",
        "      var th = ths[idx]; var dir='asc';\n",
        "      th.addEventListener('click',function(){\n",
        "        dir=(dir==='asc')?'desc':'asc';\n",
        "        for (var j = 0; j < ths.length; j++){ ths[j].innerHTML = ths[j].innerHTML.replace(/\\\\s+[↑↓]/,''); }\n",
        "        th.innerHTML += (dir==='asc' ? ' &uarr;' : ' &darr;');\n",
        "        sortTable(tbl,idx,dir);\n",
        "      },false);\n",
        "    })(i);}\n",
        "  }\n",
        "  function stampLastUpdated(){\n",
        "    var el = document.getElementById('last-updated'); if(!el) return;\n",
        "    var d  = new Date(document.lastModified || new Date());\n",
        "    var months = ['January','February','March','April','May','June','July','August','September','October','November','December'];\n",
        "    el.innerHTML = d.getDate() + ' ' + months[d.getMonth()] + ' ' + d.getFullYear();\n",
        "  }\n",
        "  function formatWithCommas(n){\n",
        "    try{ var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return ''; return x.toLocaleString('en-US'); }catch(e){ return String(n||''); }\n",
        "  }\n",
        "  function visibleRowCount(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return 0;\n",
        "    var rows=tbl.tBodies[0].rows, n=0;\n",
        "    for(var i=0;i<rows.length;i++){ if(rows[i].style.display!=='none') n++; }\n",
        "    return n;\n",
        "  }\n",
        "  function updateShowing(){\n",
        "    var el=document.getElementById('showing-count'); if(!el) return;\n",
        "    el.textContent = formatWithCommas(visibleRowCount());\n",
        "  }\n",
        "  function loadAutoCount(){\n",
        "    var el=document.getElementById('auto-count'); if(!el) return;\n",
        "    var url='$JS_COUNT_URL';\n",
        "    try{\n",
        "      var xhr=new XMLHttpRequest(); xhr.open('GET', url+(url.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true);\n",
        "      xhr.onreadystatechange=function(){ if(xhr.readyState===4){\n",
        "        if(xhr.status>=200&&xhr.status<300){\n",
        "          var m=(xhr.responseText||'').match(/(\\\\d+)/); var num=m?m[1]:'';\n",
        "          el.textContent = formatWithCommas(num) || '(unavailable)';\n",
        "        } else { el.textContent='(unavailable)'; }\n",
        "      }};\n",
        "      xhr.send(null);\n",
        "    }catch(e){ el.textContent='(unavailable)'; }\n",
        "  }\n",
        "  function getParam(name){ var m=location.search.match(new RegExp('[?&]'+name+'=([^&]+)')); return m?decodeURIComponent(m[1].replace(/\\\\+/g,' ')):''; }\n",
        "  function norm(s){ return String(s||'').replace(/\\\\s+/g,' ').toLowerCase(); }\n",
        "  function bindSearch(){\n",
        "    var box=document.getElementById('search-box'); var tbl=document.getElementById('refactor-table'); if(!(box && tbl && tbl.tBodies && tbl.tBodies[0])) return; var tb=tbl.tBodies[0];\n",
        "    function rowText(tr){ var t=''; for(var i=1;i<tr.cells.length;i++){ t+= ' ' + (tr.cells[i].textContent||tr.cells[i].innerText||''); } return norm(t); }\n",
        "    var cached=[]; (function seed(){ var rows=tb.rows; cached=[]; for(var i=0;i<rows.length;i++){ cached.push({el:rows[i], txt:rowText(rows[i])}); } })();\n",
        "    function apply(q){\n",
        "      q = String(q||''); var parts = q.split('|').map(function(s){return norm(s);}).filter(function(s){return !!s;});\n",
        "      for(var i=0;i<cached.length;i++){\n",
        "        var hit = !parts.length || parts.some(function(p){ return cached[i].txt.indexOf(p)>-1; });\n",
        "        cached[i].el.style.display = hit? '' : 'none';\n",
        "      }\n",
        "      updateShowing();\n",
        "    }\n",
        "    var to=null; function onInput(){ if(to) clearTimeout(to); to=setTimeout(function(){ apply(box.value); }, 60); }\n",
        "    box.addEventListener('input', onInput, false);\n",
        "    box.addEventListener('search', onInput, false);\n",
        "    var q0=getParam('q');\n",
        "    if(q0){ box.value=q0; apply(q0); try{ history.replaceState(null, '', location.pathname); }catch(e){} }\n",
        "    else { box.value=''; apply(''); setTimeout(function(){ if(!getParam('q')){ box.value=''; apply(''); } }, 0); }\n",
        "  }\n",
        "  function allRowCheckboxes(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return [];\n",
        "    var tb=tbl.tBodies[0], out=[];\n",
        "    for(var i=0;i<tb.rows.length;i++){\n",
        "      var cb=tb.rows[i].querySelector('.selbox');\n",
        "      if(cb) out.push(cb);\n",
        "    }\n",
        "    return out;\n",
        "  }\n",
        "  function bindGroupSync(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!tbl) return;\n",
        "    tbl.addEventListener('click', function(e){\n",
        "      var t=e.target||e.srcElement;\n",
        "      if(!(t && t.classList && t.classList.contains('selbox'))) return;\n",
        "      var nm = t.getAttribute('data-name') || '';\n",
        "      var checked = !!t.checked;\n",
        "      var cbs = allRowCheckboxes();\n",
        "      for(var i=0;i<cbs.length;i++){\n",
        "        if((cbs[i].getAttribute('data-name')||'') === nm){ cbs[i].checked = checked; }\n",
        "      }\n",
        "      updateShowing();\n",
        "    }, false);\n",
        "  }\n",
        "  function bindShowSelected(){\n",
        "    var btn=document.getElementById('show-selected'); if(!btn) return;\n",
        "    btn.addEventListener('click', function(){\n",
        "      var cbs = allRowCheckboxes();\n",
        "      var names = {};\n",
        "      for(var i=0;i<cbs.length;i++){ if(cbs[i].checked){ names[cbs[i].getAttribute('data-name')||''] = true; } }\n",
        "      var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "      var tb=tbl.tBodies[0];\n",
        "      for(var r=0;r<tb.rows.length;r++){\n",
        "        var cb = tb.rows[r].querySelector('.selbox');\n",
        "        var nm = cb ? (cb.getAttribute('data-name')||'') : '';\n",
        "        tb.rows[r].style.display = names[nm] ? '' : 'none';\n",
        "      }\n",
        "      updateShowing();\n",
        "    }, false);\n",
        "  }\n",
        "  function bindShowAll(){\n",
        "    var btn=document.getElementById('show-all'); if(!btn) return;\n",
        "    btn.addEventListener('click', function(){\n",
        "      var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "      var tb=tbl.tBodies[0];\n",
        "      for(var i=0;i<tb.rows.length;i++){ tb.rows[i].style.display=''; }\n",
        "      updateShowing();\n",
        "    }, false);\n",
        "  }\n",
        "  function bindClear(){\n",
        "    var btn=document.getElementById('clear-selected'); if(!btn) return;\n",
        "    btn.addEventListener('click', function(){\n",
        "      var cbs=allRowCheckboxes(); for(var i=0;i<cbs.length;i++) cbs[i].checked=false;\n",
        "      var tbl=document.getElementById('refactor-table'); if(tbl && tbl.tBodies && tbl.tBodies[0]){\n",
        "        var tb=tbl.tBodies[0]; for(var j=0;j<tb.rows.length;j++){ tb.rows[j].style.display=''; }\n",
        "      }\n",
        "      updateShowing();\n",
        "    }, false);\n",
        "  }\n",
        "  function addCheckboxes(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "    var tb=tbl.tBodies[0];\n",
        "    for(var i=0;i<tb.rows.length;i++){\n",
        "      var tr=tb.rows[i]; var cell=tr.cells[0]; var findBtn=cell ? cell.querySelector('.find-btn') : null;\n",
        "      var name = findBtn ? (findBtn.getAttribute('title')||'').replace('Open a filtered view for ','') : ('Row '+(i+1));\n",
        "      if(cell){\n",
        "        cell.classList.add('find-cell');\n",
        "        cell.innerHTML = '<input type=\"checkbox\" class=\"selbox\" title=\"Select this row\" data-name=\"'+name.replace(/\"/g,'&quot;')+'\" /> ' + cell.innerHTML.replace(/^\\\\s*/, '');\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  function bindPrintCousinList(){\n",
        "    var btn=document.getElementById('print-cousin-list'); if(!btn) return;\n",
        "    btn.addEventListener('click', function(){\n",
        "      var tbl=document.getElementById('refactor-table'); if(!tbl) return;\n",
        "      var headerHtml = ''; try{ headerHtml = tbl.tHead.innerHTML; }catch(e){}\n",
        "      var tb=tbl.tBodies[0];\n",
        "      var visibleRowsHtml = ''; var visibleCount = 0;\n",
        "      if(tb){\n",
        "        for (var i = 0; i < tb.rows.length; i++) {\n",
        "          if (tb.rows[i].style.display !== 'none') {\n",
        "            visibleRowsHtml += tb.rows[i].outerHTML;\n",
        "            visibleCount++;\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "      var css = '<style type=\"text/css\">' +\n",
        "        \"body { font-size:12px; margin: 20px; }\" +\n",
        "        \"h1 { font-size:20px; text-align:center; }\" +\n",
        "        \"table { border-collapse:collapse; width:100%; table-layout:fixed; }\" +\n",
        "        \"th, td { border:1px solid #999; padding: 5px 7px; vertical-align:top; text-align:left; word-wrap:break-word; }\" +\n",
        "        \"th { background:#f0f0f0; }\" +\n",
        "        \"a { color:#000; text-decoration:none; }\" +\n",
        "        \"th:first-child, td:first-child { display:none; }\" +\n",
        "        \"th:nth-child(2), td:nth-child(2) { width: 40% !important; }\" +\n",
        "        \"th:nth-child(3), td:nth-child(3) { width: 60% !important; }\" +\n",
        "        '</style>';\n",
        "      var link = '<link rel=\"stylesheet\" type=\"text/css\" href=\"'+(window.HEAD_LINK_URL || (typeof HEAD_LINK_URL!=='undefined'?HEAD_LINK_URL:''))+'\" />';\n",
        "      var tableHtml = '<table border=\"1\">' + '<thead>' + headerHtml + '</thead><tbody>' + visibleRowsHtml + '</tbody></table>';\n",
        "      var docHtml = '<html><head><title>Cousin List (Filtered)</title>' + link + css + '</head><body onload=\"window.print(); window.close();\">' +\n",
        "                    '<h1>Cousin List</h1>' +\n",
        "                    '<p>Showing ' + visibleCount + ' filtered records.</p>' +\n",
        "                    tableHtml +\n",
        "                    '</body></html>';\n",
        "      var win = window.open('', 'CousinPrint');\n",
        "      win.document.open(); win.document.write(docHtml); win.document.close(); win.focus();\n",
        "    }, false);\n",
        "  }\n",
        "  function initShowingStatic(){ try{ document.getElementById('showing-count').textContent = document.getElementById('refactor-table').tBodies[0].rows.length; }catch(e){} }\n",
        "  document.addEventListener('DOMContentLoaded', function(){\n",
        "    addCheckboxes();\n",
        "    stampLastUpdated();\n",
        "    loadAutoCount();\n",
        "    bindHeaderSort();\n",
        "    bindSearch();\n",
        "    bindGroupSync();\n",
        "    bindShowSelected();\n",
        "    bindShowAll();\n",
        "    bindClear();\n",
        "    bindPrintCousinList();\n",
        "    initShowingStatic();\n",
        "  });\n",
        "})();\n",
        " //]]>\n",
        "</script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\")\n",
        "\n",
        "html_table = display_df.to_html(index=False, escape=False, classes=\"dataframe sortable\")\n",
        "html_table = html_table.replace('<table border=\"1\" class=\"dataframe sortable\">', '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">', 1)\n",
        "html_table = html_table.replace('<tbody>\\n<tr>', '<tbody>\\n<tr id=\"first-row\">', 1)\n",
        "html_table = html_table.replace(\"<th>Find</th>\", '<th>Select:</th>', 1)\n",
        "html_table = html_table.replace('<th>Match Summary</th>', '<th>Match Summary&amp;ndash;click to sort</th>', 1)\n",
        "html_table = html_table.replace(f'<th>{_html.escape(LINEAGE_HEADER_SAFE)}</th>', '<th>Lineage (Starting with oldest ancestor&amp;ndash;click to sort)</th>', 1)\n",
        "\n",
        "colgroup_html = (\n",
        "    \"<colgroup>\\n\"\n",
        "    f\"  <col style=\\\"width:{FIND_COL_PX}px;\\\" />\\n\"\n",
        "    f\"  <col style=\\\"width:{COL_A_PX}px;\\\" />\\n\"\n",
        "    \"  <col />\\n\"\n",
        "    \"</colgroup>\\n\"\n",
        ")\n",
        "html_table = html_table.replace(\n",
        "    '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">',\n",
        "    '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">\\n' + colgroup_html,\n",
        "    1\n",
        ")\n",
        "\n",
        "final_html = page_tpl.safe_substitute(\n",
        "    HEAD_LINK=HEAD_LINK,\n",
        "    TABLE_CSS=TABLE_CSS,\n",
        "    UPDATED_BLOCK=UPDATED_BLOCK,\n",
        "    DYNAMIC_BLOCK=DYNAMIC_BLOCK,\n",
        "    HTML_TABLE=html_table,\n",
        "    JS_COUNT_URL=JS_COUNT_URL,\n",
        "    DOWNLOADS_BLOCK=DOWNLOADS_BLOCK,\n",
        "    HEAD_LINK_URL=HEAD_LINK_URL\n",
        ")\n",
        "\n",
        "# ---------- 8) PARTIALS (Row-color highlight fix applies here only) ----------\n",
        "def _norm_code_for_count(s):\n",
        "    t = str(s or \"\").strip()\n",
        "    if (t.startswith('\"') and t.endswith('\"')) or (t.startswith(\"'\") and t.endswith(\"'\")):\n",
        "        t = t[1:-1]\n",
        "    t = re.sub(r'\\s+', ' ', t).strip()\n",
        "    t = t.lower()\n",
        "    return t\n",
        "\n",
        "def _partial_css_wrapper_simple():\n",
        "    return (\n",
        "        HEAD_LINK +\n",
        "        \"<style type=\\\"text/css\\\">\\n\"\n",
        "        \"  html { scroll-behavior: smooth; }\\n\"\n",
        "        f\"  .wrap {{ max-width:{TABLE_WIDTH_PX}px; margin:0 auto; background:#ffffff; padding:20px 20px 18px 20px; }}\\n\"\n",
        "        \"  a { text-decoration:none; } a:hover { text-decoration:underline; }\\n\"\n",
        "        \"  h1 { margin:0 0 8px 0; font-size:24px; line-height:1.2; text-align:center; }\\n\"\n",
        "        \"  .meta { text-align:center; font-size:12px; color:#555; margin:2px 0 10px 0; }\\n\"\n",
        "        \"  .toolbar { display:flex; gap:10px; align-items:center; margin:6px 0 10px 0; flex-wrap:wrap; justify-content:center; }\\n\"\n",
        "        \"  .btn { display:inline-block; border:1px solid #5b79b8; background:#5b79b8; color:#fff; padding:4px 9px; text-decoration:none; cursor:pointer; border-radius:5px; line-height:1.2; }\\n\"\n",
        "        \"  .btn:disabled { opacity:0.5; cursor:not-allowed; }\\n\"\n",
        "        \"  table { border-collapse:collapse; width:100%; table-layout:auto; }\\n\"\n",
        "        \"  th, td { border:1px solid #ddd; padding:6px 8px; vertical-align:top; text-align:left; }\\n\"\n",
        "        \"  th { background:#e3eaf8; position:sticky; top:0; z-index:2; }\\n\"\n",
        "        \"  /* Row selection highlight FIX (partials only) */\\n\"\n",
        "        \"  tbody tr.sel td { background:#fff7d6 !important; }\\n\"\n",
        "        \"  tbody tr:hover td { background:#f9f6e8; }\\n\"\n",
        "        \"  .count a { font-weight:bold; }\\n\"\n",
        "        \"</style>\\n\"\n",
        "    )\n",
        "\n",
        "def _partial_head(title):\n",
        "    return (\n",
        "        \"<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Transitional//EN\\\"\\n\"\n",
        "        \"  \\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\\\">\\n\"\n",
        "        \"<html xmlns=\\\"http://www.w3.org/1999/xhtml\\\" lang=\\\"en\\\">\\n<head>\\n\"\n",
        "        \"<meta http-equiv=\\\"Content-Type\\\" content=\\\"text/html; charset=iso-8859-15\\\" />\\n\"\n",
        "        f\"<title>{_html.escape(title)}</title>\\n\"\n",
        "    )\n",
        "\n",
        "def _partial_toolbar():\n",
        "    safe_home = HOME_URL.replace('\"','&quot;')\n",
        "    return (\n",
        "        \"<div class=\\\"toolbar\\\">\"\n",
        "        f\"<a class=\\\"btn\\\" href=\\\"{safe_home}\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">DNA Register</a>\"\n",
        "        \" <button id=\\\"mc-show-selected\\\" class=\\\"btn\\\" title=\\\"Open DNA Register filtered to selected\\\">Show Selected</button>\"\n",
        "        \" <button id=\\\"mc-show-all\\\" class=\\\"btn\\\" title=\\\"Show all rows (this table)\\\">Show All</button>\"\n",
        "        \" <button id=\\\"mc-reset\\\" class=\\\"btn\\\" title=\\\"Clear selection and show all\\\">Reset</button>\"\n",
        "        \" <button id=\\\"view\\\" class=\\\"btn\\\" title=\\\"Open DNA Register with selected (alias)\\\">View Now</button>\"\n",
        "        \"</div>\\n\"\n",
        "    )\n",
        "\n",
        "def _partial_js_common():\n",
        "    _safe_home = HOME_URL.replace(\"'\", \"%27\")\n",
        "    safe_count = COUNT_PUBLIC_URL.replace(\"'\", \"%27\")\n",
        "    return (\n",
        "        \"<script type=\\\"text/javascript\\\">\\n//<![CDATA[\\n\"\n",
        "        \"(function(){\\n\"\n",
        "        \"  var REG = '\" + _safe_home + \"';\\n\"\n",
        "        \"  function fmt(n){ try{ var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return '0'; return x.toLocaleString('en-US'); }catch(e){ return String(n||'0'); } }\\n\"\n",
        "        \"  function selected(){ var out=[]; var tb=document.getElementById('ref-tb'); if(!tb) return out; var rows=tb.rows; for(var i=0;i<rows.length;i++){ if((' '+rows[i].className+' ').indexOf(' sel ')>-1) out.push(rows[i]); } return out; }\\n\"\n",
        "        \"  function update(){ var sel=selected(), sum=0; for(var i=0;i<sel.length;i++){ var v=parseInt((sel[i].getAttribute('data-count')||'0').replace(/[^0-9\\\\-]/g,''),10); if(!isNaN(v)) sum+=v; } var nEl=document.getElementById('sel-n'); var sEl=document.getElementById('sel-sum'); if(nEl) nEl.innerHTML=fmt(sel.length); if(sEl) sEl.innerHTML=fmt(sum); }\\n\"\n",
        "        \"  function qJoin(parts){ var out=[]; var seen={}; for(var i=0;i<parts.length;i++){ var p=String(parts[i]||''); if(p && !seen[p]){ seen[p]=1; out.push(encodeURIComponent(p)); } } return out.join('%7C'); }\\n\"\n",
        "        \"  function openRegisterForSelected(){ var sel=selected(); if(!sel.length) return; var qs=[]; for(var i=0;i<sel.length;i++){ qs.push(sel[i].getAttribute('data-q')||''); } var q = qJoin(qs); var url = REG + '?q=' + q; var w=null; try{ w=window.open(url,'RegisterFiltered'); if(!w) throw new Error('popup'); w.focus(); } catch(e){ window.location.href = url; } }\\n\"\n",
        "        \"  function toggleFrom(el){ var tr=el; while(tr && tr.nodeName && tr.nodeName.toLowerCase()!=='tr'){ tr=tr.parentNode; } if(!tr) return; var c=tr.className||''; tr.className = ((' '+c+' ').indexOf(' sel ')>-1) ? c.replace(/\\\\bsel\\\\b/,'').replace(/\\\\s{2,}/g,' ').trim() : (c?c+' ':'')+'sel'; update(); }\\n\"\n",
        "        \"  document.addEventListener('click', function(e){ var t=e.target||e.srcElement; if(!t) return; if(t.classList && t.classList.contains('count-pick')){ e.preventDefault(); toggleFrom(t); return; } if(t.id=='view' || t.id=='mc-show-selected'){ e.preventDefault(); openRegisterForSelected(); return; } if(t.id=='mc-reset'){ e.preventDefault(); var tb=document.getElementById('ref-tb'); if(tb){ var rows=tb.rows; for(var i=0;i<rows.length;i++){ rows[i].className = rows[i].className.replace(/\\\\bsel\\\\b/,'').replace(/\\\\s{2,}/g,' ').trim(); rows[i].style.display=''; } } update(); return; } if(t.id=='mc-show-all'){ e.preventDefault(); var tb2=document.getElementById('ref-tb'); if(!tb2) return; for(var k=0;k<tb2.rows.length;k++){ tb2.rows[k].style.display=''; } return; } }, false);\\n\"\n",
        "        \"  function stamp(){var el=document.getElementById('last-updated'); if(!el) return; var d=new Date(document.lastModified||new Date()); function z(n){return (n<10?'0':'')+n;} el.innerHTML=d.getFullYear()+'-'+z(d.getMonth()+1)+'-'+z(d.getDate())+' '+z(d.getHours())+':'+z(d.getMinutes());}\\n\"\n",
        "        \"  function load(){var el=document.getElementById('auto-count'); if(!el) return; var URL='\" + safe_count + \"'; try{var xhr=new XMLHttpRequest(); xhr.open('GET', URL+(URL.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true); xhr.onreadystatechange=function(){if(xhr.readyState===4){if(xhr.status>=200&&xhr.status<300){var m=(xhr.responseText||'').match(/(\\\\d+)/); el.textContent=(m?m[1]:'');} else {el.textContent='(unavailable)';}}}; xhr.send(null);}catch(e){el.textContent='(unavailable)';}}\\n\"\n",
        "        \"  document.addEventListener('DOMContentLoaded', function(){ stamp(); load(); update(); }, false);\\n\"\n",
        "        \"})();\\n\"\n",
        "        \"//]]>\\n</script>\\n\"\n",
        "    )\n",
        "\n",
        "def _shell_open(title):\n",
        "    return (\n",
        "        _partial_head(title) +\n",
        "        _partial_css_wrapper_simple() +\n",
        "        \"</head>\\n<body>\\n<div class=\\\"wrap\\\">\\n\" +\n",
        "        f\"<h1>{_html.escape(title)}</h1>\\n\" +\n",
        "        \"<div class=\\\"meta\\\">\"\n",
        "        \"Last updated: <span id=\\\"last-updated\\\"></span>\"\n",
        "        \" &nbsp;|&nbsp; Autosomal matches: <span id=\\\"auto-count\\\">&mdash;</span>\"\n",
        "        \" &nbsp;|&nbsp; Selected: <span id=\\\"sel-n\\\">0</span> &nbsp; Sum: <span id=\\\"sel-sum\\\">0</span>\"\n",
        "        \"</div>\\n\" +\n",
        "        _partial_toolbar() +\n",
        "        \"<div class=\\\"table-scroll\\\">\\n\"\n",
        "    )\n",
        "\n",
        "def _shell_close():\n",
        "    return (\n",
        "        \"</div>\\n</div>\\n\" +\n",
        "        _partial_js_common() +\n",
        "        \"</body>\\n</html>\"\n",
        "    )\n",
        "\n",
        "def _html_escape_text(s):\n",
        "    return _html.escape(str(s), quote=True)\n",
        "\n",
        "def build_match_count_partial(main_df: pd.DataFrame) -> str:\n",
        "    codes_raw = main_df[match_col].astype(str).map(lambda x: x.strip())\n",
        "    keys_norm = codes_raw.map(_norm_code_for_count)\n",
        "    counts_series = keys_norm.value_counts(dropna=False)\n",
        "    counts = counts_series.reset_index()\n",
        "    if counts.shape[1] >= 2:\n",
        "        counts.columns = [\"norm_key\", \"Count\"]\n",
        "    else:\n",
        "        counts[\"norm_key\"] = counts.index.astype(str)\n",
        "        counts[\"Count\"] = counts_series.values\n",
        "        counts = counts[[\"norm_key\",\"Count\"]]\n",
        "    first_display = {}\n",
        "    for code_disp, k in zip(codes_raw.tolist(), keys_norm.tolist()):\n",
        "        if k not in first_display and str(k) != \"\":\n",
        "            first_display[k] = code_disp\n",
        "    counts[\"Code\"] = counts[\"norm_key\"].map(lambda k: first_display.get(k, k))\n",
        "    counts[\"Unmasked\"] = counts[\"norm_key\"].map(lambda k: MATCH_TO_UNMASKED.get(k, \"\"))\n",
        "    counts = counts.sort_values(by=[\"Code\",\"Count\"], ascending=[True, False], kind=\"mergesort\").reset_index(drop=True)\n",
        "\n",
        "    html = []\n",
        "    html.append(_shell_open(\"Match Count\"))\n",
        "    html.append('<table id=\"ref-table\" border=\"1\" class=\"sortable\" style=\"width:100%\"><thead><tr>')\n",
        "    html.append('<th style=\"width:35%\">Code</th><th style=\"width:45%\">Unmasked</th><th style=\"width:20%\">Count</th>')\n",
        "    html.append('</tr></thead><tbody id=\"ref-tb\">')\n",
        "    for _, r in counts.iterrows():\n",
        "        code = r.get(\"Code\",\"\")\n",
        "        unm  = r.get(\"Unmasked\",\"\")\n",
        "        cnt  = int(str(r.get(\"Count\",\"0\")).strip() or \"0\")\n",
        "        label = (unm or code).strip()\n",
        "        tr = (\n",
        "            f'<tr data-q=\"{_html_escape_text(label)}\" data-count=\"{cnt}\">'\n",
        "            f'<td>{_html_escape_text(code)}</td>'\n",
        "            f'<td>{_html_escape_text(unm)}</td>'\n",
        "            f'<td class=\"count\"><a href=\"#\" class=\"count-pick\" title=\"Toggle select\">{cnt}</a></td>'\n",
        "            f'</tr>'\n",
        "        )\n",
        "        html.append(tr)\n",
        "    html.append('</tbody></table>')\n",
        "    html.append(_shell_close())\n",
        "    return \"\".join(html)\n",
        "\n",
        "def build_lineage_count_partial(main_df: pd.DataFrame) -> str:\n",
        "    first_series = main_df.get(\"First Ancestor\", pd.Series(dtype=str)).astype(str).map(lambda x: x.strip())\n",
        "    vc = first_series[first_series != \"\"].value_counts(dropna=False)\n",
        "    lin_df = vc.reset_index()\n",
        "    if lin_df.shape[1] >= 2:\n",
        "        lin_df.columns = [\"First Ancestor\",\"Count\"]\n",
        "    else:\n",
        "        lin_df[\"First Ancestor\"] = lin_df.index.astype(str)\n",
        "        lin_df[\"Count\"] = vc.values\n",
        "        lin_df = lin_df[[\"First Ancestor\",\"Count\"]]\n",
        "    lin_df = lin_df.sort_values([\"Count\",\"First Ancestor\"], ascending=[False, True], kind=\"mergesort\").reset_index(drop=True)\n",
        "\n",
        "    html = []\n",
        "    html.append(_shell_open(\"Lineage Count\"))\n",
        "    html.append('<table id=\"ref-table\" border=\"1\" class=\"sortable\" style=\"width:100%\"><thead><tr>')\n",
        "    html.append('<th style=\"width:80%\">First Ancestor</th><th style=\"width:20%\">Count</th>')\n",
        "    html.append('</tr></thead><tbody id=\"ref-tb\">')\n",
        "    for _, r in lin_df.iterrows():\n",
        "        first = str(r.get(\"First Ancestor\",\"\")).strip()\n",
        "        cnt   = int(str(r.get(\"Count\",\"0\")).strip() or \"0\")\n",
        "        tr = (\n",
        "            f'<tr data-q=\"{_html_escape_text(first)}\" data-count=\"{cnt}\">'\n",
        "            f'<td>{_html.escape(first)}</td>'\n",
        "            f'<td class=\"count\"><a href=\"#\" class=\"count-pick\" title=\"Toggle select\">{cnt}</a></td>'\n",
        "            f'</tr>'\n",
        "        )\n",
        "        html.append(tr)\n",
        "    html.append('</tbody></table>')\n",
        "    html.append(_shell_close())\n",
        "    return \"\".join(html)\n",
        "\n",
        "def build_and_write_partials(main_df: pd.DataFrame):\n",
        "    _setup_resolver()\n",
        "    os.makedirs(\"partials\", exist_ok=True)\n",
        "\n",
        "    mc_html = build_match_count_partial(main_df)\n",
        "    mc_local = os.path.join(\"partials\", \"match_count.htm\")\n",
        "    with open(mc_local, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(mc_html)\n",
        "    print(\"[OK] Wrote partial:\", mc_local)\n",
        "\n",
        "    lc_html = build_lineage_count_partial(main_df)\n",
        "    lc_local = os.path.join(\"partials\", \"lineage_count.htm\")\n",
        "    with open(lc_local, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(lc_html)\n",
        "    print(\"[OK] Wrote partial:\", lc_local)\n",
        "\n",
        "    cousin_df = main_df[[\"Match Summary\"]].copy()\n",
        "    cousin_df = cousin_df.sort_values(by=\"Match Summary\", ascending=True, kind=\"mergesort\").reset_index(drop=True)\n",
        "    cousin_rows = ['<table border=\"1\" id=\"refactor-table\"><thead><tr><th>Match Summary</th></tr></thead><tbody>']\n",
        "    for v in cousin_df[\"Match Summary\"].tolist():\n",
        "        cousin_rows.append(f\"<tr><td>{v}</td></tr>\")\n",
        "    cousin_rows.append(\"</tbody></table>\")\n",
        "    cousin_html = (\n",
        "        \"<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Transitional//EN\\\" \\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\\\">\"\n",
        "        \"<html xmlns=\\\"http://www.w3.org/1999/xhtml\\\" lang=\\\"en\\\"><head>\"\n",
        "        f\"{HEAD_LINK}\"\n",
        "        \"<meta http-equiv=\\\"Content-Type\\\" content=\\\"text/html; charset=iso-8859-15\\\" />\"\n",
        "        \"<title>Cousin List (Printable)</title>\"\n",
        "        \"<style type=\\\"text/css\\\"> body{font-size:12px;margin:20px;} h1{text-align:center;font-size:20px;} table{border-collapse:collapse;width:100%;} th,td{border:1px solid #999;padding:5px 7px;vertical-align:top;text-align:left;} th{background:#f0f0f0;} a{text-decoration:none;} </style>\"\n",
        "        \"</head><body onload=\\\"window.print();\\\">\"\n",
        "        \"<h1>Cousin List (Printable)</h1>\" + \"\".join(cousin_rows) +\n",
        "        \"</body></html>\"\n",
        "    )\n",
        "    cl_local = os.path.join(\"partials\", \"cousin_list_print.htm\")\n",
        "    with open(cl_local, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(cousin_html)\n",
        "    print(\"[OK] Wrote partial:\", cl_local)\n",
        "\n",
        "    return mc_local, lc_local, cl_local\n",
        "\n",
        "# Build partials + main page\n",
        "PARTIAL_MATCH_LOCAL, PARTIAL_LINEAGE_LOCAL, PARTIAL_COUSIN_LOCAL = build_and_write_partials(df)\n",
        "\n",
        "def build_register_html_for_abs(remote_abs_path: str) -> str:\n",
        "    q_links = []\n",
        "    subs = df[\"Subject\"].astype(str).tolist()\n",
        "    for subject_name in subs:\n",
        "        q = _u.quote(subject_name)\n",
        "        q_links.append(\n",
        "            f'<a class=\"find-btn\" href=\"{remote_abs_path}?q={q}\" target=\"_blank\" rel=\"noopener\" '\n",
        "            f'title=\"Open a filtered view for {subject_name}\">Find</a>'\n",
        "        )\n",
        "    df_plus = df.copy()\n",
        "    df_plus[\"Find\"] = q_links\n",
        "    disp_plus = df_plus[[\"Find\",\"Match Summary\", LINEAGE_HEADER_SAFE]]\n",
        "    tbl = disp_plus.to_html(index=False, escape=False, classes=\"dataframe sortable\")\n",
        "    tbl = tbl.replace('<table border=\"1\" class=\"dataframe sortable\">', '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">', 1)\n",
        "    tbl = tbl.replace('<tbody>\\n<tr>', '<tbody>\\n<tr id=\"first-row\">', 1)\n",
        "    tbl = tbl.replace(\"<th>Find</th>\", '<th>Select:</th>', 1)\n",
        "    tbl = tbl.replace(\"<th>Match Summary</th>\", '<th>Match Summary&amp;ndash;click to sort</th>', 1)\n",
        "    tbl = tbl.replace(f\"<th>{_html.escape(LINEAGE_HEADER_SAFE)}</th>\", \"<th>Lineage (Starting with oldest ancestor&amp;ndash;click to sort)</th>\", 1)\n",
        "    colgroup_html_local = (\n",
        "        \"<colgroup>\\n\"\n",
        "        f\"  <col style=\\\"width:{FIND_COL_PX}px;\\\" />\\n\"\n",
        "        f\"  <col style=\\\"width:{COL_A_PX}px;\\\" />\\n\"\n",
        "        \"  <col />\\n\"\n",
        "        \"</colgroup>\\n\"\n",
        "    )\n",
        "    tbl = tbl.replace(\n",
        "        '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">',\n",
        "        '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">\\n' + colgroup_html_local, 1\n",
        "    )\n",
        "    return page_tpl.safe_substitute(\n",
        "        HEAD_LINK=HEAD_LINK,\n",
        "        TABLE_CSS=TABLE_CSS,\n",
        "        UPDATED_BLOCK=UPDATED_BLOCK,\n",
        "        DYNAMIC_BLOCK=DYNAMIC_BLOCK,\n",
        "        HTML_TABLE=tbl,\n",
        "        JS_COUNT_URL=JS_COUNT_URL,\n",
        "        DOWNLOADS_BLOCK=DOWNLOADS_BLOCK,\n",
        "        HEAD_LINK_URL=HEAD_LINK_URL\n",
        "    )\n",
        "\n",
        "os.makedirs(\"partials\", exist_ok=True)\n",
        "final_html_plus = build_register_html_for_abs(HOME_URL)\n",
        "\n",
        "with open(LOCAL_HTML, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(final_html)\n",
        "print(\"[OK] Saved canonical render:\", os.path.abspath(LOCAL_HTML))\n",
        "\n",
        "with open(WORK_PLUS_LOCAL, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(final_html_plus)\n",
        "print(\"[OK] Saved:\", os.path.abspath(WORK_PLUS_LOCAL), \"(partials clone)\")\n",
        "\n",
        "# ---------- 9) Uploads ----------\n",
        "def save_and_upload_all():\n",
        "    if not all(os.environ.get(k) for k in ['FTP_HOST','FTP_USER','FTP_PASS']):\n",
        "        print(\"[SKIP] Missing FTP creds; uploads skipped.\")\n",
        "        return\n",
        "    try:\n",
        "        ftps = ftp_connect()\n",
        "\n",
        "        try:\n",
        "            ftp_upload_overwrite(ftps, LOCAL_HTML, _remote_path(REMOTE_HTML_CANON))\n",
        "            ftp_upload_overwrite(ftps, LOCAL_HTML, _remote_path(REMOTE_HTML_LEG))\n",
        "            ftp_upload_overwrite(ftps, LOCAL_HTML, _remote_path(REMOTE_HTML_SIMPLE))\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload main HTML failed:\", e)\n",
        "\n",
        "        try:\n",
        "            if os.path.exists(LOCAL_CSV):\n",
        "                ftp_upload_overwrite(ftps, LOCAL_CSV, _remote_path(REMOTE_CSV))\n",
        "            if os.path.exists(LOCAL_XLSX):\n",
        "                ftp_upload_overwrite(ftps, LOCAL_XLSX, _remote_path(REMOTE_XLSX))\n",
        "            print(\"[OK] Uploaded CSV/XLSX -> /partials/\")\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload CSV/XLSX failed:\", e)\n",
        "\n",
        "        if os.path.exists(LOCAL_COUNT_FILE):\n",
        "            try:\n",
        "                ftp_upload_overwrite(ftps, LOCAL_COUNT_FILE, _remote_path(REMOTE_COUNT_NAME))\n",
        "            except Exception as e:\n",
        "                print(\"[WARN] Upload autosomal count failed:\", e)\n",
        "\n",
        "        try:\n",
        "            ftp_upload_overwrite(ftps, os.path.join(\"partials\",\"match_count.htm\"),       _remote_path(posixpath.join(\"partials\",\"match_count.htm\")))\n",
        "            ftp_upload_overwrite(ftps, os.path.join(\"partials\",\"lineage_count.htm\"),     _remote_path(posixpath.join(\"partials\",\"lineage_count.htm\")))\n",
        "            ftp_upload_overwrite(ftps, os.path.join(\"partials\",\"cousin_list_print.htm\"), _remote_path(posixpath.join(\"partials\",\"cousin_list_print.htm\")))\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload partials failed:\", e)\n",
        "\n",
        "        try:\n",
        "            ftp_upload_overwrite(ftps, WORK_PLUS_LOCAL, _remote_path(WORK_PLUS_REMOTE))\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload work_plus.htm failed:\", e)\n",
        "\n",
        "        print(\"\\n--- SIZE Verification (if supported) ---\")\n",
        "        for p in [\n",
        "            _remote_path(REMOTE_HTML_CANON),\n",
        "            _remote_path(REMOTE_HTML_LEG),\n",
        "            _remote_path(REMOTE_HTML_SIMPLE),\n",
        "            _remote_path(REMOTE_CSV),\n",
        "            _remote_path(REMOTE_XLSX),\n",
        "            _remote_path(posixpath.join(\"partials\",\"match_count.htm\")),\n",
        "            _remote_path(posixpath.join(\"partials\",\"lineage_count.htm\")),\n",
        "            _remote_path(posixpath.join(\"partials\",\"cousin_list_print.htm\")),\n",
        "            _remote_path(WORK_PLUS_REMOTE),\n",
        "        ]:\n",
        "            try:\n",
        "                sz = ftp_size(ftps, p)\n",
        "                print(f\"{p} : {sz if sz is not None else '(SIZE unsupported)'}\")\n",
        "            except Exception:\n",
        "                print(f\"{p} : (check skipped)\")\n",
        "\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "\n",
        "        print(\"\\n--- Open URLs ---\")\n",
        "        print(\"Canonical (Find target):          https://yates.one-name.net/partials/yates_ancestor_register.htm\")\n",
        "        print(\"Legacy clone (same content):      https://yates.one-name.net/partials/ons_yates_dna_register.htm\")\n",
        "        print(\"JUSTDNA simple alias:             https://yates.one-name.net/partials/justdna.htm\")\n",
        "        print(\"Trees page:                       https://yates.one-name.net/partials/just-trees.htm\")\n",
        "        print(\"Match Count:                      https://yates.one-name.net/partials/match_count.htm\")\n",
        "        print(\"Lineage Count:                    https://yates.one-name.net/partials/lineage_count.htm\")\n",
        "        print(\"Cousin List (Printable):          https://yates.one-name.net/partials/cousin_list_print.htm\")\n",
        "        print(\"Work+ clone:                      https://yates.one-name.net/partials/work_plus.htm\")\n",
        "\n",
        "        print(\"\\nIf anything looks cached, hard-refresh (Ctrl/Cmd+Shift+R) or append ?v=1 once.\")\n",
        "    except Exception as e:\n",
        "        print(\"[FAIL] FTP session:\", e)\n",
        "        traceback.print_exc()\n",
        "\n",
        "# ---------- 10) Upload ----------\n",
        "save_and_upload_all()\n",
        "# ====== CUT STOP [1/1] CELL 2 ===================================================================\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKf7KgQQW_9V",
        "outputId": "32ad27c1-9774-4b1e-fa36-98c113b0fb59"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Loaded CSV: 7 rows, 6 cols\n",
            "[PULL] match_to_unmasked.csv -> /content/match_to_unmasked.server.csv\n",
            "[OK] Resolver loaded: 79 codes\n",
            "[OK] Wrote exports: /content/yates_ancestor_register.csv and /content/yates_ancestor_register.xlsx\n",
            "[OK] Wrote partial: partials/match_count.htm\n",
            "[OK] Wrote partial: partials/lineage_count.htm\n",
            "[OK] Wrote partial: partials/cousin_list_print.htm\n",
            "[OK] Saved canonical render: /content/yates_ancestor_register.htm\n",
            "[OK] Saved: /content/partials/work_plus.htm (partials clone)\n",
            "[PUT]  yates_ancestor_register.htm -> partials/yates_ancestor_register.htm\n",
            "[PUT]  yates_ancestor_register.htm -> partials/ons_yates_dna_register.htm\n",
            "[PUT]  yates_ancestor_register.htm -> partials/justdna.htm\n",
            "[PUT]  yates_ancestor_register.csv -> partials/yates_ancestor_register.csv\n",
            "[PUT]  yates_ancestor_register.xlsx -> partials/yates_ancestor_register.xlsx\n",
            "[OK] Uploaded CSV/XLSX -> /partials/\n",
            "[PUT]  /content/autosomal_count.txt -> autosomal_count.txt\n",
            "[PUT]  partials/match_count.htm -> partials/match_count.htm\n",
            "[PUT]  partials/lineage_count.htm -> partials/lineage_count.htm\n",
            "[PUT]  partials/cousin_list_print.htm -> partials/cousin_list_print.htm\n",
            "[PUT]  partials/work_plus.htm -> partials/work_plus.htm\n",
            "\n",
            "--- SIZE Verification (if supported) ---\n",
            "partials/yates_ancestor_register.htm : 20935\n",
            "partials/ons_yates_dna_register.htm : 20935\n",
            "partials/justdna.htm : 20935\n",
            "partials/yates_ancestor_register.csv : 2931\n",
            "partials/yates_ancestor_register.xlsx : 6694\n",
            "partials/match_count.htm : 6247\n",
            "partials/lineage_count.htm : 6417\n",
            "partials/cousin_list_print.htm : 3153\n",
            "partials/work_plus.htm : 20935\n",
            "\n",
            "--- Open URLs ---\n",
            "Canonical (Find target):          https://yates.one-name.net/partials/yates_ancestor_register.htm\n",
            "Legacy clone (same content):      https://yates.one-name.net/partials/ons_yates_dna_register.htm\n",
            "JUSTDNA simple alias:             https://yates.one-name.net/partials/justdna.htm\n",
            "Trees page:                       https://yates.one-name.net/partials/just-trees.htm\n",
            "Match Count:                      https://yates.one-name.net/partials/match_count.htm\n",
            "Lineage Count:                    https://yates.one-name.net/partials/lineage_count.htm\n",
            "Cousin List (Printable):          https://yates.one-name.net/partials/cousin_list_print.htm\n",
            "Work+ clone:                      https://yates.one-name.net/partials/work_plus.htm\n",
            "\n",
            "If anything looks cached, hard-refresh (Ctrl/Cmd+Shift+R) or append ?v=1 once.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 3"
      ],
      "metadata": {
        "id": "INiJljOS1kRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/6] RULES + IMPORTS + SECRETS ==============================================\n",
        "# RON RULES — QUICK CODE CARD (v2025.11.05-AncReg-Exports+Partials-JustTrees-NavDNA)\n",
        "# 1) EXECUTION: Complete & runnable in Colab; ISO-8859-15 (ASCII-only in source).\n",
        "# 2) PUNCTUATION IN STRINGS: Use HTML entities (&rsquo; &ldquo; &rdquo; &mdash; &rarr;).\n",
        "# 3) CONTENT: Deliver full runnable code (no snippets). No fabrication or inference.\n",
        "# 4) Python code (inline, executable, full COLAB Cell paste-ready section); ISO-8859-15 (ASCII-only in source).\n",
        "# 5) HTML: XHTML 1.0 Transitional style acceptable; avoid HTML5-only tags if not needed.\n",
        "# 6) INTEGRITY: Work in CUT-ready sections only; exactly five # lines after each section.\n",
        "\n",
        "# Core imports\n",
        "import os, re, socket, posixpath, traceback\n",
        "import pandas as pd\n",
        "import html as _html\n",
        "\n",
        "# Time imports (fix for ZoneInfo)\n",
        "from datetime import datetime\n",
        "try:\n",
        "    from zoneinfo import ZoneInfo  # Python 3.9+\n",
        "except Exception:\n",
        "    ZoneInfo = None\n",
        "\n",
        "# FTPS\n",
        "from ftplib import FTP_TLS\n",
        "# ====== CUT STOP  [1/6] RULES + IMPORTS + SECRETS ===============================================\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "\n",
        "\n",
        "\n",
        "# ====== CUT START [2/6] SECRETS + LOAD DATA + COUNTS + PATHS ===================================\n",
        "# --- Securely load secrets (Colab or env) ---\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ['FTP_HOST'] = userdata.get('FTP_HOST')\n",
        "    os.environ['FTP_USER'] = userdata.get('FTP_USER')\n",
        "    os.environ['FTP_PASS'] = userdata.get('FTP_PASS')\n",
        "    try:  os.environ['FTP_PORT'] = userdata.get('FTP_PORT')\n",
        "    except Exception: os.environ.setdefault('FTP_PORT', '21')\n",
        "    try:  os.environ['FTP_DIR']  = userdata.get('FTP_DIR')\n",
        "    except Exception: os.environ.setdefault('FTP_DIR', '')\n",
        "except Exception:\n",
        "    os.environ.setdefault('FTP_HOST', '')\n",
        "    os.environ.setdefault('FTP_USER', '')\n",
        "    os.environ.setdefault('FTP_PASS', '')\n",
        "    os.environ.setdefault('FTP_PORT', '21')\n",
        "    os.environ.setdefault('FTP_DIR', '')\n",
        "\n",
        "FTP_DIR  = os.environ.get('FTP_DIR', '').strip().strip('/')\n",
        "COUNT_PUBLIC_URL = (\"/%s/%s\" % (FTP_DIR, \"autosomal_count.txt\")) if FTP_DIR else \"/autosomal_count.txt\"\n",
        "\n",
        "# Inputs\n",
        "INPUT_CSV   = \"final_combined_df_with_value_labels.csv\"\n",
        "\n",
        "# OUTPUT html filename stays just-trees.htm\n",
        "OUTPUT_NAME = \"just-trees.htm\"\n",
        "\n",
        "# Button target (new nav button)\n",
        "DNA_REGISTER_ABS = \"https://yates.one-name.net/partials/justdna.htm\"\n",
        "\n",
        "# Export names for CSV/XLSX (mirror visible table); served from /partials/\n",
        "EXPORT_BASE = \"yates_ancestor_register\"\n",
        "LOCAL_CSV   = EXPORT_BASE + \".csv\"\n",
        "LOCAL_XLSX  = EXPORT_BASE + \".xlsx\"\n",
        "REMOTE_CSV  = posixpath.join(\"partials\", LOCAL_CSV)\n",
        "REMOTE_XLSX = posixpath.join(\"partials\", LOCAL_XLSX)\n",
        "\n",
        "# Upload the HTML itself into /partials/ using the OUTPUT_NAME\n",
        "REMOTE_HTML = posixpath.join(\"partials\", OUTPUT_NAME)\n",
        "\n",
        "# Load CSV (robust encodings)\n",
        "df = None\n",
        "_last_err = None\n",
        "for enc in (\"utf-8-sig\",\"utf-8\",\"cp1252\",\"iso-8859-15\",\"latin1\"):\n",
        "    try:\n",
        "        df = pd.read_csv(INPUT_CSV, dtype=str, keep_default_na=False, encoding=enc)\n",
        "        break\n",
        "    except Exception as e:\n",
        "        _last_err = e\n",
        "        df = None\n",
        "if df is None:\n",
        "    raise SystemExit(\"[ERROR] Unable to read CSV: %s (%r)\" % (INPUT_CSV, _last_err))\n",
        "print(\"[OK] Loaded CSV:\", INPUT_CSV, \"rows=%d, cols=%d\" % (len(df), len(df.columns)))\n",
        "\n",
        "# Normalize haplogroup column presence\n",
        "if 'haplogroup' not in df.columns:\n",
        "    df['haplogroup'] = ''\n",
        "else:\n",
        "    df['haplogroup'] = df['haplogroup'].fillna('')\n",
        "\n",
        "# Read autosomal count locally if present (fallback display only)\n",
        "autosomal_count = None\n",
        "try:\n",
        "    with open(\"autosomal_count.txt\", \"r\") as f:\n",
        "        autosomal_count = int(re.findall(r\"(\\d+)\", f.read() or \"\")[0])\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Optional delta vs previous run\n",
        "prev_count, additional_str = None, \"\"\n",
        "if os.path.exists(\"autosomal_count_prev.txt\"):\n",
        "    try:\n",
        "        with open(\"autosomal_count_prev.txt\", \"r\") as f:\n",
        "            prev_count = int(re.findall(r\"(\\d+)\", f.read() or \"\")[0])\n",
        "        if autosomal_count is not None and prev_count is not None:\n",
        "            diff = autosomal_count - prev_count\n",
        "            if diff != 0:\n",
        "                additional_str = \" (+%d since last run)\" % diff\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# Human-readable fallback timestamp (JS will stamp dynamically at runtime)\n",
        "try:\n",
        "    _tz = ZoneInfo(\"America/New_York\") if ZoneInfo else datetime.now().astimezone().tzinfo\n",
        "except Exception:\n",
        "    _tz = datetime.now().astimezone().tzinfo\n",
        "now = datetime.now(_tz)\n",
        "updated_fallback = now.strftime(\"%Y-%m-%d %H:%M\")\n",
        "# ====== CUT STOP  [2/6] SECRETS + LOAD DATA + COUNTS + PATHS ====================================\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "\n",
        "\n",
        "\n",
        "# ====== CUT START [3/6] MAP COLUMN B (masked code) -> COLUMN C (unmasked name) =================\n",
        "# Column letters in MAIN df:\n",
        "#   A = ID#\n",
        "#   B = match to (masked)\n",
        "#   C = Unmasked Name (output)\n",
        "\n",
        "A_IDX = 0\n",
        "B_IDX = 1\n",
        "C_IDX = 2\n",
        "\n",
        "def _norm_code(s):\n",
        "    t = str(s or \"\").strip()\n",
        "    if (t.startswith('\"') and t.endswith('\"')) or (t.startswith(\"'\") and t.endswith(\"'\")):\n",
        "        t = t[1:-1]\n",
        "    t = t.replace(\"\\u00a0\", \" \").strip()\n",
        "    t = re.sub(r\"\\s{2,}\", \" \", t)\n",
        "    return t.lower()\n",
        "\n",
        "# Resolver lives on server under /partials/\n",
        "REMOTE_PATH = \"partials/match_to_unmasked.csv\"\n",
        "LOCAL_PATH  = \"match_to_unmasked.csv\"\n",
        "\n",
        "# Pull resolver if not present\n",
        "if not os.path.exists(LOCAL_PATH):\n",
        "    print(\"Pulling resolver CSV from server...\")\n",
        "    with FTP_TLS(timeout=30) as ftps:\n",
        "        ftps.connect(os.environ.get(\"FTP_HOST\",\"\"), int(os.environ.get(\"FTP_PORT\",\"21\")))\n",
        "        ftps.login(os.environ.get(\"FTP_USER\",\"\"), os.environ.get(\"FTP_PASS\",\"\"))\n",
        "        try: ftps.prot_p()\n",
        "        except Exception: pass\n",
        "        try: ftps.set_pasv(True)\n",
        "        except Exception: pass\n",
        "        if FTP_DIR:\n",
        "            for p in FTP_DIR.split(\"/\"):\n",
        "                if not p: continue\n",
        "                try: ftps.cwd(p)\n",
        "                except Exception:\n",
        "                    try: ftps.mkd(p)\n",
        "                    except Exception: pass\n",
        "                    ftps.cwd(p)\n",
        "        try: ftps.cwd(\"partials\")\n",
        "        except Exception: pass\n",
        "        with open(LOCAL_PATH, \"wb\") as f:\n",
        "            ftps.retrbinary(\"RETR match_to_unmasked.csv\", f.write)\n",
        "    print(\"Resolver saved:\", os.path.abspath(LOCAL_PATH))\n",
        "else:\n",
        "    print(\"Using cached resolver:\", os.path.abspath(LOCAL_PATH))\n",
        "\n",
        "def _load_resolver(path):\n",
        "    last_err = None\n",
        "    m = None\n",
        "    for enc in (\"utf-8-sig\",\"iso-8859-15\",\"utf-8\",\"cp1252\",\"latin1\"):\n",
        "        try:\n",
        "            m = pd.read_csv(path, dtype=str, keep_default_na=False, encoding=enc)\n",
        "            break\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            m = None\n",
        "    if m is None:\n",
        "        raise RuntimeError(\"Unable to read resolver CSV: %s (%r)\" % (path, last_err))\n",
        "    cols = {c.lower(): c for c in m.columns}\n",
        "    if \"code\" not in cols or \"unmasked\" not in cols:\n",
        "        raise ValueError(\"Resolver CSV must have columns: code, unmasked\")\n",
        "    m = m[[cols[\"code\"], cols[\"unmasked\"]]].copy()\n",
        "    m[\"__key__\"] = m[cols[\"code\"]].map(_norm_code)\n",
        "    m[\"__val__\"] = m[cols[\"unmasked\"]].astype(str)\n",
        "    m = m.drop_duplicates(subset=\"__key__\", keep=\"first\")\n",
        "    return dict(zip(m[\"__key__\"], m[\"__val__\"]))\n",
        "\n",
        "resolver_map = _load_resolver(LOCAL_PATH)\n",
        "\n",
        "if df.shape[1] < 3:\n",
        "    raise ValueError(\"Main df must have at least 3 columns: A(ID#), B(match to), C(unmasked).\")\n",
        "\n",
        "masked_raw = df.iloc[:, B_IDX].astype(str)\n",
        "masked_key = masked_raw.map(_norm_code)\n",
        "resolved   = masked_key.map(resolver_map)\n",
        "\n",
        "df.iloc[:, C_IDX] = resolved.fillna(\"\")\n",
        "\n",
        "mapped = int(resolved.notna().sum())\n",
        "total  = len(df)\n",
        "print(\"[OK] Column B -> C mapping:\", mapped, \"/\", total, \"unmatched:\", total - mapped)\n",
        "# ====== CUT STOP  [3/6] MAP COLUMN B (masked code) -> COLUMN C (unmasked name) =================\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "\n",
        "\n",
        "\n",
        "# ====== CUT START [4/6] XHTML TEMPLATE + TABLE + DOWNLOAD LINKS ================================\n",
        "_BTN_BG   = \"#5b79b8\"\n",
        "_BTN_BG_H = \"#4668aa\"\n",
        "_TH_BG    = \"#e3eaf8\"\n",
        "_LINK     = \"#154b8b\"\n",
        "\n",
        "# Fallback number text for initial render; JS will overwrite with live values\n",
        "auto_text = \"Unknown\" if autosomal_count is None else str(autosomal_count)\n",
        "\n",
        "# Download links block points to /partials/{csv,xlsx}\n",
        "DOWNLOADS_BLOCK = (\n",
        "    \"<p style=\\\"text-align:center; margin:4px 0 10px 0; font-size:13px;\\\">\"\n",
        "    \"Download: \"\n",
        "    \"<a href=\\\"/partials/%s\\\">CSV</a> | \"\n",
        "    \"<a href=\\\"/partials/%s\\\">Excel</a>\"\n",
        "    \"</p>\" % (_html.escape(LOCAL_CSV), _html.escape(LOCAL_XLSX))\n",
        ")\n",
        "\n",
        "full_html_template = \"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "<title>Ancestor Register</title>\n",
        "<style type=\"text/css\">\n",
        "  html { scroll-behavior: smooth; }\n",
        "  body { margin:0; padding:0; font-family: \"Times New Roman\", Georgia, serif; background:#ffffff; color:#222; font-size:14px; }\n",
        "  a { color:%(LINK)s; text-decoration:none; } a:hover { text-decoration:underline; }\n",
        "\n",
        "  .intro { padding:20px; text-align:center; }\n",
        "  .intro h2 { margin:0 0 6px 0; font-size:24px; line-height:1.2; }\n",
        "  .meta { font-size:12px; color:#555; margin:4px 0 8px 0; display:inline-block; }\n",
        "\n",
        "  .toolbar { margin:6px auto 12px auto; display:flex; flex-wrap:wrap; gap:6px; justify-content:center; }\n",
        "  .btn { display:inline-block; border:1px solid %(BTN_BG)s; background:%(BTN_BG)s; color:#fff;\n",
        "         padding:4px 9px; border-radius:6px; font-size:13px; line-height:1.2; text-decoration:none;\n",
        "         cursor:pointer; user-select:none; transition:background 0.2s, transform 0.1s; }\n",
        "  .btn:hover { background:%(BTN_BG_H)s; transform:translateY(-1px); }\n",
        "  .btn.light { background:#ffffff; color:#111; border-color:#bbb; }\n",
        "\n",
        "  .output-table { max-height:75vh; overflow:auto; border:1px solid #ddd; margin:0 20px 24px 20px; }\n",
        "\n",
        "  table.sortable { width:100%%; border-collapse:collapse; min-width:720px; table-layout:auto; }\n",
        "  table.sortable th, table.sortable td { border:1px solid #ddd; padding:6px 8px; background:#ffffff; white-space:nowrap; }\n",
        "  table.sortable th { position:sticky; top:0; z-index:2; text-align:left; cursor:pointer; background:%(TH_BG)s; box-shadow:0 1px 0 #ccc; }\n",
        "  table.sortable tr#first-row td { border-top:2px solid #999 !important; }\n",
        "\n",
        "  #searchBox { padding:4px 8px; font-size:13px; border:1px solid #bbb; border-radius:6px; outline:none; }\n",
        "\n",
        "  .back-to-top { position:fixed; right:16px; bottom:16px; padding:6px 10px;\n",
        "                 border:1px solid %(BTN_BG)s; background:%(BTN_BG)s; color:#fff;\n",
        "                 border-radius:6px; font-size:12px; display:none; z-index:9999; cursor:pointer; }\n",
        "  .back-to-top:hover { background:%(BTN_BG_H)s; }\n",
        "\n",
        "  @media screen and (max-width: 820px) {\n",
        "    .intro { padding:14px; }\n",
        "    .output-table { margin:0 12px 20px 12px; }\n",
        "    .intro h2 { font-size:20px; }\n",
        "    table.sortable { min-width:560px; }\n",
        "  }\n",
        "</style>\n",
        "<script type=\"text/javascript\">\n",
        "//<![CDATA[\n",
        "// Basic helpers\n",
        "function _cellText(cell){\n",
        "  var t = (cell && (cell.textContent || cell.innerText) || '').replace(/\\\\s+/g,' ').replace(/^\\\\s+|\\\\s+$/g,'').toLowerCase();\n",
        "  return t;\n",
        "}\n",
        "function _asNumber(s){\n",
        "  var m = (s||'').replace(/[^0-9.\\\\-]/g,'');\n",
        "  if(m.length===0) return NaN;\n",
        "  var v = parseFloat(m);\n",
        "  return isNaN(v) ? NaN : v;\n",
        "}\n",
        "\n",
        "// Sorting\n",
        "function sortTableByColumn(tbl, colIndex, dirAsc){\n",
        "  if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "  var tb = tbl.tBodies[0];\n",
        "  var rows = Array.prototype.slice.call(tb.rows || []);\n",
        "  rows.sort(function(a,b){\n",
        "    var A = _cellText(a.cells[colIndex] || null);\n",
        "       var B = _cellText(b.cells[colIndex] || null);\n",
        "    var nA = _asNumber(A), nB = _asNumber(B);\n",
        "    if(!isNaN(nA) && !isNaN(nB)){ return dirAsc ? (nA - nB) : (nB - nA); }\n",
        "    if(A < B) return dirAsc ? -1 : 1;\n",
        "    if(A > B) return dirAsc ?  1 : -1;\n",
        "    return 0;\n",
        "  });\n",
        "  var frag = document.createDocumentFragment();\n",
        "  for(var i=0;i<rows.length;i++){ frag.appendChild(rows[i]); }\n",
        "  tb.appendChild(frag);\n",
        "  updateShowingCount();\n",
        "}\n",
        "function bindHeaderSort(){\n",
        "  var tbl = document.getElementById('refactor-table');\n",
        "  if(!(tbl && tbl.tHead && tbl.tHead.rows.length)) return;\n",
        "  var ths = tbl.tHead.rows[0].cells || [];\n",
        "  for(var i=0;i<ths.length;i++){\n",
        "    (function(idx){\n",
        "      var th = ths[idx];\n",
        "      var dirAsc = true;\n",
        "      th.addEventListener('click', function(){\n",
        "        for(var j=0;j<ths.length;j++){ ths[j].innerHTML = ths[j].innerHTML.replace(/\\\\s+[\\\\u2191\\\\u2193]$/, ''); }\n",
        "        sortTableByColumn(tbl, idx, dirAsc);\n",
        "        th.innerHTML = th.innerHTML.replace(/\\\\s+[\\\\u2191\\\\u2193]$/, '') + (dirAsc ? ' \\\\u2191' : ' \\\\u2193');\n",
        "        dirAsc = !dirAsc;\n",
        "      }, false);\n",
        "    })(i);\n",
        "  }\n",
        "}\n",
        "\n",
        "// Filter + live showing count\n",
        "function filterTable(){\n",
        "  var q = (document.getElementById('searchBox').value || '').toLowerCase();\n",
        "  var tbl = document.getElementById('refactor-table');\n",
        "  if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "  var rows = tbl.tBodies[0].rows || [];\n",
        "  for(var i=0;i<rows.length;i++){\n",
        "    var cells = rows[i].cells, hit=false;\n",
        "    for(var j=0;j<cells.length;j++){\n",
        "      var txt = (cells[j].textContent || cells[j].innerText || '').toLowerCase();\n",
        "      if(txt.indexOf(q) > -1){ hit=true; break; }\n",
        "    }\n",
        "    rows[i].style.display = hit ? '' : 'none';\n",
        "  }\n",
        "  updateShowingCount();\n",
        "}\n",
        "function updateShowingCount(){\n",
        "  var el = document.getElementById('showing-count');\n",
        "  var tbl = document.getElementById('refactor-table');\n",
        "  if(!(el && tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "  var rows = tbl.tBodies[0].rows || [];\n",
        "  var vis = 0;\n",
        "  for(var i=0;i<rows.length;i++){ if(rows[i].style.display !== 'none') vis++; }\n",
        "  el.textContent = vis;\n",
        "}\n",
        "\n",
        "// Dynamic stamps\n",
        "function z(n){ return (n<10 ? '0' : '') + n; }\n",
        "function stampLastUpdated(){\n",
        "  var el = document.getElementById('last-updated'); if(!el) return;\n",
        "  var d  = new Date(document.lastModified || new Date());\n",
        "  var opts = {\n",
        "    year: 'numeric',\n",
        "    month: 'long',\n",
        "    day: 'numeric',\n",
        "    hour: '2-digit',\n",
        "    minute: '2-digit',\n",
        "    hour12: false\n",
        "  };\n",
        "  var formatted = d.toLocaleString('en-US', opts).replace(',', '');\n",
        "  el.innerHTML = formatted;\n",
        "}\n",
        "  // Date stamp: \"D Month YYYY\"\n",
        "  function stampLastUpdated(){\n",
        "    var el = document.getElementById('last-updated'); if(!el) return;\n",
        "    var d  = new Date(document.lastModified || new Date());\n",
        "    var months = ['January','February','March','April','May','June','July','August','September','October','November','December'];\n",
        "    el.innerHTML = d.getDate() + ' ' + months[d.getMonth()] + ' ' + d.getFullYear();\n",
        "  }\n",
        "\n",
        "function formatWithCommas(n){\n",
        "  try{ var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return ''; return x.toLocaleString('en-US'); }catch(e){ return String(n||''); }\n",
        "}\n",
        "function loadAutoCount(){\n",
        "  var el=document.getElementById('auto-count'); if(!el) return;\n",
        "  var url='{COUNT_URL}';\n",
        "  try{\n",
        "    var xhr=new XMLHttpRequest(); xhr.open('GET', url+(url.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true);\n",
        "    xhr.onreadystatechange=function(){ if(xhr.readyState===4){\n",
        "      if(xhr.status>=200&&xhr.status<300){\n",
        "        var m=(xhr.responseText||'').match(/(\\\\d+)/); var num=m?m[1]:'';\n",
        "        el.textContent = formatWithCommas(num) || '(unavailable)';\n",
        "      } else { el.textContent='(unavailable)'; }\n",
        "    }};\n",
        "    xhr.send(null);\n",
        "  }catch(e){ el.textContent='(unavailable)'; }\n",
        "}\n",
        "\n",
        "// Back-to-top\n",
        "function bindBackToTop(){\n",
        "  var btn = document.getElementById('back-to-top');\n",
        "  if(!btn) return;\n",
        "  function toggle(){ btn.style.display = (window.scrollY > 200) ? 'block' : 'none'; }\n",
        "  toggle(); window.addEventListener('scroll', toggle, {passive:true});\n",
        "  btn.addEventListener('click', function(){ window.scrollTo(0,0); }, false);\n",
        "}\n",
        "\n",
        "document.addEventListener('DOMContentLoaded', function(){\n",
        "  bindHeaderSort();\n",
        "  bindBackToTop();\n",
        "  stampLastUpdated();\n",
        "  loadAutoCount();\n",
        "  updateShowingCount();\n",
        "}, false);\n",
        "//]]>\n",
        "</script>\n",
        "</head>\n",
        "<body>\n",
        "  <div class=\"intro\">\n",
        "    <h2>Ancestor Register</h2>\n",
        "    <div class=\"meta\">\n",
        "      Last updated: <span id=\"last-updated\">%(UPDATED)s</span>\n",
        "      &nbsp;|&nbsp; Autosomal matches: <span id=\"auto-count\">%(AUTO)s</span>\n",
        "      &nbsp;|&nbsp; Showing: <span id=\"showing-count\">0</span>\n",
        "    </div>\n",
        "    %(DL)s\n",
        "    <div class=\"toolbar\">\n",
        "      <a class=\"btn\" href=\"%(DNA_ABS)s\" target=\"_blank\" rel=\"noopener\">DNA Register</a>\n",
        "      <input type=\"text\" id=\"searchBox\" class=\"btn light\" placeholder=\"Search this page&hellip;\" oninput=\"filterTable()\" />\n",
        "    </div>\n",
        "  </div>\n",
        "\n",
        "  <div class=\"output-table\" id=\"table-container\">\n",
        "    <!-- TABLE_PLACEHOLDER -->\n",
        "  </div>\n",
        "\n",
        "  <div class=\"back-to-top\" id=\"back-to-top\">&#9650; Top</div>\n",
        "</body>\n",
        "</html>\"\"\" % {\n",
        "    \"BTN_BG\": _BTN_BG, \"BTN_BG_H\": _BTN_BG_H, \"TH_BG\": _TH_BG, \"LINK\": _LINK,\n",
        "    \"UPDATED\": _html.escape(updated_fallback),\n",
        "    \"AUTO\": _html.escape(\"Unknown\" if autosomal_count is None else str(autosomal_count)),\n",
        "    \"DL\": DOWNLOADS_BLOCK,\n",
        "    \"DNA_ABS\": DNA_REGISTER_ABS\n",
        "}\n",
        "\n",
        "# Build table HTML and mark first row\n",
        "table_html = df.to_html(index=False, border=1, classes=\"sortable\", table_id=\"refactor-table\")\n",
        "table_html = table_html.replace(\"<tbody>\\n<tr>\", \"<tbody>\\n<tr id=\\\"first-row\\\">\", 1)\n",
        "\n",
        "# Inject table and JS count URL\n",
        "final_html = full_html_template.replace(\"<!-- TABLE_PLACEHOLDER -->\", table_html)\n",
        "final_html = final_html.replace(\"{COUNT_URL}\", COUNT_PUBLIC_URL)\n",
        "\n",
        "# Build export DataFrame mirroring the visible table order (use current df as-is)\n",
        "export_df = df.copy()\n",
        "\n",
        "# Save CSV (ISO-8859-15) and XLSX\n",
        "export_df.to_csv(LOCAL_CSV, index=False, encoding=\"iso-8859-15\")\n",
        "try:\n",
        "    export_df.to_excel(LOCAL_XLSX, index=False)\n",
        "except Exception:\n",
        "    with pd.ExcelWriter(LOCAL_XLSX) as _writer:\n",
        "        export_df.to_excel(_writer, index=False)\n",
        "print(\"[OK] Wrote exports:\", os.path.abspath(LOCAL_CSV), \"and\", os.path.abspath(LOCAL_XLSX))\n",
        "# ====== CUT STOP  [4/6] XHTML TEMPLATE + TABLE + DOWNLOAD LINKS ================================\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "\n",
        "\n",
        "\n",
        "# ====== CUT START [5/6] SAVE LOCALLY + FTP UPLOAD (HTML + CSV/XLSX -> /partials) ==============\n",
        "# Save locally (iso-8859-15 safe)\n",
        "try:\n",
        "    with open(OUTPUT_NAME, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(final_html)\n",
        "    print(\"[OK] Saved locally:\", OUTPUT_NAME)\n",
        "except Exception as e:\n",
        "    print(\"[ERROR] Saving local file failed:\", e)\n",
        "    traceback.print_exc()\n",
        "\n",
        "# Upload if credentials exist\n",
        "ftp_host = os.environ.get('FTP_HOST')\n",
        "ftp_user = os.environ.get('FTP_USER')\n",
        "ftp_pass = os.environ.get('FTP_PASS')\n",
        "ftp_port = os.environ.get('FTP_PORT', '21')\n",
        "ftp_dir  = os.environ.get('FTP_DIR', '')\n",
        "\n",
        "def _ftps_ensure_dir(ftps, name):\n",
        "    if not name: return\n",
        "    for p in [p for p in name.split('/') if p]:\n",
        "        try:\n",
        "            ftps.cwd(p)\n",
        "        except Exception:\n",
        "            try:\n",
        "                ftps.mkd(p)\n",
        "            except Exception:\n",
        "                pass\n",
        "            ftps.cwd(p)\n",
        "\n",
        "if all([ftp_host, ftp_user, ftp_pass]):\n",
        "    print(\"[INFO] Attempting FTP upload...\")\n",
        "    try:\n",
        "        socket.setdefaulttimeout(30)\n",
        "        with FTP_TLS(timeout=30) as ftps:\n",
        "            ftps.connect(ftp_host, int(ftp_port))\n",
        "            ftps.login(ftp_user, ftp_pass)\n",
        "            try: ftps.prot_p()\n",
        "            except Exception: pass\n",
        "            try: ftps.set_pasv(True)\n",
        "            except Exception: pass\n",
        "\n",
        "            # Navigate to base dir\n",
        "            _ftps_ensure_dir(ftps, ftp_dir.strip('/'))\n",
        "\n",
        "            # Ensure /partials exists then upload HTML + CSV/XLSX there\n",
        "            try:\n",
        "                _ftps_ensure_dir(ftps, \"partials\")\n",
        "\n",
        "                # Upload HTML into /partials/ as just-trees.htm\n",
        "                with open(OUTPUT_NAME, \"rb\") as fh:\n",
        "                    ftps.storbinary(\"STOR \" + os.path.basename(REMOTE_HTML), fh)\n",
        "                print(\"[OK] Uploaded HTML to /partials/:\", OUTPUT_NAME, \"->\", os.path.basename(REMOTE_HTML))\n",
        "\n",
        "                # Upload CSV/XLSX into /partials/\n",
        "                with open(LOCAL_CSV, \"rb\") as fh:\n",
        "                    ftps.storbinary(\"STOR \" + os.path.basename(REMOTE_CSV), fh)\n",
        "                with open(LOCAL_XLSX, \"rb\") as fh:\n",
        "                    ftps.storbinary(\"STOR \" + os.path.basename(REMOTE_XLSX), fh)\n",
        "                print(\"[OK] Uploaded exports to /partials/:\", LOCAL_CSV, LOCAL_XLSX)\n",
        "\n",
        "                print(\"Open URL: https://yates.one-name.net/partials/just-trees.htm\")\n",
        "            except Exception as e:\n",
        "                print(\"[ERROR] Upload to /partials/ failed:\", e)\n",
        "\n",
        "            print(\"[OK] Uploads complete.\")\n",
        "    except Exception as e:\n",
        "        print(\"[ERROR] FTP session failed:\", e)\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"[INFO] Skipping FTP upload: missing FTP credentials.\")\n",
        "# ====== CUT STOP  [5/6] SAVE LOCALLY + FTP UPLOAD (HTML + CSV/XLSX -> /partials) ==============\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "\n",
        "\n",
        "\n",
        "# ====== CUT START [6/6] PERSIST COUNT + DONE ====================================================\n",
        "if autosomal_count is not None:\n",
        "    try:\n",
        "        with open(\"autosomal_count_prev.txt\", \"w\") as f:\n",
        "            f.write(str(autosomal_count))\n",
        "        print(\"[OK] Persisted autosomal_count_prev.txt\")\n",
        "    except Exception as e:\n",
        "        print(\"[WARN] Could not persist autosomal count:\", e)\n",
        "\n",
        "print(\"\\n--- Ancestor Register Build + Exports Complete (HTML now at /partials/just-trees.htm; nav button -> justdna.htm) ---\")\n",
        "# ====== CUT STOP  [6/6] PERSIST COUNT + DONE ====================================================\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySrJa6SLVEz0",
        "outputId": "f50dde55-69b3-4194-b1d9-6af4e6d84286"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Loaded CSV: final_combined_df_with_value_labels.csv rows=7, cols=6\n",
            "Using cached resolver: /content/match_to_unmasked.csv\n",
            "[OK] Column B -> C mapping: 7 / 7 unmatched: 0\n",
            "[OK] Wrote exports: /content/yates_ancestor_register.csv and /content/yates_ancestor_register.xlsx\n",
            "[OK] Saved locally: just-trees.htm\n",
            "[INFO] Attempting FTP upload...\n",
            "[OK] Uploaded HTML to /partials/: just-trees.htm -> just-trees.htm\n",
            "[OK] Uploaded exports to /partials/: yates_ancestor_register.csv yates_ancestor_register.xlsx\n",
            "Open URL: https://yates.one-name.net/partials/just-trees.htm\n",
            "[OK] Uploads complete.\n",
            "[OK] Persisted autosomal_count_prev.txt\n",
            "\n",
            "--- Ancestor Register Build + Exports Complete (HTML now at /partials/just-trees.htm; nav button -> justdna.htm) ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Cell 1"
      ],
      "metadata": {
        "id": "z7m2W6TOv1Xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] CELL 1 — GEDCOM -> final_combined_df_with_value_labels.csv + working HTML ======\n",
        "# RON RULES — QUICK CODE CARD (v2025.11.05-Cell1-NoValueScoring)\n",
        "# - Complete & runnable in Colab; ISO-8859-15 (ASCII-only in source).\n",
        "# - Punctuation in strings use HTML entities (&rsquo; &ldquo; &rdquo; &mdash; &rarr;).\n",
        "# - Python code (inline, executable, full COLAB Cell paste-ready section).\n",
        "# - XHTML 1.0 Transitional; Times New Roman body; absolute links to /partials/.\n",
        "# - Outputs uploaded to /partials/: CSV + HTML; autosomal_count.txt stays local (Cell 2 handles upload).\n",
        "\n",
        "import os, re, glob, logging, functools, socket, posixpath, traceback\n",
        "from datetime import datetime\n",
        "from collections import defaultdict, Counter\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from ftplib import FTP_TLS\n",
        "from IPython.display import display, Javascript\n",
        "from string import Template\n",
        "\n",
        "# ====== LOGGING ======\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ====== SECRETS + CONFIG + FTP HELPERS ======\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ['FTP_HOST'] = userdata.get('FTP_HOST')\n",
        "    os.environ['FTP_USER'] = userdata.get('FTP_USER')\n",
        "    os.environ['FTP_PASS'] = userdata.get('FTP_PASS')\n",
        "    try:  os.environ['FTP_PORT'] = userdata.get('FTP_PORT')\n",
        "    except Exception: os.environ.setdefault('FTP_PORT', '21')\n",
        "    try:  os.environ['FTP_DIR']  = userdata.get('FTP_DIR')\n",
        "    except Exception: os.environ.setdefault('FTP_DIR', '')\n",
        "except Exception:\n",
        "    os.environ.setdefault('FTP_HOST', '')\n",
        "    os.environ.setdefault('FTP_USER', '')\n",
        "    os.environ.setdefault('FTP_PASS', '')\n",
        "    os.environ.setdefault('FTP_PORT', '21')\n",
        "    os.environ.setdefault('FTP_DIR', '')\n",
        "\n",
        "FTP_HOST = os.environ.get('FTP_HOST','')\n",
        "FTP_USER = os.environ.get('FTP_USER','')\n",
        "FTP_PASS = os.environ.get('FTP_PASS','')\n",
        "FTP_PORT = int(os.environ.get('FTP_PORT','21'))\n",
        "FTP_DIR  = os.environ.get('FTP_DIR','').strip().strip('/')\n",
        "\n",
        "def _ftps_connect():\n",
        "    socket.setdefaulttimeout(30)\n",
        "    ftps = FTP_TLS(timeout=30)\n",
        "    ftps.connect(FTP_HOST, FTP_PORT)\n",
        "    ftps.login(FTP_USER, FTP_PASS)\n",
        "    try: ftps.prot_p()\n",
        "    except Exception: pass\n",
        "    try: ftps.set_pasv(True)\n",
        "    except Exception: pass\n",
        "    if FTP_DIR:\n",
        "        for p in [p for p in FTP_DIR.split('/') if p]:\n",
        "            try:\n",
        "                ftps.cwd(p)\n",
        "            except Exception:\n",
        "                try: ftps.mkd(p)\n",
        "                except Exception: pass\n",
        "                ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "def _ftps_ensure_dir(ftps, path):\n",
        "    if not path: return\n",
        "    for p in [p for p in path.split('/') if p]:\n",
        "        try:\n",
        "            ftps.cwd(p)\n",
        "        except Exception:\n",
        "            try: ftps.mkd(p)\n",
        "            except Exception: pass\n",
        "            ftps.cwd(p)\n",
        "\n",
        "def _ftps_upload(ftps, local_path, remote_name):\n",
        "    with open(local_path, 'rb') as fh:\n",
        "        ftps.storbinary(\"STOR \" + remote_name, fh)\n",
        "    print(f\"[OK] Uploaded: {local_path} -> {ftps.pwd().rstrip('/')}/{remote_name}\")\n",
        "\n",
        "# Output names (local + remote inside /partials/)\n",
        "CSV_OUT_LOCAL   = \"final_combined_df_with_value_labels.csv\"  # kept for compatibility with Cell 2\n",
        "HTML_OUT_LOCAL  = \"cell1_work_table.htm\"\n",
        "REMOTE_DIR      = \"partials\"\n",
        "REMOTE_CSV_NAME = os.path.basename(CSV_OUT_LOCAL)\n",
        "REMOTE_HTML_NAME= os.path.basename(HTML_OUT_LOCAL)\n",
        "\n",
        "# Absolute links used inside HTML\n",
        "ABS_CSV_URL  = f\"/{REMOTE_DIR}/{REMOTE_CSV_NAME}\"\n",
        "ABS_HOME_URL = \"/partials/ons_yates_dna_register.htm\"  # main register lives in /partials/\n",
        "\n",
        "# ====== CORE STRUCTURES (dataset, GEDCOM parse) ======\n",
        "anchor_gen1 = None\n",
        "visited_pairs = set()\n",
        "generation_table = []\n",
        "\n",
        "class GedcomDataset:\n",
        "    def __init__(self, gen_person):\n",
        "        self.gen_person = gen_person\n",
        "        self.extractable_detail = {}\n",
        "        self.anchor_gen1 = None\n",
        "    def add_extractable_detail(self, key, value):\n",
        "        self.extractable_detail[key] = value\n",
        "    def get_gen_person(self):\n",
        "        name = self.extractable_detail.get('NAME', '')\n",
        "        parts = name.split('/', 1)\n",
        "        first_name = parts[0].split(' ')[0]\n",
        "        last_name = parts[1].rstrip('/') if len(parts) > 1 else \"\"\n",
        "        self.anchor_gen1 = last_name.replace(\" \", \"\") + first_name.replace(\" \", \"\")\n",
        "        global anchor_gen1\n",
        "        anchor_gen1 = self.anchor_gen1\n",
        "        return self.gen_person.strip('@')\n",
        "    def get_extractable_NPFX(self):\n",
        "        return self.extractable_detail.get('NPFX', '')\n",
        "    def get_extractable_cm(self):\n",
        "        npfx_value = self.extractable_detail.get('NPFX','')\n",
        "        if '&' in npfx_value:\n",
        "            cm_value = npfx_value.split('&')[0].strip()\n",
        "        elif '**' in npfx_value:\n",
        "            cm_value = npfx_value.split('**')[0].strip()\n",
        "        else:\n",
        "            cm_value = npfx_value.strip()\n",
        "        try:\n",
        "            int(cm_value); return cm_value\n",
        "        except ValueError:\n",
        "            return ''\n",
        "    def get_extractable_sort(self):\n",
        "        npfx_value = self.extractable_detail.get('NPFX','')\n",
        "        if '&' in npfx_value:\n",
        "            sort_part = npfx_value.split('&')[1]\n",
        "            sort_value = sort_part.split('**')[0].strip() if '**' in sort_part else sort_part.strip()\n",
        "            return sort_value\n",
        "        return ''\n",
        "    def get_extractable_YDNA(self):\n",
        "        npfx_value = self.extractable_detail.get('NPFX','')\n",
        "        if '**' in npfx_value:\n",
        "            return npfx_value.split('**')[1].strip()\n",
        "        return ''\n",
        "    def get_extractable_FAMC(self):\n",
        "        return self.extractable_detail.get('FAMC','').strip('@')\n",
        "\n",
        "class Gedcom:\n",
        "    def __init__(self, file_name):\n",
        "        self.file_name = file_name\n",
        "        self.gedcom_datasets = []\n",
        "        self.filter_pool = []\n",
        "    def parse_gedcom(self):\n",
        "        with open(self.file_name, 'r', encoding='utf-8-sig') as f:\n",
        "            lines = f.readlines()\n",
        "        current_dataset = None\n",
        "        npfx_count = 0\n",
        "        ydna_count = 0\n",
        "        total_count = 0\n",
        "        for line in lines:\n",
        "            parts = line.strip().split(' ', 2)\n",
        "            level = int(parts[0]); tag = parts[1]; value = parts[2] if len(parts) > 2 else None\n",
        "            if level == 0 and tag.startswith('@') and tag.endswith('@') and value == 'INDI':\n",
        "                total_count += 1\n",
        "                current_dataset = GedcomDataset(tag)\n",
        "                self.gedcom_datasets.append(current_dataset)\n",
        "            elif current_dataset is not None:\n",
        "                if level == 1 and tag in ['NAME','FAMC']:\n",
        "                    current_dataset.add_extractable_detail(tag, value)\n",
        "                elif level == 2 and tag == 'NPFX':\n",
        "                    npfx_count += 1\n",
        "                    current_dataset.add_extractable_detail(tag, value)\n",
        "                    if '**' in value:\n",
        "                        ydna_count += 1\n",
        "        autosomal_count = npfx_count - ydna_count\n",
        "        print(f\"GEDCOM contained {total_count} total records\")\n",
        "        print(f\"Records tagged and filtered by NPFX: {npfx_count}\")\n",
        "        print(f\"Records with YDNA information: {ydna_count}\")\n",
        "        print(f\"Autosomal matches: {autosomal_count}\")\n",
        "        for ds in self.gedcom_datasets:\n",
        "            if ds.get_extractable_NPFX():\n",
        "                self.filter_pool.append(ds)\n",
        "        # Optional manual second-level filter\n",
        "        try:\n",
        "            df_filter = pd.read_excel('filtered_ids.xlsx')\n",
        "            manual_ids = set(df_filter['ID'])\n",
        "            self.filter_pool = [d for d in self.filter_pool if d.get_gen_person() in manual_ids]\n",
        "            print(f\"After manual filter, total records: {len(self.filter_pool)}\")\n",
        "            logger.info(f\"After manual filter, total records: {len(self.filter_pool)}\")\n",
        "        except FileNotFoundError:\n",
        "            logger.warning(\"filtered_ids.xlsx not found. Skipping second-level manual filter.\")\n",
        "        return autosomal_count\n",
        "\n",
        "def chunks(lst, n):\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i+n]\n",
        "\n",
        "def quick_extract_name(full_text):\n",
        "    name_marker = \"\\n1 NAME \"\n",
        "    idx = full_text.find(name_marker)\n",
        "    if idx == -1:\n",
        "        if full_text.startswith(\"1 NAME \"):\n",
        "            idx = 0\n",
        "        else:\n",
        "            return \"UnknownName\"\n",
        "    start = idx + len(name_marker)\n",
        "    end = full_text.find('\\n', start)\n",
        "    if end == -1: end = len(full_text)\n",
        "    name_line = full_text[start:end].strip()\n",
        "    if '/' not in name_line:\n",
        "        # Return full line if no surname delimiter, removing spaces\n",
        "        return name_line.replace(\" \", \"\")\n",
        "    first_name, last_name = name_line.split('/', 1)\n",
        "    last_name = last_name.replace(\"/\", \"\").strip()\n",
        "    # Return full names, removing spaces (NO TRUNCATION)\n",
        "    return last_name.replace(\" \", \"\") + first_name.replace(\" \", \"\")\n",
        "\n",
        "def find_parents(individual_id, generation, parents_map):\n",
        "    global visited_pairs, generation_table\n",
        "    if individual_id not in parents_map: return\n",
        "    father_id, mother_id = parents_map[individual_id]\n",
        "    if not father_id and not mother_id: return\n",
        "    pair = (father_id, mother_id)\n",
        "    if pair not in visited_pairs:\n",
        "        visited_pairs.add(pair)\n",
        "        generation_table.append((generation, pair))\n",
        "    if father_id: find_parents(father_id, generation+1, parents_map)\n",
        "    if mother_id: find_parents(mother_id, generation+1, parents_map)\n",
        "\n",
        "def find_distant_ancestors(individual_id, parents_map, path=None):\n",
        "    if path is None: path = []\n",
        "    path.append(individual_id)\n",
        "    if individual_id not in parents_map:\n",
        "        return [path]\n",
        "    father_id, mother_id = parents_map[individual_id]\n",
        "    if not father_id and not mother_id:\n",
        "        return [path]\n",
        "    paths = []\n",
        "    if father_id: paths.extend(find_distant_ancestors(father_id, parents_map, path[:]))\n",
        "    if mother_id: paths.extend(find_distant_ancestors(mother_id, parents_map, path[:]))\n",
        "    return paths if paths else [path]\n",
        "\n",
        "def filter_ancestral_line(winning_path_ids, generation_table_local, names_map):\n",
        "    matching_table = []\n",
        "    for generation, pair in generation_table_local:\n",
        "        id1, id2 = pair\n",
        "        if id1 in winning_path_ids or id2 in winning_path_ids:\n",
        "            matching_table.append((generation, pair))\n",
        "    matching_table.sort(key=lambda x: x[0])\n",
        "    lines = []\n",
        "    for gen, pair in matching_table:\n",
        "        name_pair = [names_map.get(pid, \"UnknownName\") for pid in pair]\n",
        "        lines.append(f\"{name_pair[0]}&{name_pair[1]}\")\n",
        "    lines.reverse()\n",
        "    return \"~~~\".join(lines)\n",
        "\n",
        "def process_record_wrapper(individual_id, gedcom_instance, parents_map, names_map):\n",
        "    global generation_table, visited_pairs, anchor_gen1\n",
        "    generation_table = []; visited_pairs = set()\n",
        "    find_parents(individual_id, 1, parents_map)\n",
        "    distant_paths = find_distant_ancestors(individual_id, parents_map)\n",
        "    best_score, best_path = None, None\n",
        "    for path in distant_paths:\n",
        "        name_path = [names_map.get(pid, \"UnknownName\") for pid in path]\n",
        "        score = sum((idx+1) for idx, nm in enumerate(name_path) if 'Yates' in nm)\n",
        "        if best_score is None or score > best_score:\n",
        "            best_score, best_path = score, path\n",
        "    best_path = best_path or []\n",
        "    best_path_cleaned = [pid for pid in best_path if pid != individual_id]\n",
        "    line_str = filter_ancestral_line(set(best_path_cleaned), generation_table, names_map)\n",
        "    cm_value = ''; sort_value=''; ydna_value=''\n",
        "    for ds in gedcom_instance.filter_pool:\n",
        "        if ds.get_gen_person() == individual_id:\n",
        "            cm_value = ds.get_extractable_cm()\n",
        "            sort_value = ds.get_extractable_sort()\n",
        "            ydna_value = ds.get_extractable_YDNA()\n",
        "            break\n",
        "    short_name = names_map.get(individual_id, \"UnknownName\")\n",
        "    # short_name populates the \"Name\" column\n",
        "    # sort_value populates the \"Match to\" column\n",
        "    return [individual_id, sort_value, short_name, cm_value, line_str, ydna_value]\n",
        "\n",
        "# ====== MAIN: BUILD DATAFRAME (No Value Scoring) ======\n",
        "def main():\n",
        "    files = glob.glob(\"*.ged\")\n",
        "    if not files:\n",
        "        print(\"No GEDCOM files found.\"); return False\n",
        "    print(\"Automatically selecting the first GEDCOM file.\")\n",
        "    gedcom_file_path = files[0]\n",
        "\n",
        "    ged = Gedcom(gedcom_file_path)\n",
        "    autosomal_count = ged.parse_gedcom()\n",
        "\n",
        "    with open(\"autosomal_count.txt\", \"w\") as f:\n",
        "        f.write(str(autosomal_count))\n",
        "\n",
        "    with open(gedcom_file_path, 'r', encoding='utf-8') as f:\n",
        "        raw_data = f.read()\n",
        "\n",
        "    blocks = raw_data.split('\\n0 ')\n",
        "    all_records = {}\n",
        "    for blk in blocks:\n",
        "        blk = blk.strip()\n",
        "        if not blk: continue\n",
        "        flend = blk.find('\\n'); flend = len(blk) if flend == -1 else flend\n",
        "        first_line = blk[:flend]\n",
        "        if '@' in first_line:\n",
        "            start = first_line.find('@') + 1\n",
        "            end = first_line.find('@', start)\n",
        "            rec_id = first_line[start:end].strip()\n",
        "            all_records[rec_id] = blk\n",
        "\n",
        "    parents_map, names_map, families = {}, {}, {}\n",
        "    for rec_id, txt in all_records.items():\n",
        "        if 'FAM' in txt[:50]:\n",
        "            father_idx = txt.find('1 HUSB @')\n",
        "            husb_id = txt[father_idx+len('1 HUSB @'):txt.find('@', father_idx+len('1 HUSB @'))] if father_idx != -1 else None\n",
        "            wife_idx = txt.find('1 WIFE @')\n",
        "            wife_id = txt[wife_idx+len('1 WIFE @'):txt.find('@', wife_idx+len('1 WIFE @'))] if wife_idx != -1 else None\n",
        "            kids = [ln.split('@')[1] for ln in txt.split('\\n') if ln.strip().startswith('1 CHIL @')]\n",
        "            families[rec_id] = (husb_id, wife_id, kids)\n",
        "    for fam_id, (f_id, m_id, k_list) in families.items():\n",
        "        for kid in k_list:\n",
        "            parents_map[kid] = (f_id, m_id)\n",
        "    for rec_id, txt in all_records.items():\n",
        "        names_map[rec_id] = quick_extract_name(\"\\n\" + txt)\n",
        "\n",
        "    individual_ids = [d.get_gen_person() for d in ged.filter_pool]\n",
        "    print(f\"Processing {len(individual_ids)} individuals with chunk-based parallel...\")\n",
        "\n",
        "    combined_rows = []\n",
        "    chunk_size = 50\n",
        "    max_workers = os.cpu_count() or 4\n",
        "    with ProcessPoolExecutor(max_workers=max_workers) as executor, tqdm(total=len(individual_ids), desc=\"Building Yates Lines (Stage 1)\") as pbar:\n",
        "        for chunk in chunks(individual_ids, chunk_size):\n",
        "            func = functools.partial(process_record_wrapper, gedcom_instance=ged, parents_map=parents_map, names_map=names_map)\n",
        "            results = list(executor.map(func, chunk))\n",
        "            combined_rows.extend(results)\n",
        "            pbar.update(len(chunk))\n",
        "\n",
        "    columns = [\"ID#\", \"Match to\", \"Name\", \"cM\", \"Yates DNA Ancestral Line\", \"haplogroup\"]\n",
        "    df = pd.DataFrame(combined_rows, columns=columns)\n",
        "    df.index += 1\n",
        "\n",
        "    # Trim the historical prefix if present\n",
        "    def remove_specific_prefix(row):\n",
        "        prefix = \"YatesJohn&SearchingStill~~~YatesWilliam&SearchingStill~~~YatesWilliam&SearchingStill~~~YatesEdmund&CornellMargaret~~~YatesRichard&AshendonJoan~~~YatesJohn&HydeAlice~~~YatesThomas&FauconerElizabeth~~~\"\n",
        "        if str(row[\"Yates DNA Ancestral Line\"]).startswith(prefix):\n",
        "            row[\"Yates DNA Ancestral Line\"] = row[\"Yates DNA Ancestral Line\"][len(prefix):]\n",
        "        return row\n",
        "    df = df.apply(remove_specific_prefix, axis=1)\n",
        "\n",
        "    # No Value/Range/Label computation; sort only by lineage for stability\n",
        "    df.sort_values(by=[\"Yates DNA Ancestral Line\"], inplace=True)\n",
        "\n",
        "    # Export CSV (UTF-8-SIG for downstream safety; filename kept for Cell 2 compatibility)\n",
        "    df.to_csv(CSV_OUT_LOCAL, index=False, encoding=\"utf-8-sig\")\n",
        "    logger.info(\"Exported CSV -> %s\", CSV_OUT_LOCAL)\n",
        "\n",
        "    # Simple working HTML (no Value columns)\n",
        "    # MODIFIED: Changed \"Match to\" to \"Name\" to show the full name instead of the sort key\n",
        "    final_cols = [\"ID#\", \"cM\", \"haplogroup\", \"Name\", \"Yates DNA Ancestral Line\"]\n",
        "    table_html = df.to_html(index=False, columns=final_cols, escape=False, border=1)\n",
        "\n",
        "    page_tpl = Template(\"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "<title>Cell 1 Working Table</title>\n",
        "<style type=\"text/css\">\n",
        "  html { scroll-behavior: smooth; }\n",
        "  /* MODIFIED: Removed explicit Times New Roman font-family to allow site-wide sans-serif CSS */\n",
        "  body { background:#ffffff; color:#222; margin:0; padding:20px; }\n",
        "  h1 { margin:0 0 8px 0; font-size:24px; line-height:1.2; text-align:center; }\n",
        "  .meta { text-align:center; font-size:12px; color:#555; margin:2px 0 12px 0; }\n",
        "  .downloads { text-align:center; margin:4px 0 12px 0; font-size:13px; }\n",
        "  a { color:#154b8b; text-decoration:none; } a:hover { text-decoration:underline; }\n",
        "  table { width:100%; border-collapse:collapse; }\n",
        "  th, td { border:1px solid #333; padding: 6px 8px; vertical-align:top; }\n",
        "  th { background:#e3eaf8; text-align:left; }\n",
        "  td:nth-child(5) { text-align:left; white-space:normal; }\n",
        "</style>\n",
        "<script type=\"text/javascript\">\n",
        "//<![CDATA[\n",
        "(function(){ function z(n){return (n<10?'0':'')+n;}\n",
        "document.addEventListener('DOMContentLoaded', function(){\n",
        "  var el = document.getElementById('last-updated');\n",
        "  if(el){ var d=new Date(document.lastModified||new Date());\n",
        "    el.innerHTML = d.getFullYear()+'-'+z(d.getMonth()+1)+'-'+z(d.getDate())+' '+z(d.getHours())+':'+z(d.getMinutes()); }\n",
        "}, false); })();\n",
        "//]]>\n",
        "</script>\n",
        "</head>\n",
        "<body>\n",
        "  <h1>Cell 1 Working Table</h1>\n",
        "  <div class=\"meta\">\n",
        "    <a href=\"$HOME\" target=\"_blank\" rel=\"noopener\">Home</a>\n",
        "    &nbsp;|&nbsp; Last updated: <span id=\"last-updated\"></span>\n",
        "    &nbsp;|&nbsp; Download: <a href=\"$CSV\">$CSV</a>\n",
        "  </div>\n",
        "  <div class=\"downloads\"><a href=\"$CSV\">/partials/$CSV_NAME</a></div>\n",
        "  $TABLE\n",
        "</body>\n",
        "</html>\"\"\")\n",
        "\n",
        "    page = page_tpl.safe_substitute(\n",
        "        HOME=ABS_HOME_URL,\n",
        "        CSV=ABS_CSV_URL,\n",
        "        CSV_NAME=os.path.basename(ABS_CSV_URL),\n",
        "        TABLE=table_html\n",
        "    )\n",
        "\n",
        "    with open(HTML_OUT_LOCAL, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(page)\n",
        "    logger.info(\"Exported HTML -> %s\", HTML_OUT_LOCAL)\n",
        "\n",
        "    return True\n",
        "\n",
        "ok = main()\n",
        "\n",
        "# ====== UPLOAD ALL ARTIFACTS TO /partials/ ======\n",
        "if ok and all([FTP_HOST, FTP_USER, FTP_PASS]):\n",
        "    print(\"[INFO] Uploading artifacts to /partials/ ...\")\n",
        "    try:\n",
        "        ftps = _ftps_connect()\n",
        "        _ftps_ensure_dir(ftps, \"partials\")\n",
        "        try:\n",
        "            _ftps_upload(ftps, CSV_OUT_LOCAL, os.path.basename(CSV_OUT_LOCAL))\n",
        "        except Exception as e:\n",
        "            print(\"[ERROR] CSV upload failed:\", e)\n",
        "        try:\n",
        "            _ftps_upload(ftps, HTML_OUT_LOCAL, os.path.basename(HTML_OUT_LOCAL))\n",
        "        except Exception as e:\n",
        "            print(\"[ERROR] HTML upload failed:\", e)\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "        print(\"[OK] Uploads complete to /partials/\")\n",
        "    except Exception as e:\n",
        "        print(\"[ERROR] FTP session failed:\", e)\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"[INFO] Skipping FTP upload (missing creds or build failed).\")\n",
        "\n",
        "# ====== DONE ======\n",
        "try:\n",
        "    display(Javascript('alert(\"\\\\u2705 Cell 1 build complete (no value scoring): CSV + HTML uploaded to /partials/\");'))\n",
        "except Exception:\n",
        "    pass\n",
        "print(\"\\n--- Cell 1 Complete (no value scoring): artifacts at /partials/ ---\")\n",
        "# ====== CUT STOP [1/1] CELL 1 ==================================================================="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "5k47g9ozwC1r",
        "outputId": "5f0b66f9-dbee-4bec-8dc2-5db1edc98147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically selecting the first GEDCOM file.\n",
            "GEDCOM contained 62312 total records\n",
            "Records tagged and filtered by NPFX: 1572\n",
            "Records with YDNA information: 0\n",
            "Autosomal matches: 1572\n",
            "After manual filter, total records: 7\n",
            "Processing 7 individuals with chunk-based parallel...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Yates Lines (Stage 1): 100%|██████████| 7/7 [00:03<00:00,  2.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Uploading artifacts to /partials/ ...\n",
            "[OK] Uploaded: final_combined_df_with_value_labels.csv -> /partials/final_combined_df_with_value_labels.csv\n",
            "[OK] Uploaded: cell1_work_table.htm -> /partials/cell1_work_table.htm\n",
            "[OK] Uploads complete to /partials/\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "alert(\"\\u2705 Cell 1 build complete (no value scoring): CSV + HTML uploaded to /partials/\");"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Cell 1 Complete (no value scoring): artifacts at /partials/ ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] CELL 2 — Build + Publish DNA Register (Responsive widths; external CSS handles typography) ======\n",
        "# RON RULES — QUICK CODE CARD (v2025.11.08-Cell2-Responsive-FIXED-NAMES-ASCII)\n",
        "# - Complete & runnable in Colab; ISO-8859-15 (ASCII-only in source).\n",
        "# - XHTML 1.0 Transitional; explicit prints; no fabrication.\n",
        "# - Typography is controlled ONLY by /partials/dna_tree_styles.css (no inline font-family anywhere).\n",
        "# - Publishes SAME HTML to:\n",
        "#       /partials/yates_ancestor_register.htm     (canonical)\n",
        "#       /partials/ons_yates_dna_register.htm     (legacy clone)\n",
        "#       /partials/justdna.htm                     (JUSTDNA alias)\n",
        "\n",
        "import os, re, posixpath, socket, traceback, urllib.parse as _u\n",
        "from ftplib import FTP_TLS\n",
        "import pandas as pd\n",
        "import html as _html\n",
        "from string import Template\n",
        "\n",
        "# ---------- 0) Secrets ----------\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ['FTP_HOST'] = userdata.get('FTP_HOST')\n",
        "    os.environ['FTP_USER'] = userdata.get('FTP_USER')\n",
        "    os.environ['FTP_PASS'] = userdata.get('FTP_PASS')\n",
        "    try: os.environ['FTP_DIR'] = userdata.get('FTP_DIR')\n",
        "    except Exception: os.environ.setdefault('FTP_DIR', '')\n",
        "    try: os.environ['FTP_PORT'] = userdata.get('FTP_PORT')\n",
        "    except Exception: os.environ.setdefault('FTP_PORT', '21')\n",
        "except Exception:\n",
        "    os.environ.setdefault('FTP_HOST', '')\n",
        "    os.environ.setdefault('FTP_USER', '')\n",
        "    os.environ.setdefault('FTP_PASS', '')\n",
        "    os.environ.setdefault('FTP_DIR', '')\n",
        "    os.environ.setdefault('FTP_PORT', '21')\n",
        "\n",
        "# ---------- 1) Config ----------\n",
        "CSV_IN = \"final_combined_df_with_value_labels.csv\"\n",
        "\n",
        "LOCAL_HTML = \"yates_ancestor_register.htm\"\n",
        "REMOTE_HTML_CANON = posixpath.join(\"partials\", \"yates_ancestor_register.htm\")\n",
        "REMOTE_HTML_LEG = posixpath.join(\"partials\", \"ons_yates_dna_register.htm\")\n",
        "REMOTE_HTML_SIMPLE = posixpath.join(\"partials\", \"justdna.htm\")\n",
        "\n",
        "DNA_REGISTER_ABS = \"https://yates.one-name.net/partials/justdna.htm\"\n",
        "TREES_ABS = \"https://yates.one-name.net/partials/just-trees.htm\"\n",
        "\n",
        "EXPORT_BASENAME = \"yates_ancestor_register\"\n",
        "LOCAL_CSV = f\"{EXPORT_BASENAME}.csv\"\n",
        "LOCAL_XLSX = f\"{EXPORT_BASENAME}.xlsx\"\n",
        "REMOTE_CSV = posixpath.join(\"partials\", os.path.basename(LOCAL_CSV))\n",
        "REMOTE_XLSX = posixpath.join(\"partials\", os.path.basename(LOCAL_XLSX))\n",
        "\n",
        "WORK_PLUS_LOCAL = os.path.join(\"partials\", \"work_plus.htm\")\n",
        "WORK_PLUS_REMOTE = posixpath.join(\"partials\", \"work_plus.htm\")\n",
        "\n",
        "LOCAL_COUNT_FILE = \"/content/autosomal_count.txt\"\n",
        "REMOTE_COUNT_NAME = \"autosomal_count.txt\"\n",
        "\n",
        "FTP_DIR = (os.environ.get(\"FTP_DIR\",\"\") or \"\").strip()\n",
        "TNG_BASE = \"https://yates.one-name.net/tng\"\n",
        "TNG_TREE = \"tree1\"\n",
        "HOME_URL = \"https://yates.one-name.net/partials/yates_ancestor_register.htm\"\n",
        "REMOTE_NAME_ABS = HOME_URL\n",
        "COUNT_PUBLIC_URL = (f\"/{FTP_DIR}/{REMOTE_COUNT_NAME}\" if FTP_DIR else f\"/{REMOTE_COUNT_NAME}\")\n",
        "\n",
        "# === Your requested widths (now used responsively) ===\n",
        "TABLE_WIDTH_PX       = 2550\n",
        "COL_A_PX             = 775\n",
        "FIND_COL_PX          = 75\n",
        "ARROW_ENTITY         = \"&rarr;\"\n",
        "REMOVE_PERIOD_AT_END = True\n",
        "\n",
        "SERVER_PARTIALS_DIR = \"partials\"\n",
        "SERVER_MAPPING_BASENAME = \"match_to_unmasked.csv\"\n",
        "SERVER_MAPPING_REMOTE = posixpath.join(SERVER_PARTIALS_DIR, SERVER_MAPPING_BASENAME)\n",
        "SERVER_MAPPING_LOCAL_CACHE = \"match_to_unmasked.server.csv\"\n",
        "\n",
        "# External stylesheet (controls typography site-wide)\n",
        "STYLESHEET_HREF = \"/partials/dna_tree_styles.css\"\n",
        "CSS_VERSION = \"v2025-11-06\"\n",
        "HEAD_LINK = f'<link rel=\"stylesheet\" type=\"text/css\" href=\"{STYLESHEET_HREF}?{CSS_VERSION}\" />'\n",
        "\n",
        "# ---------- 2) FTP helpers ----------\n",
        "FTP_TIMEOUT = int(os.environ.get(\"FTP_TIMEOUT\", \"30\"))\n",
        "FTP_PASSIVE = True\n",
        "\n",
        "def ftp_connect() -> FTP_TLS:\n",
        "    ftps = FTP_TLS(timeout=FTP_TIMEOUT)\n",
        "    socket.setdefaulttimeout(FTP_TIMEOUT)\n",
        "    ftps.connect(os.environ.get('FTP_HOST',''), int(os.environ.get('FTP_PORT', 21)))\n",
        "    ftps.login(os.environ.get('FTP_USER',''), os.environ.get('FTP_PASS',''))\n",
        "    try: ftps.prot_p()\n",
        "    except Exception: pass\n",
        "    try: ftps.set_pasv(FTP_PASSIVE)\n",
        "    except Exception: pass\n",
        "    if FTP_DIR:\n",
        "        parts = [p for p in FTP_DIR.split(\"/\") if p]\n",
        "        for p in parts:\n",
        "            try: ftps.mkd(p)\n",
        "            except Exception: pass\n",
        "            ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "def _remote_path(name: str) -> str:\n",
        "    return posixpath.join(FTP_DIR, name) if FTP_DIR else name\n",
        "\n",
        "def ensure_remote_dirs(ftps: FTP_TLS, remote_path: str):\n",
        "    if \"/\" not in remote_path: return\n",
        "    pwd0 = ftps.pwd()\n",
        "    for seg in [p for p in remote_path.split(\"/\")[:-1] if p and p != \".\"]:\n",
        "        try: ftps.cwd(seg)\n",
        "        except Exception:\n",
        "            try: ftps.mkd(seg)\n",
        "            except Exception: pass\n",
        "            ftps.cwd(seg)\n",
        "    ftps.cwd(pwd0)\n",
        "\n",
        "def ftp_download_if_exists(ftps: FTP_TLS, remote_name: str, local_name: str) -> bool:\n",
        "    try:\n",
        "        with open(local_name, \"wb\") as f:\n",
        "            ftps.retrbinary(f\"RETR {remote_name}\", f.write)\n",
        "        print(f\"[PULL] {remote_name} -> {os.path.abspath(local_name)}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            if os.path.exists(local_name): os.remove(local_name)\n",
        "        except Exception: pass\n",
        "        print(f\"[MISS] {remote_name} ({e})\")\n",
        "        return False\n",
        "\n",
        "def ftp_upload_overwrite(ftps: FTP_TLS, local_path: str, remote_name: str):\n",
        "    ensure_remote_dirs(ftps, remote_name)\n",
        "    with open(local_path, \"rb\") as fh:\n",
        "        ftps.storbinary(f\"STOR {remote_name}\", fh)\n",
        "    print(f\"[PUT] {local_path} -> {remote_name}\")\n",
        "\n",
        "def ftp_size(ftps: FTP_TLS, remote_name: str):\n",
        "    try:\n",
        "        sz = ftps.size(remote_name)\n",
        "        return int(sz) if sz is not None else None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# ---------- 3) Resolver ----------\n",
        "def _read_mapping_csv(path: str) -> pd.DataFrame:\n",
        "    encs = (\"iso-8859-15\",\"utf-8-sig\",\"utf-8\",\"cp1252\",\"latin1\")\n",
        "    last = None; df = None\n",
        "    for enc in encs:\n",
        "        try:\n",
        "            df = pd.read_csv(path, encoding=enc, dtype=str, keep_default_na=False)\n",
        "            break\n",
        "        except Exception as e:\n",
        "            last = e\n",
        "    if df is None:\n",
        "        raise RuntimeError(f\"Unable to read mapping CSV {path}: {last}\")\n",
        "    if df.shape[1] < 2:\n",
        "        raise RuntimeError(\"Mapping CSV must have at least two columns: code, unmasked\")\n",
        "    df = df.iloc[:, :2].copy()\n",
        "    df.columns = [\"code\",\"unmasked\"]\n",
        "    df[\"code\"] = df[\"code\"].astype(str).str.strip().str.lower()\n",
        "    df[\"unmasked\"] = df[\"unmasked\"].astype(str).str.strip()\n",
        "    df = df[df[\"code\"] != \"\"].drop_duplicates(subset=[\"code\"], keep=\"first\")\n",
        "    if df.empty:\n",
        "        raise RuntimeError(\"Mapping CSV empty after normalization.\")\n",
        "    return df\n",
        "\n",
        "def load_resolver_from_server() -> dict:\n",
        "    with ftp_connect() as ftps:\n",
        "        try:\n",
        "            ftps.cwd(SERVER_PARTIALS_DIR)\n",
        "        except Exception:\n",
        "            pass\n",
        "        ok = ftp_download_if_exists(ftps, SERVER_MAPPING_BASENAME, SERVER_MAPPING_LOCAL_CACHE)\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "    if not ok:\n",
        "        raise RuntimeError(\n",
        "            \"Resolver not found on server: /\" + _remote_path(SERVER_MAPPING_REMOTE) +\n",
        "            \". Upload match_to_unmasked.csv into /partials/ and re-run.\"\n",
        "        )\n",
        "    df_map = _read_mapping_csv(SERVER_MAPPING_LOCAL_CACHE)\n",
        "    print(f\"[OK] Resolver loaded: {len(df_map)} codes\")\n",
        "    return dict(zip(df_map[\"code\"], df_map[\"unmasked\"]))\n",
        "\n",
        "MATCH_TO_UNMASKED = {}\n",
        "def _setup_resolver():\n",
        "    global MATCH_TO_UNMASKED\n",
        "    if not MATCH_TO_UNMASKED:\n",
        "        MATCH_TO_UNMASKED = load_resolver_from_server()\n",
        "\n",
        "def resolve_match_to(code: str) -> str:\n",
        "    if not isinstance(code, str): return \"\"\n",
        "    return MATCH_TO_UNMASKED.get(code.strip().lower(), code)\n",
        "\n",
        "# ---------- 4) Name & text utils ----------\n",
        "SEP_RE = re.compile(r\"\\s*(?:\\u2192|&rarr;|;|>|,|~{2,}|/{2,}|\\|{2,})\\s*\")\n",
        "def split_tokens(s):\n",
        "    if pd.isna(s): return []\n",
        "    if not isinstance(s, str): s = str(s)\n",
        "    return [p.strip() for p in SEP_RE.split(s) if str(p).strip()]\n",
        "\n",
        "def _clean_piece(text: str) -> str:\n",
        "    t = re.sub(r'~+', ' ', str(text)); t = re.sub(r'\\s+', ' ', t)\n",
        "    return t.strip()\n",
        "\n",
        "_PARTICLES = {\"de\",\"del\",\"della\",\"der\",\"van\",\"von\",\"da\",\"dos\",\"das\",\"di\",\"la\",\"le\",\"du\",\"of\"}\n",
        "\n",
        "def _smart_title(token: str) -> str:\n",
        "    if not token: return token\n",
        "    token = re.sub(r\"(^|\\b)([a-z])(['’])([a-z])\", lambda m: m.group(1)+m.group(2).upper()+m.group(3)+m.group(4).upper(), token.lower())\n",
        "    token = \"-\".join([w.capitalize() for w in token.split(\"-\")])\n",
        "    token = re.sub(r\"\\bmc([a-z])\", lambda m: \"Mc\"+m.group(1).upper(), token)\n",
        "    token = re.sub(r\"\\bmac([a-z])\", lambda m: \"Mac\"+m.group(1).upper(), token)\n",
        "    return token\n",
        "\n",
        "def smart_titlecase(name: str) -> str:\n",
        "    name = _clean_piece(name)\n",
        "    if not name: return name\n",
        "    if \",\" in name:\n",
        "        last, first = [p.strip() for p in name.split(\",\", 1)]\n",
        "        pieces = (first + \" \" + last).split()\n",
        "    else:\n",
        "        pieces = name.split()\n",
        "    out = []\n",
        "    for i, w in enumerate(pieces):\n",
        "        out.append(w.lower() if (i>0 and w.lower() in _PARTICLES) else _smart_title(w))\n",
        "    return \" \".join(out)\n",
        "\n",
        "def surname_given_from_token(token):\n",
        "    token = token.strip()\n",
        "    idx = None\n",
        "    for i in range(1, len(token)):\n",
        "        if token[i-1].islower() and token[i].isupper():\n",
        "            idx = i; break\n",
        "    if idx is None:\n",
        "        for i in range(1, len(token)):\n",
        "            if token[i].isupper():\n",
        "                idx = i; break\n",
        "    if idx is None: return (token,)\n",
        "    surname = token[:idx]; given = token[idx:]\n",
        "    given_spaced = re.sub(r'(?<!^)([A-Z])', r' \\1', given)\n",
        "    return (f\"{given_spaced.strip()} {surname.strip()}\",)\n",
        "\n",
        "def normalize_person_name(s: str) -> str:\n",
        "    if pd.isna(s): return \"\"\n",
        "    s = _clean_piece(str(s))\n",
        "    if \",\" in s:\n",
        "        last, first = [p.strip() for p in s.split(\",\", 1)]\n",
        "        s = f\"{first} {last}\"\n",
        "    if \" \" not in s and s.isalpha():\n",
        "        return smart_titlecase(surname_given_from_token(s)[0])\n",
        "    return smart_titlecase(s)\n",
        "\n",
        "_CAMEL_WORDS = re.compile(r\"[A-Z][a-z]*|[A-Z]+(?![a-z])|[a-z]+\")\n",
        "def norm_matchee_name(raw: str) -> str:\n",
        "    raw = str(raw or \"\").strip()\n",
        "    if not raw: return \"\"\n",
        "    if \" \" in raw or \",\" in raw:\n",
        "        nm = smart_titlecase(raw)\n",
        "        parts = nm.split()\n",
        "        if len(parts) == 1: return nm\n",
        "        given = parts[0]; surname = parts[-1]\n",
        "        return f\"{given} {surname}\".strip()\n",
        "    words = _CAMEL_WORDS.findall(raw)\n",
        "    while words and len(words[0]) == 1:\n",
        "        words.pop(0)\n",
        "    if not words:\n",
        "        nm = smart_titlecase(surname_given_from_token(raw)[0])\n",
        "        ps = nm.split()\n",
        "        if len(ps) == 1: return nm\n",
        "        return f\"{ps[0]} {ps[-1]}\".strip()\n",
        "    surname = smart_titlecase(words[0])\n",
        "    given_candidates = [w for w in words[1:] if w.lower() != surname.lower()]\n",
        "    if not given_candidates: return surname\n",
        "    given = smart_titlecase(given_candidates[0])\n",
        "    return f\"{given} {surname}\".strip()\n",
        "\n",
        "def truncate_first(name: str, n: int = 7) -> str:\n",
        "    name = name.strip()\n",
        "    if not name: return name\n",
        "    parts = name.split()\n",
        "    return parts[0][:n] if len(parts) == 1 else f\"{parts[0][:n]} {parts[-1]}\"\n",
        "\n",
        "def derive_common_from_first_token(tokens):\n",
        "    if not tokens: return (\"\",\"\")\n",
        "    first = _clean_piece(tokens[0])\n",
        "    parts = re.split(r\"\\s*(?:&| and )\\s*\", first, maxsplit=1, flags=re.I)\n",
        "    if len(parts) != 2: return (\"\",\"\")\n",
        "    def _norm(s):\n",
        "        return smart_titlecase(s) if \" \" in s else smart_titlecase(surname_given_from_token(s)[0])\n",
        "    return (_norm(parts[0]), _norm(parts[1]))\n",
        "\n",
        "def degree_label_from_generations(g):\n",
        "    if g <= 1: return (\"parents\" if g == 1 else \"self\")\n",
        "    if g == 2: return \"grandparents\"\n",
        "    greats = g - 2\n",
        "    if greats == 1: return \"great-grandparents\"\n",
        "    return f\"{greats}x-great-grandparents\"\n",
        "\n",
        "def build_header(subject_name, cm_val, matchee_name_html, gens, husband, wife):\n",
        "    try:\n",
        "        cm_str = f\"{int(round(float(cm_val)))}\"\n",
        "    except Exception:\n",
        "        cm_str = (str(cm_val).strip() or \"0\")\n",
        "    degree_label = degree_label_from_generations(gens)\n",
        "    parts = [\n",
        "        f\"{subject_name} is a {cm_str} cM cousin match to {matchee_name_html}, whose\",\n",
        "        f\"{degree_label} (back {gens} Gens)\",\n",
        "        \"are\",\n",
        "        f\"{husband} & {wife}.\"\n",
        "    ]\n",
        "    s = \" \".join(parts)\n",
        "    if REMOVE_PERIOD_AT_END: s = re.sub(r'\\.\\s*$', '', s)\n",
        "    return s\n",
        "\n",
        "# ---------- 5) Read CSV; detect columns ----------\n",
        "def find_col(df, patterns, prefer_exact=None):\n",
        "    cols = list(df.columns)\n",
        "    lowmap = {c.lower(): c for c in cols}\n",
        "    if prefer_exact:\n",
        "        for name in prefer_exact:\n",
        "            if name in df.columns: return name\n",
        "            if name and name.lower() in lowmap: return lowmap[name.lower()]\n",
        "    for pat in patterns:\n",
        "        rx = re.compile(pat, re.I)\n",
        "        for c in cols:\n",
        "            if rx.search(c): return c\n",
        "    return None\n",
        "\n",
        "_encs = (\"utf-8-sig\",\"utf-8\",\"cp1252\",\"iso-8859-15\",\"latin1\")\n",
        "_last_err = None\n",
        "df = None\n",
        "for _e in _encs:\n",
        "    try:\n",
        "        df = pd.read_csv(CSV_IN, encoding=_e, dtype=str, keep_default_na=False)\n",
        "        break\n",
        "    except Exception as _ex:\n",
        "        _last_err = _ex\n",
        "        df = None\n",
        "if df is None:\n",
        "    raise RuntimeError(f\"Unable to read CSV: {CSV_IN} ({_last_err})\")\n",
        "print(f\"[OK] Loaded CSV: {len(df)} rows, {len(df.columns)} cols\")\n",
        "\n",
        "id_col = find_col(df, [r'^(id#|personid)$'], [\"ID#\",\"ID\",\"PersonID\",\"personID\"])\n",
        "match_col = find_col(df, [r'^match\\s*to$'], [\"Match to\",\"Match\"])\n",
        "name_col = find_col(df, [r'^name$'], [\"Name\"])\n",
        "cm_col = find_col(df, [r'^(c\\s*:?m|cm)$', r'centi.?morgan'], [\"cM\",\"cm\"])\n",
        "path_col = find_col(df, [r'(yates\\s*dna\\s*ancestral\\s*line|ancestral\\s*line|lineage)'], [\"Yates DNA Ancestral Line\",\"Ancestral Line\",\"Lineage\"])\n",
        "\n",
        "if not id_col: raise ValueError(\"CSV missing an ID#/PersonID column.\")\n",
        "if not match_col: raise ValueError(\"CSV missing 'Match to' column.\")\n",
        "if not name_col: raise ValueError(\"CSV missing 'Name' column.\")\n",
        "if not cm_col: raise ValueError(\"CSV missing 'cM' column.\")\n",
        "if not path_col: raise ValueError(\"CSV missing lineage/path column.\")\n",
        "\n",
        "# ---------- 6) Transform -> display_df ----------\n",
        "ID_PAT = re.compile(r\"\\bI\\d+\\b\", re.I)\n",
        "def extract_person_id(s: str) -> str:\n",
        "    m = ID_PAT.search(str(s or \"\"))\n",
        "    return m.group(0).upper() if m else \"\"\n",
        "\n",
        "# Resolver\n",
        "def _setup_resolver_and_return():\n",
        "    _setup_resolver()\n",
        "    return MATCH_TO_UNMASKED\n",
        "_ = _setup_resolver_and_return()\n",
        "\n",
        "headers, lineages, findcol = [], [], []\n",
        "subjects, first_ancestors = [], []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    subject_raw = row.get(match_col, \"\")\n",
        "    subject_name = normalize_person_name(resolve_match_to(subject_raw))\n",
        "    subject_name_b = f\"<strong>{subject_name}</strong>\" if subject_name else subject_name\n",
        "\n",
        "    pid = extract_person_id(row.get(id_col, \"\"))\n",
        "    matchee_name = norm_matchee_name(row.get(name_col, \"\")) or subject_name\n",
        "\n",
        "    if pid:\n",
        "        matchee_name_html = (\n",
        "            f'<a href=\"{TNG_BASE}/verticalchart.php?personID={pid}&tree={TNG_TREE}&parentset=0&display=vertical&generations=15\" '\n",
        "            f'target=\"_blank\" rel=\"noopener\">{matchee_name}</a>'\n",
        "        )\n",
        "    else:\n",
        "        matchee_name_html = matchee_name\n",
        "\n",
        "    cm_val = row.get(cm_col, \"0\")\n",
        "    tokens = split_tokens(row.get(path_col, \"\"))\n",
        "    gens_total = len(tokens)\n",
        "    tokens_disp = tokens[:7]\n",
        "\n",
        "    if \"common_husband\" in df.columns and \"common_wife\" in df.columns:\n",
        "        husband_raw = str(row.get(\"common_husband\",\"\")).strip()\n",
        "        wife_raw = str(row.get(\"common_wife\",\"\")).strip()\n",
        "        if not husband_raw and not wife_raw:\n",
        "            husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "    else:\n",
        "        husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "\n",
        "    header_html = build_header(\n",
        "        subject_name_b,\n",
        "        cm_val,\n",
        "        matchee_name_html,\n",
        "        gens_total,\n",
        "        husband_raw,\n",
        "        wife_raw\n",
        "    )\n",
        "\n",
        "    if tokens_disp:\n",
        "        tokens_disp[0] = f\"<strong>{tokens_disp[0]}</strong>\"\n",
        "    sep = f\" {ARROW_ENTITY} \"\n",
        "    lineage_text = sep.join(tokens_disp) if tokens_disp else \"\"\n",
        "\n",
        "    q = _u.quote(subject_name)\n",
        "    quick = (\n",
        "        f'<a class=\"find-btn\" href=\"{REMOTE_NAME_ABS}?q={q}\" target=\"_blank\" rel=\"noopener\" '\n",
        "        f'title=\"Open a filtered view for {subject_name}\">Find</a>'\n",
        "    )\n",
        "\n",
        "    headers.append(header_html)\n",
        "    lineages.append(lineage_text)\n",
        "    findcol.append(quick)\n",
        "    subjects.append(subject_name)\n",
        "    first_ancestors.append(tokens[0] if tokens else \"\")\n",
        "\n",
        "LINEAGE_HEADER_SAFE = \"Lineage (Starting with oldest ancestor, the line is:)\"\n",
        "df[\"Match Summary\"] = headers\n",
        "df[LINEAGE_HEADER_SAFE] = lineages\n",
        "df[\"Find\"] = findcol\n",
        "df[\"Subject\"] = subjects\n",
        "df[\"First Ancestor\"] = [_clean_piece(x) for x in first_ancestors]\n",
        "display_df = df[[\"Find\",\"Match Summary\", LINEAGE_HEADER_SAFE]]\n",
        "\n",
        "# ---------- 6.1) Clean exports ----------\n",
        "TAG_RE = re.compile(r\"<[^>]+>\")\n",
        "def _html_to_text(s: str) -> str:\n",
        "    t = TAG_RE.sub(\"\", str(s or \"\"))\n",
        "    t = _html.unescape(t)\n",
        "    t = t.replace(\"\\u2192\", \"->\")\n",
        "    return re.sub(r\"\\s+\", \" \", t).strip()\n",
        "\n",
        "def _extract_find_url(cell_html: str) -> str:\n",
        "    m = re.search(r'href=\"([^\"]+)\"', str(cell_html or \"\"))\n",
        "    return _html.unescape(m.group(1)) if m else \"\"\n",
        "\n",
        "export_df = pd.DataFrame({\n",
        "    \"Find URL\": [ _extract_find_url(v) for v in display_df[\"Find\"].tolist() ],\n",
        "    \"Match Summary\": [ _html_to_text(v) for v in display_df[\"Match Summary\"].tolist() ],\n",
        "    \"Lineage\": [ _html_to_text(v) for v in display_df[LINEAGE_HEADER_SAFE].tolist() ],\n",
        "})\n",
        "export_df.to_csv(LOCAL_CSV, index=False, encoding=\"iso-8859-15\")\n",
        "try:\n",
        "    export_df.to_excel(LOCAL_XLSX, index=False)\n",
        "except Exception:\n",
        "    with pd.ExcelWriter(LOCAL_XLSX) as _writer:\n",
        "        export_df.to_excel(_writer, index=False)\n",
        "print(\"[OK] Wrote exports:\", os.path.abspath(LOCAL_CSV), \"and\", os.path.abspath(LOCAL_XLSX))\n",
        "\n",
        "# ---------- 7) HTML (Register main page) ----------\n",
        "# Responsive CSS: table fills width; large screens honor px via colgroup; small screens auto/percent.\n",
        "TABLE_CSS = f\"\"\"\n",
        "<style type=\"text/css\">\n",
        "  html {{ scroll-behavior: smooth; }}\n",
        "  body {{ font-size:100%; background:#ffffff; color:#222; margin:0; padding:0; line-height:1.5; }}\n",
        "  .wrap {{ max-width:100%; margin:0 auto; background:#ffffff; padding:16px; padding-bottom:48px; }}\n",
        "  a {{ color:#154b8b; text-decoration:none; }} a:hover {{ text-decoration:underline; }}\n",
        "  h1 {{ margin:0 0 6px 0; font-size:26px; line-height:1.2; text-align:center; }}\n",
        "  .centerline {{ text-align:center; }}\n",
        "  .downloads {{ text-align:center; margin:4px 0 10px 0; font-size:13px; }}\n",
        "  .updated {{ font-size:12px; color:#555; text-align:center; margin:2px 0 10px 0; }}\n",
        "  .sortbar {{ margin:6px 0 10px 0; font-size:13px; background:#ffffff; padding:6px 8px; border-radius:6px; display:flex; flex-wrap:wrap; gap:5px; align-items:center; border:1px solid #ddd; justify-content:center; }}\n",
        "  .btn {{ display:inline-block; border:1px solid #5b79b8; background:#5b79b8; color:#fff; padding:4px 9px; text-decoration:none; cursor:pointer; border-radius:5px; line-height:1.2; }}\n",
        "  .btn:hover {{ background:#4668aa; }}\n",
        "  input.btn.search {{ background:#fff; color:#111; border-color:#bbb; }}\n",
        "\n",
        "  .table-scroll {{ max-height:70vh; overflow-y:auto; overflow-x:auto; border:1px solid #ddd; }}\n",
        "  table.sortable {{ border-collapse:collapse; width:100%; table-layout:fixed; }}\n",
        "  table.sortable th, table.sortable td {{ border:1px solid #ddd; padding:6px 8px; vertical-align:top; word-wrap:break-word; overflow-wrap:break-word; }}\n",
        "  table.sortable th {{ background:#e3eaf8; text-align:left; position:sticky; top:0; z-index:2; box-shadow:0 1px 0 #ccc; cursor:pointer; }}\n",
        "  #first-row td {{ border-top:2px solid #999; }}\n",
        "\n",
        "  .find-cell {{ white-space:nowrap; }}\n",
        "  .selbox {{ margin-right:6px; vertical-align:middle; }}\n",
        "\n",
        "  .back-to-top {{ position:fixed; right:16px; bottom:16px; padding:6px 10px; border:1px solid #3e5a97; background:#5b79b8; color:#fff; cursor:pointer; border-radius:6px; font-size:12px; display:none; z-index:9999; }}\n",
        "  .back-to-top:hover {{ background:#4668aa; }}\n",
        "\n",
        "  /* Large screens: suggest px widths from your constants */\n",
        "  @media screen and (min-width: 1200px) {{\n",
        "    #refactor-table col:nth-child(1) {{ width:{FIND_COL_PX}px; }}\n",
        "    #refactor-table col:nth-child(2) {{ width:{COL_A_PX}px; }}\n",
        "    .wrap {{ max-width:{TABLE_WIDTH_PX}px; }}\n",
        "  }}\n",
        "\n",
        "  /* Medium screens: loosen widths to percentages */\n",
        "  @media screen and (max-width: 1199px) {{\n",
        "    #refactor-table {{ table-layout:auto; }}\n",
        "    #refactor-table col:nth-child(1) {{ width:12%; }}\n",
        "    #refactor-table col:nth-child(2) {{ width:44%; }}\n",
        "    #refactor-table col:nth-child(3) {{ width:44%; }}\n",
        "  }}\n",
        "\n",
        "  /* Small screens: tighter padding and bigger first column tap targets */\n",
        "  @media screen and (max-width: 700px) {{\n",
        "    table.sortable th, table.sortable td {{ padding:5px 6px; }}\n",
        "    #refactor-table col:nth-child(1) {{ width:16%; }}\n",
        "    #refactor-table col:nth-child(2) {{ width:42%; }}\n",
        "    #refactor-table col:nth-child(3) {{ width:42%; }}\n",
        "    .btn {{ padding:4px 7px; }}\n",
        "  }}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "DYNAMIC_BLOCK = (\n",
        "    '<div class=\"sortbar\">'\n",
        "    '<a class=\"btn\" href=\"https://yates.one-name.net/gengen/dna_cousin_surname_study.htm\" target=\"_blank\" rel=\"noopener\">Study Details</a>'\n",
        "    '<a class=\"btn\" href=\"https://yates.one-name.net/gengen/dna_theory_of_the_case.htm\" target=\"_blank\" rel=\"noopener\">Theory in Action</a>'\n",
        "    '<a class=\"btn\" href=\"/gengen/images/cousin-calculator.jpg\" target=\"_blank\" rel=\"noopener\">Cousin Connection</a>'\n",
        "    '<a class=\"btn\" href=\"/gengen/images/Shared_cM_Project_v4.jpg\" target=\"_blank\" rel=\"noopener\">Cousin by DNA</a>'\n",
        "    '<a class=\"btn\" href=\"/partials/match_count.htm\" target=\"_blank\" rel=\"noopener\">Match Count</a>'\n",
        "    '<a class=\"btn\" href=\"/partials/lineage_count.htm\" target=\"_blank\" rel=\"noopener\">Lineage Count</a>'\n",
        "    f'<a class=\"btn\" href=\"{DNA_REGISTER_ABS}\" target=\"_blank\" rel=\"noopener\">DNA Register</a>'\n",
        "    f'<a class=\"btn\" href=\"{TREES_ABS}\" target=\"_blank\" rel=\"noopener\">Trees</a>'\n",
        "    '<span class=\"btn\" id=\"show-selected\" title=\"Show all rows for the checked name(s)\">Show Selected</span>'\n",
        "    '<span class=\"btn\" id=\"show-all\" title=\"Show All\">Show All</span>'\n",
        "    '<span class=\"btn\" id=\"print-cousin-list\" style=\"cursor:pointer;\" title=\"Open a printable list of the *currently visible* rows\">Cousin List (Printable)</span>'\n",
        "    '<span class=\"btn\" id=\"clear-selected\">Reset</span>'\n",
        "    '<input type=\"text\" id=\"search-box\" class=\"btn search\" size=\"24\" value=\"\" placeholder=\"Search&amp;hellip;\" />'\n",
        "    '</div>'\n",
        ")\n",
        "\n",
        "JS_COUNT_URL = COUNT_PUBLIC_URL.replace(\"'\", \"%27\")\n",
        "UPDATED_BLOCK = (\n",
        "    '<div class=\"updated centerline\">'\n",
        "    'Last updated: <span id=\"last-updated\"></span>'\n",
        "    ' &nbsp;|&nbsp; Autosomal matches: <span id=\"auto-count\" class=\"js-count\"></span>'\n",
        "    ' &nbsp;|&nbsp; Showing: <span id=\"showing-count\"></span>'\n",
        "    '</div>'\n",
        ")\n",
        "\n",
        "DOWNLOADS_BLOCK = (\n",
        "    '<p class=\"downloads centerline\">Download: '\n",
        "    f'<a href=\"/partials/{_html.escape(os.path.basename(LOCAL_CSV))}\">CSV</a> | '\n",
        "    f'<a href=\"/partials/{_html.escape(os.path.basename(LOCAL_XLSX))}\">Excel</a></p>'\n",
        ")\n",
        "\n",
        "page_tpl = Template(\"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "<title>ONS Yates Study Autosomal DNA Register</title>\n",
        "$HEAD_LINK\n",
        "$TABLE_CSS\n",
        "</head>\n",
        "<body id=\"top\">\n",
        "<div class=\"wrap\">\n",
        "  <h1 class=\"centerline\">ONS Yates Study Autosomal DNA Register</h1>\n",
        "  $DOWNLOADS_BLOCK\n",
        "  $UPDATED_BLOCK\n",
        "  $DYNAMIC_BLOCK\n",
        "  <div class=\"table-scroll\">\n",
        "    $HTML_TABLE\n",
        "  </div>\n",
        "</div>\n",
        "<button id=\"back-to-top\" class=\"back-to-top\">&#9650; Top</button>\n",
        "<script type=\"text/javascript\">\n",
        "//<![CDATA[\n",
        "(function(){\n",
        "  function textOf(cell){ return (cell && (cell.textContent || cell.innerText) || '').replace(/\\\\s+/g,' ').trim().toLowerCase(); }\n",
        "  function sortTable(tbl, colIndex, dir){\n",
        "    var tb=tbl && tbl.tBodies ? tbl.tBodies[0] : null; if(!tb) return;\n",
        "    var rows=[].slice.call(tb.rows||[]); var asc=(dir==='asc');\n",
        "    rows.sort(function(a,b){var A=textOf(a.cells[colIndex]),B=textOf(b.cells[colIndex]); if(A<B) return asc?-1:1; if(A>B) return asc?1:-1; return 0;});\n",
        "    var frag=document.createDocumentFragment(); for(var i=0;i<rows.length;i++) frag.appendChild(rows[i]); tb.appendChild(frag);\n",
        "    updateShowing();\n",
        "  }\n",
        "  function bindHeaderSort(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tHead && tbl.tHead.rows.length)) return;\n",
        "    var ths=tbl.tHead.rows[0].cells; if(!ths) return;\n",
        "    for(var i=0;i<ths.length;i++)(function(idx){\n",
        "      var th = ths[idx]; var dir='asc';\n",
        "      th.addEventListener('click',function(){\n",
        "        dir=(dir==='asc')?'desc':'asc';\n",
        "        for (var j = 0; j < ths.length; j++){ ths[j].innerHTML = ths[j].innerHTML.replace(/\\\\s+\\\\(asc\\\\)|\\\\s+\\\\(desc\\\\)/,''); }\n",
        "        th.innerHTML += (dir==='asc' ? ' (asc)' : ' (desc)');\n",
        "        sortTable(tbl,idx,dir);\n",
        "      },false);\n",
        "    })(i);\n",
        "  }\n",
        "  function formatWithCommas(n){\n",
        "    try{ var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return ''; return x.toLocaleString('en-US'); }catch(e){ return String(n||''); }\n",
        "  }\n",
        "  function visibleRowCount(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return 0;\n",
        "    var rows=tbl.tBodies[0].rows, n=0; for(var i=0;i<rows.length;i++){ if(rows[i].style.display!=='none') n++; } return n;\n",
        "  }\n",
        "  function updateShowing(){ var el=document.getElementById('showing-count'); if(!el) return; el.textContent = formatWithCommas(visibleRowCount()); }\n",
        "  function getParam(name){ var m=location.search.match(new RegExp('[?&]'+name+'=([^&]+)')); return m?decodeURIComponent(m[1].replace(/\\\\+/g,' ')):''; }\n",
        "  function norm(s){ return String(s||'').replace(/\\\\s+/g,' ').toLowerCase(); }\n",
        "  function bindSearch(){\n",
        "    var box=document.getElementById('search-box'); var tbl=document.getElementById('refactor-table'); if(!(box && tbl && tbl.tBodies && tbl.tBodies[0])) return; var tb=tbl.tBodies[0];\n",
        "    function rowText(tr){ var t=''; for(var i=1;i<tr.cells.length;i++){ t+= ' ' + (tr.cells[i].textContent||tr.cells[i].innerText||''); } return norm(t); }\n",
        "    var cached=[]; (function seed(){ var rows=tb.rows; cached=[]; for(var i=0;i<rows.length;i++){ cached.push({el:rows[i], txt:rowText(rows[i])}); } })();\n",
        "    function apply(q){\n",
        "      q = String(q||''); var parts = q.split('|').map(function(s){return norm(s);}).filter(function(s){return !!s;});\n",
        "      for(var i=0;i<cached.length;i++){\n",
        "        var hit = !parts.length || parts.some(function(p){ return cached[i].txt.indexOf(p)>-1; });\n",
        "        cached[i].el.style.display = hit? '' : 'none';\n",
        "      }\n",
        "      updateShowing();\n",
        "    }\n",
        "    var to=null; function onInput(){ if(to) clearTimeout(to); to=setTimeout(function(){ apply(box.value); }, 60); }\n",
        "    box.addEventListener('input', onInput, false);\n",
        "    box.addEventListener('search', onInput, false);\n",
        "    var q0=getParam('q');\n",
        "    if(q0){ box.value=q0; apply(q0); try{ history.replaceState(null, '', location.pathname); }catch(e){} }\n",
        "    else { box.value=''; apply(''); setTimeout(function(){ if(!getParam('q')){ box.value=''; apply(''); } }, 0); }\n",
        "  }\n",
        "  function allRowCheckboxes(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return [];\n",
        "    var tb=tbl.tBodies[0], out=[];\n",
        "    for(var i=0;i<tb.rows.length;i++){\n",
        "      var cb=tb.rows[i].querySelector('.selbox');\n",
        "      if(cb) out.push(cb);\n",
        "    }\n",
        "    return out;\n",
        "  }\n",
        "  function bindGroupSync(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!tbl) return;\n",
        "    tbl.addEventListener('click', function(e){\n",
        "      var t=e.target||e.srcElement;\n",
        "      if(!(t && t.classList && t.classList.contains('selbox'))) return;\n",
        "      var nm = t.getAttribute('data-name') || '';\n",
        "      var checked = !!t.checked;\n",
        "      var cbs = allRowCheckboxes();\n",
        "      for(var i=0;i<cbs.length;i++){\n",
        "        if((cbs[i].getAttribute('data-name')||'') === nm){ cbs[i].checked = checked; }\n",
        "      }\n",
        "      updateShowing();\n",
        "    }, false);\n",
        "  }\n",
        "  function bindShowSelected(){\n",
        "    var btn=document.getElementById('show-selected'); if(!btn) return;\n",
        "    btn.addEventListener('click', function(){\n",
        "      var cbs = allRowCheckboxes();\n",
        "      var names = {};\n",
        "      for(var i=0;i<cbs.length;i++){ if(cbs[i].checked){ names[cbs[i].getAttribute('data-name')||''] = true; } }\n",
        "      var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "      var tb=tbl.tBodies[0];\n",
        "      for(var r=0;r<tb.rows.length;r++){\n",
        "        var cb = tb.rows[r].querySelector('.selbox');\n",
        "        var nm = cb ? (cb.getAttribute('data-name')||'') : '';\n",
        "        tb.rows[r].style.display = names[nm] ? '' : 'none';\n",
        "      }\n",
        "      updateShowing();\n",
        "    }, false);\n",
        "  }\n",
        "  function bindShowAll(){\n",
        "    var btn=document.getElementById('show-all'); if(!btn) return;\n",
        "    btn.addEventListener('click', function(){\n",
        "      var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "      var tb=tbl.tBodies[0];\n",
        "      for(var i=0;i<tb.rows.length;i++){ tb.rows[i].style.display=''; }\n",
        "      updateShowing();\n",
        "    }, false);\n",
        "  }\n",
        "  function bindClear(){\n",
        "    var btn=document.getElementById('clear-selected'); if(!btn) return;\n",
        "    btn.addEventListener('click', function(){\n",
        "      var cbs=allRowCheckboxes(); for(var i=0;i<cbs.length;i++) cbs[i].checked=false;\n",
        "      var tbl=document.getElementById('refactor-table'); if(tbl && tbl.tBodies && tbl.tBodies[0]){\n",
        "        var tb=tbl.tBodies[0]; for(var j=0;j<tb.rows.length;j++){ tb.rows[j].style.display=''; }\n",
        "      }\n",
        "      updateShowing();\n",
        "    }, false);\n",
        "  }\n",
        "  function addCheckboxes(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "    var tb=tbl.tBodies[0];\n",
        "    for(var i=0;i<tb.rows.length;i++){\n",
        "      var tr=tb.rows[i]; var cell=tr.cells[0]; var findBtn=cell ? cell.querySelector('.find-btn') : null;\n",
        "      var name = findBtn ? (findBtn.getAttribute('title')||'').replace('Open a filtered view for ','') : ('Row '+(i+1));\n",
        "      if(cell){\n",
        "        cell.classList.add('find-cell');\n",
        "        cell.innerHTML = '<input type=\"checkbox\" class=\"selbox\" title=\"Select this row\" data-name=\"'+name.replace(/\"/g,'&quot;')+'\" /> ' + cell.innerHTML.replace(/^\\\\s*/, '');\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  function initShowingStatic(){ try{ document.getElementById('showing-count').textContent = document.getElementById('refactor-table').tBodies[0].rows.length; }catch(e){}}\n",
        "  document.addEventListener('DOMContentLoaded', function(){\n",
        "    addCheckboxes();\n",
        "    (function(){var el=document.getElementById('last-updated'); if(!el) return; var d=new Date(document.lastModified||new Date()); function z(n){return (n<10?'0':'')+n;} el.innerHTML=d.getFullYear()+'-'+z(d.getMonth()+1)+'-'+z(d.getDate())+' '+z(d.getHours())+':'+z(d.getMinutes());})();\n",
        "    bindHeaderSort();\n",
        "    bindSearch();\n",
        "    bindGroupSync();\n",
        "    bindShowSelected();\n",
        "    bindShowAll();\n",
        "    bindClear();\n",
        "    initShowingStatic();\n",
        "  });\n",
        "})();\n",
        " //]]>\n",
        "</script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\")\n",
        "\n",
        "html_table = display_df.to_html(index=False, escape=False, classes=\"dataframe sortable\")\n",
        "\n",
        "# Step 1: Replace default table tag with our ID and mark first row\n",
        "html_table = html_table.replace('<table border=\"1\" class=\"dataframe sortable\">', '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">', 1)\n",
        "html_table = html_table.replace('<tbody>\\n<tr>', '<tbody>\\n<tr id=\"first-row\">', 1)\n",
        "html_table = html_table.replace(\"<th>Find</th>\", '<th>Select:</th>', 1)\n",
        "\n",
        "# Step 2: Rename headers (ASCII-safe)\n",
        "html_table = html_table.replace('<th>Match Summary</th>', '<th>Match Summary&amp;ndash;click to sort</th>', 1)\n",
        "html_table = html_table.replace(f'<th>{_html.escape(LINEAGE_HEADER_SAFE)}</th>', '<th>Lineage (Starting with oldest ancestor&amp;ndash;click to sort)</th>', 1)\n",
        "\n",
        "# Step 3: Insert <colgroup> with your px widths (CSS overrides on small screens)\n",
        "colgroup_html = (\n",
        "    \"<colgroup>\\n\"\n",
        "    f\"  <col style=\\\"width:{FIND_COL_PX}px;\\\" />\\n\"\n",
        "    f\"  <col style=\\\"width:{COL_A_PX}px;\\\" />\\n\"\n",
        "    \"  <col />\\n\"\n",
        "    \"</colgroup>\\n\"\n",
        ")\n",
        "html_table = html_table.replace(\n",
        "    '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">',\n",
        "    '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">\\n' + colgroup_html,\n",
        "    1\n",
        ")\n",
        "\n",
        "# Build main page\n",
        "final_html = page_tpl.safe_substitute(\n",
        "    HEAD_LINK=HEAD_LINK,\n",
        "    TABLE_CSS=TABLE_CSS,\n",
        "    UPDATED_BLOCK=UPDATED_BLOCK,\n",
        "    DYNAMIC_BLOCK=DYNAMIC_BLOCK,\n",
        "    HTML_TABLE=html_table,\n",
        "    JS_COUNT_URL=JS_COUNT_URL,\n",
        "    DOWNLOADS_BLOCK=DOWNLOADS_BLOCK\n",
        ").replace(\"$HEAD_LINK_URL_JS$\", (STYLESHEET_HREF + \"?\" + CSS_VERSION))\n",
        "\n",
        "# ---------- 8) Partials (keep simple; no font-family inline) ----------\n",
        "def _norm_code_for_count(s):\n",
        "    t = str(s or \"\").strip()\n",
        "    if (t.startswith('\"') and t.endswith('\"')) or (t.startswith(\"'\") and t.endswith(\"'\")):\n",
        "        t = t[1:-1]\n",
        "    t = re.sub(r'\\s+', ' ', t).strip()\n",
        "    t = t.lower()\n",
        "    return t\n",
        "\n",
        "def _partial_css_wrapper_simple():\n",
        "    return (\n",
        "        \"<style type=\\\"text/css\\\">\\n\"\n",
        "        \"  html { scroll-behavior: smooth; }\\n\"\n",
        "        \"  body { background:#ffffff; color:#222; margin:0; padding:0; }\\n\"\n",
        "        \"  .wrap { max-width:100%; margin:0 auto; padding:16px; }\\n\"\n",
        "        \"  a { color:#154b8b; text-decoration:none; } a:hover { text-decoration:underline; }\\n\"\n",
        "        \"  h1 { margin:0 0 8px 0; font-size:24px; line-height:1.2; text-align:center; }\\n\"\n",
        "        \"  .meta { text-align:center; font-size:12px; color:#555; margin:2px 0 10px 0; }\\n\"\n",
        "        \"  .toolbar { display:flex; gap:10px; align-items:center; margin:6px 0 10px 0; flex-wrap:wrap; justify-content:center; }\\n\"\n",
        "        \"  .btn { display:inline-block; border:1px solid #5b79b8; background:#5b79b8; color:#fff; padding:4px 9px; text-decoration:none; cursor:pointer; border-radius:5px; line-height:1.2; }\\n\"\n",
        "        \"  table { border-collapse:collapse; width:100%; table-layout:fixed; }\\n\"\n",
        "        \"  th, td { border:1px solid #ddd; padding:6px 8px; word-wrap:break-word; overflow-wrap:break-word; }\\n\"\n",
        "        \"  th { background:#e3eaf8; text-align:left; position:sticky; top:0; z-index:2; }\\n\"\n",
        "        \"  tr.sel { background:#fff7d6; }\\n\"\n",
        "        \"  .count a { font-weight:bold; }\\n\"\n",
        "        \"  @media screen and (max-width: 700px) { th, td { padding:5px 6px; } }\\n\"\n",
        "        \"</style>\\n\"\n",
        "    )\n",
        "\n",
        "def _partial_head(title):\n",
        "    return (\n",
        "        \"<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Transitional//EN\\\"\\n\"\n",
        "        \" \\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\\\">\\n\"\n",
        "        \"<html xmlns=\\\"http://www.w3.org/1999/xhtml\\\" lang=\\\"en\\\">\\n<head>\\n\"\n",
        "        f\"{HEAD_LINK}\\n\"\n",
        "        \"<meta http-equiv=\\\"Content-Type\\\" content=\\\"text/html; charset=iso-8859-15\\\" />\\n\"\n",
        "        f\"<title>{_html.escape(title)}</title>\\n\"\n",
        "    )\n",
        "\n",
        "def _partial_toolbar():\n",
        "    safe_home = HOME_URL.replace('\"','&quot;')\n",
        "    return (\n",
        "        \"<div class=\\\"toolbar\\\">\"\n",
        "        f\"<a class=\\\"btn\\\" href=\\\"{safe_home}\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">DNA Register</a>\"\n",
        "        \" <button id=\\\"mc-show-selected\\\" class=\\\"btn\\\" title=\\\"Open DNA Register filtered to selected\\\">Show Selected</button>\"\n",
        "        \" <button id=\\\"mc-show-all\\\" class=\\\"btn\\\" title=\\\"Show all rows (this table)\\\">Show All</button>\"\n",
        "        \" <button id=\\\"mc-reset\\\" class=\\\"btn\\\" title=\\\"Clear selection and show all\\\">Reset</button>\"\n",
        "        \" <button id=\\\"view\\\" class=\\\"btn\\\" title=\\\"Open DNA Register with selected (alias)\\\">View Now</button>\"\n",
        "        \"</div>\\n\"\n",
        "    )\n",
        "\n",
        "def _partial_js_common():\n",
        "    _safe_home = HOME_URL.replace(\"'\", \"%27\")\n",
        "    return (\n",
        "        \"<script type=\\\"text/javascript\\\">\\n//<![CDATA[\\n\"\n",
        "        \"(function(){\\n\"\n",
        "        \"  var REG = '\" + _safe_home + \"';\\n\"\n",
        "        \"  function fmt(n){ try{ var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return '0'; return x.toLocaleString('en-US'); }catch(e){ return String(n||'0'); } }\\n\"\n",
        "        \"  function selected(){ var out=[]; var tb=document.getElementById('ref-tb'); if(!tb) return out; var rows=tb.rows; for(var i=0;i<rows.length;i++){ if((' '+rows[i].className+' ').indexOf(' sel ')>-1) out.push(rows[i]); } return out; }\\n\"\n",
        "        \"  function update(){ var sel=selected(), sum=0; for(var i=0;i<sel.length;i++){ var v=parseInt((sel[i].getAttribute('data-count')||'0').replace(/[^0-9\\\\-]/g,''),10); if(!isNaN(v)) sum+=v; } var nEl=document.getElementById('sel-n'); var sEl=document.getElementById('sel-sum'); if(nEl) nEl.innerHTML=fmt(sel.length); if(sEl) sEl.innerHTML=fmt(sum); }\\n\"\n",
        "        \"  function qJoin(parts){ var out=[]; var seen={}; for(var i=0;i<parts.length;i++){ var p=String(parts[i]||''); if(p && !seen[p]){ seen[p]=1; out.push(encodeURIComponent(p)); } } return out.join('%7C'); }\\n\"\n",
        "        \"  function openRegisterForSelected(){ var sel=selected(); if(!sel.length) return; var qs=[]; for(var i=0;i<sel.length;i++){ qs.push(sel[i].getAttribute('data-q')||''); } var q = qJoin(qs); var url = REG + '?q=' + q; var w=null; try{ w=window.open(url,'RegisterFiltered'); if(!w) throw new Error('popup'); w.focus(); } catch(e){ window.location.href = url; } }\\n\"\n",
        "        \"  function toggleFrom(el){ var tr=el; while(tr && tr.nodeName && tr.nodeName.toLowerCase()!=='tr'){ tr=tr.parentNode; } if(!tr) return; var c=tr.className||''; tr.className = ((' '+c+' ').indexOf(' sel ')>-1) ? c.replace(/\\\\bsel\\\\b/,'').replace(/\\\\s{2,}/g,' ').trim() : (c?c+' ':'')+'sel'; update(); }\\n\"\n",
        "        \"  document.addEventListener('click', function(e){ var t=e.target||e.srcElement; if(!t) return; if(t.classList && t.classList.contains('count-pick')){ e.preventDefault(); toggleFrom(t); return; } if(t.id=='view' || t.id=='mc-show-selected'){ e.preventDefault(); openRegisterForSelected(); return; } if(t.id=='mc-reset'){ e.preventDefault(); var tb=document.getElementById('ref-tb'); if(tb){ var rows=tb.rows; for(var i=0;i<rows.length;i++){ rows[i].className = rows[i].className.replace(/\\\\bsel\\\\b/,'').replace(/\\\\s{2,}/g,' ').trim(); rows[i].style.display=''; } } update(); return; } if(t.id=='mc-show-all'){ e.preventDefault(); var tb2=document.getElementById('ref-tb'); if(!tb2) return; for(var k=0;k<tb2.rows.length;k++){ tb2.rows[k].style.display=''; } return; } }, false);\\n\"\n",
        "        \"  document.addEventListener('DOMContentLoaded', update, false);\\n\"\n",
        "        \"})();\\n\"\n",
        "        \"//]]>\\n</script>\\n\"\n",
        "    )\n",
        "\n",
        "def _shell_open(title):\n",
        "    return (\n",
        "        _partial_head(title) +\n",
        "        _partial_css_wrapper_simple() +\n",
        "        \"</head>\\n<body>\\n<div class=\\\"wrap\\\">\\n\" +\n",
        "        f\"<h1>{_html.escape(title)}</h1>\\n\" +\n",
        "        \"<div class=\\\"meta\\\">\"\n",
        "        \"Last updated: <span id=\\\"last-updated\\\"></span>\"\n",
        "        \" &nbsp;|&nbsp; Autosomal matches: <span id=\\\"auto-count\\\">&mdash;</span>\"\n",
        "        \" &nbsp;|&nbsp; Selected: <span id=\\\"sel-n\\\">0</span> &nbsp; Sum: <span id=\\\"sel-sum\\\">0</span>\"\n",
        "        \"</div>\\n\" +\n",
        "        _partial_toolbar() +\n",
        "        \"<div class=\\\"table-scroll\\\">\\n\"\n",
        "    )\n",
        "\n",
        "def _shell_close():\n",
        "    safe_count = COUNT_PUBLIC_URL.replace(\"'\", \"%27\")\n",
        "    return (\n",
        "        \"</div>\\n</div>\\n\"\n",
        "        \"<script type=\\\"text/javascript\\\">\\n//<![CDATA[\\n\"\n",
        "        \"(function(){ function z(n){return (n<10?'0':'')+n;} function stamp(){var el=document.getElementById('last-updated'); if(!el) return; var d=new Date(document.lastModified||new Date()); el.innerHTML=d.getFullYear()+'-'+z(d.getMonth()+1)+'-'+z(d.getDate())+' '+z(d.getHours())+':'+z(d.getMinutes());}\\n\"\n",
        "        \"function load(){var el=document.getElementById('auto-count'); if(!el) return; var URL='\" + safe_count + \"'; try{var xhr=new XMLHttpRequest(); xhr.open('GET', URL+(URL.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true); xhr.onreadystatechange=function(){if(xhr.readyState===4){if(xhr.status>=200&&xhr.status<300){var m=(xhr.responseText||'').match(/(\\\\d+)/); el.textContent=(m?m[1]:'');} else {el.textContent='(unavailable)';}}}; xhr.send(null);}catch(e){el.textContent='(unavailable)';}}\\n\"\n",
        "        \"document.addEventListener('DOMContentLoaded', function(){ stamp(); load(); }, false); })();\\n\"\n",
        "        \"//]]>\\n</script>\\n\"\n",
        "        + _partial_js_common() +\n",
        "        \"</body>\\n</html>\"\n",
        "    )\n",
        "\n",
        "def build_match_count_partial(main_df: pd.DataFrame) -> str:\n",
        "    codes_raw = main_df[match_col].astype(str).map(lambda x: x.strip())\n",
        "    keys_norm = codes_raw.map(_norm_code_for_count)\n",
        "    counts_series = keys_norm.value_counts(dropna=False)\n",
        "    counts = counts_series.reset_index()\n",
        "    if counts.shape[1] >= 2:\n",
        "        counts.columns = [\"norm_key\", \"Count\"]\n",
        "    else:\n",
        "        counts[\"norm_key\"] = counts.index.astype(str)\n",
        "        counts[\"Count\"] = counts_series.values\n",
        "        counts = counts[[\"norm_key\",\"Count\"]]\n",
        "    first_display = {}\n",
        "    for code_disp, k in zip(codes_raw.tolist(), keys_norm.tolist()):\n",
        "        if k not in first_display and str(k) != \"\":\n",
        "            first_display[k] = code_disp\n",
        "    counts[\"Code\"] = counts[\"norm_key\"].map(lambda k: first_display.get(k, k))\n",
        "    counts[\"Unmasked\"] = counts[\"norm_key\"].map(lambda k: MATCH_TO_UNMASKED.get(k, \"\"))\n",
        "    counts = counts.sort_values(by=[\"Code\",\"Count\"], ascending=[True, False], kind=\"mergesort\").reset_index(drop=True)\n",
        "\n",
        "    html = []\n",
        "    html.append(_shell_open(\"Match Count\"))\n",
        "    html.append('<table id=\"ref-table\" border=\"1\" class=\"sortable\" style=\"width:100%\"><thead><tr>')\n",
        "    html.append('<th style=\"width:35%\">Code</th><th style=\"width:45%\">Unmasked</th><th style=\"width:20%\">Count</th>')\n",
        "    html.append('</tr></thead><tbody id=\"ref-tb\">')\n",
        "    for _, r in counts.iterrows():\n",
        "        code = r.get(\"Code\",\"\")\n",
        "        unm  = r.get(\"Unmasked\",\"\")\n",
        "        cnt  = int(str(r.get(\"Count\",\"0\")).strip() or \"0\")\n",
        "        label = (unm or code).strip()\n",
        "        tr = (\n",
        "            f'<tr data-q=\"{_html.escape(label, quote=True)}\" data-count=\"{cnt}\">'\n",
        "            f'<td>{_html.escape(code)}</td>'\n",
        "            f'<td>{_html.escape(unm)}</td>'\n",
        "            f'<td class=\"count\"><a href=\"#\" class=\"count-pick\" title=\"Toggle select\">{cnt}</a></td>'\n",
        "            f'</tr>'\n",
        "        )\n",
        "        html.append(tr)\n",
        "    html.append('</tbody></table>')\n",
        "    html.append(_shell_close())\n",
        "    return \"\".join(html)\n",
        "\n",
        "def build_lineage_count_partial(main_df: pd.DataFrame) -> str:\n",
        "    first_series = main_df.get(\"First Ancestor\", pd.Series(dtype=str)).astype(str).map(lambda x: x.strip())\n",
        "    vc = first_series[first_series != \"\"].value_counts(dropna=False)\n",
        "    lin_df = vc.reset_index()\n",
        "    if lin_df.shape[1] >= 2:\n",
        "        lin_df.columns = [\"First Ancestor\",\"Count\"]\n",
        "    else:\n",
        "        lin_df[\"First Ancestor\"] = lin_df.index.astype(str)\n",
        "        lin_df[\"Count\"] = vc.values\n",
        "        lin_df = lin_df[[\"First Ancestor\",\"Count\"]]\n",
        "    lin_df = lin_df.sort_values([\"Count\",\"First Ancestor\"], ascending=[False, True], kind=\"mergesort\").reset_index(drop=True)\n",
        "\n",
        "    html = []\n",
        "    html.append(_shell_open(\"Lineage Count\"))\n",
        "    html.append('<table id=\"ref-table\" border=\"1\" class=\"sortable\" style=\"width:100%\"><thead><tr>')\n",
        "    html.append('<th style=\"width:80%\">First Ancestor</th><th style=\"width:20%\">Count</th>')\n",
        "    html.append('</tr></thead><tbody id=\"ref-tb\">')\n",
        "    for _, r in lin_df.iterrows():\n",
        "        first = str(r.get(\"First Ancestor\",\"\")).strip()\n",
        "        cnt   = int(str(r.get(\"Count\",\"0\")).strip() or \"0\")\n",
        "        tr = (\n",
        "            f'<tr data-q=\"{_html.escape(first, quote=True)}\" data-count=\"{cnt}\">'\n",
        "            f'<td>{_html.escape(first)}</td>'\n",
        "            f'<td class=\"count\"><a href=\"#\" class=\"count-pick\" title=\"Toggle select\">{cnt}</a></td>'\n",
        "            f'</tr>'\n",
        "        )\n",
        "        html.append(tr)\n",
        "    html.append('</tbody></table>')\n",
        "    html.append(_shell_close())\n",
        "    return \"\".join(html)\n",
        "\n",
        "def build_and_write_partials(main_df: pd.DataFrame):\n",
        "    _setup_resolver()\n",
        "    os.makedirs(\"partials\", exist_ok=True)\n",
        "\n",
        "    mc_html = build_match_count_partial(main_df)\n",
        "    mc_local = os.path.join(\"partials\", \"match_count.htm\")\n",
        "    with open(mc_local, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(mc_html)\n",
        "    print(\"[OK] Wrote partial:\", mc_local)\n",
        "\n",
        "    lc_html = build_lineage_count_partial(main_df)\n",
        "    lc_local = os.path.join(\"partials\", \"lineage_count.htm\")\n",
        "    with open(lc_local, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(lc_html)\n",
        "    print(\"[OK] Wrote partial:\", lc_local)\n",
        "\n",
        "    # Printable cousin list\n",
        "    cousin_df = main_df[[\"Match Summary\"]].copy()\n",
        "    cousin_df = cousin_df.sort_values(by=\"Match Summary\", ascending=True, kind=\"mergesort\").reset_index(drop=True)\n",
        "    cousin_rows = ['<table border=\"1\" id=\"refactor-table\"><thead><tr><th>Match Summary</th></tr></thead><tbody>']\n",
        "    for v in cousin_df[\"Match Summary\"].tolist():\n",
        "        cousin_rows.append(f\"<tr><td>{v}</td></tr>\")\n",
        "    cousin_rows.append(\"</tbody></table>\")\n",
        "    cousin_html = (\n",
        "        \"<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Transitional//EN\\\" \\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\\\">\"\n",
        "        \"<html xmlns=\\\"http://www.w3.org/1999/xhtml\\\" lang=\\\"en\\\"><head>\"\n",
        "        f\"{HEAD_LINK}\"\n",
        "        \"<meta http-equiv=\\\"Content-Type\\\" content=\\\"text/html; charset=iso-8859-15\\\" />\"\n",
        "        \"<title>Cousin List (Printable)</title>\"\n",
        "        \"<style type=\\\"text/css\\\"> body{font-size:12px;margin:20px;} h1{text-align:center;font-size:20px;} table{border-collapse:collapse;width:100%;} th,td{border:1px solid #999;padding:5px 7px;vertical-align:top;text-align:left;} th{background:#f0f0f0;} a{color:#000;text-decoration:none;} </style>\"\n",
        "        \"</head><body onload=\\\"window.print();\\\">\"\n",
        "        \"<h1>Cousin List (Printable)</h1>\" + \"\".join(cousin_rows) +\n",
        "        \"</body></html>\"\n",
        "    )\n",
        "    cl_local = os.path.join(\"partials\", \"cousin_list_print.htm\")\n",
        "    with open(cl_local, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(cousin_html)\n",
        "    print(\"[OK] Wrote partial:\", cl_local)\n",
        "\n",
        "    return mc_local, lc_local, cl_local\n",
        "\n",
        "# Build partials + main page\n",
        "PARTIAL_MATCH_LOCAL, PARTIAL_LINEAGE_LOCAL, PARTIAL_COUSIN_LOCAL = build_and_write_partials(df)\n",
        "\n",
        "def build_register_html_for_abs(remote_abs_path: str) -> str:\n",
        "    q_links = []\n",
        "    subs = df[\"Subject\"].astype(str).tolist()\n",
        "    for subject_name in subs:\n",
        "        q = _u.quote(subject_name)\n",
        "        q_links.append(\n",
        "            f'<a class=\"find-btn\" href=\"{remote_abs_path}?q={q}\" target=\"_blank\" rel=\"noopener\" '\n",
        "            f'title=\"Open a filtered view for {subject_name}\">Find</a>'\n",
        "        )\n",
        "    df_plus = df.copy()\n",
        "    df_plus[\"Find\"] = q_links\n",
        "    disp_plus = df_plus[[\"Find\",\"Match Summary\", LINEAGE_HEADER_SAFE]]\n",
        "    tbl = disp_plus.to_html(index=False, escape=False, classes=\"dataframe sortable\")\n",
        "    tbl = tbl.replace('<table border=\"1\" class=\"dataframe sortable\">','<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">',1)\n",
        "    tbl = tbl.replace('<tbody>\\n<tr>', '<tbody>\\n<tr id=\"first-row\">', 1)\n",
        "    tbl = tbl.replace(\"<th>Find</th>\", '<th>Select:</th>', 1)\n",
        "    tbl = tbl.replace(\"<th>Match Summary</th>\", '<th>Match Summary&amp;ndash;click to sort</th>', 1)\n",
        "    tbl = tbl.replace(f\"<th>{_html.escape(LINEAGE_HEADER_SAFE)}</th>\", \"<th>Lineage (Starting with oldest ancestor&amp;ndash;click to sort)</th>\", 1)\n",
        "\n",
        "    colgroup_html_local = (\n",
        "        \"<colgroup>\\n\"\n",
        "        f\"  <col style=\\\"width:{FIND_COL_PX}px;\\\" />\\n\"\n",
        "        f\"  <col style=\\\"width:{COL_A_PX}px;\\\" />\\n\"\n",
        "        \"  <col />\\n\"\n",
        "        \"</colgroup>\\n\"\n",
        "    )\n",
        "    tbl = tbl.replace(\n",
        "        '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">',\n",
        "        '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">\\n' + colgroup_html_local, 1\n",
        "    )\n",
        "    return page_tpl.safe_substitute(\n",
        "        HEAD_LINK=HEAD_LINK,\n",
        "        TABLE_CSS=TABLE_CSS,\n",
        "        UPDATED_BLOCK=UPDATED_BLOCK,\n",
        "        DYNAMIC_BLOCK=DYNAMIC_BLOCK,\n",
        "        HTML_TABLE=tbl,\n",
        "        JS_COUNT_URL=JS_COUNT_URL,\n",
        "        DOWNLOADS_BLOCK=DOWNLOADS_BLOCK\n",
        "    ).replace(\"$HEAD_LINK_URL_JS$\", (STYLESHEET_HREF + \"?\" + CSS_VERSION))\n",
        "\n",
        "os.makedirs(\"partials\", exist_ok=True)\n",
        "final_html_plus = build_register_html_for_abs(HOME_URL)\n",
        "\n",
        "with open(LOCAL_HTML, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(final_html)\n",
        "print(\"[OK] Saved canonical render:\", os.path.abspath(LOCAL_HTML))\n",
        "\n",
        "with open(WORK_PLUS_LOCAL, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(final_html_plus)\n",
        "print(\"[OK] Saved:\", os.path.abspath(WORK_PLUS_LOCAL), \"(partials clone)\")\n",
        "\n",
        "# ---------- 10) Uploads ----------\n",
        "def save_and_upload_all():\n",
        "    if not all(os.environ.get(k) for k in ['FTP_HOST','FTP_USER','FTP_PASS']):\n",
        "        print(\"[SKIP] Missing FTP creds; uploads skipped.\")\n",
        "        return\n",
        "    try:\n",
        "        ftps = ftp_connect()\n",
        "        try:\n",
        "            ftp_upload_overwrite(ftps, LOCAL_HTML, _remote_path(REMOTE_HTML_CANON))\n",
        "            ftp_upload_overwrite(ftps, LOCAL_HTML, _remote_path(REMOTE_HTML_LEG))\n",
        "            ftp_upload_overwrite(ftps, LOCAL_HTML, _remote_path(REMOTE_HTML_SIMPLE))\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload main HTML failed:\", e)\n",
        "        try:\n",
        "            if os.path.exists(LOCAL_CSV):\n",
        "                ftp_upload_overwrite(ftps, LOCAL_CSV, _remote_path(REMOTE_CSV))\n",
        "            if os.path.exists(LOCAL_XLSX):\n",
        "                ftp_upload_overwrite(ftps, LOCAL_XLSX, _remote_path(REMOTE_XLSX))\n",
        "            print(\"[OK] Uploaded CSV/XLSX -> /partials/\")\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload CSV/XLSX failed:\", e)\n",
        "        if os.path.exists(LOCAL_COUNT_FILE):\n",
        "            try:\n",
        "                ftp_upload_overwrite(ftps, LOCAL_COUNT_FILE, _remote_path(REMOTE_COUNT_NAME))\n",
        "            except Exception as e:\n",
        "                print(\"[WARN] Upload autosomal count failed:\", e)\n",
        "        try:\n",
        "            ftp_upload_overwrite(ftps, os.path.join(\"partials\",\"match_count.htm\"),       _remote_path(posixpath.join(\"partials\",\"match_count.htm\")))\n",
        "            ftp_upload_overwrite(ftps, os.path.join(\"partials\",\"lineage_count.htm\"),     _remote_path(posixpath.join(\"partials\",\"lineage_count.htm\")))\n",
        "            ftp_upload_overwrite(ftps, os.path.join(\"partials\",\"cousin_list_print.htm\"), _remote_path(posixpath.join(\"partials\",\"cousin_list_print.htm\")))\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload partials failed:\", e)\n",
        "        try:\n",
        "            ftp_upload_overwrite(ftps, WORK_PLUS_LOCAL, _remote_path(WORK_PLUS_REMOTE))\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload work_plus.htm failed:\", e)\n",
        "\n",
        "        print(\"\\n--- SIZE Verification (if supported) ---\")\n",
        "        for p in [\n",
        "            _remote_path(REMOTE_HTML_CANON),\n",
        "            _remote_path(REMOTE_HTML_LEG),\n",
        "            _remote_path(REMOTE_HTML_SIMPLE),\n",
        "            _remote_path(REMOTE_CSV),\n",
        "            _remote_path(REMOTE_XLSX),\n",
        "            _remote_path(posixpath.join(\"partials\",\"match_count.htm\")),\n",
        "            _remote_path(posixpath.join(\"partials\",\"lineage_count.htm\")),\n",
        "            _remote_path(posixpath.join(\"partials\",\"cousin_list_print.htm\")),\n",
        "            _remote_path(WORK_PLUS_REMOTE),\n",
        "        ]:\n",
        "            sz = ftp_size(ftps, p)\n",
        "            print(f\"{p} : {sz if sz is not None else '(SIZE unsupported)'}\")\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "\n",
        "        print(\"\\n--- Open URLs ---\")\n",
        "        print(\"Canonical (Find target):          https://yates.one-name.net/partials/yates_ancestor_register.htm\")\n",
        "        print(\"Legacy clone (same content):      https://yates.one-name.net/partials/ons_yates_dna_register.htm\")\n",
        "        print(\"JUSTDNA simple alias:             https://yates.one-name.net/partials/justdna.htm\")\n",
        "        print(\"Trees page:                       https://yates.one-name.net/partials/just-trees.htm\")\n",
        "        print(\"Match Count:                      https://yates.one-name.net/partials/match_count.htm\")\n",
        "        print(\"Lineage Count:                    https://yates.one-name.net/partials/lineage_count.htm\")\n",
        "        print(\"Cousin List (Printable):          https://yates.one-name.net/partials/cousin_list_print.htm\")\n",
        "        print(\"Work+ clone:                      https://yates.one-name.net/partials/work_plus.htm\")\n",
        "\n",
        "        print(\"\\nIf a button still opens the wrong target, hard-refresh or append ?v=1 once to bust cache.\")\n",
        "    except Exception as e:\n",
        "        print(\"[FAIL] FTP session:\", e)\n",
        "        traceback.print_exc()\n",
        "\n",
        "# ---------- 11) Upload ----------\n",
        "save_and_upload_all()\n",
        "# ====== CUT STOP [1/1] CELL 2 ===================================================================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WrsvxmPQ9uT",
        "outputId": "37fa7516-8c5f-48ae-ed68-f9f7eff02e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Loaded CSV: 7 rows, 6 cols\n",
            "[PULL] match_to_unmasked.csv -> /content/match_to_unmasked.server.csv\n",
            "[OK] Resolver loaded: 79 codes\n",
            "[OK] Wrote exports: /content/yates_ancestor_register.csv and /content/yates_ancestor_register.xlsx\n",
            "[OK] Wrote partial: partials/match_count.htm\n",
            "[OK] Wrote partial: partials/lineage_count.htm\n",
            "[OK] Wrote partial: partials/cousin_list_print.htm\n",
            "[OK] Saved canonical render: /content/yates_ancestor_register.htm\n",
            "[OK] Saved: /content/partials/work_plus.htm (partials clone)\n",
            "[PUT] yates_ancestor_register.htm -> partials/yates_ancestor_register.htm\n",
            "[PUT] yates_ancestor_register.htm -> partials/ons_yates_dna_register.htm\n",
            "[PUT] yates_ancestor_register.htm -> partials/justdna.htm\n",
            "[PUT] yates_ancestor_register.csv -> partials/yates_ancestor_register.csv\n",
            "[PUT] yates_ancestor_register.xlsx -> partials/yates_ancestor_register.xlsx\n",
            "[OK] Uploaded CSV/XLSX -> /partials/\n",
            "[PUT] /content/autosomal_count.txt -> autosomal_count.txt\n",
            "[PUT] partials/match_count.htm -> partials/match_count.htm\n",
            "[PUT] partials/lineage_count.htm -> partials/lineage_count.htm\n",
            "[PUT] partials/cousin_list_print.htm -> partials/cousin_list_print.htm\n",
            "[PUT] partials/work_plus.htm -> partials/work_plus.htm\n",
            "\n",
            "--- SIZE Verification (if supported) ---\n",
            "partials/yates_ancestor_register.htm : 18794\n",
            "partials/ons_yates_dna_register.htm : 18794\n",
            "partials/justdna.htm : 18794\n",
            "partials/yates_ancestor_register.csv : 2957\n",
            "partials/yates_ancestor_register.xlsx : 6704\n",
            "partials/match_count.htm : 6347\n",
            "partials/lineage_count.htm : 6517\n",
            "partials/cousin_list_print.htm : 3165\n",
            "partials/work_plus.htm : 18794\n",
            "\n",
            "--- Open URLs ---\n",
            "Canonical (Find target):          https://yates.one-name.net/partials/yates_ancestor_register.htm\n",
            "Legacy clone (same content):      https://yates.one-name.net/partials/ons_yates_dna_register.htm\n",
            "JUSTDNA simple alias:             https://yates.one-name.net/partials/justdna.htm\n",
            "Trees page:                       https://yates.one-name.net/partials/just-trees.htm\n",
            "Match Count:                      https://yates.one-name.net/partials/match_count.htm\n",
            "Lineage Count:                    https://yates.one-name.net/partials/lineage_count.htm\n",
            "Cousin List (Printable):          https://yates.one-name.net/partials/cousin_list_print.htm\n",
            "Work+ clone:                      https://yates.one-name.net/partials/work_plus.htm\n",
            "\n",
            "If a button still opens the wrong target, hard-refresh or append ?v=1 once to bust cache.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEST Cell 2\n"
      ],
      "metadata": {
        "id": "9RkUt92dnLP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ====== CUT START [1/1] CELL 2 — Build + Publish DNA Register (Unified: Best Display + Correct First-Ancestor) ======\n",
        "# RON RULES — QUICK CODE CARD (v2025.11.08-Cell2-UNIFIED-BEST)\n",
        "# - Complete & runnable in Colab; ASCII-only source (ISO-8859-15 safe outputs).\n",
        "# - XHTML 1.0 Transitional; explicit prints; no fabrication.\n",
        "# - Typography is controlled ONLY by /partials/dna_tree_styles.css (no inline font-family anywhere).\n",
        "# - Row-highlight FIX is limited to PARTIALS ONLY (not the main register page).\n",
        "# - Publishes SAME HTML to:\n",
        "#       /partials/yates_ancestor_register.htm     (canonical, Find target)\n",
        "#       /partials/ons_yates_dna_register.htm     (legacy clone)\n",
        "#       /partials/justdna.htm                     (JUSTDNA alias)\n",
        "# - Also writes PARTIALS (match_count.htm, lineage_count.htm, cousin_list_print.htm) and CSV/XLSX exports.\n",
        "\n",
        "import os, re, io, posixpath, socket, traceback, urllib.parse as _u\n",
        "from ftplib import FTP_TLS\n",
        "import pandas as pd\n",
        "import html as _html\n",
        "from string import Template\n",
        "\n",
        "# ---------- 0) Secrets ----------\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ['FTP_HOST'] = userdata.get('FTP_HOST')\n",
        "    os.environ['FTP_USER'] = userdata.get('FTP_USER')\n",
        "    os.environ['FTP_PASS'] = userdata.get('FTP_PASS')\n",
        "    try: os.environ['FTP_DIR']  = userdata.get('FTP_DIR')\n",
        "    except Exception: os.environ.setdefault('FTP_DIR', '')\n",
        "    try: os.environ['FTP_PORT'] = userdata.get('FTP_PORT')\n",
        "    except Exception: os.environ.setdefault('FTP_PORT', '21')\n",
        "except Exception:\n",
        "    os.environ.setdefault('FTP_HOST', '')\n",
        "    os.environ.setdefault('FTP_USER', '')\n",
        "    os.environ.setdefault('FTP_PASS', '')\n",
        "    os.environ.setdefault('FTP_DIR',  '')\n",
        "    os.environ.setdefault('FTP_PORT', '21')\n",
        "\n",
        "# ---------- 1) Config ----------\n",
        "CSV_IN = \"final_combined_df_with_value_labels.csv\"\n",
        "\n",
        "LOCAL_HTML         = \"yates_ancestor_register.htm\"\n",
        "REMOTE_HTML_CANON  = posixpath.join(\"partials\", \"yates_ancestor_register.htm\")\n",
        "REMOTE_HTML_LEG    = posixpath.join(\"partials\", \"ons_yates_dna_register.htm\")\n",
        "REMOTE_HTML_SIMPLE = posixpath.join(\"partials\", \"justdna.htm\")\n",
        "\n",
        "DNA_REGISTER_ABS = \"https://yates.one-name.net/partials/justdna.htm\"\n",
        "TREES_ABS        = \"https://yates.one-name.net/partials/just-trees.htm\"\n",
        "\n",
        "EXPORT_BASENAME = \"yates_ancestor_register\"\n",
        "LOCAL_CSV       = f\"{EXPORT_BASENAME}.csv\"\n",
        "LOCAL_XLSX      = f\"{EXPORT_BASENAME}.xlsx\"\n",
        "REMOTE_CSV      = posixpath.join(\"partials\", os.path.basename(LOCAL_CSV))\n",
        "REMOTE_XLSX     = posixpath.join(\"partials\", os.path.basename(LOCAL_XLSX))\n",
        "\n",
        "WORK_PLUS_LOCAL  = os.path.join(\"partials\", \"work_plus.htm\")\n",
        "WORK_PLUS_REMOTE = posixpath.join(\"partials\", \"work_plus.htm\")\n",
        "\n",
        "LOCAL_COUNT_FILE  = \"/content/autosomal_count.txt\"\n",
        "REMOTE_COUNT_NAME = \"autosomal_count.txt\"\n",
        "\n",
        "FTP_DIR         = (os.environ.get(\"FTP_DIR\",\"\") or \"\").strip()\n",
        "TNG_BASE        = \"https://yates.one-name.net/tng\"\n",
        "TNG_TREE        = \"tree1\"\n",
        "HOME_URL        = \"https://yates.one-name.net/partials/yates_ancestor_register.htm\"\n",
        "REMOTE_NAME_ABS = HOME_URL\n",
        "COUNT_PUBLIC_URL = (f\"/{FTP_DIR}/{REMOTE_COUNT_NAME}\" if FTP_DIR else f\"/{REMOTE_COUNT_NAME}\")\n",
        "\n",
        "# Layout\n",
        "TABLE_WIDTH_PX = 3150\n",
        "COL_A_PX       = 1100\n",
        "FIND_COL_PX    = 118\n",
        "ARROW_ENTITY   = \"&rarr;\"\n",
        "REMOVE_PERIOD_AT_END = True\n",
        "\n",
        "# Resolver (server mapping for Match-to -> Unmasked)\n",
        "SERVER_PARTIALS_DIR        = \"partials\"\n",
        "SERVER_MAPPING_BASENAME    = \"match_to_unmasked.csv\"\n",
        "SERVER_MAPPING_REMOTE      = posixpath.join(SERVER_PARTIALS_DIR, SERVER_MAPPING_BASENAME)\n",
        "SERVER_MAPPING_LOCAL_CACHE = \"match_to_unmasked.server.csv\"\n",
        "\n",
        "# External stylesheet (controls typography site-wide)\n",
        "STYLESHEET_HREF = \"/partials/dna_tree_styles.css\"\n",
        "CSS_VERSION     = \"v2025-11-06\"  # bump to bust caches when CSS changes\n",
        "HEAD_LINK       = f'<link rel=\"stylesheet\" type=\"text/css\" href=\"{STYLESHEET_HREF}?{CSS_VERSION}\" />'\n",
        "HEAD_LINK_URL   = STYLESHEET_HREF + \"?\" + CSS_VERSION  # used inside JS (print window)\n",
        "\n",
        "# ---------- 2) FTP helpers ----------\n",
        "FTP_TIMEOUT = int(os.environ.get(\"FTP_TIMEOUT\", \"30\"))\n",
        "FTP_PASSIVE = True\n",
        "\n",
        "def ftp_connect() -> FTP_TLS:\n",
        "    ftps = FTP_TLS(timeout=FTP_TIMEOUT)\n",
        "    socket.setdefaulttimeout(FTP_TIMEOUT)\n",
        "    ftps.connect(os.environ.get('FTP_HOST',''), int(os.environ.get('FTP_PORT', 21)))\n",
        "    ftps.login(os.environ.get('FTP_USER',''), os.environ.get('FTP_PASS',''))\n",
        "    try: ftps.prot_p()\n",
        "    except Exception: pass\n",
        "    try: ftps.set_pasv(FTP_PASSIVE)\n",
        "    except Exception: pass\n",
        "    if FTP_DIR:\n",
        "        parts = [p for p in FTP_DIR.split(\"/\") if p]\n",
        "        for p in parts:\n",
        "            try: ftps.mkd(p)\n",
        "            except Exception: pass\n",
        "            ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "def _remote_path(name: str) -> str:\n",
        "    return posixpath.join(FTP_DIR, name) if FTP_DIR else name\n",
        "\n",
        "def ensure_remote_dirs(ftps: FTP_TLS, remote_path: str):\n",
        "    if \"/\" not in remote_path: return\n",
        "    pwd0 = ftps.pwd()\n",
        "    for seg in [p for p in remote_path.split(\"/\")[:-1] if p and p != \".\"]:\n",
        "        try: ftps.cwd(seg)\n",
        "        except Exception:\n",
        "            try: ftps.mkd(seg)\n",
        "            except Exception: pass\n",
        "            ftps.cwd(seg)\n",
        "    ftps.cwd(pwd0)\n",
        "\n",
        "def ftp_download_if_exists(ftps: FTP_TLS, remote_name: str, local_name: str) -> bool:\n",
        "    try:\n",
        "        with open(local_name, \"wb\") as f:\n",
        "            ftps.retrbinary(f\"RETR {remote_name}\", f.write)\n",
        "        print(f\"[PULL] {remote_name} -> {os.path.abspath(local_name)}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            if os.path.exists(local_name): os.remove(local_name)\n",
        "        except Exception: pass\n",
        "        print(f\"[MISS] {remote_name} ({e})\")\n",
        "        return False\n",
        "\n",
        "def ftp_upload_overwrite(ftps: FTP_TLS, local_path: str, remote_name: str):\n",
        "    ensure_remote_dirs(ftps, remote_name)\n",
        "    with open(local_path, \"rb\") as fh:\n",
        "        ftps.storbinary(f\"STOR {remote_name}\", fh)\n",
        "    print(f\"[PUT]  {local_path} -> {remote_name}\")\n",
        "\n",
        "def ftp_size(ftps: FTP_TLS, remote_name: str):\n",
        "    try:\n",
        "        sz = ftps.size(remote_name)\n",
        "        return int(sz) if sz is not None else None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# ---------- 3) Resolver ----------\n",
        "def _read_mapping_csv(path: str) -> pd.DataFrame:\n",
        "    encs = (\"iso-8859-15\",\"utf-8-sig\",\"utf-8\",\"cp1252\",\"latin1\")\n",
        "    last = None; df = None\n",
        "    for enc in encs:\n",
        "        try:\n",
        "            df = pd.read_csv(path, encoding=enc, dtype=str, keep_default_na=False)\n",
        "            break\n",
        "        except Exception as e:\n",
        "            last = e\n",
        "    if df is None:\n",
        "        raise RuntimeError(f\"Unable to read mapping CSV {path}: {last}\")\n",
        "    if df.shape[1] < 2:\n",
        "        raise RuntimeError(\"Mapping CSV must have at least two columns: code, unmasked\")\n",
        "    df = df.iloc[:, :2].copy()\n",
        "    df.columns = [\"code\",\"unmasked\"]\n",
        "    df[\"code\"] = df[\"code\"].astype(str).str.strip().str.lower()\n",
        "    df[\"unmasked\"] = df[\"unmasked\"].astype(str).str.strip()\n",
        "    df = df[df[\"code\"] != \"\"].drop_duplicates(subset=[\"code\"], keep=\"first\")\n",
        "    if df.empty:\n",
        "        raise RuntimeError(\"Mapping CSV empty after normalization.\")\n",
        "    return df\n",
        "\n",
        "def load_resolver_from_server() -> dict:\n",
        "    with ftp_connect() as ftps:\n",
        "        try:\n",
        "            ftps.cwd(SERVER_PARTIALS_DIR)\n",
        "        except Exception:\n",
        "            pass\n",
        "        ok = ftp_download_if_exists(ftps, SERVER_MAPPING_BASENAME, SERVER_MAPPING_LOCAL_CACHE)\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "    if not ok:\n",
        "        raise RuntimeError(\n",
        "            \"Resolver not found on server: /\" + _remote_path(SERVER_MAPPING_REMOTE) +\n",
        "            \". Upload match_to_unmasked.csv into /partials/ and re-run.\"\n",
        "        )\n",
        "    df_map = _read_mapping_csv(SERVER_MAPPING_LOCAL_CACHE)\n",
        "    print(f\"[OK] Resolver loaded: {len(df_map)} codes\")\n",
        "    return dict(zip(df_map[\"code\"], df_map[\"unmasked\"]))\n",
        "\n",
        "MATCH_TO_UNMASKED = {}\n",
        "def _setup_resolver():\n",
        "    global MATCH_TO_UNMASKED\n",
        "    if not MATCH_TO_UNMASKED:\n",
        "        MATCH_TO_UNMASKED = load_resolver_from_server()\n",
        "\n",
        "def resolve_match_to(code: str) -> str:\n",
        "    if not isinstance(code, str): return \"\"\n",
        "    return MATCH_TO_UNMASKED.get(code.strip().lower(), code)\n",
        "\n",
        "# ---------- 4) Name & text utils (UNIFIED: learnings from both versions) ----------\n",
        "SEP_RE = re.compile(r\"\\s*(?:\\u2192|&rarr;|;|>|,|~{2,}|/{2,}|\\|{2,})\\s*\")\n",
        "def split_tokens(s):\n",
        "    if pd.isna(s): return []\n",
        "    if not isinstance(s, str): s = str(s)\n",
        "    return [p.strip() for p in SEP_RE.split(s) if str(p).strip()]\n",
        "\n",
        "def _clean_piece(text: str) -> str:\n",
        "    t = re.sub(r'~+', ' ', str(text)); t = re.sub(r'\\s+', ' ', t)\n",
        "    return t.strip()\n",
        "\n",
        "_PARTICLES = {\"de\",\"del\",\"della\",\"der\",\"van\",\"von\",\"da\",\"dos\",\"das\",\"di\",\"la\",\"le\",\"du\",\"of\"}\n",
        "\n",
        "def _smart_title(token: str) -> str:\n",
        "    if not token: return token\n",
        "    token = re.sub(r\"(^|\\b)([a-z])(['’])([a-z])\", lambda m: m.group(1)+m.group(2).upper()+m.group(3)+m.group(4).upper(), token.lower())\n",
        "    token = \"-\".join([w.capitalize() for w in token.split(\"-\")])\n",
        "    token = re.sub(r\"\\bmc([a-z])\",  lambda m: \"Mc\"+m.group(1).upper(),  token)\n",
        "    token = re.sub(r\"\\bmac([a-z])\", lambda m: \"Mac\"+m.group(1).upper(), token)\n",
        "    return token\n",
        "\n",
        "def smart_titlecase(name: str) -> str:\n",
        "    name = _clean_piece(name)\n",
        "    if not name: return name\n",
        "    if \",\" in name:\n",
        "        last, first = [p.strip() for p in name.split(\",\", 1)]\n",
        "        pieces = (first + \" \" + last).split()\n",
        "    else:\n",
        "        pieces = name.split()\n",
        "    out = []\n",
        "    for i, w in enumerate(pieces):\n",
        "        out.append(w.lower() if (i>0 and w.lower() in _PARTICLES) else _smart_title(w))\n",
        "    return \" \".join(out)\n",
        "\n",
        "# Split CamelCase tokens like \"YatesJohn\" -> (\"Yates\",\"John\") then render \"John Yates\"\n",
        "_CAMEL_WORDS = re.compile(r\"[A-Z][a-z]*|[A-Z]+(?![a-z])|[a-z]+\")\n",
        "def surname_given_from_token(token):\n",
        "    token = token.strip()\n",
        "    if not token: return (token,)\n",
        "    idx = None\n",
        "    for i in range(1, len(token)):\n",
        "        if token[i-1].islower() and token[i].isupper():\n",
        "            idx = i; break\n",
        "    if idx is None:\n",
        "        for i in range(1, len(token)):\n",
        "            if token[i].isupper():\n",
        "                idx = i; break\n",
        "    if idx is None: return (token,)\n",
        "    surname = token[:idx]; given = token[idx:]\n",
        "    given_spaced = re.sub(r'(?<!^)([A-Z])', r' \\1', given)\n",
        "    return (f\"{given_spaced.strip()} {surname.strip()}\",)\n",
        "\n",
        "def normalize_person_name(s: str) -> str:\n",
        "    if pd.isna(s): return \"\"\n",
        "    s = _clean_piece(str(s))\n",
        "    if \",\" in s:\n",
        "        last, first = [p.strip() for p in s.split(\",\", 1)]\n",
        "        s = f\"{first} {last}\"\n",
        "    if \" \" not in s and s.isalpha():\n",
        "        return smart_titlecase(surname_given_from_token(s)[0])\n",
        "    return smart_titlecase(s)\n",
        "\n",
        "def norm_matchee_name(raw: str) -> str:\n",
        "    raw = str(raw or \"\").strip()\n",
        "    if not raw: return \"\"\n",
        "    if \" \" in raw or \",\" in raw:\n",
        "        nm = smart_titlecase(raw)\n",
        "        parts = nm.split()\n",
        "        if len(parts) == 1: return nm\n",
        "        return f\"{parts[0]} {parts[-1]}\".strip()\n",
        "    words = _CAMEL_WORDS.findall(raw)\n",
        "    while words and len(words[0]) == 1:\n",
        "        words.pop(0)\n",
        "    if not words:\n",
        "        nm = smart_titlecase(surname_given_from_token(raw)[0])\n",
        "        ps = nm.split()\n",
        "        if len(ps) == 1: return nm\n",
        "        return f\"{ps[0]} {ps[-1]}\".strip()\n",
        "    surname = smart_titlecase(words[0])\n",
        "    given_candidates = [w for w in words[1:] if w.lower() != surname.lower()]\n",
        "    if not given_candidates: return surname\n",
        "    given = smart_titlecase(given_candidates[0])\n",
        "    return f\"{given} {surname}\".strip()\n",
        "\n",
        "def truncate_first(name: str, n: int = 7) -> str:\n",
        "    name = name.strip()\n",
        "    if not name: return name\n",
        "    parts = name.split()\n",
        "    return parts[0][:n] if len(parts) == 1 else f\"{parts[0][:n]} {parts[-1]}\"\n",
        "\n",
        "def derive_common_from_first_token(tokens):\n",
        "    if not tokens: return (\"\",\"\")\n",
        "    first = _clean_piece(tokens[0])\n",
        "    parts = re.split(r\"\\s*(?:&| and )\\s*\", first, maxsplit=1, flags=re.I)\n",
        "    if len(parts) != 2: return (\"\",\"\")\n",
        "    def _norm(s):\n",
        "        # Accept \"YatesJohn\" and \"Yates, John\" and plain \"John Yates\"\n",
        "        return smart_titlecase(s) if \" \" in s or \",\" in s else smart_titlecase(surname_given_from_token(s)[0])\n",
        "    return (_norm(parts[0]), _norm(parts[1]))\n",
        "\n",
        "def degree_label_from_generations(g):\n",
        "    if g <= 1: return (\"parents\" if g == 1 else \"self\")\n",
        "    if g == 2: return \"grandparents\"\n",
        "    greats = g - 2\n",
        "    if greats == 1: return \"great-grandparents\"\n",
        "    return f\"{greats}x-great-grandparents\"\n",
        "\n",
        "def build_header(subject_name, cm_val, matchee_name_html, gens, husband, wife):\n",
        "    try:\n",
        "        cm_str = f\"{int(round(float(cm_val)))}\"\n",
        "    except Exception:\n",
        "        cm_str = (str(cm_val).strip() or \"0\")\n",
        "    degree_label = degree_label_from_generations(gens)\n",
        "    parts = [\n",
        "        f\"{subject_name} is a {cm_str} cM cousin match to {matchee_name_html}, whose\",\n",
        "        f\"{degree_label} (back {gens} Gens)\",\n",
        "        \"are\",\n",
        "        f\"{husband} & {wife}.\"\n",
        "    ]\n",
        "    s = \" \".join(parts)\n",
        "    if REMOVE_PERIOD_AT_END: s = re.sub(r'\\.\\s*$', '', s)\n",
        "    return s\n",
        "\n",
        "# ---------- 5) Read CSV; detect columns ----------\n",
        "def find_col(df, patterns, prefer_exact=None):\n",
        "    cols = list(df.columns)\n",
        "    lowmap = {c.lower(): c for c in cols}\n",
        "    if prefer_exact:\n",
        "        for name in prefer_exact:\n",
        "            if name in df.columns: return name\n",
        "            if name and name.lower() in lowmap: return lowmap[name.lower()]\n",
        "    for pat in patterns:\n",
        "        rx = re.compile(pat, re.I)\n",
        "        for c in cols:\n",
        "            if rx.search(c): return c\n",
        "    return None\n",
        "\n",
        "_encs = (\"utf-8-sig\",\"utf-8\",\"cp1252\",\"iso-8859-15\",\"latin1\")\n",
        "_last_err = None\n",
        "df = None\n",
        "for _e in _encs:\n",
        "    try:\n",
        "        df = pd.read_csv(CSV_IN, encoding=_e, dtype=str, keep_default_na=False)\n",
        "        break\n",
        "    except Exception as _ex:\n",
        "        _last_err = _ex\n",
        "        df = None\n",
        "if df is None:\n",
        "    raise RuntimeError(f\"Unable to read CSV: {CSV_IN} ({_last_err})\")\n",
        "print(f\"[OK] Loaded CSV: {len(df)} rows, {len(df.columns)} cols\")\n",
        "\n",
        "id_col    = find_col(df, [r'^(id#|personid)$'], [\"ID#\",\"ID\",\"PersonID\",\"personID\"])\n",
        "match_col = find_col(df, [r'^match\\s*to$'], [\"Match to\",\"Match\"])\n",
        "name_col  = find_col(df, [r'^name$'], [\"Name\"])\n",
        "cm_col    = find_col(df, [r'^(c\\s*:?m|cm)$', r'centi.?morgan'], [\"cM\",\"cm\"])\n",
        "path_col  = find_col(df, [r'(yates\\s*dna\\s*ancestral\\s*line|ancestral\\s*line|lineage)'], [\"Yates DNA Ancestral Line\",\"Ancestral Line\",\"Lineage\"])\n",
        "\n",
        "if not id_col:    raise ValueError(\"CSV missing an ID#/PersonID column.\")\n",
        "if not match_col: raise ValueError(\"CSV missing 'Match to' column.\")\n",
        "if not name_col:  raise ValueError(\"CSV missing 'Name' column.\")\n",
        "if not cm_col:    raise ValueError(\"CSV missing 'cM' column.\")\n",
        "if not path_col:  raise ValueError(\"CSV missing lineage/path column.\")\n",
        "\n",
        "# ---------- 6) Transform -> display_df ----------\n",
        "ID_PAT = re.compile(r\"\\bI\\d+\\b\", re.I)\n",
        "def extract_person_id(s: str) -> str:\n",
        "    m = ID_PAT.search(str(s or \"\"))\n",
        "    return m.group(0).upper() if m else \"\"\n",
        "\n",
        "_setup_resolver()\n",
        "\n",
        "headers, lineages, findcol = [], [], []\n",
        "subjects, first_ancestors  = [], []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    subject_raw  = row.get(match_col, \"\")\n",
        "    subject_name = normalize_person_name(resolve_match_to(subject_raw))\n",
        "    subject_name_b = f\"<strong>{subject_name}</strong>\" if subject_name else subject_name\n",
        "\n",
        "    pid = extract_person_id(row.get(id_col, \"\"))\n",
        "    matchee_name = norm_matchee_name(row.get(name_col, \"\")) or subject_name\n",
        "\n",
        "    if pid:\n",
        "        matchee_name_html = (\n",
        "            f'<a href=\"{TNG_BASE}/verticalchart.php?personID={pid}&tree={TNG_TREE}&parentset=0&display=vertical&generations=15\" '\n",
        "            f'target=\"_blank\" rel=\"noopener\">{matchee_name}</a>'\n",
        "        )\n",
        "    else:\n",
        "        matchee_name_html = matchee_name\n",
        "\n",
        "    cm_val = row.get(cm_col, \"0\")\n",
        "    tokens = split_tokens(row.get(path_col, \"\"))\n",
        "    gens_total = len(tokens)\n",
        "    tokens_disp = tokens[:7]\n",
        "\n",
        "    # Prefer explicit husband/wife columns if present, else derive from first token (CamelCase aware)\n",
        "    if \"common_husband\" in df.columns and \"common_wife\" in df.columns:\n",
        "        husband_raw = str(row.get(\"common_husband\",\"\")).strip()\n",
        "        wife_raw    = str(row.get(\"common_wife\",\"\")).strip()\n",
        "        if not husband_raw and not wife_raw:\n",
        "            husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "    else:\n",
        "        husband_raw, wife_raw = derive_common_from_first_token(tokens)\n",
        "\n",
        "    header_html = build_header(\n",
        "        subject_name_b,\n",
        "        cm_val,\n",
        "        matchee_name_html,\n",
        "        gens_total,\n",
        "        husband_raw,\n",
        "        wife_raw\n",
        "    )\n",
        "\n",
        "    if tokens_disp:\n",
        "        tokens_disp[0] = f\"<strong>{tokens_disp[0]}</strong>\"\n",
        "    sep = f\" {ARROW_ENTITY} \"\n",
        "    lineage_text = sep.join(tokens_disp) if tokens_disp else \"\"\n",
        "\n",
        "    q = _u.quote(subject_name)\n",
        "    quick = (\n",
        "        f'<a class=\"find-btn\" href=\"{REMOTE_NAME_ABS}?q={q}\" target=\"_blank\" rel=\"noopener\" '\n",
        "        f'title=\"Open a filtered view for {subject_name}\">Find</a>'\n",
        "    )\n",
        "\n",
        "    headers.append(header_html)\n",
        "    lineages.append(lineage_text)\n",
        "    findcol.append(quick)\n",
        "    subjects.append(subject_name)\n",
        "    first_ancestors.append(tokens[0] if tokens else \"\")\n",
        "\n",
        "LINEAGE_HEADER_SAFE = \"Lineage (Starting with oldest ancestor, the line is:)\"\n",
        "df[\"Match Summary\"]     = headers\n",
        "df[LINEAGE_HEADER_SAFE] = lineages\n",
        "df[\"Find\"]              = findcol\n",
        "df[\"Subject\"]           = subjects\n",
        "df[\"First Ancestor\"]    = [_clean_piece(x) for x in first_ancestors]\n",
        "display_df = df[[\"Find\",\"Match Summary\", LINEAGE_HEADER_SAFE]]\n",
        "\n",
        "# ---------- 6.1) Clean exports (ISO-8859-15 safe; robust) ----------\n",
        "TAG_RE = re.compile(r\"<[^>]+>\")\n",
        "def _html_to_text(s: str) -> str:\n",
        "    t = TAG_RE.sub(\"\", str(s or \"\"))\n",
        "    t = _html.unescape(t)\n",
        "    t = t.replace(\"\\u2192\", \"->\")\n",
        "    return re.sub(r\"\\s+\", \" \", t).strip()\n",
        "\n",
        "def _extract_find_url(cell_html: str) -> str:\n",
        "    m = re.search(r'href=\"([^\"]+)\"', str(cell_html or \"\"))\n",
        "    return _html.unescape(m.group(1)) if m else \"\"\n",
        "\n",
        "export_df = pd.DataFrame({\n",
        "    \"Find URL\":      [ _extract_find_url(v) for v in display_df[\"Find\"].tolist() ],\n",
        "    \"Match Summary\": [ _html_to_text(v)     for v in display_df[\"Match Summary\"].tolist() ],\n",
        "    \"Lineage\":       [ _html_to_text(v)     for v in display_df[LINEAGE_HEADER_SAFE].tolist() ],\n",
        "})\n",
        "\n",
        "# Write CSV with fallback error handler for older pandas/envs\n",
        "try:\n",
        "    export_df.to_csv(LOCAL_CSV, index=False, encoding=\"iso-8859-15\")\n",
        "except TypeError:\n",
        "    # Older pandas may not recognize encoding error args; do manual encode\n",
        "    buf = io.StringIO()\n",
        "    export_df.to_csv(buf, index=False)\n",
        "    with open(LOCAL_CSV, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(buf.getvalue())\n",
        "\n",
        "try:\n",
        "    export_df.to_excel(LOCAL_XLSX, index=False)\n",
        "except Exception:\n",
        "    with pd.ExcelWriter(LOCAL_XLSX) as _writer:\n",
        "        export_df.to_excel(_writer, index=False)\n",
        "print(\"[OK] Wrote exports:\", os.path.abspath(LOCAL_CSV), \"and\", os.path.abspath(LOCAL_XLSX))\n",
        "\n",
        "# ---------- 7) HTML (Register main page; no inline font-family) ----------\n",
        "TABLE_CSS = \"\"\"\n",
        "<style type=\"text/css\">\n",
        "  html { scroll-behavior: smooth; }\n",
        "  body { font-size:100%; background:#ffffff; color:#222; margin:0; padding:0; line-height:1.5; }\n",
        "  .wrap { max-width:3150px; margin:0 auto; background:#ffffff; padding:20px; padding-bottom:48px; }\n",
        "  a { color:#154b8b; text-decoration:none; } a:hover { text-decoration:underline; }\n",
        "  h1 { margin:0 0 4px 0; font-size:26px; line-height:1.2; text-align:center; }\n",
        "  .centerline { text-align:center; }\n",
        "  .downloads { text-align:center; margin:4px 0 10px 0; font-size:13px; }\n",
        "  .updated { font-size:12px; color:#555; text-align:center; margin:2px 0 10px 0; }\n",
        "  .sortbar { margin:6px 0 10px 0; font-size:13px; background:#ffffff; padding:6px 8px; border-radius:6px; display:flex; flex-wrap:wrap; gap:5px; align-items:center; border:1px solid #ddd; justify-content:center; }\n",
        "  .btn { display:inline-block; border:1px solid #5b79b8; background:#5b79b8; color:#fff; padding:4px 9px; text-decoration:none; cursor:pointer; border-radius:5px; line-height:1.2; }\n",
        "  .btn:hover { background:#4668aa; }\n",
        "  input.btn.search { background:#fff; color:#111; border-color:#bbb; }\n",
        "  .find-cell { white-space:nowrap; }\n",
        "  .selbox { margin-right:6px; vertical-align:middle; }\n",
        "  .table-scroll { max-height:70vh; overflow-y:auto; overflow-x:auto; border:1px solid #ddd; }\n",
        "  table.sortable { border-collapse:collapse; width:3150px; table-layout:fixed; }\n",
        "  table.sortable th, table.sortable td { border:1px solid #ddd; padding:6px 8px; vertical-align:top; }\n",
        "  table.sortable th { background:#e3eaf8; text-align:left; position:sticky; top:0; z-index:2; box-shadow:0 1px 0 #ccc; cursor:pointer; }\n",
        "  #first-row td { border-top:2px solid #999; }\n",
        "  .back-to-top { position:fixed; right:16px; bottom:16px; padding:6px 10px; border:1px solid #3e5a97; background:#5b79b8; color:#fff; cursor:pointer; border-radius:6px; font-size:12px; display:none; z-index:9999; }\n",
        "  .back-to-top:hover { background:#4668aa; }\n",
        "  #dynamicContent { margin:10px 0 14px 0; }\n",
        "  @media screen and (max-width: 820px) { .wrap { padding:12px; } h1 { font-size:22px; } }\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "DYNAMIC_BLOCK = (\n",
        "    '<div class=\"sortbar\">'\n",
        "    '<a class=\"btn\" href=\"https://yates.one-name.net/gengen/dna_cousin_surname_study.htm\" target=\"_blank\" rel=\"noopener\">Study Details</a>'\n",
        "    '<a class=\"btn\" href=\"https://yates.one-name.net/gengen/dna_theory_of_the_case.htm\" target=\"_blank\" rel=\"noopener\">Theory in Action</a>'\n",
        "    '<a class=\"btn\" href=\"/gengen/images/cousin-calculator.jpg\" target=\"_blank\" rel=\"noopener\">Cousin Connection</a>'\n",
        "    '<a class=\"btn\" href=\"/gengen/images/Shared_cM_Project_v4.jpg\" target=\"_blank\" rel=\"noopener\">Cousin by DNA</a>'\n",
        "    '<a class=\"btn\" href=\"/partials/match_count.htm\" target=\"_blank\" rel=\"noopener\">Match Count</a>'\n",
        "    '<a class=\"btn\" href=\"/partials/lineage_count.htm\" target=\"_blank\" rel=\"noopener\">Lineage Count</a>'\n",
        "    f'<a class=\"btn\" href=\"{DNA_REGISTER_ABS}\" target=\"_blank\" rel=\"noopener\">DNA Register</a>'\n",
        "    f'<a class=\"btn\" href=\"{TREES_ABS}\" target=\"_blank\" rel=\"noopener\">Trees</a>'\n",
        "    '<span class=\"btn\" id=\"show-selected\" title=\"Show all rows for the checked name(s)\">Show Selected</span>'\n",
        "    '<span class=\"btn\" id=\"show-all\" title=\"Show All\">Show All</span>'\n",
        "    '<span class=\"btn\" id=\"print-cousin-list\" style=\"cursor:pointer;\" title=\"Open a printable list of the *currently visible* rows\">Cousin List (Printable)</span>'\n",
        "    '<span class=\"btn\" id=\"clear-selected\">Reset</span>'\n",
        "    '<input type=\"text\" id=\"search-box\" class=\"btn search\" size=\"24\" value=\"\" placeholder=\"Search&amp;hellip;\" />'\n",
        "    '</div>'\n",
        ")\n",
        "\n",
        "JS_COUNT_URL = COUNT_PUBLIC_URL.replace(\"'\", \"%27\")\n",
        "UPDATED_BLOCK = (\n",
        "    '<div class=\"updated centerline\">'\n",
        "    'Last updated: <span id=\"last-updated\"></span>'\n",
        "    ' &nbsp;|&nbsp; Autosomal matches: <span id=\"auto-count\" class=\"js-count\"></span>'\n",
        "    ' &nbsp;|&nbsp; Showing: <span id=\"showing-count\"></span>'\n",
        "    '</div>'\n",
        ")\n",
        "\n",
        "DOWNLOADS_BLOCK = (\n",
        "    '<p class=\"downloads centerline\">Download: '\n",
        "    f'<a href=\"/partials/{_html.escape(os.path.basename(LOCAL_CSV))}\">CSV</a> | '\n",
        "    f'<a href=\"/partials/{_html.escape(os.path.basename(LOCAL_XLSX))}\">Excel</a></p>'\n",
        ")\n",
        "\n",
        "page_tpl = Template(\"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "<title>ONS Yates Study Autosomal DNA Register</title>\n",
        "$HEAD_LINK\n",
        "$TABLE_CSS\n",
        "<script type=\"text/javascript\">var HEAD_LINK_URL = \"$HEAD_LINK_URL\";</script>\n",
        "</head>\n",
        "<body id=\"top\">\n",
        "<div class=\"wrap\">\n",
        "  <h1 class=\"centerline\">ONS Yates Study Autosomal DNA Register</h1>\n",
        "  $DOWNLOADS_BLOCK\n",
        "  $UPDATED_BLOCK\n",
        "  $DYNAMIC_BLOCK\n",
        "  <div class=\"table-scroll\">\n",
        "    $HTML_TABLE\n",
        "  </div>\n",
        "</div>\n",
        "<button id=\"back-to-top\" class=\"back-to-top\">&#9650; Top</button>\n",
        "<script type=\"text/javascript\">\n",
        "//<![CDATA[\n",
        "(function(){\n",
        "  function textOf(cell){ return (cell && (cell.textContent || cell.innerText) || '').replace(/\\\\s+/g,' ').trim().toLowerCase(); }\n",
        "  function sortTable(tbl, colIndex, dir){\n",
        "    var tb=tbl && tbl.tBodies ? tbl.tBodies[0] : null; if(!tb) return;\n",
        "    var rows=[].slice.call(tb.rows||[]); var asc=(dir==='asc');\n",
        "    rows.sort(function(a,b){var A=textOf(a.cells[colIndex]),B=textOf(b.cells[colIndex]); if(A<B) return asc?-1:1; if(A>B) return asc?1:-1; return 0;});\n",
        "    var frag=document.createDocumentFragment(); for(var i=0;i<rows.length;i++) frag.appendChild(rows[i]); tb.appendChild(frag);\n",
        "    updateShowing();\n",
        "  }\n",
        "  function bindHeaderSort(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tHead && tbl.tHead.rows.length)) return;\n",
        "    var ths=tbl.tHead.rows[0].cells; if(!ths) return;\n",
        "    for(var i=0;i<ths.length;i++){(function(idx){\n",
        "      var th = ths[idx]; var dir='asc';\n",
        "      th.addEventListener('click',function(){\n",
        "        dir=(dir==='asc')?'desc':'asc';\n",
        "        for (var j = 0; j < ths.length; j++){ ths[j].innerHTML = ths[j].innerHTML.replace(/\\\\s+[↑↓]/,''); }\n",
        "        th.innerHTML += (dir==='asc' ? ' &uarr;' : ' &darr;');\n",
        "        sortTable(tbl,idx,dir);\n",
        "      },false);\n",
        "    })(i);}\n",
        "  }\n",
        "  function stampLastUpdated(){\n",
        "    var el = document.getElementById('last-updated'); if(!el) return;\n",
        "    var d  = new Date(document.lastModified || new Date());\n",
        "    var months = ['January','February','March','April','May','June','July','August','September','October','November','December'];\n",
        "    el.innerHTML = d.getDate() + ' ' + months[d.getMonth()] + ' ' + d.getFullYear();\n",
        "  }\n",
        "  function formatWithCommas(n){\n",
        "    try{ var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return ''; return x.toLocaleString('en-US'); }catch(e){ return String(n||''); }\n",
        "  }\n",
        "  function visibleRowCount(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return 0;\n",
        "    var rows=tbl.tBodies[0].rows, n=0;\n",
        "    for(var i=0;i<rows.length;i++){ if(rows[i].style.display!=='none') n++; }\n",
        "    return n;\n",
        "  }\n",
        "  function updateShowing(){\n",
        "    var el=document.getElementById('showing-count'); if(!el) return;\n",
        "    el.textContent = formatWithCommas(visibleRowCount());\n",
        "  }\n",
        "  function loadAutoCount(){\n",
        "    var el=document.getElementById('auto-count'); if(!el) return;\n",
        "    var url='$JS_COUNT_URL';\n",
        "    try{\n",
        "      var xhr=new XMLHttpRequest(); xhr.open('GET', url+(url.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true);\n",
        "      xhr.onreadystatechange=function(){ if(xhr.readyState===4){\n",
        "        if(xhr.status>=200&&xhr.status<300){\n",
        "          var m=(xhr.responseText||'').match(/(\\\\d+)/); var num=m?m[1]:'';\n",
        "          el.textContent = formatWithCommas(num) || '(unavailable)';\n",
        "        } else { el.textContent='(unavailable)'; }\n",
        "      }};\n",
        "      xhr.send(null);\n",
        "    }catch(e){ el.textContent='(unavailable)'; }\n",
        "  }\n",
        "  function getParam(name){ var m=location.search.match(new RegExp('[?&]'+name+'=([^&]+)')); return m?decodeURIComponent(m[1].replace(/\\\\+/g,' ')):''; }\n",
        "  function norm(s){ return String(s||'').replace(/\\\\s+/g,' ').toLowerCase(); }\n",
        "  function bindSearch(){\n",
        "    var box=document.getElementById('search-box'); var tbl=document.getElementById('refactor-table'); if(!(box && tbl && tbl.tBodies && tbl.tBodies[0])) return; var tb=tbl.tBodies[0];\n",
        "    function rowText(tr){ var t=''; for(var i=1;i<tr.cells.length;i++){ t+= ' ' + (tr.cells[i].textContent||tr.cells[i].innerText||''); } return norm(t); }\n",
        "    var cached=[]; (function seed(){ var rows=tb.rows; cached=[]; for(var i=0;i<rows.length;i++){ cached.push({el:rows[i], txt:rowText(rows[i])}); } })();\n",
        "    function apply(q){\n",
        "      q = String(q||''); var parts = q.split('|').map(function(s){return norm(s);}).filter(function(s){return !!s;});\n",
        "      for(var i=0;i<cached.length;i++){\n",
        "        var hit = !parts.length || parts.some(function(p){ return cached[i].txt.indexOf(p)>-1; });\n",
        "        cached[i].el.style.display = hit? '' : 'none';\n",
        "      }\n",
        "      updateShowing();\n",
        "    }\n",
        "    var to=null; function onInput(){ if(to) clearTimeout(to); to=setTimeout(function(){ apply(box.value); }, 60); }\n",
        "    box.addEventListener('input', onInput, false);\n",
        "    box.addEventListener('search', onInput, false);\n",
        "    var q0=getParam('q');\n",
        "    if(q0){ box.value=q0; apply(q0); try{ history.replaceState(null, '', location.pathname); }catch(e){} }\n",
        "    else { box.value=''; apply(''); setTimeout(function(){ if(!getParam('q')){ box.value=''; apply(''); } }, 0); }\n",
        "  }\n",
        "  function allRowCheckboxes(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return [];\n",
        "    var tb=tbl.tBodies[0], out=[];\n",
        "    for(var i=0;i<tb.rows.length;i++){\n",
        "      var cb=tb.rows[i].querySelector('.selbox');\n",
        "      if(cb) out.push(cb);\n",
        "    }\n",
        "    return out;\n",
        "  }\n",
        "  function bindGroupSync(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!tbl) return;\n",
        "    tbl.addEventListener('click', function(e){\n",
        "      var t=e.target||e.srcElement;\n",
        "      if(!(t && t.classList && t.classList.contains('selbox'))) return;\n",
        "      var nm = t.getAttribute('data-name') || '';\n",
        "      var checked = !!t.checked;\n",
        "      var cbs = allRowCheckboxes();\n",
        "      for(var i=0;i<cbs.length;i++){\n",
        "        if((cbs[i].getAttribute('data-name')||'') === nm){ cbs[i].checked = checked; }\n",
        "      }\n",
        "      updateShowing();\n",
        "    }, false);\n",
        "  }\n",
        "  function bindShowSelected(){\n",
        "    var btn=document.getElementById('show-selected'); if(!btn) return;\n",
        "    btn.addEventListener('click', function(){\n",
        "      var cbs = allRowCheckboxes();\n",
        "      var names = {};\n",
        "      for(var i=0;i<cbs.length;i++){ if(cbs[i].checked){ names[cbs[i].getAttribute('data-name')||''] = true; } }\n",
        "      var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "      var tb=tbl.tBodies[0];\n",
        "      for(var r=0;r<tb.rows.length;r++){\n",
        "        var cb = tb.rows[r].querySelector('.selbox');\n",
        "        var nm = cb ? (cb.getAttribute('data-name')||'') : '';\n",
        "        tb.rows[r].style.display = names[nm] ? '' : 'none';\n",
        "      }\n",
        "      updateShowing();\n",
        "    }, false);\n",
        "  }\n",
        "  function bindShowAll(){\n",
        "    var btn=document.getElementById('show-all'); if(!btn) return;\n",
        "    btn.addEventListener('click', function(){\n",
        "      var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "      var tb=tbl.tBodies[0];\n",
        "      for(var i=0;i<tb.rows.length;i++){ tb.rows[i].style.display=''; }\n",
        "      updateShowing();\n",
        "    }, false);\n",
        "  }\n",
        "  function bindClear(){\n",
        "    var btn=document.getElementById('clear-selected'); if(!btn) return;\n",
        "    btn.addEventListener('click', function(){\n",
        "      var cbs=allRowCheckboxes(); for(var i=0;i<cbs.length;i++) cbs[i].checked=false;\n",
        "      var tbl=document.getElementById('refactor-table'); if(tbl && tbl.tBodies && tbl.tBodies[0]){\n",
        "        var tb=tbl.tBodies[0]; for(var j=0;j<tb.rows.length;j++){ tb.rows[j].style.display=''; }\n",
        "      }\n",
        "      updateShowing();\n",
        "    }, false);\n",
        "  }\n",
        "  function addCheckboxes(){\n",
        "    var tbl=document.getElementById('refactor-table'); if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "    var tb=tbl.tBodies[0];\n",
        "    for(var i=0;i<tb.rows.length;i++){\n",
        "      var tr=tb.rows[i]; var cell=tr.cells[0]; var findBtn=cell ? cell.querySelector('.find-btn') : null;\n",
        "      var name = findBtn ? (findBtn.getAttribute('title')||'').replace('Open a filtered view for ','') : ('Row '+(i+1));\n",
        "      if(cell){\n",
        "        cell.classList.add('find-cell');\n",
        "        cell.innerHTML = '<input type=\"checkbox\" class=\"selbox\" title=\"Select this row\" data-name=\"'+name.replace(/\"/g,'&quot;')+'\" /> ' + cell.innerHTML.replace(/^\\\\s*/, '');\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  function bindPrintCousinList(){\n",
        "    var btn=document.getElementById('print-cousin-list'); if(!btn) return;\n",
        "    btn.addEventListener('click', function(){\n",
        "      var tbl=document.getElementById('refactor-table'); if(!tbl) return;\n",
        "      var headerHtml = ''; try{ headerHtml = tbl.tHead.innerHTML; }catch(e){}\n",
        "      var tb=tbl.tBodies[0];\n",
        "      var visibleRowsHtml = ''; var visibleCount = 0;\n",
        "      if(tb){\n",
        "        for (var i = 0; i < tb.rows.length; i++) {\n",
        "          if (tb.rows[i].style.display !== 'none') {\n",
        "            visibleRowsHtml += tb.rows[i].outerHTML;\n",
        "            visibleCount++;\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "      var css = '<style type=\"text/css\">' +\n",
        "        \"body { font-size:12px; margin: 20px; }\" +\n",
        "        \"h1 { font-size:20px; text-align:center; }\" +\n",
        "        \"table { border-collapse:collapse; width:100%; table-layout:fixed; }\" +\n",
        "        \"th, td { border:1px solid #999; padding: 5px 7px; vertical-align:top; text-align:left; word-wrap:break-word; }\" +\n",
        "        \"th { background:#f0f0f0; }\" +\n",
        "        \"a { color:#000; text-decoration:none; }\" +\n",
        "        \"th:first-child, td:first-child { display:none; }\" +\n",
        "        \"th:nth-child(2), td:nth-child(2) { width: 40% !important; }\" +\n",
        "        \"th:nth-child(3), td:nth-child(3) { width: 60% !important; }\" +\n",
        "        '</style>';\n",
        "      var link = '<link rel=\"stylesheet\" type=\"text/css\" href=\"'+(window.HEAD_LINK_URL || (typeof HEAD_LINK_URL!=='undefined'?HEAD_LINK_URL:''))+'\" />';\n",
        "      var tableHtml = '<table border=\"1\">' + '<thead>' + headerHtml + '</thead><tbody>' + visibleRowsHtml + '</tbody></table>';\n",
        "      var docHtml = '<html><head><title>Cousin List (Filtered)</title>' + link + css + '</head><body onload=\"window.print(); window.close();\">' +\n",
        "                    '<h1>Cousin List</h1>' +\n",
        "                    '<p>Showing ' + visibleCount + ' filtered records.</p>' +\n",
        "                    tableHtml +\n",
        "                    '</body></html>';\n",
        "      var win = window.open('', 'CousinPrint');\n",
        "      win.document.open(); win.document.write(docHtml); win.document.close(); win.focus();\n",
        "    }, false);\n",
        "  }\n",
        "  function initShowingStatic(){ try{ document.getElementById('showing-count').textContent = document.getElementById('refactor-table').tBodies[0].rows.length; }catch(e){} }\n",
        "  document.addEventListener('DOMContentLoaded', function(){\n",
        "    addCheckboxes();\n",
        "    stampLastUpdated();\n",
        "    loadAutoCount();\n",
        "    bindHeaderSort();\n",
        "    bindSearch();\n",
        "    bindGroupSync();\n",
        "    bindShowSelected();\n",
        "    bindShowAll();\n",
        "    bindClear();\n",
        "    bindPrintCousinList();\n",
        "    initShowingStatic();\n",
        "  });\n",
        "})();\n",
        " //]]>\n",
        "</script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\")\n",
        "\n",
        "html_table = display_df.to_html(index=False, escape=False, classes=\"dataframe sortable\")\n",
        "html_table = html_table.replace('<table border=\"1\" class=\"dataframe sortable\">', '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">', 1)\n",
        "html_table = html_table.replace('<tbody>\\n<tr>', '<tbody>\\n<tr id=\"first-row\">', 1)\n",
        "html_table = html_table.replace(\"<th>Find</th>\", '<th>Select:</th>', 1)\n",
        "html_table = html_table.replace('<th>Match Summary</th>', '<th>Match Summary&amp;ndash;click to sort</th>', 1)\n",
        "html_table = html_table.replace(f'<th>{_html.escape(LINEAGE_HEADER_SAFE)}</th>', '<th>Lineage (Starting with oldest ancestor&amp;ndash;click to sort)</th>', 1)\n",
        "\n",
        "colgroup_html = (\n",
        "    \"<colgroup>\\n\"\n",
        "    f\"  <col style=\\\"width:{FIND_COL_PX}px;\\\" />\\n\"\n",
        "    f\"  <col style=\\\"width:{COL_A_PX}px;\\\" />\\n\"\n",
        "    \"  <col />\\n\"\n",
        "    \"</colgroup>\\n\"\n",
        ")\n",
        "html_table = html_table.replace(\n",
        "    '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">',\n",
        "    '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">\\n' + colgroup_html,\n",
        "    1\n",
        ")\n",
        "\n",
        "final_html = page_tpl.safe_substitute(\n",
        "    HEAD_LINK=HEAD_LINK,\n",
        "    TABLE_CSS=TABLE_CSS,\n",
        "    UPDATED_BLOCK=UPDATED_BLOCK,\n",
        "    DYNAMIC_BLOCK=DYNAMIC_BLOCK,\n",
        "    HTML_TABLE=html_table,\n",
        "    JS_COUNT_URL=JS_COUNT_URL,\n",
        "    DOWNLOADS_BLOCK=DOWNLOADS_BLOCK,\n",
        "    HEAD_LINK_URL=HEAD_LINK_URL\n",
        ")\n",
        "\n",
        "# ---------- 8) PARTIALS (Row-color highlight fix applies here only) ----------\n",
        "def _norm_code_for_count(s):\n",
        "    t = str(s or \"\").strip()\n",
        "    if (t.startswith('\"') and t.endswith('\"')) or (t.startswith(\"'\") and t.endswith(\"'\")):\n",
        "        t = t[1:-1]\n",
        "    t = re.sub(r'\\s+', ' ', t).strip()\n",
        "    t = t.lower()\n",
        "    return t\n",
        "\n",
        "def _partial_css_wrapper_simple():\n",
        "    return (\n",
        "        HEAD_LINK +\n",
        "        \"<style type=\\\"text/css\\\">\\n\"\n",
        "        \"  html { scroll-behavior: smooth; }\\n\"\n",
        "        f\"  .wrap {{ max-width:{TABLE_WIDTH_PX}px; margin:0 auto; background:#ffffff; padding:20px 20px 18px 20px; }}\\n\"\n",
        "        \"  a { text-decoration:none; } a:hover { text-decoration:underline; }\\n\"\n",
        "        \"  h1 { margin:0 0 8px 0; font-size:24px; line-height:1.2; text-align:center; }\\n\"\n",
        "        \"  .meta { text-align:center; font-size:12px; color:#555; margin:2px 0 10px 0; }\\n\"\n",
        "        \"  .toolbar { display:flex; gap:10px; align-items:center; margin:6px 0 10px 0; flex-wrap:wrap; justify-content:center; }\\n\"\n",
        "        \"  .btn { display:inline-block; border:1px solid #5b79b8; background:#5b79b8; color:#fff; padding:4px 9px; text-decoration:none; cursor:pointer; border-radius:5px; line-height:1.2; }\\n\"\n",
        "        \"  .btn:disabled { opacity:0.5; cursor:not-allowed; }\\n\"\n",
        "        \"  table { border-collapse:collapse; width:100%; table-layout:auto; }\\n\"\n",
        "        \"  th, td { border:1px solid #ddd; padding:6px 8px; vertical-align:top; text-align:left; }\\n\"\n",
        "        \"  th { background:#e3eaf8; position:sticky; top:0; z-index:2; }\\n\"\n",
        "        \"  /* Row selection highlight FIX (partials only) */\\n\"\n",
        "        \"  tbody tr.sel td { background:#fff7d6 !important; }\\n\"\n",
        "        \"  tbody tr:hover td { background:#f9f6e8; }\\n\"\n",
        "        \"  .count a { font-weight:bold; }\\n\"\n",
        "        \"</style>\\n\"\n",
        "    )\n",
        "\n",
        "def _partial_head(title):\n",
        "    return (\n",
        "        \"<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Transitional//EN\\\"\\n\"\n",
        "        \"  \\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\\\">\\n\"\n",
        "        \"<html xmlns=\\\"http://www.w3.org/1999/xhtml\\\" lang=\\\"en\\\">\\n<head>\\n\"\n",
        "        \"<meta http-equiv=\\\"Content-Type\\\" content=\\\"text/html; charset=iso-8859-15\\\" />\\n\"\n",
        "        f\"<title>{_html.escape(title)}</title>\\n\"\n",
        "    )\n",
        "\n",
        "def _partial_toolbar():\n",
        "    safe_home = HOME_URL.replace('\"','&quot;')\n",
        "    return (\n",
        "        \"<div class=\\\"toolbar\\\">\"\n",
        "        f\"<a class=\\\"btn\\\" href=\\\"{safe_home}\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">DNA Register</a>\"\n",
        "        \" <button id=\\\"mc-show-selected\\\" class=\\\"btn\\\" title=\\\"Open DNA Register filtered to selected\\\">Show Selected</button>\"\n",
        "        \" <button id=\\\"mc-show-all\\\" class=\\\"btn\\\" title=\\\"Show all rows (this table)\\\">Show All</button>\"\n",
        "        \" <button id=\\\"mc-reset\\\" class=\\\"btn\\\" title=\\\"Clear selection and show all\\\">Reset</button>\"\n",
        "        \" <button id=\\\"view\\\" class=\\\"btn\\\" title=\\\"Open DNA Register with selected (alias)\\\">View Now</button>\"\n",
        "        \"</div>\\n\"\n",
        "    )\n",
        "\n",
        "def _partial_js_common():\n",
        "    _safe_home = HOME_URL.replace(\"'\", \"%27\")\n",
        "    safe_count = COUNT_PUBLIC_URL.replace(\"'\", \"%27\")\n",
        "    return (\n",
        "        \"<script type=\\\"text/javascript\\\">\\n//<![CDATA[\\n\"\n",
        "        \"(function(){\\n\"\n",
        "        \"  var REG = '\" + _safe_home + \"';\\n\"\n",
        "        \"  function fmt(n){ try{ var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return '0'; return x.toLocaleString('en-US'); }catch(e){ return String(n||'0'); } }\\n\"\n",
        "        \"  function selected(){ var out=[]; var tb=document.getElementById('ref-tb'); if(!tb) return out; var rows=tb.rows; for(var i=0;i<rows.length;i++){ if((' '+rows[i].className+' ').indexOf(' sel ')>-1) out.push(rows[i]); } return out; }\\n\"\n",
        "        \"  function update(){ var sel=selected(), sum=0; for(var i=0;i<sel.length;i++){ var v=parseInt((sel[i].getAttribute('data-count')||'0').replace(/[^0-9\\\\-]/g,''),10); if(!isNaN(v)) sum+=v; } var nEl=document.getElementById('sel-n'); var sEl=document.getElementById('sel-sum'); if(nEl) nEl.innerHTML=fmt(sel.length); if(sEl) sEl.innerHTML=fmt(sum); }\\n\"\n",
        "        \"  function qJoin(parts){ var out=[]; var seen={}; for(var i=0;i<parts.length;i++){ var p=String(parts[i]||''); if(p && !seen[p]){ seen[p]=1; out.push(encodeURIComponent(p)); } } return out.join('%7C'); }\\n\"\n",
        "        \"  function openRegisterForSelected(){ var sel=selected(); if(!sel.length) return; var qs=[]; for(var i=0;i<sel.length;i++){ qs.push(sel[i].getAttribute('data-q')||''); } var q = qJoin(qs); var url = REG + '?q=' + q; var w=null; try{ w=window.open(url,'RegisterFiltered'); if(!w) throw new Error('popup'); w.focus(); } catch(e){ window.location.href = url; } }\\n\"\n",
        "        \"  function toggleFrom(el){ var tr=el; while(tr && tr.nodeName && tr.nodeName.toLowerCase()!=='tr'){ tr=tr.parentNode; } if(!tr) return; var c=tr.className||''; tr.className = ((' '+c+' ').indexOf(' sel ')>-1) ? c.replace(/\\\\bsel\\\\b/,'').replace(/\\\\s{2,}/g,' ').trim() : (c?c+' ':'')+'sel'; update(); }\\n\"\n",
        "        \"  document.addEventListener('click', function(e){ var t=e.target||e.srcElement; if(!t) return; if(t.classList && t.classList.contains('count-pick')){ e.preventDefault(); toggleFrom(t); return; } if(t.id=='view' || t.id=='mc-show-selected'){ e.preventDefault(); openRegisterForSelected(); return; } if(t.id=='mc-reset'){ e.preventDefault(); var tb=document.getElementById('ref-tb'); if(tb){ var rows=tb.rows; for(var i=0;i<rows.length;i++){ rows[i].className = rows[i].className.replace(/\\\\bsel\\\\b/,'').replace(/\\\\s{2,}/g,' ').trim(); rows[i].style.display=''; } } update(); return; } if(t.id=='mc-show-all'){ e.preventDefault(); var tb2=document.getElementById('ref-tb'); if(!tb2) return; for(var k=0;k<tb2.rows.length;k++){ tb2.rows[k].style.display=''; } return; } }, false);\\n\"\n",
        "        \"  function stamp(){var el=document.getElementById('last-updated'); if(!el) return; var d=new Date(document.lastModified||new Date()); function z(n){return (n<10?'0':'')+n;} el.innerHTML=d.getFullYear()+'-'+z(d.getMonth()+1)+'-'+z(d.getDate())+' '+z(d.getHours())+':'+z(d.getMinutes());}\\n\"\n",
        "        \"  function load(){var el=document.getElementById('auto-count'); if(!el) return; var URL='\" + safe_count + \"'; try{var xhr=new XMLHttpRequest(); xhr.open('GET', URL+(URL.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true); xhr.onreadystatechange=function(){if(xhr.readyState===4){if(xhr.status>=200&&xhr.status<300){var m=(xhr.responseText||'').match(/(\\\\d+)/); el.textContent=(m?m[1]:'');} else {el.textContent='(unavailable)';}}}; xhr.send(null);}catch(e){el.textContent='(unavailable)';}}\\n\"\n",
        "        \"  document.addEventListener('DOMContentLoaded', function(){ stamp(); load(); update(); }, false);\\n\"\n",
        "        \"})();\\n\"\n",
        "        \"//]]>\\n</script>\\n\"\n",
        "    )\n",
        "\n",
        "def _shell_open(title):\n",
        "    return (\n",
        "        _partial_head(title) +\n",
        "        _partial_css_wrapper_simple() +\n",
        "        \"</head>\\n<body>\\n<div class=\\\"wrap\\\">\\n\" +\n",
        "        f\"<h1>{_html.escape(title)}</h1>\\n\" +\n",
        "        \"<div class=\\\"meta\\\">\"\n",
        "        \"Last updated: <span id=\\\"last-updated\\\"></span>\"\n",
        "        \" &nbsp;|&nbsp; Autosomal matches: <span id=\\\"auto-count\\\">&mdash;</span>\"\n",
        "        \" &nbsp;|&nbsp; Selected: <span id=\\\"sel-n\\\">0</span> &nbsp; Sum: <span id=\\\"sel-sum\\\">0</span>\"\n",
        "        \"</div>\\n\" +\n",
        "        _partial_toolbar() +\n",
        "        \"<div class=\\\"table-scroll\\\">\\n\"\n",
        "    )\n",
        "\n",
        "def _shell_close():\n",
        "    return (\n",
        "        \"</div>\\n</div>\\n\" +\n",
        "        _partial_js_common() +\n",
        "        \"</body>\\n</html>\"\n",
        "    )\n",
        "\n",
        "def _html_escape_text(s):\n",
        "    return _html.escape(str(s), quote=True)\n",
        "\n",
        "def build_match_count_partial(main_df: pd.DataFrame) -> str:\n",
        "    codes_raw = main_df[match_col].astype(str).map(lambda x: x.strip())\n",
        "    keys_norm = codes_raw.map(_norm_code_for_count)\n",
        "    counts_series = keys_norm.value_counts(dropna=False)\n",
        "    counts = counts_series.reset_index()\n",
        "    if counts.shape[1] >= 2:\n",
        "        counts.columns = [\"norm_key\", \"Count\"]\n",
        "    else:\n",
        "        counts[\"norm_key\"] = counts.index.astype(str)\n",
        "        counts[\"Count\"] = counts_series.values\n",
        "        counts = counts[[\"norm_key\",\"Count\"]]\n",
        "    first_display = {}\n",
        "    for code_disp, k in zip(codes_raw.tolist(), keys_norm.tolist()):\n",
        "        if k not in first_display and str(k) != \"\":\n",
        "            first_display[k] = code_disp\n",
        "    counts[\"Code\"] = counts[\"norm_key\"].map(lambda k: first_display.get(k, k))\n",
        "    counts[\"Unmasked\"] = counts[\"norm_key\"].map(lambda k: MATCH_TO_UNMASKED.get(k, \"\"))\n",
        "    counts = counts.sort_values(by=[\"Code\",\"Count\"], ascending=[True, False], kind=\"mergesort\").reset_index(drop=True)\n",
        "\n",
        "    html = []\n",
        "    html.append(_shell_open(\"Match Count\"))\n",
        "    html.append('<table id=\"ref-table\" border=\"1\" class=\"sortable\" style=\"width:100%\"><thead><tr>')\n",
        "    html.append('<th style=\"width:35%\">Code</th><th style=\"width:45%\">Unmasked</th><th style=\"width:20%\">Count</th>')\n",
        "    html.append('</tr></thead><tbody id=\"ref-tb\">')\n",
        "    for _, r in counts.iterrows():\n",
        "        code = r.get(\"Code\",\"\")\n",
        "        unm  = r.get(\"Unmasked\",\"\")\n",
        "        cnt  = int(str(r.get(\"Count\",\"0\")).strip() or \"0\")\n",
        "        label = (unm or code).strip()\n",
        "        tr = (\n",
        "            f'<tr data-q=\"{_html_escape_text(label)}\" data-count=\"{cnt}\">'\n",
        "            f'<td>{_html_escape_text(code)}</td>'\n",
        "            f'<td>{_html_escape_text(unm)}</td>'\n",
        "            f'<td class=\"count\"><a href=\"#\" class=\"count-pick\" title=\"Toggle select\">{cnt}</a></td>'\n",
        "            f'</tr>'\n",
        "        )\n",
        "        html.append(tr)\n",
        "    html.append('</tbody></table>')\n",
        "    html.append(_shell_close())\n",
        "    return \"\".join(html)\n",
        "\n",
        "def build_lineage_count_partial(main_df: pd.DataFrame) -> str:\n",
        "    first_series = main_df.get(\"First Ancestor\", pd.Series(dtype=str)).astype(str).map(lambda x: x.strip())\n",
        "    vc = first_series[first_series != \"\"].value_counts(dropna=False)\n",
        "    lin_df = vc.reset_index()\n",
        "    if lin_df.shape[1] >= 2:\n",
        "        lin_df.columns = [\"First Ancestor\",\"Count\"]\n",
        "    else:\n",
        "        lin_df[\"First Ancestor\"] = lin_df.index.astype(str)\n",
        "        lin_df[\"Count\"] = vc.values\n",
        "        lin_df = lin_df[[\"First Ancestor\",\"Count\"]]\n",
        "    lin_df = lin_df.sort_values([\"Count\",\"First Ancestor\"], ascending=[False, True], kind=\"mergesort\").reset_index(drop=True)\n",
        "\n",
        "    html = []\n",
        "    html.append(_shell_open(\"Lineage Count\"))\n",
        "    html.append('<table id=\"ref-table\" border=\"1\" class=\"sortable\" style=\"width:100%\"><thead><tr>')\n",
        "    html.append('<th style=\"width:80%\">First Ancestor</th><th style=\"width:20%\">Count</th>')\n",
        "    html.append('</tr></thead><tbody id=\"ref-tb\">')\n",
        "    for _, r in lin_df.iterrows():\n",
        "        first = str(r.get(\"First Ancestor\",\"\")).strip()\n",
        "        cnt   = int(str(r.get(\"Count\",\"0\")).strip() or \"0\")\n",
        "        tr = (\n",
        "            f'<tr data-q=\"{_html_escape_text(first)}\" data-count=\"{cnt}\">'\n",
        "            f'<td>{_html.escape(first)}</td>'\n",
        "            f'<td class=\"count\"><a href=\"#\" class=\"count-pick\" title=\"Toggle select\">{cnt}</a></td>'\n",
        "            f'</tr>'\n",
        "        )\n",
        "        html.append(tr)\n",
        "    html.append('</tbody></table>')\n",
        "    html.append(_shell_close())\n",
        "    return \"\".join(html)\n",
        "\n",
        "def build_and_write_partials(main_df: pd.DataFrame):\n",
        "    _setup_resolver()\n",
        "    os.makedirs(\"partials\", exist_ok=True)\n",
        "\n",
        "    mc_html = build_match_count_partial(main_df)\n",
        "    mc_local = os.path.join(\"partials\", \"match_count.htm\")\n",
        "    with open(mc_local, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(mc_html)\n",
        "    print(\"[OK] Wrote partial:\", mc_local)\n",
        "\n",
        "    lc_html = build_lineage_count_partial(main_df)\n",
        "    lc_local = os.path.join(\"partials\", \"lineage_count.htm\")\n",
        "    with open(lc_local, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(lc_html)\n",
        "    print(\"[OK] Wrote partial:\", lc_local)\n",
        "\n",
        "    cousin_df = main_df[[\"Match Summary\"]].copy()\n",
        "    cousin_df = cousin_df.sort_values(by=\"Match Summary\", ascending=True, kind=\"mergesort\").reset_index(drop=True)\n",
        "    cousin_rows = ['<table border=\"1\" id=\"refactor-table\"><thead><tr><th>Match Summary</th></tr></thead><tbody>']\n",
        "    for v in cousin_df[\"Match Summary\"].tolist():\n",
        "        cousin_rows.append(f\"<tr><td>{v}</td></tr>\")\n",
        "    cousin_rows.append(\"</tbody></table>\")\n",
        "    cousin_html = (\n",
        "        \"<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Transitional//EN\\\" \\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\\\">\"\n",
        "        \"<html xmlns=\\\"http://www.w3.org/1999/xhtml\\\" lang=\\\"en\\\"><head>\"\n",
        "        f\"{HEAD_LINK}\"\n",
        "        \"<meta http-equiv=\\\"Content-Type\\\" content=\\\"text/html; charset=iso-8859-15\\\" />\"\n",
        "        \"<title>Cousin List (Printable)</title>\"\n",
        "        \"<style type=\\\"text/css\\\"> body{font-size:12px;margin:20px;} h1{text-align:center;font-size:20px;} table{border-collapse:collapse;width:100%;} th,td{border:1px solid #999;padding:5px 7px;vertical-align:top;text-align:left;} th{background:#f0f0f0;} a{text-decoration:none;} </style>\"\n",
        "        \"</head><body onload=\\\"window.print();\\\">\"\n",
        "        \"<h1>Cousin List (Printable)</h1>\" + \"\".join(cousin_rows) +\n",
        "        \"</body></html>\"\n",
        "    )\n",
        "    cl_local = os.path.join(\"partials\", \"cousin_list_print.htm\")\n",
        "    with open(cl_local, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(cousin_html)\n",
        "    print(\"[OK] Wrote partial:\", cl_local)\n",
        "\n",
        "    return mc_local, lc_local, cl_local\n",
        "\n",
        "# Build partials + main page\n",
        "PARTIAL_MATCH_LOCAL, PARTIAL_LINEAGE_LOCAL, PARTIAL_COUSIN_LOCAL = build_and_write_partials(df)\n",
        "\n",
        "def build_register_html_for_abs(remote_abs_path: str) -> str:\n",
        "    q_links = []\n",
        "    subs = df[\"Subject\"].astype(str).tolist()\n",
        "    for subject_name in subs:\n",
        "        q = _u.quote(subject_name)\n",
        "        q_links.append(\n",
        "            f'<a class=\"find-btn\" href=\"{remote_abs_path}?q={q}\" target=\"_blank\" rel=\"noopener\" '\n",
        "            f'title=\"Open a filtered view for {subject_name}\">Find</a>'\n",
        "        )\n",
        "    df_plus = df.copy()\n",
        "    df_plus[\"Find\"] = q_links\n",
        "    disp_plus = df_plus[[\"Find\",\"Match Summary\", LINEAGE_HEADER_SAFE]]\n",
        "    tbl = disp_plus.to_html(index=False, escape=False, classes=\"dataframe sortable\")\n",
        "    tbl = tbl.replace('<table border=\"1\" class=\"dataframe sortable\">', '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">', 1)\n",
        "    tbl = tbl.replace('<tbody>\\n<tr>', '<tbody>\\n<tr id=\"first-row\">', 1)\n",
        "    tbl = tbl.replace(\"<th>Find</th>\", '<th>Select:</th>', 1)\n",
        "    tbl = tbl.replace(\"<th>Match Summary</th>\", '<th>Match Summary&amp;ndash;click to sort</th>', 1)\n",
        "    tbl = tbl.replace(f\"<th>{_html.escape(LINEAGE_HEADER_SAFE)}</th>\", \"<th>Lineage (Starting with oldest ancestor&amp;ndash;click to sort)</th>\", 1)\n",
        "    colgroup_html_local = (\n",
        "        \"<colgroup>\\n\"\n",
        "        f\"  <col style=\\\"width:{FIND_COL_PX}px;\\\" />\\n\"\n",
        "        f\"  <col style=\\\"width:{COL_A_PX}px;\\\" />\\n\"\n",
        "        \"  <col />\\n\"\n",
        "        \"</colgroup>\\n\"\n",
        "    )\n",
        "    tbl = tbl.replace(\n",
        "        '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">',\n",
        "        '<table border=\"1\" class=\"dataframe sortable\" id=\"refactor-table\">\\n' + colgroup_html_local, 1\n",
        "    )\n",
        "    return page_tpl.safe_substitute(\n",
        "        HEAD_LINK=HEAD_LINK,\n",
        "        TABLE_CSS=TABLE_CSS,\n",
        "        UPDATED_BLOCK=UPDATED_BLOCK,\n",
        "        DYNAMIC_BLOCK=DYNAMIC_BLOCK,\n",
        "        HTML_TABLE=tbl,\n",
        "        JS_COUNT_URL=JS_COUNT_URL,\n",
        "        DOWNLOADS_BLOCK=DOWNLOADS_BLOCK,\n",
        "        HEAD_LINK_URL=HEAD_LINK_URL\n",
        "    )\n",
        "\n",
        "os.makedirs(\"partials\", exist_ok=True)\n",
        "final_html_plus = build_register_html_for_abs(HOME_URL)\n",
        "\n",
        "with open(LOCAL_HTML, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(final_html)\n",
        "print(\"[OK] Saved canonical render:\", os.path.abspath(LOCAL_HTML))\n",
        "\n",
        "with open(WORK_PLUS_LOCAL, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(final_html_plus)\n",
        "print(\"[OK] Saved:\", os.path.abspath(WORK_PLUS_LOCAL), \"(partials clone)\")\n",
        "\n",
        "# ---------- 9) Uploads ----------\n",
        "def save_and_upload_all():\n",
        "    if not all(os.environ.get(k) for k in ['FTP_HOST','FTP_USER','FTP_PASS']):\n",
        "        print(\"[SKIP] Missing FTP creds; uploads skipped.\")\n",
        "        return\n",
        "    try:\n",
        "        ftps = ftp_connect()\n",
        "\n",
        "        try:\n",
        "            ftp_upload_overwrite(ftps, LOCAL_HTML, _remote_path(REMOTE_HTML_CANON))\n",
        "            ftp_upload_overwrite(ftps, LOCAL_HTML, _remote_path(REMOTE_HTML_LEG))\n",
        "            ftp_upload_overwrite(ftps, LOCAL_HTML, _remote_path(REMOTE_HTML_SIMPLE))\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload main HTML failed:\", e)\n",
        "\n",
        "        try:\n",
        "            if os.path.exists(LOCAL_CSV):\n",
        "                ftp_upload_overwrite(ftps, LOCAL_CSV, _remote_path(REMOTE_CSV))\n",
        "            if os.path.exists(LOCAL_XLSX):\n",
        "                ftp_upload_overwrite(ftps, LOCAL_XLSX, _remote_path(REMOTE_XLSX))\n",
        "            print(\"[OK] Uploaded CSV/XLSX -> /partials/\")\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload CSV/XLSX failed:\", e)\n",
        "\n",
        "        if os.path.exists(LOCAL_COUNT_FILE):\n",
        "            try:\n",
        "                ftp_upload_overwrite(ftps, LOCAL_COUNT_FILE, _remote_path(REMOTE_COUNT_NAME))\n",
        "            except Exception as e:\n",
        "                print(\"[WARN] Upload autosomal count failed:\", e)\n",
        "\n",
        "        try:\n",
        "            ftp_upload_overwrite(ftps, os.path.join(\"partials\",\"match_count.htm\"),       _remote_path(posixpath.join(\"partials\",\"match_count.htm\")))\n",
        "            ftp_upload_overwrite(ftps, os.path.join(\"partials\",\"lineage_count.htm\"),     _remote_path(posixpath.join(\"partials\",\"lineage_count.htm\")))\n",
        "            ftp_upload_overwrite(ftps, os.path.join(\"partials\",\"cousin_list_print.htm\"), _remote_path(posixpath.join(\"partials\",\"cousin_list_print.htm\")))\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload partials failed:\", e)\n",
        "\n",
        "        try:\n",
        "            ftp_upload_overwrite(ftps, WORK_PLUS_LOCAL, _remote_path(WORK_PLUS_REMOTE))\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] Upload work_plus.htm failed:\", e)\n",
        "\n",
        "        print(\"\\n--- SIZE Verification (if supported) ---\")\n",
        "        for p in [\n",
        "            _remote_path(REMOTE_HTML_CANON),\n",
        "            _remote_path(REMOTE_HTML_LEG),\n",
        "            _remote_path(REMOTE_HTML_SIMPLE),\n",
        "            _remote_path(REMOTE_CSV),\n",
        "            _remote_path(REMOTE_XLSX),\n",
        "            _remote_path(posixpath.join(\"partials\",\"match_count.htm\")),\n",
        "            _remote_path(posixpath.join(\"partials\",\"lineage_count.htm\")),\n",
        "            _remote_path(posixpath.join(\"partials\",\"cousin_list_print.htm\")),\n",
        "            _remote_path(WORK_PLUS_REMOTE),\n",
        "        ]:\n",
        "            try:\n",
        "                sz = ftp_size(ftps, p)\n",
        "                print(f\"{p} : {sz if sz is not None else '(SIZE unsupported)'}\")\n",
        "            except Exception:\n",
        "                print(f\"{p} : (check skipped)\")\n",
        "\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "\n",
        "        print(\"\\n--- Open URLs ---\")\n",
        "        print(\"Canonical (Find target):          https://yates.one-name.net/partials/yates_ancestor_register.htm\")\n",
        "        print(\"Legacy clone (same content):      https://yates.one-name.net/partials/ons_yates_dna_register.htm\")\n",
        "        print(\"JUSTDNA simple alias:             https://yates.one-name.net/partials/justdna.htm\")\n",
        "        print(\"Trees page:                       https://yates.one-name.net/partials/just-trees.htm\")\n",
        "        print(\"Match Count:                      https://yates.one-name.net/partials/match_count.htm\")\n",
        "        print(\"Lineage Count:                    https://yates.one-name.net/partials/lineage_count.htm\")\n",
        "        print(\"Cousin List (Printable):          https://yates.one-name.net/partials/cousin_list_print.htm\")\n",
        "        print(\"Work+ clone:                      https://yates.one-name.net/partials/work_plus.htm\")\n",
        "\n",
        "        print(\"\\nIf anything looks cached, hard-refresh (Ctrl/Cmd+Shift+R) or append ?v=1 once.\")\n",
        "    except Exception as e:\n",
        "        print(\"[FAIL] FTP session:\", e)\n",
        "        traceback.print_exc()\n",
        "\n",
        "# ---------- 10) Upload ----------\n",
        "save_and_upload_all()\n",
        "# ====== CUT STOP [1/1] CELL 2 ==================================================================="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUFcLOJDR2pT",
        "outputId": "1e634bf9-1b5e-403e-9ce1-bc9efa3d5281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Loaded CSV: 7 rows, 6 cols\n",
            "[PULL] match_to_unmasked.csv -> /content/match_to_unmasked.server.csv\n",
            "[OK] Resolver loaded: 79 codes\n",
            "[OK] Wrote exports: /content/yates_ancestor_register.csv and /content/yates_ancestor_register.xlsx\n",
            "[OK] Wrote partial: partials/match_count.htm\n",
            "[OK] Wrote partial: partials/lineage_count.htm\n",
            "[OK] Wrote partial: partials/cousin_list_print.htm\n",
            "[OK] Saved canonical render: /content/yates_ancestor_register.htm\n",
            "[OK] Saved: /content/partials/work_plus.htm (partials clone)\n",
            "[PUT] yates_ancestor_register.htm -> partials/yates_ancestor_register.htm\n",
            "[PUT] yates_ancestor_register.htm -> partials/ons_yates_dna_register.htm\n",
            "[PUT] yates_ancestor_register.htm -> partials/justdna.htm\n",
            "[PUT] yates_ancestor_register.csv -> partials/yates_ancestor_register.csv\n",
            "[PUT] yates_ancestor_register.xlsx -> partials/yates_ancestor_register.xlsx\n",
            "[OK] Uploaded CSV/XLSX -> /partials/\n",
            "[PUT] /content/autosomal_count.txt -> autosomal_count.txt\n",
            "[PUT] partials/match_count.htm -> partials/match_count.htm\n",
            "[PUT] partials/lineage_count.htm -> partials/lineage_count.htm\n",
            "[PUT] partials/cousin_list_print.htm -> partials/cousin_list_print.htm\n",
            "[PUT] partials/work_plus.htm -> partials/work_plus.htm\n",
            "\n",
            "--- SIZE Verification (if supported) ---\n",
            "partials/yates_ancestor_register.htm : 21149\n",
            "partials/ons_yates_dna_register.htm : 21149\n",
            "partials/justdna.htm : 21149\n",
            "partials/yates_ancestor_register.csv : 2957\n",
            "partials/yates_ancestor_register.xlsx : 6704\n",
            "partials/match_count.htm : 6304\n",
            "partials/lineage_count.htm : 6474\n",
            "partials/cousin_list_print.htm : 3165\n",
            "partials/work_plus.htm : 21149\n",
            "\n",
            "--- Open URLs ---\n",
            "Canonical (Find target):          https://yates.one-name.net/partials/yates_ancestor_register.htm\n",
            "Legacy clone (same content):      https://yates.one-name.net/partials/ons_yates_dna_register.htm\n",
            "JUSTDNA simple alias:             https://yates.one-name.net/partials/justdna.htm\n",
            "Trees page:                       https://yates.one-name.net/partials/just-trees.htm\n",
            "Match Count:                      https://yates.one-name.net/partials/match_count.htm\n",
            "Lineage Count:                    https://yates.one-name.net/partials/lineage_count.htm\n",
            "Cousin List (Printable):          https://yates.one-name.net/partials/cousin_list_print.htm\n",
            "Work+ clone:                      https://yates.one-name.net/partials/work_plus.htm\n",
            "\n",
            "If a button still opens the wrong target, hard-refresh or append ?v=1 once to bust cache.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEST Cell 3"
      ],
      "metadata": {
        "id": "ZST5Z7Gxnene"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/6] RULES + IMPORTS + SECRETS ==============================================\n",
        "# RON RULES — QUICK CODE CARD (v2025.11.05-AncReg-Exports+Partials-JustTrees-NavDNA)\n",
        "# 1) EXECUTION: Complete & runnable in Colab; ISO-8859-15 (ASCII-only in source).\n",
        "# 2) PUNCTUATION IN STRINGS: Use HTML entities (&rsquo; &ldquo; &rdquo; &mdash; &rarr;).\n",
        "# 3) CONTENT: Deliver full runnable code (no snippets). No fabrication or inference.\n",
        "# 4) Python code (inline, executable, full COLAB Cell paste-ready section); ISO-8859-15 (ASCII-only in source).\n",
        "# 5) HTML: XHTML 1.0 Transitional style acceptable; avoid HTML5-only tags if not needed.\n",
        "# 6) INTEGRITY: Work in CUT-ready sections only; exactly five # lines after each section.\n",
        "\n",
        "# Core imports\n",
        "import os, re, socket, posixpath, traceback\n",
        "import pandas as pd\n",
        "import html as _html\n",
        "\n",
        "# Time imports (fix for ZoneInfo)\n",
        "from datetime import datetime\n",
        "try:\n",
        "    from zoneinfo import ZoneInfo  # Python 3.9+\n",
        "except Exception:\n",
        "    ZoneInfo = None\n",
        "\n",
        "# FTPS\n",
        "from ftplib import FTP_TLS\n",
        "# ====== CUT STOP  [1/6] RULES + IMPORTS + SECRETS ===============================================\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "\n",
        "\n",
        "\n",
        "# ====== CUT START [2/6] SECRETS + LOAD DATA + COUNTS + PATHS ===================================\n",
        "# --- Securely load secrets (Colab or env) ---\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ['FTP_HOST'] = userdata.get('FTP_HOST')\n",
        "    os.environ['FTP_USER'] = userdata.get('FTP_USER')\n",
        "    os.environ['FTP_PASS'] = userdata.get('FTP_PASS')\n",
        "    try:  os.environ['FTP_PORT'] = userdata.get('FTP_PORT')\n",
        "    except Exception: os.environ.setdefault('FTP_PORT', '21')\n",
        "    try:  os.environ['FTP_DIR']  = userdata.get('FTP_DIR')\n",
        "    except Exception: os.environ.setdefault('FTP_DIR', '')\n",
        "except Exception:\n",
        "    os.environ.setdefault('FTP_HOST', '')\n",
        "    os.environ.setdefault('FTP_USER', '')\n",
        "    os.environ.setdefault('FTP_PASS', '')\n",
        "    os.environ.setdefault('FTP_PORT', '21')\n",
        "    os.environ.setdefault('FTP_DIR', '')\n",
        "\n",
        "FTP_DIR  = os.environ.get('FTP_DIR', '').strip().strip('/')\n",
        "COUNT_PUBLIC_URL = (\"/%s/%s\" % (FTP_DIR, \"autosomal_count.txt\")) if FTP_DIR else \"/autosomal_count.txt\"\n",
        "\n",
        "# Inputs\n",
        "INPUT_CSV   = \"final_combined_df_with_value_labels.csv\"\n",
        "\n",
        "# OUTPUT html filename stays just-trees.htm\n",
        "OUTPUT_NAME = \"just-trees.htm\"\n",
        "\n",
        "# Button target (new nav button)\n",
        "DNA_REGISTER_ABS = \"https://yates.one-name.net/partials/justdna.htm\"\n",
        "\n",
        "# Export names for CSV/XLSX (mirror visible table); served from /partials/\n",
        "EXPORT_BASE = \"yates_ancestor_register\"\n",
        "LOCAL_CSV   = EXPORT_BASE + \".csv\"\n",
        "LOCAL_XLSX  = EXPORT_BASE + \".xlsx\"\n",
        "REMOTE_CSV  = posixpath.join(\"partials\", LOCAL_CSV)\n",
        "REMOTE_XLSX = posixpath.join(\"partials\", LOCAL_XLSX)\n",
        "\n",
        "# Upload the HTML itself into /partials/ using the OUTPUT_NAME\n",
        "REMOTE_HTML = posixpath.join(\"partials\", OUTPUT_NAME)\n",
        "\n",
        "# Load CSV (robust encodings)\n",
        "df = None\n",
        "_last_err = None\n",
        "for enc in (\"utf-8-sig\",\"utf-8\",\"cp1252\",\"iso-8859-15\",\"latin1\"):\n",
        "    try:\n",
        "        df = pd.read_csv(INPUT_CSV, dtype=str, keep_default_na=False, encoding=enc)\n",
        "        break\n",
        "    except Exception as e:\n",
        "        _last_err = e\n",
        "        df = None\n",
        "if df is None:\n",
        "    raise SystemExit(\"[ERROR] Unable to read CSV: %s (%r)\" % (INPUT_CSV, _last_err))\n",
        "print(\"[OK] Loaded CSV:\", INPUT_CSV, \"rows=%d, cols=%d\" % (len(df), len(df.columns)))\n",
        "\n",
        "# Normalize haplogroup column presence\n",
        "if 'haplogroup' not in df.columns:\n",
        "    df['haplogroup'] = ''\n",
        "else:\n",
        "    df['haplogroup'] = df['haplogroup'].fillna('')\n",
        "\n",
        "# Read autosomal count locally if present (fallback display only)\n",
        "autosomal_count = None\n",
        "try:\n",
        "    with open(\"autosomal_count.txt\", \"r\") as f:\n",
        "        autosomal_count = int(re.findall(r\"(\\d+)\", f.read() or \"\")[0])\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Optional delta vs previous run\n",
        "prev_count, additional_str = None, \"\"\n",
        "if os.path.exists(\"autosomal_count_prev.txt\"):\n",
        "    try:\n",
        "        with open(\"autosomal_count_prev.txt\", \"r\") as f:\n",
        "            prev_count = int(re.findall(r\"(\\d+)\", f.read() or \"\")[0])\n",
        "        if autosomal_count is not None and prev_count is not None:\n",
        "            diff = autosomal_count - prev_count\n",
        "            if diff != 0:\n",
        "                additional_str = \" (+%d since last run)\" % diff\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# Human-readable fallback timestamp (JS will stamp dynamically at runtime)\n",
        "try:\n",
        "    _tz = ZoneInfo(\"America/New_York\") if ZoneInfo else datetime.now().astimezone().tzinfo\n",
        "except Exception:\n",
        "    _tz = datetime.now().astimezone().tzinfo\n",
        "now = datetime.now(_tz)\n",
        "updated_fallback = now.strftime(\"%Y-%m-%d %H:%M\")\n",
        "# ====== CUT STOP  [2/6] SECRETS + LOAD DATA + COUNTS + PATHS ====================================\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "\n",
        "\n",
        "\n",
        "# ====== CUT START [3/6] MAP COLUMN B (masked code) -> COLUMN C (unmasked name) =================\n",
        "# Column letters in MAIN df:\n",
        "#   A = ID#\n",
        "#   B = match to (masked)\n",
        "#   C = Unmasked Name (output)\n",
        "\n",
        "A_IDX = 0\n",
        "B_IDX = 1\n",
        "C_IDX = 2\n",
        "\n",
        "def _norm_code(s):\n",
        "    t = str(s or \"\").strip()\n",
        "    if (t.startswith('\"') and t.endswith('\"')) or (t.startswith(\"'\") and t.endswith(\"'\")):\n",
        "        t = t[1:-1]\n",
        "    t = t.replace(\"\\u00a0\", \" \").strip()\n",
        "    t = re.sub(r\"\\s{2,}\", \" \", t)\n",
        "    return t.lower()\n",
        "\n",
        "# Resolver lives on server under /partials/\n",
        "REMOTE_PATH = \"partials/match_to_unmasked.csv\"\n",
        "LOCAL_PATH  = \"match_to_unmasked.csv\"\n",
        "\n",
        "# Pull resolver if not present\n",
        "if not os.path.exists(LOCAL_PATH):\n",
        "    print(\"Pulling resolver CSV from server...\")\n",
        "    with FTP_TLS(timeout=30) as ftps:\n",
        "        ftps.connect(os.environ.get(\"FTP_HOST\",\"\"), int(os.environ.get(\"FTP_PORT\",\"21\")))\n",
        "        ftps.login(os.environ.get(\"FTP_USER\",\"\"), os.environ.get(\"FTP_PASS\",\"\"))\n",
        "        try: ftps.prot_p()\n",
        "        except Exception: pass\n",
        "        try: ftps.set_pasv(True)\n",
        "        except Exception: pass\n",
        "        if FTP_DIR:\n",
        "            for p in FTP_DIR.split(\"/\"):\n",
        "                if not p: continue\n",
        "                try: ftps.cwd(p)\n",
        "                except Exception:\n",
        "                    try: ftps.mkd(p)\n",
        "                    except Exception: pass\n",
        "                    ftps.cwd(p)\n",
        "        try: ftps.cwd(\"partials\")\n",
        "        except Exception: pass\n",
        "        with open(LOCAL_PATH, \"wb\") as f:\n",
        "            ftps.retrbinary(\"RETR match_to_unmasked.csv\", f.write)\n",
        "    print(\"Resolver saved:\", os.path.abspath(LOCAL_PATH))\n",
        "else:\n",
        "    print(\"Using cached resolver:\", os.path.abspath(LOCAL_PATH))\n",
        "\n",
        "def _load_resolver(path):\n",
        "    last_err = None\n",
        "    m = None\n",
        "    for enc in (\"utf-8-sig\",\"iso-8859-15\",\"utf-8\",\"cp1252\",\"latin1\"):\n",
        "        try:\n",
        "            m = pd.read_csv(path, dtype=str, keep_default_na=False, encoding=enc)\n",
        "            break\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            m = None\n",
        "    if m is None:\n",
        "        raise RuntimeError(\"Unable to read resolver CSV: %s (%r)\" % (path, last_err))\n",
        "    cols = {c.lower(): c for c in m.columns}\n",
        "    if \"code\" not in cols or \"unmasked\" not in cols:\n",
        "        raise ValueError(\"Resolver CSV must have columns: code, unmasked\")\n",
        "    m = m[[cols[\"code\"], cols[\"unmasked\"]]].copy()\n",
        "    m[\"__key__\"] = m[cols[\"code\"]].map(_norm_code)\n",
        "    m[\"__val__\"] = m[cols[\"unmasked\"]].astype(str)\n",
        "    m = m.drop_duplicates(subset=\"__key__\", keep=\"first\")\n",
        "    return dict(zip(m[\"__key__\"], m[\"__val__\"]))\n",
        "\n",
        "resolver_map = _load_resolver(LOCAL_PATH)\n",
        "\n",
        "if df.shape[1] < 3:\n",
        "    raise ValueError(\"Main df must have at least 3 columns: A(ID#), B(match to), C(unmasked).\")\n",
        "\n",
        "masked_raw = df.iloc[:, B_IDX].astype(str)\n",
        "masked_key = masked_raw.map(_norm_code)\n",
        "resolved   = masked_key.map(resolver_map)\n",
        "\n",
        "df.iloc[:, C_IDX] = resolved.fillna(\"\")\n",
        "\n",
        "mapped = int(resolved.notna().sum())\n",
        "total  = len(df)\n",
        "print(\"[OK] Column B -> C mapping:\", mapped, \"/\", total, \"unmatched:\", total - mapped)\n",
        "# ====== CUT STOP  [3/6] MAP COLUMN B (masked code) -> COLUMN C (unmasked name) =================\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "\n",
        "\n",
        "\n",
        "# ====== CUT START [4/6] XHTML TEMPLATE + TABLE + DOWNLOAD LINKS ================================\n",
        "_BTN_BG   = \"#5b79b8\"\n",
        "_BTN_BG_H = \"#4668aa\"\n",
        "_TH_BG    = \"#e3eaf8\"\n",
        "_LINK     = \"#154b8b\"\n",
        "\n",
        "# Fallback number text for initial render; JS will overwrite with live values\n",
        "auto_text = \"Unknown\" if autosomal_count is None else str(autosomal_count)\n",
        "\n",
        "# Download links block points to /partials/{csv,xlsx}\n",
        "DOWNLOADS_BLOCK = (\n",
        "    \"<p style=\\\"text-align:center; margin:4px 0 10px 0; font-size:13px;\\\">\"\n",
        "    \"Download: \"\n",
        "    \"<a href=\\\"/partials/%s\\\">CSV</a> | \"\n",
        "    \"<a href=\\\"/partials/%s\\\">Excel</a>\"\n",
        "    \"</p>\" % (_html.escape(LOCAL_CSV), _html.escape(LOCAL_XLSX))\n",
        ")\n",
        "\n",
        "full_html_template = \"\"\"<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
        " \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
        "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n",
        "<head>\n",
        "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
        "<title>Ancestor Register</title>\n",
        "<style type=\"text/css\">\n",
        "  html { scroll-behavior: smooth; }\n",
        "  body { margin:0; padding:0; font-family: \"Times New Roman\", Georgia, serif; background:#ffffff; color:#222; font-size:14px; }\n",
        "  a { color:%(LINK)s; text-decoration:none; } a:hover { text-decoration:underline; }\n",
        "\n",
        "  .intro { padding:20px; text-align:center; }\n",
        "  .intro h2 { margin:0 0 6px 0; font-size:24px; line-height:1.2; }\n",
        "  .meta { font-size:12px; color:#555; margin:4px 0 8px 0; display:inline-block; }\n",
        "\n",
        "  .toolbar { margin:6px auto 12px auto; display:flex; flex-wrap:wrap; gap:6px; justify-content:center; }\n",
        "  .btn { display:inline-block; border:1px solid %(BTN_BG)s; background:%(BTN_BG)s; color:#fff;\n",
        "         padding:4px 9px; border-radius:6px; font-size:13px; line-height:1.2; text-decoration:none;\n",
        "         cursor:pointer; user-select:none; transition:background 0.2s, transform 0.1s; }\n",
        "  .btn:hover { background:%(BTN_BG_H)s; transform:translateY(-1px); }\n",
        "  .btn.light { background:#ffffff; color:#111; border-color:#bbb; }\n",
        "\n",
        "  .output-table { max-height:75vh; overflow:auto; border:1px solid #ddd; margin:0 20px 24px 20px; }\n",
        "\n",
        "  table.sortable { width:100%%; border-collapse:collapse; min-width:720px; table-layout:auto; }\n",
        "  table.sortable th, table.sortable td { border:1px solid #ddd; padding:6px 8px; background:#ffffff; white-space:nowrap; }\n",
        "  table.sortable th { position:sticky; top:0; z-index:2; text-align:left; cursor:pointer; background:%(TH_BG)s; box-shadow:0 1px 0 #ccc; }\n",
        "  table.sortable tr#first-row td { border-top:2px solid #999 !important; }\n",
        "\n",
        "  #searchBox { padding:4px 8px; font-size:13px; border:1px solid #bbb; border-radius:6px; outline:none; }\n",
        "\n",
        "  .back-to-top { position:fixed; right:16px; bottom:16px; padding:6px 10px;\n",
        "                 border:1px solid %(BTN_BG)s; background:%(BTN_BG)s; color:#fff;\n",
        "                 border-radius:6px; font-size:12px; display:none; z-index:9999; cursor:pointer; }\n",
        "  .back-to-top:hover { background:%(BTN_BG_H)s; }\n",
        "\n",
        "  @media screen and (max-width: 820px) {\n",
        "    .intro { padding:14px; }\n",
        "    .output-table { margin:0 12px 20px 12px; }\n",
        "    .intro h2 { font-size:20px; }\n",
        "    table.sortable { min-width:560px; }\n",
        "  }\n",
        "</style>\n",
        "<script type=\"text/javascript\">\n",
        "//<![CDATA[\n",
        "// Basic helpers\n",
        "function _cellText(cell){\n",
        "  var t = (cell && (cell.textContent || cell.innerText) || '').replace(/\\\\s+/g,' ').replace(/^\\\\s+|\\\\s+$/g,'').toLowerCase();\n",
        "  return t;\n",
        "}\n",
        "function _asNumber(s){\n",
        "  var m = (s||'').replace(/[^0-9.\\\\-]/g,'');\n",
        "  if(m.length===0) return NaN;\n",
        "  var v = parseFloat(m);\n",
        "  return isNaN(v) ? NaN : v;\n",
        "}\n",
        "\n",
        "// Sorting\n",
        "function sortTableByColumn(tbl, colIndex, dirAsc){\n",
        "  if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "  var tb = tbl.tBodies[0];\n",
        "  var rows = Array.prototype.slice.call(tb.rows || []);\n",
        "  rows.sort(function(a,b){\n",
        "    var A = _cellText(a.cells[colIndex] || null);\n",
        "       var B = _cellText(b.cells[colIndex] || null);\n",
        "    var nA = _asNumber(A), nB = _asNumber(B);\n",
        "    if(!isNaN(nA) && !isNaN(nB)){ return dirAsc ? (nA - nB) : (nB - nA); }\n",
        "    if(A < B) return dirAsc ? -1 : 1;\n",
        "    if(A > B) return dirAsc ?  1 : -1;\n",
        "    return 0;\n",
        "  });\n",
        "  var frag = document.createDocumentFragment();\n",
        "  for(var i=0;i<rows.length;i++){ frag.appendChild(rows[i]); }\n",
        "  tb.appendChild(frag);\n",
        "  updateShowingCount();\n",
        "}\n",
        "function bindHeaderSort(){\n",
        "  var tbl = document.getElementById('refactor-table');\n",
        "  if(!(tbl && tbl.tHead && tbl.tHead.rows.length)) return;\n",
        "  var ths = tbl.tHead.rows[0].cells || [];\n",
        "  for(var i=0;i<ths.length;i++){\n",
        "    (function(idx){\n",
        "      var th = ths[idx];\n",
        "      var dirAsc = true;\n",
        "      th.addEventListener('click', function(){\n",
        "        for(var j=0;j<ths.length;j++){ ths[j].innerHTML = ths[j].innerHTML.replace(/\\\\s+[\\\\u2191\\\\u2193]$/, ''); }\n",
        "        sortTableByColumn(tbl, idx, dirAsc);\n",
        "        th.innerHTML = th.innerHTML.replace(/\\\\s+[\\\\u2191\\\\u2193]$/, '') + (dirAsc ? ' \\\\u2191' : ' \\\\u2193');\n",
        "        dirAsc = !dirAsc;\n",
        "      }, false);\n",
        "    })(i);\n",
        "  }\n",
        "}\n",
        "\n",
        "// Filter + live showing count\n",
        "function filterTable(){\n",
        "  var q = (document.getElementById('searchBox').value || '').toLowerCase();\n",
        "  var tbl = document.getElementById('refactor-table');\n",
        "  if(!(tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "  var rows = tbl.tBodies[0].rows || [];\n",
        "  for(var i=0;i<rows.length;i++){\n",
        "    var cells = rows[i].cells, hit=false;\n",
        "    for(var j=0;j<cells.length;j++){\n",
        "      var txt = (cells[j].textContent || cells[j].innerText || '').toLowerCase();\n",
        "      if(txt.indexOf(q) > -1){ hit=true; break; }\n",
        "    }\n",
        "    rows[i].style.display = hit ? '' : 'none';\n",
        "  }\n",
        "  updateShowingCount();\n",
        "}\n",
        "function updateShowingCount(){\n",
        "  var el = document.getElementById('showing-count');\n",
        "  var tbl = document.getElementById('refactor-table');\n",
        "  if(!(el && tbl && tbl.tBodies && tbl.tBodies[0])) return;\n",
        "  var rows = tbl.tBodies[0].rows || [];\n",
        "  var vis = 0;\n",
        "  for(var i=0;i<rows.length;i++){ if(rows[i].style.display !== 'none') vis++; }\n",
        "  el.textContent = vis;\n",
        "}\n",
        "\n",
        "// Dynamic stamps\n",
        "function z(n){ return (n<10 ? '0' : '') + n; }\n",
        "function stampLastUpdated(){\n",
        "  var el = document.getElementById('last-updated'); if(!el) return;\n",
        "  var d  = new Date(document.lastModified || new Date());\n",
        "  var opts = {\n",
        "    year: 'numeric',\n",
        "    month: 'long',\n",
        "    day: 'numeric',\n",
        "    hour: '2-digit',\n",
        "    minute: '2-digit',\n",
        "    hour12: false\n",
        "  };\n",
        "  var formatted = d.toLocaleString('en-US', opts).replace(',', '');\n",
        "  el.innerHTML = formatted;\n",
        "}\n",
        "\n",
        "\n",
        "function formatWithCommas(n){\n",
        "  try{ var x=parseInt(String(n||'').replace(/[^0-9\\\\-]/g,''),10); if(isNaN(x)) return ''; return x.toLocaleString('en-US'); }catch(e){ return String(n||''); }\n",
        "}\n",
        "function loadAutoCount(){\n",
        "  var el=document.getElementById('auto-count'); if(!el) return;\n",
        "  var url='{COUNT_URL}';\n",
        "  try{\n",
        "    var xhr=new XMLHttpRequest(); xhr.open('GET', url+(url.indexOf('?')>-1?'':'?v='+(new Date()).getTime()), true);\n",
        "    xhr.onreadystatechange=function(){ if(xhr.readyState===4){\n",
        "      if(xhr.status>=200&&xhr.status<300){\n",
        "        var m=(xhr.responseText||'').match(/(\\\\d+)/); var num=m?m[1]:'';\n",
        "        el.textContent = formatWithCommas(num) || '(unavailable)';\n",
        "      } else { el.textContent='(unavailable)'; }\n",
        "    }};\n",
        "    xhr.send(null);\n",
        "  }catch(e){ el.textContent='(unavailable)'; }\n",
        "}\n",
        "\n",
        "// Back-to-top\n",
        "function bindBackToTop(){\n",
        "  var btn = document.getElementById('back-to-top');\n",
        "  if(!btn) return;\n",
        "  function toggle(){ btn.style.display = (window.scrollY > 200) ? 'block' : 'none'; }\n",
        "  toggle(); window.addEventListener('scroll', toggle, {passive:true});\n",
        "  btn.addEventListener('click', function(){ window.scrollTo(0,0); }, false);\n",
        "}\n",
        "\n",
        "document.addEventListener('DOMContentLoaded', function(){\n",
        "  bindHeaderSort();\n",
        "  bindBackToTop();\n",
        "  stampLastUpdated();\n",
        "  loadAutoCount();\n",
        "  updateShowingCount();\n",
        "}, false);\n",
        "//]]>\n",
        "</script>\n",
        "</head>\n",
        "<body>\n",
        "  <div class=\"intro\">\n",
        "    <h2>Ancestor Register</h2>\n",
        "    <div class=\"meta\">\n",
        "      Last updated: <span id=\"last-updated\">%(UPDATED)s</span>\n",
        "      &nbsp;|&nbsp; Autosomal matches: <span id=\"auto-count\">%(AUTO)s</span>\n",
        "      &nbsp;|&nbsp; Showing: <span id=\"showing-count\">0</span>\n",
        "    </div>\n",
        "    %(DL)s\n",
        "    <div class=\"toolbar\">\n",
        "      <a class=\"btn\" href=\"%(DNA_ABS)s\" target=\"_blank\" rel=\"noopener\">DNA Register</a>\n",
        "      <input type=\"text\" id=\"searchBox\" class=\"btn light\" placeholder=\"Search this page&hellip;\" oninput=\"filterTable()\" />\n",
        "    </div>\n",
        "  </div>\n",
        "\n",
        "  <div class=\"output-table\" id=\"table-container\">\n",
        "    <!-- TABLE_PLACEHOLDER -->\n",
        "  </div>\n",
        "\n",
        "  <div class=\"back-to-top\" id=\"back-to-top\">&#9650; Top</div>\n",
        "</body>\n",
        "</html>\"\"\" % {\n",
        "    \"BTN_BG\": _BTN_BG, \"BTN_BG_H\": _BTN_BG_H, \"TH_BG\": _TH_BG, \"LINK\": _LINK,\n",
        "    \"UPDATED\": _html.escape(updated_fallback),\n",
        "    \"AUTO\": _html.escape(\"Unknown\" if autosomal_count is None else str(autosomal_count)),\n",
        "    \"DL\": DOWNLOADS_BLOCK,\n",
        "    \"DNA_ABS\": DNA_REGISTER_ABS\n",
        "}\n",
        "\n",
        "# Build table HTML and mark first row\n",
        "table_html = df.to_html(index=False, border=1, classes=\"sortable\", table_id=\"refactor-table\")\n",
        "table_html = table_html.replace(\"<tbody>\\n<tr>\", \"<tbody>\\n<tr id=\\\"first-row\\\">\", 1)\n",
        "\n",
        "# Inject table and JS count URL\n",
        "final_html = full_html_template.replace(\"<!-- TABLE_PLACEHOLDER -->\", table_html)\n",
        "final_html = final_html.replace(\"{COUNT_URL}\", COUNT_PUBLIC_URL)\n",
        "\n",
        "# Build export DataFrame mirroring the visible table order (use current df as-is)\n",
        "export_df = df.copy()\n",
        "\n",
        "# Save CSV (ISO-8859-15) and XLSX\n",
        "export_df.to_csv(LOCAL_CSV, index=False, encoding=\"iso-8859-15\")\n",
        "try:\n",
        "    export_df.to_excel(LOCAL_XLSX, index=False)\n",
        "except Exception:\n",
        "    with pd.ExcelWriter(LOCAL_XLSX) as _writer:\n",
        "        export_df.to_excel(_writer, index=False)\n",
        "print(\"[OK] Wrote exports:\", os.path.abspath(LOCAL_CSV), \"and\", os.path.abspath(LOCAL_XLSX))\n",
        "# ====== CUT STOP  [4/6] XHTML TEMPLATE + TABLE + DOWNLOAD LINKS ================================\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "\n",
        "\n",
        "\n",
        "# ====== CUT START [5/6] SAVE LOCALLY + FTP UPLOAD (HTML + CSV/XLSX -> /partials) ==============\n",
        "# Save locally (iso-8859-15 safe)\n",
        "try:\n",
        "    with open(OUTPUT_NAME, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        f.write(final_html)\n",
        "    print(\"[OK] Saved locally:\", OUTPUT_NAME)\n",
        "except Exception as e:\n",
        "    print(\"[ERROR] Saving local file failed:\", e)\n",
        "    traceback.print_exc()\n",
        "\n",
        "# Upload if credentials exist\n",
        "ftp_host = os.environ.get('FTP_HOST')\n",
        "ftp_user = os.environ.get('FTP_USER')\n",
        "ftp_pass = os.environ.get('FTP_PASS')\n",
        "ftp_port = os.environ.get('FTP_PORT', '21')\n",
        "ftp_dir  = os.environ.get('FTP_DIR', '')\n",
        "\n",
        "def _ftps_ensure_dir(ftps, name):\n",
        "    if not name: return\n",
        "    for p in [p for p in name.split('/') if p]:\n",
        "        try:\n",
        "            ftps.cwd(p)\n",
        "        except Exception:\n",
        "            try:\n",
        "                ftps.mkd(p)\n",
        "            except Exception:\n",
        "                pass\n",
        "            ftps.cwd(p)\n",
        "\n",
        "if all([ftp_host, ftp_user, ftp_pass]):\n",
        "    print(\"[INFO] Attempting FTP upload...\")\n",
        "    try:\n",
        "        socket.setdefaulttimeout(30)\n",
        "        with FTP_TLS(timeout=30) as ftps:\n",
        "            ftps.connect(ftp_host, int(ftp_port))\n",
        "            ftps.login(ftp_user, ftp_pass)\n",
        "            try: ftps.prot_p()\n",
        "            except Exception: pass\n",
        "            try: ftps.set_pasv(True)\n",
        "            except Exception: pass\n",
        "\n",
        "            # Navigate to base dir\n",
        "            _ftps_ensure_dir(ftps, ftp_dir.strip('/'))\n",
        "\n",
        "            # Ensure /partials exists then upload HTML + CSV/XLSX there\n",
        "            try:\n",
        "                _ftps_ensure_dir(ftps, \"partials\")\n",
        "\n",
        "                # Upload HTML into /partials/ as just-trees.htm\n",
        "                with open(OUTPUT_NAME, \"rb\") as fh:\n",
        "                    ftps.storbinary(\"STOR \" + os.path.basename(REMOTE_HTML), fh)\n",
        "                print(\"[OK] Uploaded HTML to /partials/:\", OUTPUT_NAME, \"->\", os.path.basename(REMOTE_HTML))\n",
        "\n",
        "                # Upload CSV/XLSX into /partials/\n",
        "                with open(LOCAL_CSV, \"rb\") as fh:\n",
        "                    ftps.storbinary(\"STOR \" + os.path.basename(REMOTE_CSV), fh)\n",
        "                with open(LOCAL_XLSX, \"rb\") as fh:\n",
        "                    ftps.storbinary(\"STOR \" + os.path.basename(REMOTE_XLSX), fh)\n",
        "                print(\"[OK] Uploaded exports to /partials/:\", LOCAL_CSV, LOCAL_XLSX)\n",
        "\n",
        "                print(\"Open URL: https://yates.one-name.net/partials/just-trees.htm\")\n",
        "            except Exception as e:\n",
        "                print(\"[ERROR] Upload to /partials/ failed:\", e)\n",
        "\n",
        "            print(\"[OK] Uploads complete.\")\n",
        "    except Exception as e:\n",
        "        print(\"[ERROR] FTP session failed:\", e)\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"[INFO] Skipping FTP upload: missing FTP credentials.\")\n",
        "# ====== CUT STOP  [5/6] SAVE LOCALLY + FTP UPLOAD (HTML + CSV/XLSX -> /partials) ==============\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "\n",
        "\n",
        "\n",
        "# ====== CUT START [6/6] PERSIST COUNT + DONE ====================================================\n",
        "if autosomal_count is not None:\n",
        "    try:\n",
        "        with open(\"autosomal_count_prev.txt\", \"w\") as f:\n",
        "            f.write(str(autosomal_count))\n",
        "        print(\"[OK] Persisted autosomal_count_prev.txt\")\n",
        "    except Exception as e:\n",
        "        print(\"[WARN] Could not persist autosomal count:\", e)\n",
        "\n",
        "print(\"\\n--- Ancestor Register Build + Exports Complete (HTML now at /partials/just-trees.htm; nav button -> justdna.htm) ---\")\n",
        "# ====== CUT STOP  [6/6] PERSIST COUNT + DONE ====================================================\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "#####\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwRXWsZlp_4O",
        "outputId": "e99637ff-1c89-402f-afcd-bd7c44fd657c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Loaded CSV: final_combined_df_with_value_labels.csv rows=7, cols=6\n",
            "Using cached resolver: /content/match_to_unmasked.csv\n",
            "[OK] Column B -> C mapping: 7 / 7 unmatched: 0\n",
            "[OK] Wrote exports: /content/yates_ancestor_register.csv and /content/yates_ancestor_register.xlsx\n",
            "[OK] Saved locally: just-trees.htm\n",
            "[INFO] Attempting FTP upload...\n",
            "[OK] Uploaded HTML to /partials/: just-trees.htm -> just-trees.htm\n",
            "[OK] Uploaded exports to /partials/: yates_ancestor_register.csv yates_ancestor_register.xlsx\n",
            "Open URL: https://yates.one-name.net/partials/just-trees.htm\n",
            "[OK] Uploads complete.\n",
            "[OK] Persisted autosomal_count_prev.txt\n",
            "\n",
            "--- Ancestor Register Build + Exports Complete (HTML now at /partials/just-trees.htm; nav button -> justdna.htm) ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhTUln_oOVyo",
        "outputId": "43f9f1ea-9bf6-40f3-9077-a5c599c95e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected. PWD: /\n",
            "\n",
            "--- Directory listing: web root (/) ---\n",
            "drwxr-x---   23 onenamen   65534            4096 Nov  5 19:04 .\n",
            "drwxr-x---   23 onenamen   65534            4096 Nov  5 19:04 ..\n",
            "-rw-------    1 onenamen   onenamen           19 Oct 19 02:45 .ftpquota\n",
            "-rw-r--r--    1 onenamen   onenamen          514 Jul 20 07:46 .htaccess\n",
            "drwxr-xr-x    3 onenamen   onenamen         4096 Jan 23  2023 .well-known\n",
            "-rw-r--r--    1 onenamen   onenamen       770679 May 25 01:55 DNA_Cousin_Surname_App.htm\n",
            "drwxr-xr-x    5 onenamen   onenamen         4096 Nov  5 18:43 admin\n",
            "-rw-r--r--    1 onenamen   onenamen            4 Nov  5 18:59 autosomal_count.txt\n",
            "drwxr-xr-x    5 onenamen   onenamen         4096 Nov  5 05:44 blog\n",
            "drwxr-xr-x    2 onenamen   onenamen         4096 Jan 23  2023 cgi-bin\n",
            "drwxr-xr-x    4 onenamen   onenamen         4096 Mar 16  2023 content-yatesdb\n",
            "-rw-r--r--    1 onenamen   onenamen         8620 Apr 25  2023 contribute.htm\n",
            "drwxr-xr-x   12 onenamen   onenamen         4096 Mar 30  2023 country\n",
            "-rw-r--r--    1 onenamen   onenamen       107002 Oct 14 14:00 cousin_list.xlsx\n",
            "-rw-r--r--    1 onenamen   onenamen         8061 Oct 29 13:52 dna_cousin_surname_app.htm\n",
            "drwxr-xr-x    2 onenamen   onenamen         4096 Mar 13  2023 documents\n",
            "drwxr-xr-x    2 onenamen   onenamen         4096 Jan 25  2023 events\n",
            "drwxr-xr-x   15 onenamen   onenamen         4096 Oct 27 15:25 gengen\n",
            "drwxr-xr-x    4 onenamen   onenamen         4096 Apr  1  2023 history\n",
            "drwxr-xr-x   10 onenamen   onenamen         4096 Dec 29  2023 imagealbums\n",
            "drwxr-xr-x    4 onenamen   onenamen         4096 Dec  5  2023 images\n",
            "-rw-r--r--    1 onenamen   onenamen        10626 Mar 31  2023 index-page2.htm\n",
            "-rw-r--r--    1 onenamen   onenamen        20244 Sep 14 16:00 index.htm\n",
            "-rw-r--r--    1 onenamen   onenamen          114 Oct 28 14:23 lineage_count_report.csv\n",
            "drwxr-xr-x    3 onenamen   onenamen         4096 Apr 19  2023 litart\n",
            "-rw-r--r--    1 onenamen   onenamen         1900 Oct 15 14:09 match_to_unmasked.csv\n",
            "drwxr-xr-x   11 onenamen   onenamen         4096 Feb 27  2023 military\n",
            "drwxr-xr-x    2 onenamen   onenamen         4096 Nov  5 19:04 partials\n",
            "drwxr-xr-x   29 onenamen   onenamen         4096 Oct  1 13:58 people\n",
            "drwxr-xr-x   15 onenamen   onenamen         4096 May 16  2023 places\n",
            "drwxr-xr-x    3 onenamen   onenamen         4096 Sep 19 22:29 public_html\n",
            "-rw-r--r--    1 onenamen   onenamen         1991 Oct 28 14:23 resolver_usage_report.csv\n",
            "-rw-r--r--    1 onenamen   onenamen         2154 Oct 27 22:42 shared_utils.py\n",
            "drwxr-xr-x    3 onenamen   onenamen         4096 Jan 25  2023 sitemap\n",
            "-rw-r--r--    1 onenamen   onenamen        16877 Jan 25  2023 sorttable.js\n",
            "-rw-r--r--    1 onenamen   onenamen         5354 Nov  6  2023 styles_connect.css\n",
            "-rw-r--r--    1 onenamen   onenamen        29645 Nov  5 18:59 the_match_cousins.csv\n",
            "drwxr-xr-x   23 onenamen   onenamen        28672 Aug 15 02:27 tng\n",
            "drwxr-xr-x    2 onenamen   onenamen         4096 Jan  1  2025 tng-tree-gedcoms\n",
            "-rw-r--r--    1 onenamen   onenamen        12074 May 17 17:57 y_dna_comparison_table.htm\n",
            "-rw-r--r--    1 onenamen   onenamen        18750 May 25 02:34 y_dna_grid.htm\n",
            "\n",
            "--- Index candidates present? ---\n",
            "index.htm  SIZE=20244\n",
            "\n",
            "--- .htaccess (if present) ---\n",
            "# Enforce HTTPS\n",
            "<IfModule mod_rewrite.c>\n",
            "\tRewriteEngine on\n",
            "\tRewriteCond %{HTTPS} off\n",
            "\tRewriteRule ^(.*)$ https://%{HTTP_HOST}%{REQUEST_URI} [R=301,L]\n",
            "</IfModule>\n",
            "<Files 403.shtml>\n",
            "order allow,deny\n",
            "allow from all\n",
            "</Files>\n",
            "\n",
            "deny from 188.239.0.0/20\n",
            "deny from 124.243.128.0/18\n",
            "deny from 166.108.224.0/20\n",
            "deny from 46.250.160.0/20\n",
            "deny from 101.44.16.0/20\n",
            "deny from 101.46.0.0/20\n",
            "deny from 110.238.104.0/21\n",
            "deny from 111.119.224.0/20\n",
            "deny from 113.190.224.0/20\n",
            "\n",
            "deny from 119.13.76.0/22\n",
            "deny from 119.12.160.0/20\n",
            "\n",
            "\n",
            "--- Directory listing: /partials ---\n",
            "drwxr-xr-x    2 onenamen   onenamen         4096 Nov  5 19:04 .\n",
            "drwxr-x---   23 onenamen   65534            4096 Nov  5 19:04 ..\n",
            "-rw-r--r--    1 onenamen   onenamen        40915 Nov  5 18:44 cell1_work_table.htm\n",
            "-rw-r--r--    1 onenamen   onenamen        31285 Nov  5 18:59 cousin_list_print.htm\n",
            "-rw-r--r--    1 onenamen   onenamen        28786 Nov  5 18:44 final_combined_df_with_value_labels.csv\n",
            "-rw-r--r--    1 onenamen   onenamen        10245 Nov  5 18:59 lineage_count.htm\n",
            "-rw-r--r--    1 onenamen   onenamen        10581 Nov  5 18:59 match_count.htm\n",
            "-rw-r--r--    1 onenamen   onenamen         1900 Nov  2 20:34 match_to_unmasked.csv\n",
            "-rw-r--r--    1 onenamen   onenamen          541 Nov  5 18:59 ons_yates_dna_register.htm\n",
            "-rw-r--r--    1 onenamen   onenamen        87844 Nov  5 18:59 work_plus.htm\n",
            "-rw-r--r--    1 onenamen   onenamen        28527 Nov  5 18:59 yates_ancestor_register.csv\n",
            "-rw-r--r--    1 onenamen   onenamen        53998 Nov  5 18:59 yates_ancestor_register.htm\n",
            "-rw-r--r--    1 onenamen   onenamen        16965 Nov  5 18:59 yates_ancestor_register.xlsx\n",
            "\n",
            "--- SIZE check ---\n",
            "partials/yates_ancestor_register.htm: 53998\n",
            "partials/ons_yates_dna_register.htm: 541\n",
            "ons_yates_dna_register.htm: (SIZE unsupported or not found)\n",
            "\n",
            "Notes:\n",
            "• The server decides '/' by DirectoryIndex order OR a rewrite in .htaccess.\n",
            "• If multiple index.* exist, the first in the server’s order wins.\n",
            "• Safe, reversible fix: ensure ONLY the desired index.* exists, or upload an index.html meta-redirect to your canonical target.\n",
            "• Canonical target currently set to: /partials/yates_ancestor_register.htm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] CANONICAL RESET — Root wrapper -> partials (XHTML, FTPS upload) =========\n",
        "# RON RULES — QUICK CODE CARD (v2025.11.05-Canonical-Reset)\n",
        "# - Complete & runnable in Colab; ISO-8859-15 (ASCII-only in source).\n",
        "# - No fabrication; no JSON/triple-quote artifacts beyond this single cell.\n",
        "\n",
        "import os, socket, posixpath, traceback\n",
        "from ftplib import FTP_TLS\n",
        "\n",
        "# ---------- 0) Secrets ----------\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ['FTP_HOST'] = userdata.get('FTP_HOST')\n",
        "    os.environ['FTP_USER'] = userdata.get('FTP_USER')\n",
        "    os.environ['FTP_PASS'] = userdata.get('FTP_PASS')\n",
        "    try: os.environ['FTP_DIR'] = userdata.get('FTP_DIR')\n",
        "    except Exception: os.environ.setdefault('FTP_DIR', '')\n",
        "    try: os.environ['FTP_PORT'] = userdata.get('FTP_PORT') or '21'\n",
        "    except Exception: os.environ.setdefault('FTP_PORT', '21')\n",
        "except Exception:\n",
        "    os.environ.setdefault('FTP_HOST', '')\n",
        "    os.environ.setdefault('FTP_USER', '')\n",
        "    os.environ.setdefault('FTP_PASS', '')\n",
        "    os.environ.setdefault('FTP_DIR', '')\n",
        "    os.environ.setdefault('FTP_PORT', '21')\n",
        "\n",
        "# ---------- 1) Config (edit if needed) ----------\n",
        "# The true content lives here (ABSOLUTE URL in partials/)\n",
        "PARTIALS_TARGET_ABS = \"https://yates.one-name.net/partials/yates_ancestor_register.htm\"\n",
        "\n",
        "# Restore the old canonical \"home\" filename in the web root:\n",
        "CANONICAL_HOME_NAME = \"ons_yates_dna_register.htm\"   # this will be created at site root\n",
        "\n",
        "# Optionally refresh /index.html to point at the canonical home (set True to write/overwrite)\n",
        "WRITE_INDEX_HTML = True\n",
        "\n",
        "# If writing index.html, should it point to \"canonical\" or \"partials\"?\n",
        "INDEX_TARGET_MODE = \"canonical\"  # options: \"canonical\" or \"partials\"\n",
        "\n",
        "FTP_DIR      = (os.environ.get(\"FTP_DIR\") or \"\").strip()\n",
        "FTP_TIMEOUT  = int(os.environ.get(\"FTP_TIMEOUT\") or \"30\")\n",
        "FTP_PASSIVE  = True\n",
        "\n",
        "def _remote_path(basename: str) -> str:\n",
        "    return posixpath.join(FTP_DIR, basename) if FTP_DIR else basename\n",
        "\n",
        "def ftp_connect() -> FTP_TLS:\n",
        "    ftps = FTP_TLS(timeout=FTP_TIMEOUT)\n",
        "    socket.setdefaulttimeout(FTP_TIMEOUT)\n",
        "    ftps.connect(os.environ.get('FTP_HOST',''), int(os.environ.get('FTP_PORT','21')))\n",
        "    ftps.login(os.environ.get('FTP_USER',''), os.environ.get('FTP_PASS',''))\n",
        "    try: ftps.prot_p()\n",
        "    except Exception: pass\n",
        "    try: ftps.set_pasv(FTP_PASSIVE)\n",
        "    except Exception: pass\n",
        "    if FTP_DIR:\n",
        "        try:\n",
        "            ftps.cwd(FTP_DIR)\n",
        "        except Exception:\n",
        "            # Create path parts if missing\n",
        "            parts = [p for p in FTP_DIR.split(\"/\") if p]\n",
        "            for p in parts:\n",
        "                try: ftps.mkd(p)\n",
        "                except Exception: pass\n",
        "                ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "def ftp_upload_overwrite(ftps: FTP_TLS, local_path: str, remote_name: str):\n",
        "    with open(local_path, \"rb\") as fh:\n",
        "        ftps.storbinary(f\"STOR {remote_name}\", fh)\n",
        "    print(\"Uploaded:\", local_path, \"->\", remote_name)\n",
        "\n",
        "# ---------- 2) Build XHTML redirect wrappers ----------\n",
        "def _xhtml_redirect_page(title: str, target_abs_url: str, also_canonical: bool = True) -> str:\n",
        "    # Old-school, XHTML 1.0 Transitional; includes <meta refresh>, JS replace, and clickable fallback link\n",
        "    link_canon = f'\\n<link rel=\"canonical\" href=\"{target_abs_url}\" />' if also_canonical else ''\n",
        "    return (\n",
        "        '<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" '\n",
        "        '\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\\n'\n",
        "        '<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\\n<head>\\n'\n",
        "        '<meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-15\" />\\n'\n",
        "        f'<title>{title}</title>\\n'\n",
        "        f'<meta http-equiv=\"refresh\" content=\"0; url={target_abs_url}\" />{link_canon}\\n'\n",
        "        '<style type=\"text/css\">body{font-family:\\'Times New Roman\\',Georgia,serif;margin:40px;}</style>\\n'\n",
        "        '</head>\\n<body>\\n'\n",
        "        f'<p>If you are not redirected, <a href=\"{target_abs_url}\">click here</a>.</p>\\n'\n",
        "        f'<script type=\"text/javascript\">\\n//<![CDATA[\\n'\n",
        "        f'try{{ window.location.replace(\"{target_abs_url}\"); }}catch(e){{ window.location.href=\"{target_abs_url}\"; }}\\n'\n",
        "        f'//]]>\\n</script>\\n'\n",
        "        '</body>\\n</html>\\n'\n",
        "    )\n",
        "\n",
        "# File 1: canonical home wrapper -> partials\n",
        "canonical_local = CANONICAL_HOME_NAME\n",
        "with open(canonical_local, \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "    f.write(_xhtml_redirect_page(\"ONS Yates DNA Register (Canonical Home)\", PARTIALS_TARGET_ABS, True))\n",
        "print(\"[OK] Wrote:\", os.path.abspath(canonical_local))\n",
        "canonical_remote = _remote_path(CANONICAL_HOME_NAME)\n",
        "\n",
        "# File 2 (optional): index.html -> canonical or partials\n",
        "index_local = None\n",
        "index_remote = None\n",
        "if WRITE_INDEX_HTML:\n",
        "    index_target = PARTIALS_TARGET_ABS if INDEX_TARGET_MODE == \"partials\" else (\"./\" + CANONICAL_HOME_NAME)\n",
        "    # If we point to \"./ons_yates_dna_register.htm\", browsers stay in root then hop to partials via the canonical page.\n",
        "    with open(\"index.html\", \"w\", encoding=\"iso-8859-15\", errors=\"xmlcharrefreplace\") as f:\n",
        "        # canonical link here is not added to avoid confusion; the canonical tag exists in the canonical page above\n",
        "        f.write(_xhtml_redirect_page(\"Home → ONS Yates DNA Register\", index_target, False))\n",
        "    index_local = \"index.html\"\n",
        "    index_remote = _remote_path(\"index.html\")\n",
        "    print(\"[OK] Wrote:\", os.path.abspath(index_local), \"target:\", index_target)\n",
        "\n",
        "# ---------- 3) Upload ----------\n",
        "if not all(os.environ.get(k) for k in ['FTP_HOST','FTP_USER','FTP_PASS']):\n",
        "    print(\"Missing FTP creds; skipping uploads.\")\n",
        "else:\n",
        "    try:\n",
        "        ftps = ftp_connect()\n",
        "        ftp_upload_overwrite(ftps, canonical_local, canonical_remote)\n",
        "        if index_local and index_remote:\n",
        "            ftp_upload_overwrite(ftps, index_local, index_remote)\n",
        "        try: ftps.quit()\n",
        "        except Exception: pass\n",
        "        print(\"\\n=== SUMMARY ===\")\n",
        "        print(\"Canonical target set to:\", \"/\" + CANONICAL_HOME_NAME)\n",
        "        print(\"Canonical page redirects to:\", PARTIALS_TARGET_ABS)\n",
        "        if index_remote:\n",
        "            print(\"Home (/index.html) now points to:\", (\"canonical\" if INDEX_TARGET_MODE==\"canonical\" else \"partials\"))\n",
        "        else:\n",
        "            print(\"Home (/index.html) unchanged (WRITE_INDEX_HTML=False).\")\n",
        "    except Exception as e:\n",
        "        print(\"FTP session failed:\", e)\n",
        "        traceback.print_exc()\n",
        "\n",
        "# ====== CUT STOP [1/1] CANONICAL RESET ==========================================================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QWsgvjZPhGX",
        "outputId": "7e2a49e8-faa3-4f09-cfbc-5577636cd434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Wrote: /content/ons_yates_dna_register.htm\n",
            "[OK] Wrote: /content/index.html target: ./ons_yates_dna_register.htm\n",
            "Uploaded: ons_yates_dna_register.htm -> ons_yates_dna_register.htm\n",
            "Uploaded: index.html -> index.html\n",
            "\n",
            "=== SUMMARY ===\n",
            "Canonical target set to: /ons_yates_dna_register.htm\n",
            "Canonical page redirects to: https://yates.one-name.net/partials/yates_ancestor_register.htm\n",
            "Home (/index.html) now points to: canonical\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# debug"
      ],
      "metadata": {
        "id": "9G7Y0HwjtZIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== CUT START [1/1] UPDATE /partials/dna_tree_styles.css — FIXED PX WIDTHS (1–4) ============\n",
        "# RON RULES — QUICK CODE CARD (v2025.11.08-ColumnWidths-PX)\n",
        "# - Complete & runnable Colab cell; ISO-8859-15 (ASCII-only source).\n",
        "# - Adds explicit pixel widths for columns:\n",
        "#     1 → 75px   (\"Select\")\n",
        "#     2 → 250px  (main name / match)\n",
        "#     3 → 40px\n",
        "#     4 → 50px\n",
        "# - Leaves centering, padding, and other layout rules unchanged.\n",
        "\n",
        "import os, re, socket, time, traceback\n",
        "from ftplib import FTP_TLS\n",
        "\n",
        "# ---------- Secrets ----------\n",
        "try:\n",
        "    from google.colab import userdata  # type: ignore\n",
        "    os.environ['FTP_HOST'] = userdata.get('FTP_HOST')\n",
        "    os.environ['FTP_USER'] = userdata.get('FTP_USER')\n",
        "    os.environ['FTP_PASS'] = userdata.get('FTP_PASS')\n",
        "    try:  os.environ['FTP_PORT'] = userdata.get('FTP_PORT')\n",
        "    except Exception: os.environ.setdefault('FTP_PORT', '21')\n",
        "    try:  os.environ['FTP_DIR']  = userdata.get('FTP_DIR')\n",
        "    except Exception: os.environ.setdefault('FTP_DIR', '')\n",
        "except Exception:\n",
        "    os.environ.setdefault('FTP_HOST', '')\n",
        "    os.environ.setdefault('FTP_USER', '')\n",
        "    os.environ.setdefault('FTP_PASS', '')\n",
        "    os.environ.setdefault('FTP_PORT', '21')\n",
        "    os.environ.setdefault('FTP_DIR', '')\n",
        "\n",
        "FTP_HOST = os.environ.get('FTP_HOST','')\n",
        "FTP_USER = os.environ.get('FTP_USER','')\n",
        "FTP_PASS = os.environ.get('FTP_PASS','')\n",
        "FTP_PORT = int(os.environ.get('FTP_PORT','21'))\n",
        "FTP_DIR  = (os.environ.get('FTP_DIR','') or '').strip('/')\n",
        "\n",
        "TARGET_DIR  = 'partials'\n",
        "TARGET_NAME = 'dna_tree_styles.css'\n",
        "LOCAL_ORIG  = 'dna_tree_styles.orig.css'\n",
        "LOCAL_NEW   = 'dna_tree_styles.css'\n",
        "\n",
        "if not all([FTP_HOST, FTP_USER, FTP_PASS]):\n",
        "    raise SystemExit(\"[EXIT] Missing FTP creds in Colab userdata: FTP_HOST/FTP_USER/FTP_PASS\")\n",
        "\n",
        "# ---------- FTP helpers ----------\n",
        "def _connect():\n",
        "    socket.setdefaulttimeout(30)\n",
        "    ftps = FTP_TLS(timeout=30)\n",
        "    ftps.connect(FTP_HOST, FTP_PORT)\n",
        "    ftps.login(FTP_USER, FTP_PASS)\n",
        "    try: ftps.prot_p()\n",
        "    except Exception: pass\n",
        "    ftps.set_pasv(True)\n",
        "    if FTP_DIR:\n",
        "        for p in [p for p in FTP_DIR.split('/') if p]:\n",
        "            try: ftps.cwd(p)\n",
        "            except Exception:\n",
        "                try: ftps.mkd(p)\n",
        "                except Exception: pass\n",
        "                ftps.cwd(p)\n",
        "    return ftps\n",
        "\n",
        "def _cwd(ftps, path):\n",
        "    for p in [q for q in path.split('/') if q]:\n",
        "        try: ftps.cwd(p)\n",
        "        except Exception:\n",
        "            try: ftps.mkd(p)\n",
        "            except Exception: pass\n",
        "            ftps.cwd(p)\n",
        "\n",
        "def _download(ftps, remote_name, local_name):\n",
        "    with open(local_name, 'wb') as f:\n",
        "        ftps.retrbinary('RETR ' + remote_name, f.write)\n",
        "    print(\"[OK] Downloaded:\", remote_name)\n",
        "\n",
        "def _upload(ftps, local_name, remote_name):\n",
        "    with open(local_name, 'rb') as f:\n",
        "        ftps.storbinary('STOR ' + remote_name, f)\n",
        "    print(\"[OK] Uploaded:\", local_name, \"->\", remote_name)\n",
        "\n",
        "def _server_backup(ftps, remote_name):\n",
        "    ts = time.strftime(\"%Y%m%d%H%M\")\n",
        "    bak = remote_name + \".\" + ts + \".bak\"\n",
        "    try:\n",
        "        with open(\"__tmp_bak.css\", \"wb\") as tmp:\n",
        "            ftps.retrbinary('RETR ' + remote_name, tmp.write)\n",
        "        with open(\"__tmp_bak.css\", \"rb\") as tmp:\n",
        "            ftps.storbinary('STOR ' + bak, tmp)\n",
        "        os.remove(\"__tmp_bak.css\")\n",
        "        print(\"[OK] Server backup created:\", bak)\n",
        "    except Exception as e:\n",
        "        print(\"[WARN] Backup skipped:\", e)\n",
        "\n",
        "# ---------- CSS injection ----------\n",
        "def _inject_fixed_widths(css_text):\n",
        "    rule = (\n",
        "        \"\\n/* === Explicit fixed column widths (v2025.11.08) === */\\n\"\n",
        "        \"table { table-layout: fixed; width: 100%; }\\n\"\n",
        "        \"table th:first-child, table td:first-child { width: 75px !important; max-width: 75px !important; }\\n\"\n",
        "        \"table th:nth-child(2), table td:nth-child(2) { width: 250px !important; max-width: 250px !important; }\\n\"\n",
        "        \"table th:nth-child(3), table td:nth-child(3) { width: 400px !important;  max-width: 40px !important; }\\n\"\n",
        "        \"table th:nth-child(4), table td:nth-child(4) { width: 50px !important;  max-width: 50px !important; }\\n\"\n",
        "    )\n",
        "    if \"Explicit fixed column widths\" not in css_text:\n",
        "        css_text += \"\\n\" + rule\n",
        "    else:\n",
        "        css_text = re.sub(r'/\\* === Explicit fixed column widths[^*]+\\*/.*?(?=/\\*|$)', rule, css_text, flags=re.S)\n",
        "    return css_text\n",
        "\n",
        "# ---------- Main ----------\n",
        "try:\n",
        "    ftps = _connect()\n",
        "    _cwd(ftps, TARGET_DIR)\n",
        "\n",
        "    _download(ftps, TARGET_NAME, LOCAL_ORIG)\n",
        "    with open(LOCAL_ORIG, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "        css = f.read()\n",
        "\n",
        "    new_css = _inject_fixed_widths(css)\n",
        "    with open(LOCAL_NEW, 'w', encoding='iso-8859-15', errors='xmlcharrefreplace') as f:\n",
        "        f.write(new_css)\n",
        "\n",
        "    _server_backup(ftps, TARGET_NAME)\n",
        "    _upload(ftps, LOCAL_NEW, TARGET_NAME)\n",
        "    ftps.quit()\n",
        "\n",
        "    print(\"\\nDONE. Columns 1–4 now have fixed widths: 75, 250, 40, 50 px.  Refresh with Ctrl+F5 or ?v=1.\")\n",
        "except Exception as e:\n",
        "    print(\"[ERROR]\", e)\n",
        "    traceback.print_exc()\n",
        "# ====== CUT STOP  [1/1] UPDATE /partials/dna_tree_styles.css — FIXED PX WIDTHS (1–4) ============\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGe3N1K6jHad",
        "outputId": "64d210f0-14b9-4d39-dcc0-9ba5ba66ac49"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Downloaded: dna_tree_styles.css\n",
            "[OK] Server backup created: dna_tree_styles.css.202511081739.bak\n",
            "[OK] Uploaded: dna_tree_styles.css -> dna_tree_styles.css\n",
            "\n",
            "DONE. Columns 1–4 now have fixed widths: 75, 250, 40, 50 px.  Refresh with Ctrl+F5 or ?v=1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dC_vUzrXiVu",
        "outputId": "a79647ad-34a1-4b89-fe2c-9aa5e57ec7b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Loaded CSV: 7 rows, 6 cols\n",
            "[PULL] match_to_unmasked.csv -> /content/match_to_unmasked.server.csv\n",
            "[OK] Resolver loaded: 79 codes\n",
            "[OK] Wrote exports: /content/yates_ancestor_register.csv and /content/yates_ancestor_register.xlsx\n",
            "[OK] Wrote partial: partials/match_count.htm\n",
            "[OK] Wrote partial: partials/lineage_count.htm\n",
            "[OK] Wrote partial: partials/cousin_list_print.htm\n",
            "[OK] Saved canonical render: /content/yates_ancestor_register.htm\n",
            "[OK] Saved: /content/partials/work_plus.htm (partials clone)\n",
            "[PUT]  yates_ancestor_register.htm -> partials/yates_ancestor_register.htm\n",
            "[PUT]  yates_ancestor_register.htm -> partials/ons_yates_dna_register.htm\n",
            "[PUT]  yates_ancestor_register.htm -> partials/justdna.htm\n",
            "[PUT]  yates_ancestor_register.csv -> partials/yates_ancestor_register.csv\n",
            "[PUT]  yates_ancestor_register.xlsx -> partials/yates_ancestor_register.xlsx\n",
            "[OK] Uploaded CSV/XLSX -> /partials/\n",
            "[PUT]  /content/autosomal_count.txt -> autosomal_count.txt\n",
            "[PUT]  partials/match_count.htm -> partials/match_count.htm\n",
            "[PUT]  partials/lineage_count.htm -> partials/lineage_count.htm\n",
            "[PUT]  partials/cousin_list_print.htm -> partials/cousin_list_print.htm\n",
            "[PUT]  partials/work_plus.htm -> partials/work_plus.htm\n",
            "\n",
            "--- SIZE Verification (if supported) ---\n",
            "partials/yates_ancestor_register.htm : 20961\n",
            "partials/ons_yates_dna_register.htm : 20961\n",
            "partials/justdna.htm : 20961\n",
            "partials/yates_ancestor_register.csv : 2957\n",
            "partials/yates_ancestor_register.xlsx : 6704\n",
            "partials/match_count.htm : 6247\n",
            "partials/lineage_count.htm : 6417\n",
            "partials/cousin_list_print.htm : 3154\n",
            "partials/work_plus.htm : 20961\n",
            "\n",
            "--- Open URLs ---\n",
            "Canonical (Find target):          https://yates.one-name.net/partials/yates_ancestor_register.htm\n",
            "Legacy clone (same content):      https://yates.one-name.net/partials/ons_yates_dna_register.htm\n",
            "JUSTDNA simple alias:             https://yates.one-name.net/partials/justdna.htm\n",
            "Trees page:                       https://yates.one-name.net/partials/just-trees.htm\n",
            "Match Count:                      https://yates.one-name.net/partials/match_count.htm\n",
            "Lineage Count:                    https://yates.one-name.net/partials/lineage_count.htm\n",
            "Cousin List (Printable):          https://yates.one-name.net/partials/cousin_list_print.htm\n",
            "Work+ clone:                      https://yates.one-name.net/partials/work_plus.htm\n",
            "\n",
            "If anything looks cached, hard-refresh (Ctrl/Cmd+Shift+R) or append ?v=1 once.\n"
          ]
        }
      ]
    }
  ]
}